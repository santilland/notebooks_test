{"version":"1","records":[{"hierarchy":{"lvl1":"Location for eodashboard notebooks"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Location for eodashboard notebooks"},"content":"","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Jupyter notebooks"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/readme","position":0},{"hierarchy":{"lvl1":"Jupyter notebooks"},"content":"Curated list of Jupyter notebooks demonstrating the capabilities of the Euro Data Cube offering. These notebooks can be directly executed by all Euro Data Cube customers within their own Jupyter Lab environment without further setup.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/readme","position":1},{"hierarchy":{"lvl1":"Euro Data Cube Notebooks"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/readme","position":0},{"hierarchy":{"lvl1":"Euro Data Cube Notebooks"},"content":"from eoxhub import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/readme","position":1},{"hierarchy":{"lvl1":"Euro Data Cube Notebooks"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/readme#euro-data-cube-notebooks","position":2},{"hierarchy":{"lvl1":"Euro Data Cube Notebooks"},"content":"https://​www​.eurodatacube​.com","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/readme#euro-data-cube-notebooks","position":3},{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice","position":0},{"hierarchy":{"lvl1":"Introduction"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[\"SH\"])\n\n!python3 -m pip install git+https://github.com/aireo-project/aireo_lib\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice","position":1},{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#introduction","position":2},{"hierarchy":{"lvl1":"Introduction"},"content":"The notebook demonstrates the use of aireo_lib, a python library created as a part of the \n\nAIREO (Artificial Intelligence Ready Earth Observation training datasets) project. The project aims to make EO datasets easily accessible for the ML (Machine Learning) community. As such, AIREO specifications (shorthand specs) which define metadata elements to be included with the training dataset are proposed, supplemented by a best-practices document which suggests how to fill those metadata elements. Finally, the library takes all into account and implements specs, best-practices and offers an easy-to-use pythonic interface bridging the gap between EO and ML community.\n\nTherefore, this notebook is divided into two sections, one for the training dataset creator (usually from the EO community) and the other for its user (usually from the ML community). The structure of the notebook is the following:\n\nFor Creator\n\nCreate a \n\nSTAC catalog object using the library\n\nPopulate metadata elements prescribed by the AIREO specs\n\nGenerate a STAC metadata directory using the library\n\nCheck AIREO compliance level and metadata completeness\n\nFor User\n\nCreate a training dataset object as defined in the library using only the STAC metadata\n\nGet example instances from the object and other dataset variables like the number of instances, etc.\n\nUse library’s functions to plot the data\n\nInvestigate statistics using the library\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#introduction","position":3},{"hierarchy":{"lvl1":"Introduction","lvl3":"About the training dataset"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#about-the-training-dataset","position":4},{"hierarchy":{"lvl1":"Introduction","lvl3":"About the training dataset"},"content":"The AI4Artic ASIP Sea Ice Dataset contains 461 files in network Common Data Form (netCDF), coming from Sentinel 1 SAR and AMSR2 microwave radiometer imagery with corresponding ice charts from Danish Meteorological Institute of the Arctic area.\n\nData is in netCDF format with over 300 GB of it accompanied by a well written manual. Sentinel 1 data is 90m resolution with 40 x 40m pixel spacing and AMSR2 data is resmpled to its pixels. Each satellite image comes with a timestamp and the data is acquired between 2018-2019. It also contains excel sheet where it can be found all images IDs along with the percentage of water and ice present per image. Finally it contains as well a shapefile with all S1 scenes bounding boxes.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#about-the-training-dataset","position":5},{"hierarchy":{"lvl1":"TDS Description"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#tds-description","position":6},{"hierarchy":{"lvl1":"TDS Description"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#tds-description","position":7},{"hierarchy":{"lvl1":"AIREO STAC Catalog basics"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#aireo-stac-catalog-basics","position":8},{"hierarchy":{"lvl1":"AIREO STAC Catalog basics"},"content":"\n\nThe AIREO specs propose a hierarchical structure for STAC metadata. It is a two level structure where the dataset is represented by a collection of AOIs (Area Of Interests), hence, the dataset and AOI being the two levels.\n\nAt the dataset level we have a dataset catalog whose metadata elements are the core elements proposed in the AIREO spec. In addition to it, the common metadata elements across each AOI are also at the dataset level, which we shall call root level henceforth. Here, for each data variable there is a separate json which is a STAC Item by definition and is named using the field_schema metadata element. Additionally, there is also a datasheet file in markdown format at the root level which contains human readable information about the key elements of the dataset.\n\nEach AOI has a separate folder within the root level. And in each AOI folder there is a STAC collection representing that AOI and additional json files for each data variable. The additional json files here too, are STAC Items and follow a similar naming convention to the ones at the root level. The assets for each AOI, i.e. the files containing actual data are also in the folder.\n\nThe diagram below summarises this hierarchical structure:Root level (dataset)\n│\n│   DatasetCatalog.json\n│   datasheet.md\n│   references_output1.json\n│   features_input1.json\n│   ...\n│\n│\n└───AOI 1\n│      1.json (AOI Collection)\n│      feature_input1.json\n│      reference_output1.json\n│      <reference_asset>\n│      <feature_asseet>\n│   \n│   \n└───AOI 2\n│      ...\n│   \n│\n└───AOI 3\n│      ...\n│   \n...     \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#aireo-stac-catalog-basics","position":9},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#creating-a-stac-catalog-with-aireo-lib","position":10},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib"},"content":"The aireo_lib library makes it easier to generate the STAC metadata directory as defined above. Some of the useful functionalities in the library are:\n\nDefine python dictionaries for metadata at the root level and use a simple function to add it to the STAC catalog. The library validates the data automatically when it is added.\n\nSimilarly, python dictionaries can be defined for each AOI and are also validated automatically.\n\nLinks and assets for all the json files are automatically generated.\n\nDatasheet is also generated automatically.\n\nThe directory structure is created by the library and assets copied to their respective locations in the hierarchy.\n\nEvaluating metadata completeness and compliance level.\n\nFollow the code and comments below to understand the steps needed to generate STAC metadata with the library.\n\nimport aireo_lib.core\nimport os\nimport json\nimport numpy as np\nfrom osgeo import gdal\nfrom shapely import geometry\nimport rioxarray\nimport xarray as xr\nfrom pathlib import Path\nimport pandas as pd\nimport geopandas as gp\nimport glob\n\nfrom importlib import reload\nreload(aireo_lib.core)\n\n\n\n# Path to write the STAC root metadata file too\ncatalog_fn_w_path = os.environ['EDC_PATH']  +'/data/Sea-Ice/sea-ice_stac_generated/EO_TDS.json'\n\n# Creating an empty STAC Catalog object\nnew_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog()\n\n#Gather some metadata files to be used to create the STAC catalog\n\nurl = os.environ['EDC_PATH'] + \"/data/Sea-Ice/dataset/S1_frames.shp\"\nfgdf = gp.read_file(url)\n\nreference_path = os.environ['EDC_PATH'] + '/data/Sea-Ice/dataset/Data_ice_water.xlsx'\ndf = pd.read_excel(reference_path)\n\n# Get AOI list for the TDS\n\naoi_path = os.environ['EDC_PATH'] + '/data/Sea-Ice/dataset/sea-ice_nc/'\naoi_ids = glob.glob(aoi_path + '/*')\naoi_ids = [x.split('/')[-1].split('.')[0] for x in aoi_ids]\naoi_ids\n\n# Creating root metadata dictionary\n\ntds_root_core_metadata_d = {}\ntds_root_core_metadata_d['aireo_version'] = \"0.0.1-alpha.1\"\ntds_root_core_metadata_d['title'] = \"AI4Artic ASIP Sea Ice Dataset\"\ntds_root_core_metadata_d['description'] = \"AI4Artic ASIP Sea Ice Dataset contains 461 files in network Common Data Form (netCDF), coming from Sentinel 1 SAR and AMSR2 microwave radiometer imagery with corresponding ice charts from Danish Meteorological Institute of the Arctic area.\"\ntds_root_core_metadata_d['created'] = \"Null\"\ntds_root_core_metadata_d['license_url_list'] = 'https://creativecommons.org/licenses/by/4.0/deed.de' \ntds_root_core_metadata_d['license'] = \"CC-BY-4.0\"\ntds_root_core_metadata_d[\"providers_name\"]= \"[Danish Meteorological Institute (DMI), the Technical University of Denmark (DTU) and Nansen Environmen-tal Remote Sensing Center (NERSC), AIREO]\"\ntds_root_core_metadata_d[\"providers_description\"] = \"Danish Meteorological Institute (DMI), the Technical University of Denmark (DTU) and Nansen Environmen-tal Remote Sensing Center (NERSC)\"\ntds_root_core_metadata_d[\"providers_roles\"] = {'AIREO':[\"producer\", \"processor\" , \"host\"],'DMI, DTU, NERSC':[\"producer\", \"processor\" ]}\ntds_root_core_metadata_d[\"providers_url\"]= {'DMI':'https://www.dmi.dk/', 'DTU':'https://www.dtu.dk', 'NERSC':'https://www.nersc.no/', 'AIREO': 'https://aireo.net/'}                         \ntds_root_core_metadata_d['id'] =  \"270460aa-7835-11eb-9439-0242ac130002\"\ntds_root_core_metadata_d['type'] = \"Collection\"\ntds_root_core_metadata_d['stac_version'] = '1.0.0-beta.2'\ntds_root_core_metadata_d['provenance'] = 'The AI4Arctic sea ice dataset –version 2, ASID-v2, includes 461 files in netCDF format; two channel dual polarized(HH and HV) Sentinel-1 Extra WideSwath (EW) images, withboth ESA and NERSC noise correction;auxiliary Sentinel-1 image parameters,microwave radiometer measurements from the AMSR2 sensor on board the JAXA GCOM-W satellite, the corresponding DMI ice chart based on that Sentinel-1 image,'\ntds_root_core_metadata_d['purpose'] = \"Data is in netCDF format with over 300 GB of it accompanied by a well written manual. Sentinel 1 data is 90m resolution with 40 x 40m pixel spacing and AMSR2 data is resmpled to its pixels. Each satellite image comes with a timestamp and the data is acquired between 2018-2019. These can be used to perform semantic segmentation to infer sea ice level.\"\ntds_root_core_metadata_d['tasks'] =  ['Semantic Segmentation']\ntds_root_core_metadata_d['data_preprocessing'] = {'type':'free-text', 'recipe':\"Null\"}\ntds_root_core_metadata_d['funding_info'] = \"The AIREO project is funded by ESA, the AI4Arctiv sea ice dataset was funded by ESA Contract No. 4000129762/20/I-NB and Innovation Fund Denmark, Grant: 7049-00008B\"\ntds_root_core_metadata_d['field_schema'] = {'features': {'input1': ['georeferenced_eo_image']}, 'references': {'output1': ['reference_data']}}\ntds_root_core_metadata_d['example_definition'] = \"An example for ML training would be one satellite image with various bands as features and the mask as reference data. This can be used for predicting sea ice levels.\"\ntds_root_core_metadata_d['example_window_size'] = 256\ntds_root_core_metadata_d['example_stride'] = 26\n                                                 \ntds_root_core_metadata_d['data_completeness'] = \"The dataset contains 461 netCDF files covering a large area with corresponding masks for sea-ice level for all areas.\"\ntds_root_core_metadata_d['data_split'] = \"The dataset can be split in a number of different ways but a standard way is to take 70% of the aoi's for training, 10% for validation and the remaining 20% as a test set.\"\ntds_root_core_metadata_d['data_sharing'] = \"The dataset will be shared on Euro Data Cube (EDC) and can be accessed through jupyter notebooks on EDC.\"\ntds_root_core_metadata_d['compliance_level'] = 'level 1'\ntds_root_core_metadata_d['links'] =  []\n\n\n#Creating common predictive feature metadata dictionary\n\ng_feature_metadata_d = {}\ng_feature_metadata_d['type'] = \"Feature\"\ng_feature_metadata_d['stac_version'] = \"1.0.0-beta.2\"\ng_feature_metadata_d['stac_extensions'] = [\"georeferenced_eo_image\"]\ng_feature_metadata_d['id'] = f'common_predictive_feature_metadata'\ng_feature_metadata_d['collection'] = \"270460aa-7835-11eb-9439-0242ac130002\"\n\ngeom = np.array(fgdf[fgdf['filename'] == '20180521T103156_S1B_AMSR2_Icechart-Greenland-NorthWest.nc']['geometry'][0].exterior.coords.xy)\nxs = geom[0]\nys = geom[1]\nxys = zip(xs,ys)\narr = []\nfor x, y in xys:\n    arr.append([x,y])\ng_feature_metadata_d['geometry'] = {'type': 'Polygon', 'coordinates': [arr]}\ng_feature_metadata_d['bbox'] = [min(xs),min(ys), max(xs), max(ys)]\ng_feature_metadata_d['properties'] = {}\ng_feature_metadata_d[\"properties\"][\"status\"]= \"Null\"\ng_feature_metadata_d[\"properties\"]['parent_identifier'] = \"270460aa-7835-11eb-9439-0242ac130002\"\ng_feature_metadata_d[\"properties\"]['acquisition_type'] = \"Null\"\ng_feature_metadata_d[\"properties\"]['product_type']  = \"Null\"\ng_feature_metadata_d[\"properties\"]['processing_level'] = 1.0\ng_feature_metadata_d[\"properties\"]['platform_short_name'] = \"Sentinel 2\"\ng_feature_metadata_d[\"properties\"]['sensor_type'] = \"SAR\"\ng_feature_metadata_d[\"properties\"]['sensor_resolution'] = \"10m\"\ng_feature_metadata_d[\"properties\"]['gsd'] = 10\ng_feature_metadata_d['properties']['datetime'] = \"2019\"\ng_feature_metadata_d[\"properties\"]['identifier'] = \"Null\"\ng_feature_metadata_d['links'] = []\ng_feature_metadata_d[\"assets\"] =  {}\nfeature_metadata_d = {}\nfeature_metadata_d['input1'] = g_feature_metadata_d\n\n#Creating common reference metadata dictionary\n\ng_ref_data_metadata_d = {}\n\ng_ref_data_metadata_d['id'] = f'common_reference_metadata'\ng_ref_data_metadata_d['type'] = \"Feature\"\ng_ref_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\ng_ref_data_metadata_d['stac_extensions'] = [\"reference_data\"]\ng_ref_data_metadata_d['collection'] = \"270460aa-7835-11eb-9439-0242ac130002\"\n\ngeom = np.array(fgdf[fgdf['filename'] == '20180521T103156_S1B_AMSR2_Icechart-Greenland-NorthWest.nc']['geometry'][0].exterior.coords.xy)\nxs = geom[0]\nys = geom[1]\nxys = zip(xs,ys)\narr = []\nfor x, y in xys:\n    arr.append([x,y])\ng_ref_data_metadata_d['geometry'] = {'type': 'Polygon', 'coordinates': [arr]}\ng_ref_data_metadata_d['bbox'] = [min(xs),min(ys), max(xs), max(ys)]\ng_ref_data_metadata_d['properties'] = {}\ng_ref_data_metadata_d[\"properties\"]['name'] = \" Reference metadata\"\ng_ref_data_metadata_d['properties']['description'] = \"The reference data consists of polygons with the percentage of sea ice for a given mask.\"\ng_ref_data_metadata_d['properties']['type'] = \"Raster\"\ng_ref_data_metadata_d['properties']['task'] = \"Semantic Segmentation\"\ng_ref_data_metadata_d['properties']['classes'] = [[{'pct_ice': 416, 'pct_water': 416, 'pct_nodata': 416}]]\ng_ref_data_metadata_d['properties']['overviews'] = []\ng_ref_data_metadata_d['properties']['collection_method'] = \"Sentinel-1 Synthetic Aperture Radar (SAR) scenes matched with sea ice charts produced by the Danish Meteorological Institute in 2018-2019.\"\ng_ref_data_metadata_d['properties']['data_preprocessing'] = {'type':'free-text', 'recipe':\"Null\"}\ng_ref_data_metadata_d['properties']['CRS'] = 'EPSG:32631'\ng_ref_data_metadata_d['properties']['time_range'] = '2018-2019'\n\ng_ref_data_metadata_d[\"properties\"]['value'] = 0\ng_ref_data_metadata_d['properties'][\"orientation\"]= \"Null\"\ng_ref_data_metadata_d[\"properties\"]['datetime'] = \"2019\"\ng_ref_data_metadata_d['links'] = []\ng_ref_data_metadata_d[\"assets\"] = {}\n\nref_metadata_d = {}\nref_metadata_d['output1'] = g_ref_data_metadata_d\n\n# Add TDS global core elements metadata, and add global level profile metadata to the catalog object.\n\nnew_tds_ctl_o.add_tds_root_metadata(tds_root_core_metadata_d, feature_metadata_d, ref_metadata_d)\n\n\n# Adding metadata for each AOI\n\nfor idx, aoi_id in enumerate(aoi_ids):\n    # Dictionary for each AOI collection metadata\n    aoi_metadata_d = {}\n    aoi_metadata_d['type'] = \"Collection\"\n    aoi_metadata_d[\"id\"] = f\"{aoi_id}\"\n    aoi_metadata_d['stac_version'] = '1.0.0-beta.2'\n    aoi_metadata_d['title'] = f\"{aoi_id} Collection\"\n    aoi_metadata_d['description'] = \"Each AOI contains satellite images with crop masks.\"\n    aoi_metadata_d[\"license\"] = \"CC-BY-4.0\"\n    mask = aoi_id + '.nc'\n    #aoi_metadata_d['geometry'] = fgdf[fgdf['filename'] == '20180521T103156_S1B_AMSR2_Icechart-Greenland-NorthWest.nc']['geometry'][0]\n    geom = np.array(fgdf[fgdf['filename'] == mask]['geometry'].values[0].exterior.coords.xy)\n    xs = geom[0]\n    ys = geom[1]\n    minx = min(xs)\n    miny = min(ys)\n    maxx = max(xs)\n    maxy = max(ys)\n    aoi_metadata_d['bbox'] = [minx, miny, maxx, maxy]\n    #aoi_metadata_d[\"bbox\"]= [minx, miny, maxx, maxy]\n    aoi_metadata_d['geometry'] = geometry.mapping(geometry.box(*aoi_metadata_d[\"bbox\"]))\n    aoi_metadata_d[\"extent\"] = {\"spatial\" : {\"bbox\":[[minx, miny, maxx, maxy]]}, \n                      \"temporal\": {\"interval\":[[aoi_id[:4]]]}}\n    aoi_metadata_d['time_range'] = '2019'\n    aoi_metadata_d['links'] = []\n    aoi_metadata_d[\"assets\"] = {}\n    \n    \n    # Dictionary for each AOI's predictive feature metadata\n    aoi_feature_metadata_d = {}\n    aoi_feature_metadata_d['id'] = f'reference_metadata_AOI_{aoi_id}'\n    aoi_feature_metadata_d['type'] = \"Feature\"\n    aoi_feature_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n    aoi_feature_metadata_d['stac_extensions'] = [\"reference_data\"]\n    aoi_feature_metadata_d['collection'] = \"270460aa-7835-11eb-9439-0242ac130002\"\n    aoi_feature_metadata_d['bbox'] = aoi_metadata_d[\"bbox\"]\n    aoi_feature_metadata_d['geometry'] = aoi_metadata_d[\"geometry\"]\n    aoi_feature_metadata_d['properties'] = {}\n    aoi_feature_metadata_d[\"properties\"]['name'] = str(aoi_id) + \" Reference metadata\"\n    aoi_feature_metadata_d['properties']['description'] = \"AI4Artic ASIP Sea Ice Dataset contains 461 files in network Common Data Form (netCDF), coming from Sentinel 1 SAR and AMSR2 microwave radiometer imagery with corresponding ice charts from Danish Meteorological Institute of the Arctic area.\"\n    aoi_feature_metadata_d['properties']['type'] = \"Raster\"\n    aoi_feature_metadata_d['properties']['task'] = \"Semantic Segmentation\"\n    aoi_feature_metadata_d['properties']['classes'] = [[{'pct_ice': 416, 'pct_water': 416, 'pct_nodata': 416}]]\n    aoi_feature_metadata_d['properties']['overviews'] = []\n    aoi_feature_metadata_d['properties']['collection_method'] = \"Sentinel-1 Synthetic Aperture Radar (SAR) scenes matched with sea ice charts produced by the Danish Meteorological Institute in 2018-2019.\"\n    aoi_feature_metadata_d['properties']['data_preprocessing'] = \"Null\"\n    aoi_feature_metadata_d['properties']['CRS'] = 'EPSG:32631'\n    aoi_feature_metadata_d['properties']['time_range'] = aoi_id[:4]\n    aoi_feature_metadata_d[\"properties\"]['value'] = 0\n    aoi_feature_metadata_d['properties'][\"orientation\"]= \"null\"\n    aoi_feature_metadata_d[\"properties\"]['datetime'] = \"2020-03-09T14:53:23.262208+00:00\"\n\n    aoi_feature_metadata_d['links'] = []  \n    aoi_feature_metadata_d[\"assets\"] = {}\n\n    aoi_feature_d = {}\n    aoi_feature_d['input1'] = aoi_feature_metadata_d\n    \n    # Dictionary for each AOI's reference metadata\n    aoi_ref_data_metadata_d = {}\n    aoi_ref_data_metadata_d['type'] = \"Feature\"\n    aoi_ref_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n    aoi_ref_data_metadata_d['stac_extensions'] = [\"georeferenced_eo_image\"]\n    aoi_ref_data_metadata_d['id'] = f'predictive_feature_metadata_AOI_{aoi_id}'\n    aoi_ref_data_metadata_d['collection'] = \"270460aa-7835-11eb-9439-0242ac130002\"\n    aoi_ref_data_metadata_d[\"bbox\"]= aoi_metadata_d[\"bbox\"]\n    aoi_ref_data_metadata_d['geometry'] = aoi_metadata_d[\"geometry\"]\n    aoi_ref_data_metadata_d[\"properties\"] = {}\n    aoi_ref_data_metadata_d[\"properties\"][\"status\"]= \"Null\"\n    aoi_ref_data_metadata_d[\"properties\"]['parent_identifier'] = \"270460aa-7835-11eb-9439-0242ac130002\"\n    aoi_ref_data_metadata_d[\"properties\"]['acquisition_type'] = \"Null\"\n    aoi_ref_data_metadata_d[\"properties\"]['product_type']  = \"Null\"\n    aoi_ref_data_metadata_d[\"properties\"]['processing_level'] = 1.0\n    aoi_ref_data_metadata_d[\"properties\"]['platform_short_name'] = \"Sentinel 2\"\n    aoi_ref_data_metadata_d[\"properties\"]['sensor_type'] = \"SAR\"\n    aoi_ref_data_metadata_d[\"properties\"]['sensor_resolution'] = \"10m\"\n    aoi_ref_data_metadata_d[\"properties\"]['gsd'] = 10\n    aoi_ref_data_metadata_d[\"properties\"]['identifier'] = str(aoi_id)\n    aoi_ref_data_metadata_d[\"properties\"]['acquisition_date'] = '2019'\n    aoi_ref_data_metadata_d[\"properties\"]['datetime'] = \"2019\"\n    aoi_ref_data_metadata_d['links'] = []\n    aoi_ref_data_metadata_d[\"assets\"] = {}\n    aoi_ref_d = {}\n    aoi_ref_d['output1'] = aoi_ref_data_metadata_d\n    \n    \n    output_path = os.path.join(os.environ['EDC_PATH'] + '/data/Sea-Ice/dataset/sea-ice_mask')\n    input_path = os.path.join(os.environ['EDC_PATH'] + '/data/Sea-Ice/dataset/sea-ice_tiff')\n    aoi_ref_data_asset_path_d = {'output1':os.path.join(output_path, f'patch_mask_{aoi_id}.json')}\n    aoi_feature_asset_path_d = {'input1':os.path.join(input_path, f'patch_{aoi_id}.tif')}\n                                            \n    print(new_tds_ctl_o.add_aoi_metadata(aoi_metadata_d=aoi_metadata_d,\n                                   aoi_feature_metadata_d=aoi_feature_d,\n                                   aoi_ref_data_metadata_d=aoi_ref_d,\n                                   aoi_feature_asset_path_d=aoi_feature_asset_path_d,\n                                   aoi_ref_data_asset_path_d=aoi_ref_data_asset_path_d))\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#creating-a-stac-catalog-with-aireo-lib","position":11},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl3":"stac_generated folder"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#stac-generated-folder","position":12},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl3":"stac_generated folder"},"content":"\n\nPrior to this step, you will need to create a folder called ‘biomass_stac_generated’ in your environment and leave it empty\n\n# If a STAC catalog has already been generated remove it before re generating the catalog below\n\nimport shutil\nstac_generated_path = os.path.join('./Sea-ice_stac_generated_')\nif os.path.exists(stac_generated_path):\n    shutil.rmtree(stac_generated_path)\n\n#import shutil\n#shutil.rmtree('sea-ice_stac_generated')\n\n# Writing the STAC metadata. The directory along with its structure is generated, with correct links and assets defined. \n#A datasheet is also generated\ncatalog_fn_w_path = './Sea-ice_stac_generated_/TDS.json'\nnew_tds_ctl_o.write_TDS_STAC_Catalog(catalog_fn_w_path)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#stac-generated-folder","position":13},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl4":"Checking AIREO compiance level","lvl3":"stac_generated folder"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#checking-aireo-compiance-level","position":14},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl4":"Checking AIREO compiance level","lvl3":"stac_generated folder"},"content":"\n\ncatalog_fn_w_path = os.path.join('./Sea-ice_stac_generated_/TDS.json')\nnew_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog.from_TDSCatalog(catalog_fn_w_path)\nnew_tds_ctl_o.compute_compliance_level()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#checking-aireo-compiance-level","position":15},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl4":"Checking metadata completeness","lvl3":"stac_generated folder"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#checking-metadata-completeness","position":16},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl4":"Checking metadata completeness","lvl3":"stac_generated folder"},"content":"\n\nnew_tds_ctl_o.report_metadata_completeness()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#checking-metadata-completeness","position":17},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl3":"Defining AOI class"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#defining-aoi-class","position":18},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl3":"Defining AOI class"},"content":"\n\nfile = os.environ['EDC_PATH']+'/data/Sea-Ice/sea-ice_stac_generated/20180327T104059_S1B_AMSR2_Icechart-Greenland-CentralWest/patch_mask_20180327T104059_S1B_AMSR2_Icechart-Greenland-CentralWest.json'\n\nwith open(file, 'r') as f:\n        #print(f.read())\n        data = json.load(f)\n        print(data)\nprint(data['pct_ice'])\n#xr.Dataset.to_dict(dictio)\nt = [data['pct_ice']]\nx = [1,2]\ny = [1,2]\nd = {\n    \"pct_ice\": {\"dims\": (\"t\"), \"data\": t},\n}\n\nxr.Dataset.from_dict(d)\n\n#should inherit AOIDataset\n\nfrom aireo_lib.core import AOIDataset\n\nclass AOIDatasetSeaIce(AOIDataset):\n\n    def __init__(self, AOI_STAC_collection, TDS_STAC_catalog):\n\n        self.AOI_STAC_collection = AOI_STAC_collection\n        self.TDS_STAC_catalog = TDS_STAC_catalog\n        self.stride = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_stride']\n        self.window_size = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_window_size']\n        \n        _first = True\n        \n        for eo_feature in self.AOI_STAC_collection.aoi_all_field_metadata.features:\n            aoi_feature_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.features[eo_feature].data_asset_w_path\n            self.feature_var_name = 'features_' + eo_feature\n            if _first:\n                self.data = rioxarray.open_rasterio(aoi_feature_asset_path_d).to_dataset(name = self.feature_var_name)\n                _first = False\n            else:\n                self.data[self.feature_var_name] = rioxarray.open_rasterio(aoi_feature_asset_path_d)\n        \n        for reference_data in self.AOI_STAC_collection.aoi_all_field_metadata.references:\n            aoi_ref_data_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.references[reference_data].data_asset_w_path\n            self.ref_var_name = 'references_'+ reference_data\n            if _first:\n                with open(aoi_ref_data_asset_path_d, 'r') as f:\n                    data = json.load(f)\n                t = [data['pct_ice']]\n                x = [data['pct_water']]\n                y = [data['pct_nodata']]\n                d = {\n                    \"pct_ice\": {\"dims\": (\"t\"), \"data\": t},\n                    \"pct_ice\": {\"dims\": (\"t\"), \"data\": x},\n                    \"pct_ice\": {\"dims\": (\"t\"), \"data\": y},\n                }\n                self.data = xr.Dataset.from_dict(d).to_dataset(name = self.ref_var_name).to_array()\n                print(self.data)\n                _first = False\n            else:\n                with open(aoi_ref_data_asset_path_d, 'r') as f:\n                    data = json.load(f)\n                t = [data['pct_ice']]\n                x = [data['pct_water']]\n                y = [data['pct_nodata']]\n                d = {\n                    \"pct_ice\": {\"dims\": (\"t\"), \"data\": t},\n                    \"pct_ice\": {\"dims\": (\"t\"), \"data\": x},\n                    \"pct_ice\": {\"dims\": (\"t\"), \"data\": y},\n                }\n                self.data[self.ref_var_name] = xr.Dataset.from_dict(d).to_array().rename({'t':'mask'})\n        \n\n\n    def __getitem__(self, index):\n        \n        along_x = int((self.data[self.feature_var_name].shape[1] - self.window_size)/self.stride)\n        along_y = int((self.data[self.feature_var_name].shape[-1] - self.window_size)/self.stride)\n        x1 = self.stride * int(index % along_x)\n        y1 = self.stride * int(index / along_y)\n        x2 = x1 + self.window_size\n        y2 = y1 + self.window_size\n        \n        #store feature and reference data in same xarray, name the axes\n        ds = self.data.isel(band=[0], mask=[0], x=slice(x1,x2), y=slice(y1, y2))        \n        return ds\n    \n\n    def __len__(self):\n        \n        along_x = int((self.data[self.feature_var_name].shape[1] - self.window_size)/self.stride) + 1\n        along_y = int((self.data[self.feature_var_name].shape[-1] - self.window_size)/self.stride) + 1\n        return along_x * along_y\n    \n    def get_length(self):\n        return self.__len__()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#defining-aoi-class","position":19},{"hierarchy":{"lvl1":"TDS user"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#tds-user","position":20},{"hierarchy":{"lvl1":"TDS user"},"content":"The user of the dataset can access most of what is offered by the dataset using just its STAC catalog. All he/she needs to do is create a dataset object by passing to it the path to the STAC catalog at the root level. The library automatically reads in all the metadata and loads the assets into the dataset object. Some of the functionalities that a dataset object offers through aireo_lib are:\n\nCan access an example instance from the dataset which serves as an input-output pair for a Machine Learning algorithm.\n\nXarrays are used to store data and give examples.\n\nDataset can also return each AOI independently\n\nOffer basic plotting functions for each variable in the dataset and AOI.\n\nSome statistics can also be calculated at both the AOI level and whole dataset level.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#tds-user","position":21},{"hierarchy":{"lvl1":"TDS user","lvl2":"Parsing TDS"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#parsing-tds","position":22},{"hierarchy":{"lvl1":"TDS user","lvl2":"Parsing TDS"},"content":"\n\nfrom aireo_lib.core import EOTrainingDataset\n\ncap_tds_ctl_fn = Path(catalog_fn_w_path)\n\neo_tds_obj = EOTrainingDataset(cap_tds_ctl_fn, AOIDatasetSeaIce)\n\nlen(eo_tds_obj)\n\neo_tds_obj[0]\n\neo_tds_obj.get_subset([19,1121], data_type='numpy')\n\naoi_objs = eo_tds_obj.get_aoi_datasets()\nlen(aoi_objs[1])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#parsing-tds","position":23},{"hierarchy":{"lvl1":"TDS user","lvl2":"Plotting"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#plotting","position":24},{"hierarchy":{"lvl1":"TDS user","lvl2":"Plotting"},"content":"\n\nimport aireo_lib.plotting \n#import matplotlib.pyplot as plt\nfrom importlib import reload\nreload(aireo_lib.plotting)\n\n\nplot_d = aireo_lib.plotting.EOTDSPlot.plot_example(EOTDS=eo_tds_obj, \n                       ex_index=123, \n                       field_names=['features_input1', 'references_output1'])\nplot_d\n\nplot_d['references_output1']\n\nplot_d['features_input1']\n\naoi_obj = eo_tds_obj.get_aoi_dataset(2)\n\n# aoi_plots_d = aireo_lib.plotting.EOTDSPlot.plot_aoi_dataset(aoi_obj)\n# aoi_plots_d\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#plotting","position":25},{"hierarchy":{"lvl1":"TDS user","lvl2":"Statistics"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#statistics","position":26},{"hierarchy":{"lvl1":"TDS user","lvl2":"Statistics"},"content":"\n\nimport aireo_lib.statistics\nfrom importlib import reload\nreload(aireo_lib.statistics)\n\naireo_lib.statistics.EOTDSStatistics.feature_data_statistics(eo_tds_obj)\n\naireo_lib.statistics.EOTDSStatistics.reference_data_statistics(eo_tds_obj)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-ai4arctic-sea-ice#statistics","position":27},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys","position":0},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[\"SH\"])\n\n#Install aireo library\n!python3 -m pip install git+https://github.com/aireo-project/aireo_lib\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys","position":1},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#aireo-pilot-dataset-biomass-forest-observation-system","position":2},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)"},"content":"\n\nForest Observation System \n\nFOS is an international cooperation aiming to establish an in-situ forest biomass database in order to support Earth Observation with reliable, up to date, representative and comparable data for validation (Schepaschenko, D. et al. 2019).\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#aireo-pilot-dataset-biomass-forest-observation-system","position":3},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"Introduction"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#introduction","position":4},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"Introduction"},"content":"The notebook demonstrates the use of aireo_lib, a python library created as a part of the \n\nAIREO (Artificial Intelligence Ready Earth Observation training datasets) project. The project aims to make EO datasets easily accessible for the ML (Machine Learning) community. As such, AIREO specifications (shorthand specs) which define metadata elements to be included with the training dataset are proposed, supplemented by a best-practices document which suggests how to fill those metadata elements. Finally, the library takes all into account and implements specs, best-practices and offers an easy-to-use pythonic interface bridging the gap between EO and ML community.\n\nTherefore, this notebook is divided into two sections, one for the training dataset creator (usually from the EO community) and the other for its user (usually from the ML community). The structure of the notebook is the following:\n\nFor Creator\n\nCreate a \n\nSTAC catalog object using the library\n\nPopulate metadata elements prescribed by the AIREO specs\n\nGenerate a STAC metadata directory using the library\n\nCheck AIREO compliance level and metadata completeness\n\nFor User\n\nCreate a training dataset object as defined in the library using only the STAC metadata\n\nGet example instances from the object and other dataset variables like the number of instances, etc.\n\nUse library’s functions to plot the data\n\nInvestigate statistics using the library\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#introduction","position":5},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"AIREO STAC Catalog basics"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#aireo-stac-catalog-basics","position":6},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"AIREO STAC Catalog basics"},"content":"\n\nThe AIREO specs propose a hierarchical structure for STAC metadata. It is a two level structure where the dataset is represented by a collection of AOIs (Area Of Interests), hence, the dataset and AOI being the two levels.\n\nAt the dataset level we have a dataset catalog whose metadata elements are the core elements proposed in the AIREO spec. In addition to it, the common metadata elements across each AOI are also at the dataset level, which we shall call root level henceforth. Here, for each data variable there is a separate json which is a STAC Item by definition and is named using the field_schema metadata element. Additionally, there is also a datasheet file in markdown format at the root level which contains human readable information about the key elements of the dataset.\n\nEach AOI has a separate folder within the root level. And in each AOI folder there is a STAC collection representing that AOI and additional json files for each data variable. The additional json files here too, are STAC Items and follow a similar naming convention to the ones at the root level. The assets for each AOI, i.e. the files containing actual data are also in the folder.\n\nThe diagram below summarises this hierarchical structure:Root level (dataset)\n│\n│   DatasetCatalog.json\n│   datasheet.md\n│   references_output1.json\n│   features_input1.json\n│   ...\n│\n│\n└───AOI 1\n│      1.json (AOI Collection)\n│      feature_input1.json\n│      reference_output1.json\n│      <reference_asset>\n│      <feature_asseet>\n│   \n│   \n└───AOI 2\n│      ...\n│   \n│\n└───AOI 3\n│      ...\n│   \n...     \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#aireo-stac-catalog-basics","position":7},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"Creator perpsective"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#creator-perpsective","position":8},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"Creator perpsective"},"content":"\n\nimport aireo_lib.core\nimport os\nimport json\nimport numpy as np\nfrom osgeo import gdal\nfrom tqdm.notebook import tqdm\nfrom shapely import geometry\nimport shutil\nimport rioxarray\nimport xarray as xr\nfrom pathlib import Path\nfrom sentinelhub import (SHConfig, BBox, bbox_to_dimensions, CRS,SentinelHubBatch, SentinelHubRequest, DataCollection, MimeType, FisRequest)\nfrom sentinelhub.geometry import Geometry\nimport PIL.Image as Image\nimport pandas as pd\npd.set_option('display.max_rows', None)\nimport geopandas as gp\n\n# set ssl permissions correctly so Biomass excel shee can be pulled\n\nimport ssl\n\ntry:\n    _create_unverified_https_context = ssl._create_unverified_context\nexcept AttributeError:\n    # Legacy Python that doesn't verify HTTPS certificates by default\n    pass\nelse:\n    # Handle target environment that doesn't support HTTPS verification\n    ssl._create_default_https_context = _create_unverified_https_context\n\n#Pull Biomass excel sheet\npath = ('https://forest-observation-system.net/Data/FOS_Plots_v2019.04.10.xlsx')\ndf = pd.read_excel (path)\ndf.keys()\ngdf = gp.GeoDataFrame(\n    df, geometry=gp.points_from_xy(df.Lon_cnt, df.Lat_cnt))\n\n# Path to write the STAC root metadata file too\ncatalog_fn_w_path = os.environ['EDC_PATH']+'/data/biomass/Biomass_stac_generated/EO_TDS.json'\n\n# Creating an empty STAC Catalog object\nnew_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog()\n\n\n# Get AOI list for the TDS\n\nreference_path = os.environ['EDC_PATH']  + '/data/biomass/Biomass_tiff/'\n#print(os.listdir(reference_path))\naoi_ids = [i.replace('.tif','').replace('patch_', '') for i in os.listdir(reference_path) if '.tif' in i]\naoi_ids = ['ALP-02_0_3',\n 'ALP-02_0_2',\n 'ASN-02_0_0',\n 'ALP-02_0_0',\n 'ALP-02_0_1']\n\n# Creating root metadata dictionary\n\ntds_root_core_metadata_d = {}\ntds_root_core_metadata_d['aireo_version'] = \"0.0.1-alpha.1\"\ntds_root_core_metadata_d['title'] = \"Aireo Pilot datasets - Forest Observatory System - Biomass\"\ntds_root_core_metadata_d['description'] = \"Above ground biomass split in 260 plots of 50 x 50 m.\"\ntds_root_core_metadata_d['created'] = 'Null'\ntds_root_core_metadata_d['license_url_list'] = 'https://creativecommons.org/licenses/by/4.0/deed.de' \ntds_root_core_metadata_d['license'] = \"CC-BY-4.0\"\ntds_root_core_metadata_d[\"providers_name\"]= \"[FOS, RAINFOR, AfriTRON]\"\ntds_root_core_metadata_d[\"providers_description\"] = \"international cooperation to establish a global in-situ forest biomass database to support earth observation and to encourage investment in relevant field-based observations and science.\"\ntds_root_core_metadata_d[\"providers_roles\"] = {'FOS': [\"licensor\", \"host\"], 'RAINFOR':[\"producer\", \"processor\" , \"host\"],'AfriTRON':[\"producer\", \"processor\" ]}\ntds_root_core_metadata_d[\"providers_url\"]= {'FOS':'https://forest-observation-system.net', 'RAINFOR': 'https://www.rainfor.org/', \n                        'AfriTRON': 'https://www.afritron.org/'}                         \ntds_root_core_metadata_d['id'] =  \"aa24c994-e8a9-4175-9a16-7def23bf762b\" #changed UUID\ntds_root_core_metadata_d['type'] = \"Collection\"\ntds_root_core_metadata_d['stac_version'] = '1.0.0-beta.2'\ntds_root_core_metadata_d['provenance'] = 'The dataset was fed by providers based on ground field measurements (see providers) and the accompanying satellite images were provided by Sentinel Hub (see links in providers) using Sentinel 2 images.'\ntds_root_core_metadata_d['purpose'] = \"The dataset has sentinel 2 images matching the location of each plotID in order to add remote sensing imagery to in-situ data taken from dataset  \"\ntds_root_core_metadata_d['tasks'] =  ['regression']\ntds_root_core_metadata_d['data_preprocessing'] = {'type':'free-text', 'recipe':'Only satellite images with cloud cover less than 20% are considered'}\ntds_root_core_metadata_d['funding_info'] = \"The AIREO project is funded by ESA, the underlying fields and crop data are funded by Agricultural Market Austria and the satellite imagery used is through funds from ESA.\"\ntds_root_core_metadata_d['field_schema'] = {'features': {'input1': ['georeferenced_eo_image']}, 'references': {'output1': ['reference_data']}}\ntds_root_core_metadata_d['example_definition'] = \"An example for ML training would be a satellite imagery with its biomass associated as referece. That could be used to predict Biomass measurements in other parts of the planet using regression method\"\n\ntds_root_core_metadata_d['example_window_size'] = 256 #do you need these twofor biomass? they are for sampling\ntds_root_core_metadata_d['example_stride'] = 26\n                                                 \ntds_root_core_metadata_d['data_completeness'] = \"Data has lots of entries in different languages. Not all entries are completed\"\ntds_root_core_metadata_d['data_split'] = \"It should be split in wide acceptance proportion 80%-20%\"\ntds_root_core_metadata_d['data_sharing'] = \"The dataset will be shared on Euro Data Cube (EDC) and can be accessed through jupyter notebooks on EDC.\"\ntds_root_core_metadata_d['compliance_level'] = 'level 1'\ntds_root_core_metadata_d['links'] =  []\n\n\n#Creating common predictive feature metadata dictionary\n\ng_feature_metadata_d = {}\ng_feature_metadata_d['type'] = \"Feature\"\ng_feature_metadata_d['stac_version'] = \"1.0.0-beta.2\"\ng_feature_metadata_d['stac_extensions'] = [\"georeferenced_eo_image\"]\ng_feature_metadata_d['id'] = f'common_predictive_feature_metadata'\ng_feature_metadata_d['collection'] = \"aa24c994-e8a9-4175-9a16-7def23bf762b\"\n\nshape = gdf.geometry\ngeom = np.array(shape[0])\ncoords = [\"x\",\"y\"]\n\nlon = df['Lon_cnt'][1]\nlat = df['Lat_cnt'][1]\nLON = round(lon+0.05,2)\nLAT = round(lat+0.05,1)\nroi_bbox = BBox(bbox=[ lon,lat,LON, LAT], crs=CRS.WGS84)\n\nfrom shapely import geometry\ng_feature_metadata_d['geometry'] = geometry.mapping(geometry.MultiPoint(shape))\ng_feature_metadata_d['bbox'] = list(roi_bbox)\ng_feature_metadata_d['properties'] = {}\ng_feature_metadata_d[\"properties\"][\"status\"]= \"Null\"\ng_feature_metadata_d[\"properties\"]['parent_identifier'] = \"aa24c994-e8a9-4175-9a16-7def23bf762b\"\ng_feature_metadata_d[\"properties\"]['acquisition_type'] = \"Null\"\ng_feature_metadata_d[\"properties\"]['product_type']  = \"Null\"\ng_feature_metadata_d[\"properties\"]['processing_level'] = 1.0\ng_feature_metadata_d[\"properties\"]['platform_short_name'] = \"Sentinel 2\"\ng_feature_metadata_d[\"properties\"]['sensor_type'] = \"OPTICAL\"\ng_feature_metadata_d[\"properties\"]['sensor_resolution'] = \"10m\"\ng_feature_metadata_d[\"properties\"]['gsd'] = 10\ng_feature_metadata_d['properties']['datetime'] = \"2019\" #change as per biomass\ng_feature_metadata_d[\"properties\"]['identifier'] = \"Null\"\ng_feature_metadata_d['links'] = []\ng_feature_metadata_d[\"assets\"] =  {}\nfeature_metadata_d = {}\nfeature_metadata_d['input1'] = g_feature_metadata_d\n\n#Creating common reference metadata dictionary\n\ng_ref_data_metadata_d = {}\n\ng_ref_data_metadata_d['id'] = f'common_reference_metadata'\ng_ref_data_metadata_d['type'] = \"Feature\"\ng_ref_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\ng_ref_data_metadata_d['stac_extensions'] = [\"reference_data\"]\ng_ref_data_metadata_d['collection'] = \"aa24c994-e8a9-4175-9a16-7def23bf762b\"\nshape = gdf.geometry\ngeom = np.array(shape[0])\ncoords = [\"x\",\"y\"]\n\nfrom shapely import geometry\ng_ref_data_metadata_d['geometry'] = geometry.mapping(geometry.MultiPoint(shape))\n\ng_ref_data_metadata_d['bbox'] = list(roi_bbox)\n#[min(xs),min(ys), max(xs), max(ys)]\ng_ref_data_metadata_d['properties'] = {}\ng_ref_data_metadata_d[\"properties\"]['name'] = \" Reference metadata\"\ng_ref_data_metadata_d['properties']['description'] = \"The reference data \"\ng_ref_data_metadata_d['properties']['type'] = \"Raster\"\ng_ref_data_metadata_d['properties']['task'] = \"regression\"\ng_ref_data_metadata_d['properties']['classes']=[]\ng_ref_data_metadata_d['properties']['overviews']=[]\ng_ref_data_metadata_d['properties']['collection_method'] = \"The reference data was collected by Agricultural Market Austria for the year 2019 for Common Agriculture Practices for EU to process agriculture subsidies, etc. The exact method for ground surveys was not clearly documented and the only info available is that \\\"all field uses were recorded by the applicants\\\".\"\ng_ref_data_metadata_d['properties']['data_preprocessing'] = {'type':'free-text', 'recipe':\"The polygons in the original reference data were converted into rasters overlayed on satellite image of 10m resoltuion. As such no other changes were made to the fields or the crop types themselves.\"}\ng_ref_data_metadata_d['properties']['CRS'] = 'EPSG:4326'\ng_ref_data_metadata_d['properties']['time_range'] = '2018'\ng_ref_data_metadata_d[\"properties\"]['value'] = 0.663\ng_ref_data_metadata_d['properties'][\"orientation\"]= \"Null\"\ng_ref_data_metadata_d[\"properties\"]['datetime'] = \"2019\"\ng_ref_data_metadata_d['links'] = []\ng_ref_data_metadata_d[\"assets\"] = {}\n\nref_metadata_d = {}\nref_metadata_d['output1'] = g_ref_data_metadata_d\n\n# Add TDS global core elements metadata, and add global level profile metadata to the catalog object.\n\nnew_tds_ctl_o.add_tds_root_metadata(tds_root_core_metadata_d, feature_metadata_d, ref_metadata_d)\n\n\n# Adding metadata for each AOI\n\nfor aoi_id in aoi_ids[:5]:\n    # Dictionary for each AOI collection metadata\n    aoi_metadata_d = {}\n    aoi_metadata_d['type'] = \"Collection\"\n    aoi_metadata_d[\"id\"] = f\"{aoi_id}\"\n    aoi_metadata_d['stac_version'] = '1.0.0-beta.2'\n    aoi_metadata_d['title'] = f\"{aoi_id} Collection\"\n    aoi_metadata_d['description'] = \"Each AOI contains satellite images \"\n    aoi_metadata_d[\"license\"] = \"CC-BY-4.0\"\n    shape = gdf.geometry\n    geom = np.array(shape[0])\n    coords = [\"x\",\"y\"]\n    \n    aoi_metadata_d[\"bbox\"]= list(roi_bbox)\n    aoi_metadata_d['geometry'] = geometry.mapping(geometry.MultiPoint(shape))\n    aoi_metadata_d[\"extent\"] = {\"spatial\" : {\"bbox\":[[geom[0], geom[1], geom[0], geom[1]]]}, \n                      \"temporal\": {\"interval\": [['2019']]}}\n    aoi_metadata_d['time_range'] = '2019'\n    aoi_metadata_d['links'] = []\n    aoi_metadata_d[\"assets\"] = {}\n    \n    \n    # Dictionary for each AOI's predictive feature metadata\n    aoi_feature_metadata_d = {}\n    aoi_feature_metadata_d['id'] = f'reference_metadata_AOI_{aoi_id}'\n    aoi_feature_metadata_d['type'] = \"Feature\"\n    aoi_feature_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n    aoi_feature_metadata_d['stac_extensions'] = [\"reference_data\"]\n    aoi_feature_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n    aoi_feature_metadata_d['bbox'] = aoi_metadata_d[\"bbox\"]\n    aoi_feature_metadata_d['geometry'] = aoi_metadata_d[\"geometry\"]\n    aoi_feature_metadata_d['properties'] = {}\n    aoi_feature_metadata_d[\"properties\"]['name'] = str(aoi_id)+ \" Reference metadata\"\n    aoi_feature_metadata_d['properties']['description'] = \"The reference data consists in different data from biomass dataset\"\n    aoi_feature_metadata_d['properties']['type'] = \"Raster\"\n    aoi_feature_metadata_d['properties']['task'] = \"regression\"\n    aoi_feature_metadata_d['properties']['classes'] = []\n    aoi_feature_metadata_d['properties']['overviews'] = []\n    aoi_feature_metadata_d['properties']['collection_method'] = \"The reference data consists in varios in-situ measurements taken by providers in different plots distributed worldwide.\"\n    aoi_feature_metadata_d['properties']['data_preprocessing'] = \"Null\"\n    aoi_feature_metadata_d['properties']['CRS'] = 'EPSG:4326'\n    aoi_feature_metadata_d['properties']['time_range'] = '2019'\n    aoi_feature_metadata_d[\"properties\"]['value'] = 0\n    aoi_feature_metadata_d['properties'][\"orientation\"]= \"null\"\n    aoi_feature_metadata_d[\"properties\"]['datetime'] = \"2020-03-09T14:53:23.262208+00:00\"\n\n    aoi_feature_metadata_d['links'] = []  \n    aoi_feature_metadata_d[\"assets\"] = {}\n\n    aoi_feature_d = {}\n    aoi_feature_d['input1'] = aoi_feature_metadata_d\n    \n    # Dictionary for each AOI's reference metadata\n    aoi_ref_data_metadata_d = {}\n    aoi_ref_data_metadata_d['type'] = \"Feature\"\n    aoi_ref_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n    aoi_ref_data_metadata_d['stac_extensions'] = [\"georeferenced_eo_image\"]\n    aoi_ref_data_metadata_d['id'] = f'predictive_feature_metadata_AOI_{aoi_id}'\n    aoi_ref_data_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n    aoi_ref_data_metadata_d[\"bbox\"]= aoi_metadata_d[\"bbox\"]\n    aoi_ref_data_metadata_d['geometry'] = aoi_metadata_d[\"geometry\"]\n    aoi_ref_data_metadata_d[\"properties\"] = {}\n    aoi_ref_data_metadata_d[\"properties\"][\"status\"]= \"Null\"\n    aoi_ref_data_metadata_d[\"properties\"]['parent_identifier'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n    aoi_ref_data_metadata_d[\"properties\"]['acquisition_type'] = \"Null\"\n    aoi_ref_data_metadata_d[\"properties\"]['product_type']  = \"Null\"\n    aoi_ref_data_metadata_d[\"properties\"]['processing_level'] = 1.0\n    aoi_ref_data_metadata_d[\"properties\"]['platform_short_name'] = \"Sentinel 2\"\n    aoi_ref_data_metadata_d[\"properties\"]['sensor_type'] = \"OPTICAL\"\n    aoi_ref_data_metadata_d[\"properties\"]['sensor_resolution'] = \"10m\"\n    aoi_ref_data_metadata_d[\"properties\"]['gsd'] = 10\n    aoi_ref_data_metadata_d[\"properties\"]['identifier'] = str(aoi_id)\n    aoi_ref_data_metadata_d[\"properties\"]['acquisition_date'] = '2018'\n    aoi_ref_data_metadata_d[\"properties\"]['datetime'] = \"2018\"\n    aoi_ref_data_metadata_d['links'] = []\n    aoi_ref_data_metadata_d[\"assets\"] = {}\n    aoi_ref_d = {}\n    aoi_ref_d['output1'] = aoi_ref_data_metadata_d\n    \n    output_path = os.path.join(os.environ['EDC_PATH'] + '/data/biomass/Biomass_mask')\n    input_path = os.path.join(os.environ['EDC_PATH'] + '/data/biomass/Biomass_tiff')\n    aoi_ref_data_asset_path_d = {'output1':os.path.join(output_path, f'patch_mask_{aoi_id}.json')}\n    aoi_feature_asset_path_d = {'input1':os.path.join(input_path, f'patch_{aoi_id}.tif')}\n                                            \n    print(new_tds_ctl_o.add_aoi_metadata(aoi_metadata_d=aoi_metadata_d,\n                                   aoi_feature_metadata_d=aoi_feature_d,\n                                   aoi_ref_data_metadata_d=aoi_ref_d,\n                                   aoi_feature_asset_path_d=aoi_feature_asset_path_d,\n                                   aoi_ref_data_asset_path_d=aoi_ref_data_asset_path_d))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#creator-perpsective","position":9},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl4":"stac_generated folder creation","lvl2":"Creator perpsective"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#stac-generated-folder-creation","position":10},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl4":"stac_generated folder creation","lvl2":"Creator perpsective"},"content":"\n\nPrior to this step, you will need to create a folder called ‘biomass_stac_generated’ in your environment and leave it empty\n\n# If a STAC catalog has already been generated remove it before re generating the catalog below\n\nimport shutil\nstac_generated_path = os.path.join('./biomass_stac_generated')\nif os.path.exists(stac_generated_path):\n    shutil.rmtree(stac_generated_path)\n\ncatalog_fn_w_path = './biomass_stac_generated/TDS.json'\nnew_tds_ctl_o.write_TDS_STAC_Catalog(catalog_fn_w_path)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#stac-generated-folder-creation","position":11},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl4":"Checking Compliance Level","lvl2":"Creator perpsective"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#checking-compliance-level","position":12},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl4":"Checking Compliance Level","lvl2":"Creator perpsective"},"content":"\n\ncatalog_fn_w_path = os.path.join('./biomass_stac_generated/TDS.json')\nnew_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog.from_TDSCatalog(catalog_fn_w_path)\nnew_tds_ctl_o.compute_compliance_level()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#checking-compliance-level","position":13},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl5":"Checking metadata completeness","lvl4":"Checking Compliance Level","lvl2":"Creator perpsective"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#checking-metadata-completeness","position":14},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl5":"Checking metadata completeness","lvl4":"Checking Compliance Level","lvl2":"Creator perpsective"},"content":"\n\nnew_tds_ctl_o.report_metadata_completeness()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#checking-metadata-completeness","position":15},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl4":"Defining AOI class","lvl2":"Creator perpsective"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#defining-aoi-class","position":16},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl4":"Defining AOI class","lvl2":"Creator perpsective"},"content":"\n\n#should inherit AOIDataset\n\nfrom aireo_lib.core import AOIDataset\n\nclass AOIDatasetBiomass(AOIDataset):\n\n    def __init__(self, AOI_STAC_collection, TDS_STAC_catalog):\n\n        self.AOI_STAC_collection = AOI_STAC_collection\n        self.TDS_STAC_catalog = TDS_STAC_catalog\n        self.stride = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_stride']\n        self.window_size = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_window_size']\n        \n        _first = True\n        \n        for eo_feature in self.AOI_STAC_collection.aoi_all_field_metadata.features:\n            aoi_feature_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.features[eo_feature].data_asset_w_path\n            self.feature_var_name = 'features_' + eo_feature\n            if _first:\n                self.data = rioxarray.open_rasterio(aoi_feature_asset_path_d).to_dataset(name = self.feature_var_name)\n                _first = False\n            else:\n                self.data[self.feature_var_name] = rioxarray.open_rasterio(aoi_feature_asset_path_d)\n        \n        for reference_data in self.AOI_STAC_collection.aoi_all_field_metadata.references:\n            aoi_ref_data_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.references[reference_data].data_asset_w_path\n            self.ref_var_name = 'references_'+reference_data\n            if _first:\n                with open(aoi_ref_data_asset_path_d, 'r') as f:\n                    data = json.load(f)\n                t = [data['Wood density']]\n                d = {\n                    \"Wood density\": {\"dims\": (\"t\"), \"data\": t},\n                }\n                self.data = xr.Dataset.from_dict(d).to_dataset(name = self.ref_var_name).to_array()\n            else:\n                with open(aoi_ref_data_asset_path_d, 'r') as f:\n                    data = json.load(f)\n                t = [data['Wood density']]\n                d = {\n                    \"Wood density\": {\"dims\": (\"t\"), \"data\": t},\n                }\n                self.data[self.ref_var_name] = xr.Dataset.from_dict(d).to_array().rename({'t':'mask'})\n        \n\n\n    def __getitem__(self, index):\n        \n        along_x = int((self.data[self.feature_var_name].shape[1] - self.window_size)/self.stride)\n        along_y = int((self.data[self.feature_var_name].shape[-1] - self.window_size)/self.stride)\n        x1 = self.stride * int(index % along_x)\n        y1 = self.stride * int(index / along_y)\n        x2 = x1 + self.window_size\n        y2 = y1 + self.window_size\n        \n        #store feature and reference data in same xarray, name the axes\n        ds = self.data.isel(band=[0], mask=[0], x=slice(x1,x2), y=slice(y1, y2))        \n        return ds\n    \n\n    def __len__(self):\n        \n        along_x = int((self.data[self.feature_var_name].shape[1] - self.window_size)/self.stride) + 1\n        along_y = int((self.data[self.feature_var_name].shape[-1] - self.window_size)/self.stride) + 1\n        return along_x * along_y\n    \n    def get_length(self):\n        return self.__len__()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#defining-aoi-class","position":17},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"TDS user"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#tds-user","position":18},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"TDS user"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#tds-user","position":19},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl3":"Parsing TDS","lvl2":"TDS user"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#parsing-tds","position":20},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl3":"Parsing TDS","lvl2":"TDS user"},"content":"\n\nfrom aireo_lib.core import EOTrainingDataset\n\ncap_tds_ctl_fn = Path(catalog_fn_w_path)\n\neo_tds_obj = EOTrainingDataset(cap_tds_ctl_fn, AOIDatasetBiomass)\n\nlen(eo_tds_obj)\n\neo_tds_obj[0]\n\neo_tds_obj.get_subset([19,1121], data_type='numpy')\n\naoi_objs = eo_tds_obj.get_aoi_datasets()\nlen(aoi_objs[1])\n\nimport aireo_lib.plotting \n#import matplotlib.pyplot as plt\nfrom importlib import reload\nreload(aireo_lib.plotting)\n\nplot_d = aireo_lib.plotting.EOTDSPlot.plot_example(EOTDS=eo_tds_obj, \n                       ex_index=1, \n                       field_names=['features_input1', 'references_output1'])\nplot_d['references_output1']\n\nplot_d['features_input1']\n\naoi_obj = eo_tds_obj.get_aoi_dataset(2)\n\naoi_plots_d = aireo_lib.plotting.EOTDSPlot.plot_aoi_dataset(aoi_obj)\naoi_plots_d\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#parsing-tds","position":21},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl3":"Statistics","lvl2":"TDS user"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#statistics","position":22},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl3":"Statistics","lvl2":"TDS user"},"content":"\n\nimport aireo_lib.statistics\nfrom importlib import reload\nreload(aireo_lib.statistics)\n\naireo_lib.statistics.EOTDSStatistics.feature_data_statistics(eo_tds_obj)\n\naireo_lib.statistics.EOTDSStatistics.reference_data_statistics(eo_tds_obj)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#statistics","position":23},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"Format"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#format","position":24},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"Format"},"content":"\n\nThe dataset is in spreadsheet format (.xlsx)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#format","position":25},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"Version"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#version","position":26},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"Version"},"content":"\n\nFOS plot data v2019.04.10\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#version","position":27},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"License"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#license","position":28},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"License"},"content":"\n\nThis dataset is licensed under a \n\nCreative Commons Attribution 4.0 International License (CC-BY 4.0).\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#license","position":29},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"References"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#references","position":30},{"hierarchy":{"lvl1":"AIREO pilot dataset - Biomass (Forest Observation System)","lvl2":"References"},"content":"\n\nSchepaschenko, D., Chave, J., Phillips, O. L., Lewis, S. L., Davies, S. J., Réjou-Méchain, M., ... & Labrière, N. (2019). The Forest Observation System, building a global reference dataset for remote sensing of forest biomass. Scientific data, 6(1), 1-11.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-biomass-forest-observation-sys#references","position":31},{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap","position":0},{"hierarchy":{"lvl1":"Introduction"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[\"SH\"])\n\n!python3 -m pip install git+https://github.com/aireo-project/aireo_lib\n\n!python3 -m pip install shapely geopandas torch torchvision\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap","position":1},{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#introduction","position":2},{"hierarchy":{"lvl1":"Introduction"},"content":"\n\nThe notebook demonstrates the use of aireo_lib, a python library created as a part of the \n\nAIREO (Artificial Intelligence Ready Earth Observation training datasets) project. The project aims to make EO datasets easily accessible for the ML (Machine Learning) community. As such, AIREO specifications (shorthand specs) which define metadata elements to be included with the training dataset are proposed, supplemented by a best-practices document which suggests how to fill those metadata elements. Finally, the library takes all into account and implements specs, best-practices and offers an easy-to-use pythonic interface bridging the gap between EO and ML community.\n\nTherefore, this notebook is divided into two sections, one for the training dataset creator (usually from the EO community) and the other for its user (usually from the ML community). The structure of the notebook is the following:\n\nFor Creator\n\nCreate a \n\nSTAC catalog object using the library\n\nPopulate metadata elements prescribed by the AIREO specs\n\nGenerate a STAC metadata directory using the library\n\nCheck AIREO compliance level and metadata completeness\n\nFor User\n\nCreate a training dataset object as defined in the library using only the STAC metadata\n\nGet example instances from the object and other dataset variables like the number of instances, etc.\n\nUse library’s functions to plot the data\n\nInvestigate statistics using the library\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#introduction","position":3},{"hierarchy":{"lvl1":"Introduction","lvl4":"About the training dataset"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#about-the-training-dataset","position":4},{"hierarchy":{"lvl1":"Introduction","lvl4":"About the training dataset"},"content":"The CAP (Common Agricultural Policy) dataset, contains crop fields in Austria with different crop types. We have divided all of Austria in rectangular AOIs (Area if Interests) and downloaded Sentinel 2 images at 10 m resolution for each of those, they have been saved as geotiff files. The field shapes and the crop types have been converted to raster masks over these Sentinel 2 images, with each crop denoted by a different number, these are also stored as geotiffs. Only top 10 crop types which occupied almost 85% of the area are used. Hope this information will help you getting started and more can be found in various metadata elements below.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#about-the-training-dataset","position":5},{"hierarchy":{"lvl1":"Dataset Creator"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#dataset-creator","position":6},{"hierarchy":{"lvl1":"Dataset Creator"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#dataset-creator","position":7},{"hierarchy":{"lvl1":"Dataset Creator","lvl2":"AIREO STAC Catalog basics"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#aireo-stac-catalog-basics","position":8},{"hierarchy":{"lvl1":"Dataset Creator","lvl2":"AIREO STAC Catalog basics"},"content":"\n\nThe AIREO specs propose a hierarchical structure for STAC metadata. It is a two level structure where the dataset is represented by a collection of AOIs (Area Of Interests), hence, the dataset and AOI being the two levels.\n\nAt the dataset level we have a dataset catalog whose metadata elements are the core elements proposed in the AIREO spec. In addition to it, the common metadata elements across each AOI are also at the dataset level, which we shall call root level henceforth. Here, for each data variable there is a separate json which is a STAC Item by definition and is named using the field_schema metadata element. Additionally, there is also a datasheet file in markdown format at the root level which contains human readable information about the key elements of the dataset.\n\nEach AOI has a separate folder within the root level. And in each AOI folder there is a STAC collection representing that AOI and additional json files for each data variable. The additional json files here too, are STAC Items and follow a similar naming convention to the ones at the root level. The assets for each AOI, i.e. the files containing actual data are also in the folder.\n\nThe diagram below summarises this hierarchical structure:Root level (dataset)\n│\n│   DatasetCatalog.json\n│   datasheet.md\n│   references_output1.json\n│   features_input1.json\n│   ...\n│\n│\n└───AOI 1\n│      1.json (AOI Collection)\n│      feature_input1.json\n│      reference_output1.json\n│      <reference_asset>\n│      <feature_asseet>\n│   \n│   \n└───AOI 2\n│      ...\n│   \n│\n└───AOI 3\n│      ...\n│   \n...     \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#aireo-stac-catalog-basics","position":9},{"hierarchy":{"lvl1":"Dataset Creator","lvl2":"Creating a STAC catalog with aireo_lib"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#creating-a-stac-catalog-with-aireo-lib","position":10},{"hierarchy":{"lvl1":"Dataset Creator","lvl2":"Creating a STAC catalog with aireo_lib"},"content":"The aireo_lib library makes it easier to generate the STAC metadata directory as defined above. Some of the useful functionalities in the library are:\n\nDefine python dictionaries for metadata at the root level and use a simple function to add it to the STAC catalog. The library validates the data automatically when it is added.\n\nSimilarly, python dictionaries can be defined for each AOI and are also validated automatically.\n\nLinks and assets for all the json files are automatically generated.\n\nDatasheet is also generated automatically.\n\nThe directory structure is created by the library and assets copied to their respective locations in the hierarchy.\n\nEvaluating metadata completeness and compliance level.\n\nFollow the code and comments below to understand the steps needed to generate STAC metadata with the library.\n\nimport aireo_lib.core\nimport os\nimport json\nimport numpy as np\nfrom osgeo import gdal\nfrom tqdm.notebook import tqdm\nfrom shapely import geometry\nimport shutil\nimport rioxarray\nimport xarray as xr\nfrom pathlib import Path\n\n\n# Creating an empty STAC Catalog object to add metadata to\n\nnew_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog()\n\n\n# Creating a list of AOIs in the TDS\n\nreference_path = os.environ['EDC_PATH']+'/data/CAP/dataset/cap_tiff_mask'\naoi_ids = [int(i.replace('.tif','').replace('patch_mask_','')) for i in os.listdir(reference_path) if '.tif' in i]\nprint(aoi_ids)\n\n# A function to get train, validation and test splits of the dataset which can be recorded in the root Catalog\ndef get_train_val_test_dict():\n    patches = [int(i.replace('patch_mask_','').replace('.tif','')) for i in os.listdir(os.environ['EDC_PATH']+'/data/CAP/dataset/cap_tiff_mask') if 'mask' in i]\n    patches.sort()\n    # 15% of the AOIs for test and validation split each and the remaning 70% for training\n    dim = int(len(patches)*0.15)\n    splits = {}\n    splits['test_aois'] = patches[:dim]\n    splits['val_aois'] = patches[-dim:]\n    splits['train_aois'] = patches[dim:-dim]\n    return splits\n\n# Creating root Catalog metadata dictionary. These are the CoreElements of AIREO spec.\n\ntds_root_core_metadata_d = {}\ntds_root_core_metadata_d['aireo_version'] = \"0.0.1-alpha.1\"\ntds_root_core_metadata_d['title'] = \"Fields with crop types from Austria, 2019\"\ntds_root_core_metadata_d['description'] = \"The dataset contains the fields in Austria (as recorded in 2019) with their shapes stored as polygons and the crop type that was grown in the fields. Accompanied with the dataset are satellite images from sentinel 2 with fields as masks over the image. The masks of different crop types have a different number as label.\"\ntds_root_core_metadata_d['created'] = None\ntds_root_core_metadata_d['license_url_list'] = ['https://creativecommons.org/licenses/by/4.0/deed.de, https://creativecommons.org/licenses/by-sa/3.0/igo/legalcode']\ntds_root_core_metadata_d['license'] = \"Various (CC-BY-4.0, Creative Commons CC BY-SA 3.0 IGO)\"\ntds_root_core_metadata_d[\"providers_name\"]= \"[Agricultural Market Austria, Sentinel Hub, AIREO]\"\ntds_root_core_metadata_d[\"providers_description\"] = \"Agricultural Market Austria publsihed the data on field shapes and crop types grown in them. AIREO network downloaded the corresponding satellite imagery for the fields and created masks. AIREO network also created this metadata.\"\ntds_root_core_metadata_d[\"providers_role\"] = {'Sentinel Hub': [\"licensor\", \"producer\"], 'AIREO':[\"producer\", \"processor\" , \"host\"],'Agricultural Market Austria':[\"producer\", \"processor\" ]}\ntds_root_core_metadata_d[\"providers_url\"]= {'Agricultural Market Austria':'https://www.ama.at/Intro.', 'Sentinel Hub': 'https://www.sentinel-hub.com/', \n                        'AIREO': 'https://aireo.net/'}                         \ntds_root_core_metadata_d['id'] =  \"970460aa-7835-11eb-9439-0242ac130002\"\ntds_root_core_metadata_d['type'] = \"Collection\"\ntds_root_core_metadata_d['stac_version'] = '1.0.0-beta.2'\ntds_root_core_metadata_d['provenance'] = 'The shapes of fields and the crop type were taken from the data provided by Agricultural Market Austria (see providers) and the accompanying satellite images were provided by Sentinel Hub (see links in providers), as Sentinel 2 images.'\ntds_root_core_metadata_d['purpose'] = \"The dataset has sentinel 2 images with a mask of fields with 10 different crop types. Each crop type is denoted by a unique identifier. The main prupose for this creating this dataset was to serve as a pilot use case for AIREO specifications. But it can also be used for crop type indentification from satellite images or parcel identification.\"\ntds_root_core_metadata_d['tasks'] =  ['Semantic Segmentation']\ntds_root_core_metadata_d['collection_mechanism'] = \"The way the underlying data about fields was collected hasn't been mentioned in the source of that data. The satellite images were acquired by optical sensors aboard Sentinel 2 satellite.\"\ntds_root_core_metadata_d['data_preprocessing'] = {'type': \"free-text\", 'recipe':'The data was collated using two sources of data: field and crop type from Agricultural Market Austria and Sentinel 2 images from sentinel hub. The process of combining these two datasets by downloading satellite image and overlaying it with a mask of different crop types and fields was done through eo-learn library. \\\nOnly satellite images with cloud cover less than 1% were considered and the dates for the images were chosen to be in late 2019. Also, only the top 10 crop types occupying most area (85% of the total area) were considered from 214 present in the original dataset.'}\ntds_root_core_metadata_d['funding_info'] = \"The AIREO project is funded by ESA, the collection of data on fields and crop types were \\\nare funded by Agricultural Market Austria and the satellite imagery used is through funds from ESA's Sentinel programme.\"\ntds_root_core_metadata_d['field_schema'] = {'features': {'input1': ['georeferenced_eo_image']}, 'references': {'output1': ['reference_data']}}\ntds_root_core_metadata_d['example_definition'] = \"An example instance for training a machine learning model would be one satellite image with various bands as predicitve features and the mask as reference data. This can be used for predicting various fields with crop types or for field parcel identification.\"\ntds_root_core_metadata_d['example_window_size'] = 256\ntds_root_core_metadata_d['example_stride'] = 26\n                                                 \ntds_root_core_metadata_d['data_completeness'] = \"The data has 10 crop types with fields only from Austria. \\\nThe names of these crops do not follow any standard and are in German and these might not be the only crop types available. There is no information whether these are all the fields in Austria or there are more not included in the dataset. The scenario where multiple crops are grown in a field over the year is also not addressed. There is no unique time for when the crop type for each field was ascertained during 2019.\"\ntds_root_core_metadata_d['data_split'] = f\"The  split  should  reflect  a  similar  distribution  of  field  types as in the whole dataset.  It  is  not  necessary  to  match \\\ndistributions of all these 10 crop types but only a few ones occupying most area. \\n {get_train_val_test_dict()}\"\ntds_root_core_metadata_d['data_sharing'] = \"The dataset will be shared on Euro Data Cube (EDC) and can be accessed through jupyter notebooks on EDC.\"\ntds_root_core_metadata_d['compliance_level'] = 'level 1'\ntds_root_core_metadata_d['links'] =  []\n\n\n#Common metadata dictionary for predictive feature variable\n\ng_feature_metadata_d = {}\ng_feature_metadata_d['type'] = \"Feature\"\ng_feature_metadata_d['stac_version'] = \"1.0.0-beta.2\"\ng_feature_metadata_d['stac_extensions'] = [\"georeferenced_eo_image\"]\ng_feature_metadata_d['id'] = f'common_predictive_feature_metadata'\ng_feature_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\nwith open(os.environ['EDC_PATH']+'/data/CAP/dataset/austria.geojson','r') as austria:\n    shape = json.load(austria)\n# The geometry accepts pydantic Geometry type, which is a dictionary. See pydantic's documentation for more info\ng_feature_metadata_d['geometry'] = shape['features'][0]['geometry']\ngeom = np.array(shape['features'][0]['geometry']['coordinates'][0])\nxs = geom[:,0]\nys = geom[:,1]\ng_feature_metadata_d['bbox'] = [min(xs),min(ys), max(xs), max(ys)]\ng_feature_metadata_d['properties'] = {}\ng_feature_metadata_d[\"properties\"]['parent_identifier'] = \"970460aa-7835-11eb-9439-0242ac130002\"\ng_feature_metadata_d[\"properties\"]['product_type']  = \"Null\"\ng_feature_metadata_d[\"properties\"]['processing_level'] = 1.0\ng_feature_metadata_d[\"properties\"]['platform_short_name'] = \"Sentinel 2\"\ng_feature_metadata_d[\"properties\"]['sensor_type'] = \"OPTICAL\"\ng_feature_metadata_d[\"properties\"]['sensor_resolution'] = \"10m\"\ng_feature_metadata_d[\"properties\"]['gsd'] = 10\ng_feature_metadata_d['properties']['datetime'] = \"2019\"\ng_feature_metadata_d['properties']['acquisition_date'] = \"2019\"\ng_feature_metadata_d[\"properties\"]['identifier'] = f'common_predictive_feature_metadata'\ng_feature_metadata_d['links'] = []\ng_feature_metadata_d[\"assets\"] =  {}\nfeature_metadata_d = {}\nfeature_metadata_d['input1'] = g_feature_metadata_d\n\n#Common metadata dictionary for reference data variable\n\ng_ref_data_metadata_d = {}\n\ng_ref_data_metadata_d['id'] = f'common_reference_metadata'\ng_ref_data_metadata_d['type'] = \"Feature\"\ng_ref_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\ng_ref_data_metadata_d['stac_extensions'] = [\"reference_data\"]\ng_ref_data_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\nwith open(os.environ['EDC_PATH']+'/data/CAP/dataset/austria.geojson','r') as austria:\n    shape = json.load(austria)\n# The geometry accepts pydantic Geometry type, which is a dictionary. See pydantic's documentation for more info\ng_ref_data_metadata_d['geometry'] = shape['features'][0]['geometry']\ngeom = np.array(shape['features'][0]['geometry']['coordinates'][0])\nxs = geom[:,0]\nys = geom[:,1]\ng_ref_data_metadata_d['bbox'] = [min(xs),min(ys), max(xs), max(ys)]\ng_ref_data_metadata_d['properties'] = {}\ng_ref_data_metadata_d[\"properties\"]['name'] = \"Reference metadata\"\ng_ref_data_metadata_d['properties']['description'] = \"The reference data consists of masks of different field types as given in the 2019 dataset by Agricultural Market Austria. Originally, it was  meant for processing of CAP subsidies but can be used for segmentation in the current form.\"\ng_ref_data_metadata_d['properties']['type'] = \"Raster\"\ng_ref_data_metadata_d['properties']['task'] = \"Semantic Segmentation\"\ng_ref_data_metadata_d['properties']['classes'] = [{'ALM FORAGE AREA': 990, 'MOWING MEADOW / PASTURE THREE AND MORE USES': 717,\n                   'WINTER SOFT WHEAT': 138, 'MOWING MEADOW / PASTURE TWO USES': 716,\n                   'GRAIN CORN': 105, 'WINTER BARLEY': 110, 'SILO CORN': 109, 'PERMANENT PASTURE': 715,\n                   'SOYBEANS': 308, 'HAT WILLOW': 707, 'BACKGROUND': 0}]\ng_ref_data_metadata_d['properties']['overviews'] = [\"They are two overviews total area covered by each field type anda and total number of each field types. Total area covered in hectares ,\\\n    990: 922491.316277, 717: 495099.341968, 138 : 245556.123391, 716: 212395.276761, 105: 196645.398665, 110: 100947.839432,\\\n    109: 85574.511958, 715: 77478.090196, 308: 69023.96593, 707: 62440.674009 \\\n    total number of fields with the crop type, 717: 403540, 716: 315165, 990: 237072, 771: 120610, 351: 120479, 138: 120310, 105: 112095, 707: 110882, 715: 89674,\\\n    901: 81586\"]\ng_ref_data_metadata_d['properties']['collection_methods'] = \"The reference data was collected by Agricultural Market Austria for the year 2019 for Common Agriculture Practices for EU to process agriculture subsidies, etc. The exact method for ground surveys was not clearly documented and the only info available is that \\\"all field uses were recorded by the applicants\\\".\"\ng_ref_data_metadata_d['properties']['data_preprocessing'] = {'type': 'free-text', 'recipe': \"The polygons in the original reference data were converted into rasters overlayed on satellite image of 10m resoltuion. \\\nOnly the top 10 crop types occupying most area (85% of total) were used and others were filtered out and labelled as background.\"}\ng_ref_data_metadata_d['properties']['CRS'] = 'EPSG:32631'\ng_ref_data_metadata_d['properties']['time_range'] = '2019'\ng_ref_data_metadata_d[\"properties\"]['value'] = 0\ng_ref_data_metadata_d[\"properties\"]['datetime'] = \"2019\"\ng_ref_data_metadata_d['links'] = []\ng_ref_data_metadata_d[\"assets\"] = {}\n\nref_metadata_d = {}\nref_metadata_d['output1'] = g_ref_data_metadata_d\n\n# Add TDS root Catalog and common Item metadata to the catalog object. \n# Note, that it returns True, if the data isn't validated it will return False\n\nnew_tds_ctl_o.add_tds_root_metadata(tds_root_core_metadata_d, feature_metadata_d, ref_metadata_d)\n\n\n# Adding metadata for each AOI\n\nfor aoi_id in tqdm(aoi_ids[:7]):\n        \n    # Dictionary for each AOI collection metadata\n    aoi_metadata_d = {}\n    aoi_metadata_d['type'] = \"Collection\"\n    aoi_metadata_d[\"id\"] = f\"{aoi_id}\"\n    aoi_metadata_d['stac_version'] = '1.0.0-beta.2'\n    aoi_metadata_d['title'] = f\"{aoi_id} Collection\"\n    aoi_metadata_d['description'] = \"Each AOI contains satellite images with crop masks.\"\n    aoi_metadata_d[\"license\"] = \"Various (CC-BY-4.0, Creative Commons CC BY-SA 3.0 IGO)\"\n    mask = gdal.Open(os.path.join(reference_path, f'patch_mask_{aoi_id}.tif'))\n    geoTransform = mask.GetGeoTransform()\n    minx = geoTransform[0]\n    maxy = geoTransform[3]\n    maxx = minx + geoTransform[1] * mask.RasterXSize\n    miny = maxy + geoTransform[5] * mask.RasterYSize\n    aoi_metadata_d[\"bbox\"]= [minx, miny, maxx, maxy]\n    # The geometry accepts pydantic Geometry type, which is a dictionary. See pydantic's documentation for more info\n    aoi_metadata_d['geometry'] = geometry.mapping(geometry.box(*aoi_metadata_d[\"bbox\"]))\n    aoi_metadata_d[\"extent\"] = {\"spatial\" : {\"bbox\":[[minx, miny, maxx, maxy]]}, \n                      \"temporal\": {\"interval\":[['2019']]}}\n    aoi_metadata_d['time_range'] = '2019'\n    aoi_metadata_d['links'] = []\n    aoi_metadata_d[\"assets\"] = {}\n    \n    \n    # Dictionary for each AOI's predictive feature variable metadata\n    aoi_feature_metadata_d = {}\n    aoi_feature_metadata_d['id'] = f'predictive_feature_metadata_AOI_{aoi_id}'\n    aoi_feature_metadata_d['type'] = \"Feature\"\n    aoi_feature_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n    aoi_feature_metadata_d['stac_extensions'] = [\"georeferenced_eo_image\"]\n    aoi_feature_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n    aoi_feature_metadata_d['bbox'] = aoi_metadata_d[\"bbox\"]\n    aoi_feature_metadata_d['geometry'] = aoi_metadata_d[\"geometry\"]\n    aoi_feature_metadata_d['properties'] = {}\n    aoi_feature_metadata_d[\"properties\"]['parent_identifier'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n    aoi_feature_metadata_d[\"properties\"]['product_type']  = \"Null\"\n    aoi_feature_metadata_d[\"properties\"]['processing_level'] = 1.0\n    aoi_feature_metadata_d[\"properties\"]['platform_short_name'] = \"Sentinel 2\"\n    aoi_feature_metadata_d[\"properties\"]['sensor_type'] = \"OPTICAL\"\n    aoi_feature_metadata_d[\"properties\"]['sensor_resolution'] = \"10m\"\n    aoi_feature_metadata_d[\"properties\"]['gsd'] = 10\n    aoi_feature_metadata_d[\"properties\"]['CRS'] = 'EPSG:32631'\n    aoi_feature_metadata_d[\"properties\"]['identifier'] = str(aoi_id)\n    aoi_feature_metadata_d[\"properties\"]['acquisition_date'] = '2019'\n    aoi_feature_metadata_d[\"properties\"]['datetime'] = \"2019\"\n    aoi_feature_metadata_d['links'] = []  \n    aoi_feature_metadata_d[\"assets\"] = {}\n\n    aoi_feature_d = {}\n    aoi_feature_d['input1'] = aoi_feature_metadata_d\n    \n    # Dictionary for each AOI's reference variable metadata\n    aoi_ref_data_metadata_d = {}\n    aoi_ref_data_metadata_d['type'] = \"Feature\"\n    aoi_ref_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n    aoi_ref_data_metadata_d['stac_extensions'] = [\"reference_data\"]\n    aoi_ref_data_metadata_d['id'] = f'reference_metadata_AOI_{aoi_id}'\n    aoi_ref_data_metadata_d['collection'] = \"970460aa-7835-11eb-9439-0242ac130002\"\n    aoi_ref_data_metadata_d[\"bbox\"]= aoi_metadata_d[\"bbox\"]\n    aoi_ref_data_metadata_d['geometry'] = aoi_metadata_d[\"geometry\"]\n    aoi_ref_data_metadata_d[\"properties\"] = {}\n    aoi_ref_data_metadata_d['properties']['classes'] = [{'ALM FORAGE AREA': 990, 'MOWING MEADOW / PASTURE THREE AND MORE USES': 717,\n                       'WINTER SOFT WHEAT': 138, 'MOWING MEADOW / PASTURE TWO USES': 716,\n                       'GRAIN CORN': 105, 'WINTER BARLEY': 110, 'SILO CORN': 109, 'PERMANENT PASTURE': 715,\n                       'SOYBEANS': 308, 'HAT WILLOW': 707, 'BACKGROUND': 0}]\n    aoi_ref_data_metadata_d[\"properties\"]['name'] = str(aoi_id)+ \" Reference metadata\"\n    aoi_ref_data_metadata_d['properties']['description'] = \"The reference data consists of masks of different field types as given in the 2019 dataset by Agricultural Market Austria. Originally, it was  meant for processing of CAP subsidies but can be used for segmentation in the current form.\"\n    aoi_ref_data_metadata_d['properties']['type'] = \"Raster\"\n    aoi_ref_data_metadata_d['properties']['task'] = \"Semantic Segmentation\"\n    aoi_ref_data_metadata_d['properties']['CRS'] = 'EPSG:32631'\n    aoi_ref_data_metadata_d['properties']['time_range'] = '2019'\n    aoi_ref_data_metadata_d[\"properties\"]['value'] = 0\n    aoi_ref_data_metadata_d['properties'][\"orientation\"]= \"null\"\n    aoi_ref_data_metadata_d[\"properties\"]['datetime'] = \"2019\"\n    aoi_ref_data_metadata_d['links'] = []\n    aoi_ref_data_metadata_d[\"assets\"] = {}\n    aoi_ref_d = {}\n    aoi_ref_d['output1'] = aoi_ref_data_metadata_d\n    \n    # Defining path to assets to copy over to AOI directory\n    aoi_ref_data_asset_path_d = {'output1':os.path.join(os.environ['EDC_PATH']+'/data/CAP/dataset/cap_tiff_mask', f'patch_mask_{aoi_id}.tif')}\n    aoi_feature_asset_path_d = {'input1':os.path.join(os.environ['EDC_PATH']+'/data/CAP/dataset/cap_tiff', f'patch_{aoi_id}.tif')}\n    \n    # Add each AOI's metadata to catalog object. Note, each AOI is also validated and returns True.\n    print(new_tds_ctl_o.add_aoi_metadata(aoi_metadata_d=aoi_metadata_d,\n                                   aoi_feature_metadata_d=aoi_feature_d,\n                                   aoi_ref_data_metadata_d=aoi_ref_d,\n                                   aoi_feature_asset_path_d=aoi_feature_asset_path_d,\n                                   aoi_ref_data_asset_path_d=aoi_ref_data_asset_path_d))\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#creating-a-stac-catalog-with-aireo-lib","position":11},{"hierarchy":{"lvl1":"Dataset Creator","lvl4":"stac_generated folder creation","lvl2":"Creating a STAC catalog with aireo_lib"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#stac-generated-folder-creation","position":12},{"hierarchy":{"lvl1":"Dataset Creator","lvl4":"stac_generated folder creation","lvl2":"Creating a STAC catalog with aireo_lib"},"content":"\n\nPrior to this step, you will need to create a folder called ‘biomass_stac_generated’ in your environment and leave it empty\n\n# If a STAC catalog has already been generated remove it before re generating the catalog below\n\nimport shutil\nstac_generated_path = os.path.join('./cap_stac_generated')\nif os.path.exists(stac_generated_path):\n    shutil.rmtree(stac_generated_path)\n\n#import shutil\n#shutil.rmtree(os.environ['EDC_PATH']+'/data/CAP/cap_stac_generated')\n\n# Writing the STAC metadata. The directory along with its structure is generated, with correct links and assets defined. \n#A datasheet is also generated\n\ncatalog_fn_w_path = './cap_stac_generated/TDS.json'\nnew_tds_ctl_o.write_TDS_STAC_Catalog(catalog_fn_w_path)\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#stac-generated-folder-creation","position":13},{"hierarchy":{"lvl1":"Dataset Creator","lvl4":"Checking AIREO compliance level","lvl2":"Creating a STAC catalog with aireo_lib"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#checking-aireo-compliance-level","position":14},{"hierarchy":{"lvl1":"Dataset Creator","lvl4":"Checking AIREO compliance level","lvl2":"Creating a STAC catalog with aireo_lib"},"content":"\n\n# Checks the compliance level of the metadata as defined in AIREO spec.\n\ncatalog_fn_w_path = './cap_stac_generated/TDS.json'\nnew_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog.from_TDSCatalog(catalog_fn_w_path)\nnew_tds_ctl_o.compute_compliance_level()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#checking-aireo-compliance-level","position":15},{"hierarchy":{"lvl1":"Dataset Creator","lvl4":"Checking metadata completeness","lvl2":"Creating a STAC catalog with aireo_lib"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#checking-metadata-completeness","position":16},{"hierarchy":{"lvl1":"Dataset Creator","lvl4":"Checking metadata completeness","lvl2":"Creating a STAC catalog with aireo_lib"},"content":"\n\nnew_tds_ctl_o.report_metadata_completeness()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#checking-metadata-completeness","position":17},{"hierarchy":{"lvl1":"Dataset Creator","lvl3":"Defining AOI class","lvl2":"Creating a STAC catalog with aireo_lib"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#defining-aoi-class","position":18},{"hierarchy":{"lvl1":"Dataset Creator","lvl3":"Defining AOI class","lvl2":"Creating a STAC catalog with aireo_lib"},"content":"For enabling many other functionalities of the library the dataset creator needs to create an AOI class which defines how the asset files are loaded, can return an example and length of the dataset. The blueprint is given in the library by the AOIDataset class which this class should inherit. In the future, it is planned to automate the creation of the AOI class also.\n\n#should inherit AOIDataset\n\nfrom aireo_lib.core import AOIDataset\n\nclass AOIDatasetCAP(AOIDataset):\n\n    def __init__(self, AOI_STAC_collection, TDS_STAC_catalog):\n\n        self.AOI_STAC_collection = AOI_STAC_collection\n        self.TDS_STAC_catalog = TDS_STAC_catalog\n        self.stride = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_stride']\n        self.window_size = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_window_size']\n        \n\n        _first = True\n        \n        for eo_feature in self.AOI_STAC_collection.aoi_all_field_metadata.features:\n            aoi_feature_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.features[eo_feature].data_asset_w_path\n            self.feature_var_name = 'features_'+eo_feature\n            if _first:\n                self.data = rioxarray.open_rasterio(aoi_feature_asset_path_d).to_dataset(name=self.feature_var_name) \n                _first = False\n            else:\n                tmp = rioxarray.open_rasterio(aoi_feature_asset_path_d)\n                self.data[self.feature_var_name] = tmp\n                self.data[self.feature_var_name].values = tmp.values\n                \n        aoi_name = aoi_feature_asset_path_d.split('/')[-1].replace('patch_','').replace('.tif','')\n        for reference_data in self.AOI_STAC_collection.aoi_all_field_metadata.references:\n            aoi_ref_data_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.references[reference_data].data_asset_w_path\n            self.ref_var_name = 'references_'+reference_data\n            if _first:\n                self.data = rioxarray.open_rasterio(aoi_ref_data_asset_path_d).to_dataset(name = self.ref_var_name)\n                _first = False\n            else:\n                tmp = rioxarray.open_rasterio(aoi_ref_data_asset_path_d).rename({'band':'mask'})\n                self.data[self.ref_var_name] = tmp\n                self.data[self.ref_var_name].values = tmp.values\n                self.data.attrs = tmp.attrs\n\n\n    def __getitem__(self, index):\n       \n        along_x = int((self.data[self.feature_var_name].shape[1] - self.window_size)/self.stride)\n        along_y = int((self.data[self.feature_var_name].shape[-1] - self.window_size)/self.stride)\n        x1 = self.stride * int(index % along_x)\n        y1 = self.stride * int(index / along_y)\n        x2 = x1 + self.window_size\n        y2 = y1 + self.window_size\n        \n        #store feature and reference data in same xarray, name the axes\n        ds = self.data.isel(band=[0,1,2,3], mask=[0], x=slice(x1,x2), y=slice(y1, y2))        \n        return ds\n    \n\n    def __len__(self):\n        \n        along_x = int((self.data[self.feature_var_name].shape[1] - self.window_size)/self.stride) + 1\n        along_y = int((self.data[self.feature_var_name].shape[-1] - self.window_size)/self.stride) + 1\n        return along_x * along_y\n    \n    def get_length(self):\n        return self.__len__()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#defining-aoi-class","position":19},{"hierarchy":{"lvl1":"Dataset Creator","lvl2":"Dataset user"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#dataset-user","position":20},{"hierarchy":{"lvl1":"Dataset Creator","lvl2":"Dataset user"},"content":"\n\nThe user of the dataset can access most of what is offered by the dataset using just its STAC catalog. All he/she needs to do is create a dataset object by passing to it the path to the STAC catalog at the root level. The library automatically reads in all the metadata and loads the assets into the dataset object. Some of the functionalities that a dataset object offers through aireo_lib are:\n\nCan access an example instance from the dataset which serves as an input-output pair for a Machine Learning algorithm.\n\nXarrays are used to store data and give examples.\n\nDataset can also return each AOI independently\n\nOffer basic plotting functions for each variable in the dataset and AOI.\n\nSome statistics can also be calculated at both the AOI level and whole dataset level.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#dataset-user","position":21},{"hierarchy":{"lvl1":"Dataset Creator","lvl3":"Parsing the dataset by creating a dataset object","lvl2":"Dataset user"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#parsing-the-dataset-by-creating-a-dataset-object","position":22},{"hierarchy":{"lvl1":"Dataset Creator","lvl3":"Parsing the dataset by creating a dataset object","lvl2":"Dataset user"},"content":"\n\nfrom aireo_lib.core import EOTrainingDataset\n\ncap_tds_ctl_fn = Path(os.environ['EDC_PATH']+'/data/CAP/cap_stac_generated/TDS.json')\n\neo_tds_obj = EOTrainingDataset(cap_tds_ctl_fn, AOIDatasetCAP)\n\n\n# Getting the number of instances/examples in the dataset\n\nlen(eo_tds_obj)\n\n\n# Accessing an example through index\n\neo_tds_obj[-5]\n\n# Accessing one variable of the instance\n\neo_tds_obj[-5]['references_output1'].values\n\n\n# Get a subset of examples\n\neo_tds_obj.get_subset([19,1121, 2000, 2345])\n\n# Access each AOI independently\n\naoi_objs = eo_tds_obj.get_aoi_datasets()\nlen(aoi_objs[1])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#parsing-the-dataset-by-creating-a-dataset-object","position":23},{"hierarchy":{"lvl1":"Dataset Creator","lvl3":"Plotting functions in aireo_lib","lvl2":"Dataset user"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#plotting-functions-in-aireo-lib","position":24},{"hierarchy":{"lvl1":"Dataset Creator","lvl3":"Plotting functions in aireo_lib","lvl2":"Dataset user"},"content":"\n\nfrom aireo_lib.plotting import EOTDSPlot as aireo_viz\n\n\n# Basic plot of all the variables in the dataset, returns a dict of matplotlib figures\n\nplot_d = aireo_viz.plot_example(EOTDS=eo_tds_obj, \n                       ex_index=-50, \n                       field_names=['features_input1', 'references_output1'])\nplot_d\n\n\n%matplotlib inline\n\nplot_d['references_output1']\n\nplot_d['features_input1']\n\n\naoi_obj = eo_tds_obj.get_aoi_dataset(2)\n\n# Basic plot of all the variables in an AOI, returns a dict of matplotlib figures\n\naoi_plots_d = aireo_viz.plot_aoi_dataset(aoi_obj)\naoi_plots_d\n\naoi_plots_d['references_output1']\n\naoi_plots_d['features_input1']\n\n# Plotting different AOIs on the map of the world\n\naireo_viz.map_aois(eo_tds_obj)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#plotting-functions-in-aireo-lib","position":25},{"hierarchy":{"lvl1":"Dataset Creator","lvl3":"Statistics functions in aireo_lib","lvl2":"Dataset user"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#statistics-functions-in-aireo-lib","position":26},{"hierarchy":{"lvl1":"Dataset Creator","lvl3":"Statistics functions in aireo_lib","lvl2":"Dataset user"},"content":"\n\nfrom aireo_lib.statistics import EOTDSStatistics as stats\n\n\n# Common reference data statistics llike number of samples of each class in the whole dataset and each AOI\n\nstats.reference_data_statistics(eo_tds_obj)\n\n# Common feature data statistics like mean, standard deviation, min and max for each channel in each AOI\n\nstats.feature_data_statistics(eo_tds_obj)\n\nstats.dataset_statistics(eo_tds_obj)\n\n# Metadata completeness statistics also included\n\nstats.metadata_statistics(eo_tds_obj)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#statistics-functions-in-aireo-lib","position":27},{"hierarchy":{"lvl1":"Dataset Creator","lvl2":"ML model"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#ml-model","position":28},{"hierarchy":{"lvl1":"Dataset Creator","lvl2":"ML model"},"content":"We try to demonstrate here how the library interfaces with existing ML libraries. This is an over simplistic implementation of resnet50 from pytorch to show this functionality of our library. We train the model for a few epochs with a few instances from our dataset object. The choices made here like loss function, optimizer, training indexes, etc. are only meant for demonstration and are in no way recommended and do not claim to be sensible choices.\n\nimport torchvision\nimport torch\n\n# Creating the model object from torchvision\n\nmodel = torchvision.models.segmentation.fcn_resnet50(pretrained=False, progress=True, num_classes=11)\n\n# Defining a loss function and optimizer\n\ndef loss_fn(pred, truth):\n    pred = np.amax(pred.detach().numpy(),1)\n    return torch.tensor(sum(abs(pred-truth).flatten()), requires_grad=True)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# Generating a few training instances from the dataset object\n\nimport random\ntrain_indexes = random.choices(list(range(0, len(eo_tds_obj))),k=10)\ntrain_indexes\n\n# Training the model for a few epochs\n\nmodel.train()\nfor epoch in range(4):\n    print(f\"Epoch {epoch}\")\n    total_loss = 0\n    for train_idx in train_indexes:\n        optimizer.zero_grad()\n        \n        # Getting one training instance from the dataset object\n        instance = eo_tds_obj[train_idx]\n        \n        # As resnet50 accepts only 3-D inputs we use only the first three bands of our satellite image\n        train_input = torch.tensor(np.expand_dims(instance.features_input1.values[:3,:,:], axis=0))\n        \n        # Reference data becomes label for training\n        train_labels = instance.references_output1.values\n        \n        output = model.forward(train_input)\n        loss = loss_fn(output['out'], train_labels)\n        \n        loss.backward()\n        optimizer.step()\n        total_loss += loss\n    print('Total Running Loss:', loss.item())","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-cap#ml-model","position":29},{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7","position":0},{"hierarchy":{"lvl1":"Introduction"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[\"SH\"])\n\n!python3 -m pip install git+https://github.com/aireo-project/aireo_lib\n\n!python3 -m pip install shapely geopandas\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7","position":1},{"hierarchy":{"lvl1":"Introduction"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#introduction","position":2},{"hierarchy":{"lvl1":"Introduction"},"content":"The notebook demonstrates the use of aireo_lib , a python library created as a part of the AIREO (Artificial Intelligence Ready Earth Observation training datasets) project. The project aims to make EO datasets easily accessible for the ML (Machine Learning) community. As such, AIREO specifications (shorthand specs) which define metadata elements to be included with the training dataset are proposed, supplemented by a best-practices document which suggests how to fill those metadata elements. Finally, the library takes all into account and implements specs, best-practices and offers an easy-to-use pythonic interface bridging the gap between EO and ML community.\n\nTherefore, this notebook is divided into two sections, one for the training dataset creator (usually from the EO community) and the other for its user (usually from the ML community). The structure of the notebook is the following:\n\nFor Creator\n\nCreate a \n\nSTAC catalog object using the library\n\nPopulate metadata elements prescribed by the AIREO specs\n\nGenerate a STAC metadata directory using the library\n\nCheck AIREO compliance level and metadata completeness\n\nFor User\n\nCreate a training dataset object as defined in the library using only the STAC metadata\n\nGet example instances from the object and other dataset variables like the number of instances, etc.\n\nUse library’s functions to plot the data\n\nInvestigate statistics using the library\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#introduction","position":3},{"hierarchy":{"lvl1":"Introduction","lvl3":"About the training dataset"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#about-the-training-dataset","position":4},{"hierarchy":{"lvl1":"Introduction","lvl3":"About the training dataset"},"content":"SpaceNet7 is a collection of satellite image time series covering 100 different locations in a diverse range of environments. It also includes a set of polygons for each image marking out the building footprints. The image data was collected by Planet satellites at an interval of roughly one month for each location for a period of two years. This is not compeltely consistent across different locations. The data was then manually annotated by a team at SpaceNet to produce the building footprint polygons. The full data from 60 areas was released as a public dataset.\n\nWe have simplified the dataset slightly for the purpose of creating a pilot AIREO dataset. We have converted all building polygons to boolean raster masks, and have stored these and the images in netcdf files as time series of raster data, one for each location. We have also standardized image resolution across all locations. This notebook only makes use of 5 AOIs out of 60 for demonstration purposes.\n\nThis dataset can be used to train ML models for the task of automatic building detection in satellite images, and for the tracking of building development over time.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#about-the-training-dataset","position":5},{"hierarchy":{"lvl1":"AIREO STAC Catalog basics"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#aireo-stac-catalog-basics","position":6},{"hierarchy":{"lvl1":"AIREO STAC Catalog basics"},"content":"\n\nThe AIREO specs propose a hierarchical structure for STAC metadata. It is a two level structure where the dataset is represented by a collection of AOIs (Area Of Interests), hence, the dataset and AOI being the two levels.\n\nAt the dataset level we have a dataset catalog whose metadata elements are the core elements proposed in the AIREO spec. In addition to it, the common metadata elements across each AOI are also at the dataset level, which we shall call root level henceforth. Here, for each data variable there is a separate json which is a STAC Item by definition and is named using the field_schema metadata element. Additionally, there is also a datasheet file in markdown format at the root level which contains human readable information about the key elements of the dataset.\n\nEach AOI has a separate folder within the root level. And in each AOI folder there is a STAC collection representing that AOI and additional json files for each data variable. The additional json files here too, are STAC Items and follow a similar naming convention to the ones at the root level. The assets for each AOI, i.e. the files containing actual data are also in the folder.\n\nThe diagram below summarises this hierarchical structure:Root level (dataset)\n│\n│   DatasetCatalog.json\n│   datasheet.md\n│   references_output1.json\n│   features_input1.json\n│   ...\n│\n│\n└───AOI 1\n│      1.json (AOI Collection)\n│      feature_input1.json\n│      reference_output1.json\n│      <reference_asset>\n│      <feature_asseet>\n│   \n│   \n└───AOI 2\n│      ...\n│   \n│\n└───AOI 3\n│      ...\n│   \n...     \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#aireo-stac-catalog-basics","position":7},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#creating-a-stac-catalog-with-aireo-lib","position":8},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib"},"content":"The aireo_lib library makes it easier to generate the STAC metadata directory as defined above. Some of the useful functionalities in the library are:\n\nDefine python dictionaries for metadata at the root level and use a simple function to add it to the STAC catalog. The library validates the data automatically when it is added.\n\nSimilarly, python dictionaries can be defined for each AOI and are also validated automatically.\n\nLinks and assets for all the json files are automatically generated.\n\nDatasheet is also generated automatically.\n\nThe directory structure is created by the library and assets copied to their respective locations in the hierarchy.\n\nEvaluating metadata completeness and compliance level.\n\nFollow the code and comments below to understand the steps needed to generate STAC metadata with the library.\n\nimport aireo_lib.core\nimport os\nimport json\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom shapely import geometry\nimport shutil\nimport xarray as xr\nfrom pathlib import Path\nimport geopandas as gpd\n\n\n\n# Path to write the STAC root metadata file too\ncatalog_fn_w_path = os.environ['EDC_PATH']+'/data/SpaceNet7/sp7_stac/TDS.json'\n\n# Creating an empty STAC Catalog object\nnew_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog()\n\n# AOI list int the TDS\n\ndataset_path = os.environ['EDC_PATH']+'/data/SpaceNet7/Data/sp7_sample'\n\naoi_ids = [aoi_id for aoi_id in os.listdir(dataset_path) if aoi_id[0]!='.'][0:3]\n\n# Creating root metadata dictionary\n\ntds_root_core_metadata_d = {}\ntds_root_core_metadata_d['aireo_version'] = \"0.0.1-alpha.1\"\ntds_root_core_metadata_d['title'] = \"Images with buildings labelled covering short range of time for each AOI\"\ntds_root_core_metadata_d['description'] = \"Covers 60 areas of interest at 4m resolution with images at monthly intervals. Each image is annotated with polygons labelling buildings. Dataset allows for the monitioring and prediction of building development over time.\"\ntds_root_core_metadata_d['created'] = '2020-07-13'\ntds_root_core_metadata_d['license_url_list'] = 'https://creativecommons.org/licenses/by-sa/4.0/' \ntds_root_core_metadata_d['license'] = \"CC-BY-SA-4.0\"\ntds_root_core_metadata_d[\"providers_name\"]= \"[SpaceNet LLC]\"\ntds_root_core_metadata_d[\"providers_description\"] = \"Data gathered by Planet satellites, dataset then created by Spacenet \"\ntds_root_core_metadata_d[\"providers_roles\"] = {\"SpaceNet\":[\"processor\",\"host\",\"licensor\",\"producer\"], 'AIREO':[\"producer\", \"processor\" , \"host\"]}\ntds_root_core_metadata_d[\"providers_url\"]= {\"Spacenet\":\"https://spacenet.ai/\", \n                            'AIREO': 'https://aireo.net/'}                         \ntds_root_core_metadata_d['id'] =  \"706cf9e2-bd46-11eb-8529-0242ac130003\"\ntds_root_core_metadata_d['type'] = \"Collection\"\ntds_root_core_metadata_d['stac_version'] = '1.0.0-beta.2'\ntds_root_core_metadata_d['provenance'] = 'Data gathered from Planet satellites and annotatations produced by SpaceNet LLC'\ntds_root_core_metadata_d['purpose'] = \"Using semantic segmentation track buidling development over time. Segment individual images from each timestep then use this knowledge to track development over time for one AOI.\"\ntds_root_core_metadata_d['tasks'] =  ['Semantic Segmentation']\ntds_root_core_metadata_d['data_preprocessing'] = {'type':'free-text', 'recipe':'Original dataset included images from one AOI as seperate tiff files. We have combined these into one netcdf datacube for each AOI. The building labels were stored as polygons in the original dataset. We have converted to raster masks and have stored them in netcdf datacubes, one for each AOI.'}\ntds_root_core_metadata_d['funding_info'] = \"The AIREO project is funded by ESA. The underlying data was gathered by Planet, then annotated and released by SpaceNet for free use.\"\ntds_root_core_metadata_d['field_schema'] = {'features': {'input1': ['georeferenced_eo_data','georeferenced_eo_datacube']}, 'references': {'output1': ['reference_data']}}\ntds_root_core_metadata_d['example_definition'] = \"An individual example consists of a single image, and a raster mask representing the buildings visible in the image.\"\ntds_root_core_metadata_d['data_completeness'] = \"Dataset is sufficent for task and requires no external sources.\"\ntds_root_core_metadata_d['data_split'] = \"Recommend train/test/validation split of 40 AOIs in train, 10 in test and 10 in validation. Should ensure the density of buildings in images is roughly equal for these splits ie. not training on sparsely populated areas then testing on densely populated areas.\"\ntds_root_core_metadata_d['data_sharing'] = \"The dataset will be shared on Euro Data Cube (EDC) and can be accessed through jupyter notebooks on EDC.\"\ntds_root_core_metadata_d['compliance_level'] = 'level 1'\ntds_root_core_metadata_d['example_window_size'] = 100\ntds_root_core_metadata_d['example_stride'] = 80\n\ntds_root_core_metadata_d['data_completeness'] = \"The data spans a large geographic range. There are some unusable sections of the images due to cloud cover and instrument malfunction.\"\ntds_root_core_metadata_d['data_split'] = \"It is important when splitting data for testing, training and validation, that the density of buildings is similar in each split. For example if we train on sparsely developed areas then our model's performance will likely suffer when tested on highly developed areas.\"\ntds_root_core_metadata_d['data_sharing'] = \"The dataset will be shared on Euro Data Cube (EDC) and can be accessed through jupyter notebooks on EDC.\"\ntds_root_core_metadata_d['compliance_level'] = 'level 1'\ntds_root_core_metadata_d['links'] =  []\n\n# Make root level feature metadata\n\ng_feature_metadata_d = {}\ng_feature_metadata_d['type'] = \"Feature\"\ng_feature_metadata_d['stac_version'] = \"1.0.0-beta.2\"\ng_feature_metadata_d['stac_extensions'] = [\"georeferenced_eo_data\",\"georeferenced_eo_datacube\"]\ng_feature_metadata_d['id'] = \"common_feature_metadata\"\ng_feature_metadata_d['collection'] = \"706cf9e2-bd46-11eb-8529-0242ac130003\"\n    \ng_feature_metadata_d[\"properties\"] = {}\n# add metadata from georeferencedeodata profile first\ng_feature_metadata_d[\"properties\"]['parent_identifier'] = \"706cf9e2-bd46-11eb-8529-0242ac130003\"\ng_feature_metadata_d[\"properties\"]['identifier'] = \"Null\"\ng_feature_metadata_d[\"properties\"]['composed_of'] = \"Null\"\ng_feature_metadata_d[\"properties\"]['linked_with'] = \"Null\"\ng_feature_metadata_d['properties']['product_type'] = \"Time series of monthly images for one AOI. Each image shares geometry and bounding box.\"\ng_feature_metadata_d[\"properties\"][\"native_product_format\"] = \"netcdf\"\ng_feature_metadata_d[\"properties\"]['processing_level'] = \"Null\"\ng_feature_metadata_d[\"properties\"]['auxiliary_dataset_filename'] = \"Null\"\ng_feature_metadata_d['properties']['CRS'] = 'EPSG:3857'\n\n# dimensions of the whole dataset\nx_min = -13545862.01592866\ny_min = -4510398.55370881\nx_max = 16133718.82286585\ny_max = 6887891.10417667\ng_feature_metadata_d['bbox'] = [x_min,y_min,x_max,y_max]\ng_feature_metadata_d['geometry'] = geometry.mapping(geometry.box(x_min,y_min,x_max,y_max,ccw=True))\n\n\n# now add data for georeferencedeodatacube profile\ng_feature_metadata_d[\"properties\"][\"dimensions\"] = {}\ng_feature_metadata_d[\"properties\"][\"dimensions\"][\"x\"] = {\n                      \"type\": \"spatial\",\n                      \"axis\": \"x\",\n                      \"extent\": [\n                        x_min,\n                        x_max\n                      ],\n                      \"reference_system\": 3857\n                    }\ng_feature_metadata_d[\"properties\"][\"dimensions\"][\"y\"] = {\n                      \"type\": \"spatial\",\n                      \"axis\": \"y\",\n                      \"extent\": [\n                        y_min,\n                        y_max\n                      ],\n                      \"reference_system\": 3857\n                    }\ng_feature_metadata_d[\"properties\"][\"dimensions\"][\"temporal\"] = {\n                      \"type\": \"temporal\",\n                      \"extent\": [\n                        \"2017-07-01T00:00:00.000000000\",\n                        \"2020-01-01T00:00:00.000000000\"\n                         ]\n                    }\ng_feature_metadata_d[\"properties\"][\"dimensions\"][\"spectral\"] = {\n                      \"type\": \"bands\",\n                      \"values\": [\n                          \"red\",\n                          \"green\",\n                          \"blue\"\n                      ]\n    }\ng_feature_metadata_d[\"properties\"]['datetime'] = \"2019\"\n\n\ng_feature_metadata_d['links'] = []\ng_feature_metadata_d[\"assets\"] = {}\n\n# make feature metadata dictionary \nfeature_metadata_d = {}\nfeature_metadata_d['input1'] = g_feature_metadata_d\n\n\n# create common reference data    \n\ng_ref_data_metadata_d  = {}\ng_ref_data_metadata_d['id'] = f'common_reference_metadata'\ng_ref_data_metadata_d['type'] = \"Feature\"\ng_ref_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\ng_ref_data_metadata_d['stac_extensions'] = [\"reference_data\"]\ng_ref_data_metadata_d['collection'] = \"706cf9e2-bd46-11eb-8529-0242ac130003\"\ng_ref_data_metadata_d['properties'] = {}\ng_ref_data_metadata_d['properties']['name'] = 'Reference Metadata'\ng_ref_data_metadata_d['properties']['description'] = \"The reference data consists of datacubes of raster masks representing the building outlines in the training images. One datacube corresponds to one AOI.\"\ng_ref_data_metadata_d['properties']['type'] = \"annotated\"\ng_ref_data_metadata_d['properties']['task'] = \"Semantic Segmentation\"\ng_ref_data_metadata_d['properties']['classes'] = [[{'BUILDING':255,'NOT_BUILDING':0}]]\ng_ref_data_metadata_d['properties']['overviews'] = [\"The are dataset covers roughly 40000 square kilometers. 6.94% of this is labelled by this reference data as containing buildings.\"]\ng_ref_data_metadata_d['properties']['collection_method'] = \"The reference data was produced by manual annotation of the original satellite images.\"\ng_ref_data_metadata_d['properties']['data_preprocessing'] = {'type': 'free-text', 'recipe':\"The polygons in the original reference data were converted into rasters with the same dimensions and coordinates as the relevant feature data.\"}\ng_ref_data_metadata_d['properties']['CRS'] = 'EPSG:3857'\ng_ref_data_metadata_d[\"properties\"]['value'] = 0.\ng_ref_data_metadata_d['properties'][\"orientation\"]= \"Null\"\ng_ref_data_metadata_d[\"properties\"]['time_range'] = \"2021\"\ng_ref_data_metadata_d[\"properties\"]['datetime'] = \"2019\"\ng_ref_data_metadata_d['bbox'] = [x_min,y_min, x_max, y_max]\ng_ref_data_metadata_d['geometry'] = geometry.mapping(geometry.box(x_min,y_min,x_max,y_max,ccw=True))\n\ng_ref_data_metadata_d['links'] = []\ng_ref_data_metadata_d[\"assets\"] = {}\n\nref_metadata_d = {}\nref_metadata_d['output1'] = g_ref_data_metadata_d\n\n# Check if feature data is compliant\n\naireo_lib.tds_stac_io.validate_item(feature_metadata_d['input1'])\n\n# Add TDS global core elements metadata, and add global level profile metadata to the catalog object.\n\nnew_tds_ctl_o.add_tds_root_metadata(tds_root_core_metadata_d, feature_metadata_d, ref_metadata_d)\n\n\nnew_tds_ctl_o.valid_tds_root\n\n# Adding metadata for each AOI\n\nfor aoi_id in tqdm(aoi_ids):\n        \n    # Dictionary for each AOI collection metadata\n    aoi_metadata_d = {}\n    aoi_metadata_d['type'] = \"Collection\"\n    aoi_metadata_d[\"id\"] = f\"{aoi_id}\"\n    aoi_metadata_d['stac_version'] = '1.0.0-beta.2'\n    aoi_metadata_d['title'] = f\"{aoi_id} Collection\"\n    aoi_metadata_d['description'] = \"Datacube of Satellite images for one AOI and datacube of corresponding building masks.\"\n    aoi_metadata_d[\"license\"] = \"Various (CC-BY-4.0, Creative Commons CC BY-SA 3.0 IGO)\"\n    masks_path = dataset_path + '/' + aoi_id + '/building_masks.nc'\n    with xr.open_dataarray(masks_path) as masks:\n        minx = masks.coords['x'].values[0]\n        maxx = masks.coords['x'].values[-1]\n        miny = masks.coords['y'].values[0]\n        maxy = masks.coords['y'].values[-1]\n        start_time = str(min(masks['date'].values))\n        end_time = str(max(masks['date'].values))\n        unique, counts = np.unique(masks.values,return_counts=True)\n        # calculate percentage of images taken up by buildings\n        building_percent = 100*(counts[1]/counts[0])\n    bbox = [minx,miny,maxx,maxy]\n    geo = geometry.mapping(geometry.box(minx,miny,maxx,maxy))\n    aoi_metadata_d[\"bbox\"]= bbox\n    aoi_metadata_d['geometry'] = geo\n    aoi_metadata_d[\"extent\"] = {\"spatial\" : {\"bbox\":[bbox]}, \n                          \"temporal\": {\"interval\":[[start_time,end_time]]}}\n    aoi_metadata_d['time_range'] = start_time+' to '+end_time\n    aoi_metadata_d['links'] = []\n    aoi_metadata_d[\"assets\"] = {}\n\n    \n    \n    # Dictionary for each AOI's reference metadata\n    aoi_reference_metadata_d = {}\n    aoi_reference_metadata_d['id'] = f'reference_metadata_AOI_{aoi_id}'\n    aoi_reference_metadata_d['type'] = \"Feature\"\n    aoi_reference_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n    aoi_reference_metadata_d['stac_extensions'] = [\"reference_data\"]\n    aoi_reference_metadata_d['collection'] = \"706cf9e2-bd46-11eb-8529-0242ac130003\"\n    aoi_reference_metadata_d['bbox'] = bbox\n    aoi_reference_metadata_d['geometry'] = geo\n    aoi_reference_metadata_d['properties'] = {}\n    aoi_reference_metadata_d[\"properties\"]['name'] = str(aoi_id)+ \" Reference metadata\"\n    aoi_reference_metadata_d['properties']['description'] = \"The reference data consists of time series of raster masks stored in datacubes. These masks cover the buildings present in the corresponding satellite images.\"\n    aoi_reference_metadata_d['properties']['type'] = \"Raster\"\n    aoi_reference_metadata_d['properties']['task'] = \"Semantic Segmentation\"\n    aoi_reference_metadata_d['properties']['classes'] = [[{'BUILDING':255,'NOT_BUILDING':0}]]\n    aoi_reference_metadata_d['properties']['overviews'] = [str(building_percent)+\"% of this AOI is covered by buildings\"]\n    aoi_reference_metadata_d['properties']['collection_method'] = \"Building polygons were manually created by a team at SpaceNet.\"\n    aoi_reference_metadata_d['properties']['data_preprocessing'] = \"The polygons in the original reference data were converted into rasters.\"\n    aoi_reference_metadata_d['properties']['CRS'] = 'EPSG:3857'\n    aoi_reference_metadata_d['time_range'] = start_time+' to '+end_time\n    aoi_reference_metadata_d[\"properties\"]['value'] = 0\n    aoi_reference_metadata_d['properties'][\"orientation\"]= \"null\"\n    aoi_reference_metadata_d[\"properties\"]['datetime'] = start_time\n\n    aoi_reference_metadata_d['links'] = []  \n    aoi_reference_metadata_d[\"assets\"] = {}\n\n    aoi_reference_d = {}\n    aoi_reference_d['output1'] = aoi_reference_metadata_d\n    \n    # Dictionary for each AOI's feature metadata\n    aoi_feature_data_metadata_d = {}\n    aoi_feature_data_metadata_d['type'] = \"Feature\"\n    aoi_feature_data_metadata_d['stac_version'] = \"1.0.0-beta.2\"\n    aoi_feature_data_metadata_d['stac_extensions'] = [\"georeferenced_eo_datacube\",\"georeferenced_eo_data\"]\n    aoi_feature_data_metadata_d['id'] = f'predictive_feature_metadata_AOI_{aoi_id}'\n    aoi_feature_data_metadata_d['collection'] = \"706cf9e2-bd46-11eb-8529-0242ac130003\"\n    aoi_feature_data_metadata_d[\"bbox\"]= bbox\n    aoi_feature_data_metadata_d['geometry'] = geo\n    # first add data from Georeferenced data profile\n    aoi_feature_data_metadata_d[\"properties\"] = {}\n    aoi_feature_data_metadata_d[\"properties\"]['parent_identifier'] = \"706cf9e2-bd46-11eb-8529-0242ac130003\"\n    aoi_feature_data_metadata_d[\"properties\"]['identifier'] = aoi_id\n    aoi_feature_data_metadata_d[\"properties\"]['composed_of'] = \"Null\"\n    aoi_feature_data_metadata_d[\"properties\"]['linked_with'] = \"Null\"\n    aoi_feature_data_metadata_d['properties']['product_type'] = \"Time series of monthly images for one AOI. Each image shares geometry and bounding box.\"\n    aoi_feature_data_metadata_d[\"properties\"][\"native_product_format\"] = \"netcdf\"\n    aoi_feature_data_metadata_d[\"properties\"]['processing_level'] = \"Null\"\n    aoi_feature_data_metadata_d[\"properties\"]['auxiliary_dataset_filename'] = \"Null\"\n    aoi_feature_data_metadata_d[\"properties\"]['identifier'] = str(aoi_id)\n    aoi_feature_data_metadata_d[\"properties\"]['datetime'] = start_time\n    # add dimension object for datacube profile\n    aoi_feature_data_metadata_d[\"properties\"][\"dimensions\"] = {}\n    aoi_feature_data_metadata_d[\"properties\"][\"dimensions\"][\"x\"] = {\n                      \"type\": \"spatial\",\n                      \"axis\": \"x\",\n                      \"extent\": [\n                        minx,\n                        maxx\n                      ],\n                      \"reference_system\": 3857\n                    }\n    aoi_feature_data_metadata_d[\"properties\"][\"dimensions\"][\"y\"] = {\n                      \"type\": \"spatial\",\n                      \"axis\": \"y\",\n                      \"extent\": [\n                        miny,\n                        maxy\n                      ],\n                      \"reference_system\": 3857\n                    }\n    aoi_feature_data_metadata_d[\"properties\"][\"dimensions\"][\"temporal\"] = {\n                      \"type\": \"temporal\",\n                      \"extent\": [\n                        start_time,\n                        end_time\n                         ]\n                    }\n    aoi_feature_data_metadata_d[\"properties\"][\"dimensions\"][\"spectral\"] = {\n                      \"type\": \"bands\",\n                      \"values\": [\n                          \"red\",\n                          \"green\",\n                          \"blue\"\n                      ]\n    }\n    \n    aoi_feature_data_metadata_d['links'] = []\n    aoi_feature_data_metadata_d[\"assets\"] = {}\n    \n    aoi_feature_d = {}\n    aoi_feature_d['input1'] = aoi_feature_data_metadata_d\n\n\n    aoi_ref_data_asset_path_d = {'output1':dataset_path+'/'+aoi_id+'/building_masks.nc'}\n    aoi_feature_asset_path_d = {'input1':dataset_path+'/'+aoi_id+'/images_masked.nc'}\n    \n    print(new_tds_ctl_o.add_aoi_metadata(aoi_metadata_d=aoi_metadata_d,\n                                   aoi_feature_metadata_d=aoi_feature_d,\n                                   aoi_ref_data_metadata_d=aoi_reference_d,\n                                   aoi_feature_asset_path_d=aoi_feature_asset_path_d,\n                                   aoi_ref_data_asset_path_d=aoi_ref_data_asset_path_d))\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#creating-a-stac-catalog-with-aireo-lib","position":9},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl3":"stac_generated folder creation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#stac-generated-folder-creation","position":10},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl3":"stac_generated folder creation"},"content":"\n\nPrior to this step, you will need to create a folder called ‘biomass_stac_generated’ in your environment and leave it empty\n\n\ncatalog_fn_w_path = './sp7_stac/TDS.json'\n\nif os.path.exists('./sp7_stac'):\n    shutil.rmtree(catalog_fn_w_path.replace('/TDS.json',''))\n    \n# Write catalog to json    \nnew_tds_ctl_o.write_TDS_STAC_Catalog(catalog_fn_w_path)\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#stac-generated-folder-creation","position":11},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl4":"Checking AIREO compiance level","lvl3":"stac_generated folder creation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#checking-aireo-compiance-level","position":12},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl4":"Checking AIREO compiance level","lvl3":"stac_generated folder creation"},"content":"\n\nnew_tds_ctl_o = aireo_lib.core.tds_stac_io.DatasetSTACCatalog.from_TDSCatalog(catalog_fn_w_path)\nnew_tds_ctl_o.compute_compliance_level()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#checking-aireo-compiance-level","position":13},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl4":"Checking metadata completeness","lvl3":"stac_generated folder creation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#checking-metadata-completeness","position":14},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl4":"Checking metadata completeness","lvl3":"stac_generated folder creation"},"content":"\n\nnew_tds_ctl_o.report_metadata_completeness()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#checking-metadata-completeness","position":15},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl3":"Defining AOI class"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#defining-aoi-class","position":16},{"hierarchy":{"lvl1":"Creating a STAC catalog with aireo_lib","lvl3":"Defining AOI class"},"content":"\n\nclass AOIDatasetSpaceNet:\n    \"\"\"\n    This class is to load and to store all data (input features/ reference data) for one area of interest. An area of interest is defined by its bounding box, its geometry, and its time interval. For each specific EO TDS the user needs to create a subclass of AOIDataset and implements its abstract methods.\n    \"\"\"\n\n    def __init__(self, AOI_STAC_collection, TDS_STAC_catalog):\n\n        self.AOI_STAC_collection = AOI_STAC_collection\n        self.TDS_STAC_catalog = TDS_STAC_catalog\n        self.stride = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_stride']\n        self.window_size = self.TDS_STAC_catalog.tds_ctl_root_info.tds_root_metadata_d['example_window_size']\n        for eo_feature in self.AOI_STAC_collection.aoi_all_field_metadata.features:\n            aoi_feature_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.features[eo_feature].data_asset_w_path\n            self.feature_var_name = 'features_'+eo_feature\n            self.feature_data = xr.open_dataarray(aoi_feature_asset_path_d)\n            \n        for reference_data in self.AOI_STAC_collection.aoi_all_field_metadata.references:\n            aoi_ref_data_asset_path_d = self.AOI_STAC_collection.aoi_all_field_metadata.references[reference_data].data_asset_w_path\n            self.ref_var_name = 'references_'+reference_data\n            self.reference_data = xr.open_dataarray(aoi_ref_data_asset_path_d)\n\n        self.timesteps = self.feature_data['date'].values\n\n        self.data = self.feature_data.to_dataset(name=self.feature_var_name)\n\n        # Add second DataArray to existing dataset\n        self.data[self.ref_var_name] = self.reference_data\n        \n        \n\n\n    def __getitem__(self, index):        \n\n        if index >= len(self):\n            sys.exit('index out of range')\n            \n        # Return examples based on window size and stride metadata\n\n        sample_image = self.feature_data[0]\n        x1_ceiling = int((sample_image.shape[1]-self.window_size)/self.stride) +1\n        y1_ceiling = int((sample_image.shape[2]-self.window_size)/self.stride) +1\n        single_image_examples = x1_ceiling*y1_ceiling\n        timestep = int(index/single_image_examples)\n        image = self.feature_data[timestep]\n        image_index = index - timestep*single_image_examples\n        x1 = self.stride*(image_index%x1_ceiling)\n        y1 = self.stride*(int(image_index/x1_ceiling))\n        x2 = x1+self.window_size\n        y2 = y1+self.window_size\n        date = self.timesteps[timestep]\n\n        image = image[:,x1:x2,y1:y2]\n        building_mask = self.reference_data[timestep,x1:x2,y1:y2]\n        \n        \n        ds = self.data.isel(date=[timestep],band=[0,1,2,3],x=slice(x1,x2),y=slice(y1,y2)).squeeze()\n        \n        return ds\n\n    # return the number of timesteps multiplied by number of examples in a single timestep \n    def __len__(self):\n        sample_image = self.feature_data[0]\n        x1_ceiling = int((sample_image.shape[1]-self.window_size)/self.stride) +1\n        y1_ceiling = int((sample_image.shape[2]-self.window_size)/self.stride) +1\n        single_image_examples = int(x1_ceiling)*int(y1_ceiling)\n        return len(self.timesteps)*single_image_examples\n\n    def get_length(self):\n        return len(self)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#defining-aoi-class","position":17},{"hierarchy":{"lvl1":"Dataset user"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#dataset-user","position":18},{"hierarchy":{"lvl1":"Dataset user"},"content":"\n\nThe user of the dataset can access most of what is offered by the dataset using just its STAC catalog. All he/she needs to do is create a dataset object by passing to it the path to the STAC catalog at the root level. The library automatically reads in all the metadata and loads the assets into the dataset object. Some of the functionalities that a dataset object offers through aireo_lib are:\n\nCan access an example instance from the dataset which serves as an input-output pair for a Machine Learning algorithm.\n\nXarrays are used to store data and give examples.\n\nDataset can also return each AOI independently\n\nOffer basic plotting functions for each variable in the dataset and AOI.\n\nSome statistics can also be calculated at both the AOI level and whole dataset level.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#dataset-user","position":19},{"hierarchy":{"lvl1":"Dataset user","lvl2":"Parsing TDS"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#parsing-tds","position":20},{"hierarchy":{"lvl1":"Dataset user","lvl2":"Parsing TDS"},"content":"\n\nfrom aireo_lib.core import EOTrainingDataset\n\nsp7_tds_ctl_fn = Path(os.environ['EDC_PATH']+'/data/SpaceNet7/sp7_stac/TDS.json')\n    \neo_tds_obj = EOTrainingDataset(sp7_tds_ctl_fn, AOIDatasetSpaceNet)\n\nlen(eo_tds_obj)\n\neo_tds_obj[4204]\n\nhelp(eo_tds_obj.get_subset)\n\neo_tds_obj.get_subset([19,1121])\n\naoi_objs = eo_tds_obj.get_aoi_datasets()\nlen(aoi_objs[1])\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#parsing-tds","position":21},{"hierarchy":{"lvl1":"Dataset user","lvl2":"Plotting functions in aireo_lib"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#plotting-functions-in-aireo-lib","position":22},{"hierarchy":{"lvl1":"Dataset user","lvl2":"Plotting functions in aireo_lib"},"content":"\n\nfrom importlib import reload\nfrom aireo_lib.plotting import EOTDSPlot as aireo_viz\n\nreload(aireo_lib.plotting)\nplot_d = aireo_viz.plot_example(EOTDS=eo_tds_obj, \n                       ex_index=128, \n                       field_names=['features_input1', 'references_output1'])\n\naoi_obj = eo_tds_obj.get_aoi_dataset(2)\n\n# Basic plot of all the variables in an AOI, returns a dict of matplotlib figures\n\naoi_plots_d = aireo_viz.plot_aoi_dataset(aoi_obj)\naoi_plots_d\n\naireo_viz.map_aois(eo_tds_obj)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#plotting-functions-in-aireo-lib","position":23},{"hierarchy":{"lvl1":"Dataset user","lvl2":"Statistics functions in aireo_lib"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#statistics-functions-in-aireo-lib","position":24},{"hierarchy":{"lvl1":"Dataset user","lvl2":"Statistics functions in aireo_lib"},"content":"\n\nimport aireo_lib.statistics\n\naireo_lib.statistics.EOTDSStatistics.reference_data_statistics(eo_tds_obj)\n\naireo_lib.statistics.EOTDSStatistics.metadata_statistics(eo_tds_obj)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aireo-pilot-dataset-spacenet7#statistics-functions-in-aireo-lib","position":25},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19","position":0},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2"},"content":"from edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19","position":1},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#aerosol-optical-thickness-aot-anomaly-detection-using-sentinel-2","position":2},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2"},"content":"\n\nAuthor: Henrik Fisser, 2020\n\nThis script was developed and executed on the EOxHub-hosted JupyterLab and uses xcube for computations on data cubes retrieved from the Sentinel Hub. To run this script you will need to ensure that you have access to these resources.\n\nImportant: This is a draft and was created during the COVID-19 crisis. Its purpose was to quickly implement an idea.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#aerosol-optical-thickness-aot-anomaly-detection-using-sentinel-2","position":3},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"What does this script do?"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#what-does-this-script-do","position":4},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"What does this script do?"},"content":"During the COVID-19 crisis parts of the world were more or less locked up at home. The hypothesis is that these social distancing measures impact aerosol amounts in the troposphere. During the sen2cor (\n\nhttps://​earth​.esa​.int​/web​/sentinel​/technical​-guides​/sentinel​-2​-msi​/level​-2a​/algorithm) atmospheric correction and preprocessing of Sentinel-2 the aerosol amount is calculated as the dimensionless aerosol optical thickness (AOT). We use this data from computing temporal AOT medians on a Sentinel-2 stack from a baseline period and from the lockdown period, since the AOT is spatially and temporally highly variable. The reference period must be the same season from previous year. This script covers the respective period from 2017, 2018 and 2019. Finally, the percentage AOT difference is calculated. We call this difference the ‘COVID-19 AOT anomaly’.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#what-does-this-script-do","position":5},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"Questions or Feedback?"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#questions-or-feedback","position":6},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"Questions or Feedback?"},"content":"Just send me a message :).","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#questions-or-feedback","position":7},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"Load dependencies"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#load-dependencies","position":8},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"Load dependencies"},"content":"\n\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\nfrom xcube.core.maskset import MaskSet\n\nimport os\nimport geopandas as gpd\nimport xarray as xr\nimport shapely.geometry\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#load-dependencies","position":9},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"General parameters"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#general-parameters","position":10},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"General parameters"},"content":"run_batch: shall we process everything?dataset: “S2L2A” for Sentinel-2 Level 2Aspatial_res: spatial resolution. AOT will be 20 m anyways but VIS 10 m, so request 10\nband_names:\nfor all years we need the AOT and the scene classification (SCL)band_names_2020: also request VIS bands for 2020 for visualization of the results.time_period_before: this is the period in which we consider an observation to be valid. As we request data from several months from three years for the reference period before COVID-19 we use a period of five days in order no to request and process too much data.time_period_after: the periods during COVID-19 lockdown-like measures is short, so use all available observations.\n\nrun_batch = True # for batch processing\ndataset = \"S2L2A\"\nspatial_res = 0.00009 # 10m, AOT is 20 m though\nband_names = [\"AOT\", \"SCL\"]\nband_names_2020 = [\"B02\", \"B03\", \"B04\", \"AOT\", \"SCL\"]\nt = \"time\"\n\n# temporal parameters of data cubes\ntime_period_before = \"5D\"\ntime_period_after = \"1D\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#general-parameters","position":11},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"Prepare areas of interest"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#prepare-areas-of-interest","position":12},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"Prepare areas of interest"},"content":"Some areas are loaded from geojsons, others are provided as bounding boxes from coordinates in the script.\n\n# read areas of interest\ndef read_bbox(place):\n    aoi = gpd.read_file(os.path.expanduser(f\"~/.shared/notebooks/eurodatacube/notebooks/contributions/AOT_COVID-19/{place}.geojson\")).bounds.values[0]\n    return aoi[0].item(), aoi[1].item(), aoi[2].item(), aoi[3].item()\n\nplace = \"beijing\"\nbbox_beijing = read_bbox(place)\nstart_beijing = \"2020-02-09\"\nend_beijing = \"2020-03-15\"\nplace = \"rome\"\nbbox_rome = 12.35, 41.79, 12.65, 41.99\nstart_italy = \"2020-03-09\"\nplace = \"madrid\"\nbbox_madrid = read_bbox(place)\nstart_madrid = \"2020-03-14\"\nplace = \"berlin\"\nbbox_berlin = read_bbox(place)\nplace = \"london\"\nbbox_london = bbox = read_bbox(place)\nstart_london = \"2020-03-23\"\n# NOTE: bucharest is currently disabled due to missing .geojson file\n# place = \"bucharest\"\n# bbox_bucharest = bbox = read_bbox(place)\nstart_bucharest = \"2020-03-25\"\nplace = \"paris\"\nbbox_paris = 2., 48.675, 2.6, 49.05\nplace = \"brussels\"\nbbox_brussels = bbox = read_bbox(place)\nplace = \"budapest\"\nbbox_budapest = bbox = read_bbox(place)\nplace = \"prague\"\nbbox_prague = bbox = read_bbox(place)\nplace = \"athens\"\nbbox_athens = 23.6, 37.935, 23.8, 38.05\nplace = \"zurich\"\nbbox_zurich = bbox = read_bbox(place)\n\nbboxes = {\"beijing\":bbox_beijing, \"rome\":bbox_rome, \"madrid\":bbox_madrid, \n          \"berlin\":bbox_berlin, \"london\":bbox_london, # \"bucharest\":bbox_bucharest, \n          \"paris\":bbox_paris, \"brussels\":bbox_brussels, \"budapest\":bbox_budapest, \n          \"prague\":bbox_prague, \"athens\":bbox_athens, \"zurich\":bbox_zurich}\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#prepare-areas-of-interest","position":13},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"Process area-wise"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#process-area-wise","position":14},{"hierarchy":{"lvl1":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","lvl2":"Process area-wise"},"content":"This is scripted for batch processing. If you would like to test it e.g. only in one area just provide a single place name and the corresponding aoi in the bboxes dictionary.Since this is a very functional draft script, the handling of different lockdown period is kind of messy. Essentially, due to area-specific lockdown periods we have to provide different temporal bounds for the cubes.\n\nif run_batch:\n    for place in bboxes:\n        print(\"Processing: \" + place)\n        if not os.path.exists(place):\n            is_beijing = place == \"beijing\"\n            is_london = place == \"london\"\n            is_italy = place in [\"rome\", \"milan\"]\n            is_madrid = place == \"madrid\"\n            is_vienna = place == \"vienna\"\n            is_bucharest = place == \"bucharest\"\n\n            bbox = bboxes.get(place)\n\n            # cube 2017\n            start = \"2017-03-04\"\n            end = \"2017-05-05\"\n            start = \"2017-01-26\" if is_beijing else start\n            end = \"2017-03-29\" if is_beijing else end\n            start = \"2017-02-24\" if is_italy else start\n            start = \"2017-03-09\" if is_london else start\n            start = \"2017-03-01\" if is_madrid else start\n            start = \"2017-03-11\" if is_bucharest else start\n            cube_config_2017 = CubeConfig(dataset_name = dataset,\n                                        band_names = band_names,\n                                        tile_size = [512, 512],\n                                        geometry = bbox,\n                                        spatial_res = spatial_res,\n                                        time_range = [start, end],\n                                        time_period = time_period_before)\n            cube_2017 = open_cube(cube_config_2017)\n            scl = MaskSet(cube_2017.SCL)\n            cube_2017_masked = cube_2017.where((scl.no_data + \n                                                scl.cloud_shadows +\n                                                scl.clouds_high_probability + \n                                                scl.clouds_medium_probability) == 0)\n            cube_2017_masked = cube_2017_masked.drop_vars([\"SCL\"])\n\n            # cube 2018\n            start = \"2018-03-04\"\n            end = \"2018-05-05\"\n            start = \"2018-01-26\" if is_beijing else start\n            end = \"2018-03-29\" if is_beijing else end\n            start = \"2018-02-24\" if is_italy else start\n            start = \"2018-03-09\" if is_london else start\n            start = \"2018-03-01\" if is_madrid else start\n            start = \"2018-03-11\" if is_bucharest else start\n            cube_config_2018 = CubeConfig(dataset_name = dataset,\n                                        band_names = band_names,\n                                        tile_size = [512, 512],\n                                        geometry = bbox,\n                                        spatial_res = spatial_res,\n                                        time_range = [start, end],\n                                        time_period = time_period_before)\n            cube_2018 = open_cube(cube_config_2018)\n            scl = MaskSet(cube_2018.SCL)\n            cube_2018_masked = cube_2018.where((scl.no_data + \n                                                scl.cloud_shadows +\n                                                scl.clouds_high_probability + \n                                                scl.clouds_medium_probability) == 0)\n            cube_2018_masked = cube_2018_masked.drop_vars([\"SCL\"])\n\n            # cube 2019\n            start = \"2019-03-04\"\n            end = \"2019-05-05\"\n            start = \"2019-01-26\" if is_beijing else start\n            end = \"2019-03-29\" if is_beijing else end\n            start = \"2019-02-24\" if is_italy else start\n            start = \"2019-03-09\" if is_london else start\n            start = \"2019-03-01\" if is_madrid else start\n            start = \"2019-03-11\" if is_bucharest else start\n            cube_config_2019 = CubeConfig(dataset_name = dataset,\n                                         band_names = band_names,\n                                         tile_size = [512, 512],\n                                         geometry = bbox,\n                                         spatial_res = spatial_res,\n                                         time_range = [start, end],\n                                         time_period = time_period_before)\n            cube_2019 = open_cube(cube_config_2019)\n            scl = MaskSet(cube_2019.SCL)\n            cube_2019_masked = cube_2019.where((scl.no_data + \n                                                scl.cloud_shadows +\n                                                scl.clouds_high_probability + \n                                                scl.clouds_medium_probability) == 0)\n            cube_2019_masked = cube_2019_masked.drop_vars([\"SCL\"])\n\n            # median AOT 2017, 2018 and 2019\n            cube_171819 = xr.merge([cube_2017_masked, cube_2018_masked, cube_2019_masked])\n            median_aot_171819 = cube_171819.AOT.median(dim = t)\n\n            # cube 2020\n            start = \"2020-03-18\"\n            end = \"2020-04-21\"\n            start = start_italy if is_italy else start\n            start = start_beijing if is_beijing else start\n            start = start_london if is_london else start\n            start = start_madrid if is_madrid else start\n            start = start_bucharest if is_bucharest else start\n            end = end_beijing if is_beijing else end\n            cube_config_2020 = CubeConfig(dataset_name = dataset,\n                                         band_names = band_names_2020,\n                                         tile_size = [512, 512],\n                                         geometry = bbox,\n                                         spatial_res = spatial_res,\n                                         time_range = [start, end],\n                                         time_period = \"1D\")\n            cube_2020 = open_cube(cube_config_2020)\n            scl = MaskSet(cube_2020.SCL)\n            cube_2020_masked = cube_2020.where((scl.no_data + \n                                                scl.cloud_shadows +\n                                                scl.clouds_high_probability + \n                                                scl.clouds_medium_probability) == 0)\n            median_aot_2020 = cube_2020_masked.AOT.median(dim = t)\n\n            # percentage difference\n            diff_aot_percent = ((median_aot_2020 / median_aot_171819) * 100) - 100\n\n            # median RGB for visualization\n            median_red = cube_2020_masked.B04.median(dim = t)\n            median_green = cube_2020_masked.B03.median(dim = t)\n            median_blue = cube_2020_masked.B02.median(dim = t)\n\n            # write results\n            os.mkdir(place)\n            suffix = \"_\" + place + \".nc\"\n            diff_aot_percent.to_netcdf(os.path.join(place, \"aot_diff_percent\" + suffix))\n            median_aot_2020.to_netcdf(os.path.join(place, \"median_aot_2020\" + suffix))\n            median_aot_171819.to_netcdf(os.path.join(place, \"median_aot_171819\" + suffix))\n            median_red.to_netcdf(os.path.join(place, \"B04\" + suffix))\n            median_green.to_netcdf(os.path.join(place, \"B03\" + suffix))\n            median_blue.to_netcdf(os.path.join(place, \"B02\" + suffix))\n            print(\"Done with: \" + place)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/aot-covid19#process-area-wise","position":15},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output","position":0},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API"},"content":"In this notebook, we will first create Zarr data cube using Sentinel Hub Batch Processing API. The results (zarr group) will be first be stored on S3 and then we will download them and read them into xarray dataset.\n\nYou will need an EDC Sentinel Hub Enterprise subscription to execute this notebook as well as your own object storage (S3).\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output","position":1},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API","lvl2":"Imports and authentication"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output#imports-and-authentication","position":2},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API","lvl2":"Imports and authentication"},"content":"\n\nFirst, let’s import all pacakges we will be using and authenticate at Sentinel Hub.\n\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\nimport os\nimport fsspec\nimport xarray as xr\n\n# Your client credentials\nclient_id = os.environ[\"SH_CLIENT_ID\"]\nclient_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_secret=client_secret)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output#imports-and-authentication","position":3},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API","lvl2":"Create Batch Processing request to calculate maximum NDVI in for three months"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output#create-batch-processing-request-to-calculate-maximum-ndvi-in-for-three-months","position":4},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API","lvl2":"Create Batch Processing request to calculate maximum NDVI in for three months"},"content":"\n\nThis example is taken from the official Sentinel Hub documentation: \n\nhttps://​docs​.sentinel​-hub​.com​/api​/latest​/api​/batch​/examples​/​#option​-2​-zarr​-format​-output. To run it, please replace a placeholder <your-bucket> with your value (e.g. “s3://my-bucket/batch-zarr-demo”). Your object storage has to be configured as described here: \n\nhttps://​docs​.sentinel​-hub​.com​/api​/latest​/api​/batch​/​#aws​-bucket​-settings\n\nThe example requests all Sentinel-2 data acquired between April 2019 and June 2019 for the selected AOI, which is an island of Corsica in this example. The request returns the maximum value of NDVI in this period as well as values of bands 4 and 8 based on which the max NDVI was calculated. The output is stored on selected S3 storage in a Zarr format.\n\nurl = \"https://services.sentinel-hub.com/api/v1/batch/process\"\n\nevalscript = \"\"\"\n    //VERSION=3\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B04\", \"B08\"]\n            }],\n            output: [{\n                id: \"maxNDVI\",\n                sampleType: \"FLOAT32\",\n                bands: 1\n            },\n            {\n                id: \"band04\",\n                sampleType: \"UINT16\",\n                bands: 1\n            },\n            {\n                id: \"band08\",\n                sampleType: \"UINT16\",\n                bands: 1\n            }],\n            mosaicking: Mosaicking.ORBIT\n        }\n    }\n\n    function calcNDVI(sample) {\n        var denom = sample.B04 + sample.B08\n        return ((denom != 0) ? (sample.B08 - sample.B04) / denom : 0.0)\n    }\n\n    function evaluatePixel(samples) {\n        var maxNDVI = 0\n        var band04 = 0\n        var band08 = 0\n        for (var i = 0; i < samples.length; i++) {\n            var ndvi = calcNDVI(samples[i])\n            if (ndvi > maxNDVI){\n                maxNDVI = ndvi\n                band04 = samples[i].B04\n                band08 = samples[i].B08\n            }\n        }\n\n        return {\n            maxNDVI: [maxNDVI],\n            band04: [band04],\n            band08: [band08]\n        }\n    }\n\"\"\"\n\npayload = {\n    \"processRequest\": {\n        \"input\": {\n            \"bounds\": {\n                \"bbox\": [\n                    8.44,\n                    41.31,\n                    9.66,\n                    43.1\n                ],\n                \"properties\": {\n                    \"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"\n                }\n            },\n            \"data\": [{\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": \"2019-04-01T00:00:00Z\",\n                        \"to\": \"2019-06-30T00:00:00Z\"\n                    },\n                \"maxCloudCoverage\": 70.0\n                },\n                \"type\": \"sentinel-2-l2a\"\n            }]\n        },\n        \"output\": {\n            \"responses\": [{\n                \"identifier\": \"band08\",\n                \"format\": {\n                    \"type\": \"zarr/array\"\n                }\n            },\n                {\n                \"identifier\": \"band04\",\n                \"format\": {\n                    \"type\": \"zarr/array\"\n                }\n            },\n                {\n                \"identifier\": \"maxNDVI\",\n                \"format\": {\n                    \"type\": \"zarr/array\"\n                }\n            }]\n        },\n        \"evalscript\": evalscript\n    },\n    \"tilingGrid\": {\n        \"id\": 6,\n        \"resolution\": 100.0\n    },\n    \"zarrOutput\": {\n        \"path\": \"<your-bucket>/<requestId>\",\n        \"group\": {\n            \"zarr_format\": 2\n        },\n        \"arrayParameters\": {\n            \"dtype\": \"<u2\",\n            \"order\": \"C\",\n            \"chunks\": [1, 1000, 1000],\n            \"fill_value\": 0\n        },\n        \"arrayOverrides\": {\n            \"maxNDVI\": {\n                \"dtype\": \"<f4\",\n                \"fill_value\": \"NaN\"\n            },\n        }\n    },\n    \"description\": \"Max NDVI over Corsica with Zarr format output\"\n}\n\nheaders = {\n  'Content-Type': 'application/json'\n}\n\nresponse = oauth.request(\"POST\", url, headers=headers, json = payload)\n\nFrom the response, we will extract a request id and store it in a separate variable:\n\nbatch_request_id = response.json()['id']\nbatch_request_id\n\nWe could request an analysis of the batch request in order to ensure that everything will run smoothly. However, to shorten the process for this demo, we will simply request start of the processing:\n\n# Start processing\nurl = f\"https://services.sentinel-hub.com/api/v1/batch/process/{batch_request_id}/start\"\n\nresponse = oauth.request(\"POST\", url)\n\nresponse.status_code\n\nNow we have to wait until the processing is DONE. We can check the status of the request with running:\n\n# Check status\nurl = f\"https://services.sentinel-hub.com/api/v1/batch/process/{batch_request_id}\"\n\nresponse = oauth.request(\"GET\", url)\n\nresponse.json()[\"status\"]\n\nThe processing is DONE and the results are available in my object storage as shown below. Note that the folder name is batch request id, since we used a placeholder <requestId> in the path parameter earlier.\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output#create-batch-processing-request-to-calculate-maximum-ndvi-in-for-three-months","position":5},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API","lvl2":"Explore the results with xarray"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output#explore-the-results-with-xarray","position":6},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API","lvl2":"Explore the results with xarray"},"content":"\n\nWe can now download the results and store them in the ./results folder. Note that you will have to set up your AWS credentials correctly in order to execute this command.\n\n!aws s3 cp <your-bucket>/9920066c-5336-4129-9e49-583dd6088ac3 ./results --recursive \n\nWe can now open and explore the date with xarray:\n\ncube_before = xr.open_zarr(\"./results\")\ncube_before\n\ncube_before.maxNDVI.isel(time=0).plot(figsize=[12,12], vmax=1.0)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output#explore-the-results-with-xarray","position":7},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API","lvl2":"Ingest results to Sentinel Hub with Zarr import API"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output#ingest-results-to-sentinel-hub-with-zarr-import-api","position":8},{"hierarchy":{"lvl1":"Generating Zarr data cubes with Sentinel Hub Batch API","lvl2":"Ingest results to Sentinel Hub with Zarr import API"},"content":"\n\nThe results can also be ingested back to the Sentinel Hub:\n\ncollection = {\n  'name': 'My Zarr Test Nov',\n  's3Bucket': <your-bucket-name>,\n  'path': f'<folder-in-your-bucket>/{batch_request_id}/',\n  \"crs\":\"http://www.opengis.net/def/crs/EPSG/0/3035\"\n}\n\nresponse = oauth.post('https://services.sentinel-hub.com/api/v1/zarr/collections', json=collection)\nresponse.raise_for_status()\n\nThis create a data collection. To get its id, run response.json()[\"data\"][\"id\"]. Form here on, we can use all Sentinel Hub funcionalites when working with this data collection.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/batch-zarr-output#ingest-results-to-sentinel-hub-with-zarr-import-api","position":9},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop","position":0},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop","position":1},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl2":"Introduction"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#introduction","position":2},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl2":"Introduction"},"content":"Welcome the OGC Testbed 16 DAPA evaluation workshop. With this Jupyter Notebook we (EOX IT Services and the German Aerospace Center - DLR) would like to provide you some introduction material, links to Jupyter Notebooks, and a documentation about our API definition.\n\nOur DAPA service endpoint is based on the EuroDataCube environment, which allows us to provide acess to a wide range of datasets:\n\nSentinel-1 GRD\n\nSentinel-2 L1C and L2A\n\nSentinel-3 OLCI and SLSTR\n\nSentinel-5P L2\n\nLandsat-8 L1C (ESA archive)\n\nMODIS\n\nDEM\n\nPlease see the Jupyter Notebooks for working examples. You can also use the DAPA service endpoint from your own environment (e.g., local computer, server). But please make sure, you do not publish the DAPA service endpoint URL (DAPA_URL) as this is connected to your personal account.\n\nPlease note: Not any feature of the API is currently supported. The API might also not work with every dataset. It should work at least with Sentinel-1, Sentinel-2, Sentinel-3, and the Digital Elevation Model (DEM).\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#introduction","position":3},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl2":"Tutorials"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#tutorials","position":4},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl2":"Tutorials"},"content":"We have made the following tutorials as Jupyter Notebooks available:\n\nDAPA Tutorial #1: Cube - Sentinel-2 - OGC Testbed 16\n\nDAPA Tutorial #2: Area - Sentinel-2 - OGC Testbed 16\n\nDAPA Tutorial #3: Timeseries - Sentinel-2 - OGC Testbed 16\n\nDAPA Tutorial #4: Value - Sentinel-2 - OGC Testbed 16\n\nDAPA Tutorial #5: DEM example – OGC Testbed 16\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#tutorials","position":5},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl2":"Documentation"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#documentation","position":6},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl2":"Documentation"},"content":"This API definition has been developed by EOX and DLR. This definition focuses on the provision of raster/coverage data, but might also be applied for scattered time-series data.\n\nPlease note: This is an early draft proposal of the API definition. It is subject to change within the time frame of OGC Testbed 16. Also other proposals exist with different API definitions.\n\nOverview of URL endpoints:/oapi/collections/{collection}/dapa/\n    fields/\n    cube/\n    area/\n    timeseries/\n        area/\n        position/\n    value/\n        area/\n        position/\n\nThe first hierarchy level after /dapa/ describes the output type of the data requested (except for “fields”):\n\ncube: 2d raster time-series (each with one or multiple bands)\n\narea: Single 2d raster (with one or multiple bands)\n\ntimeseries: 1d time-series (each with values from one or multiple fields)\n\nvalue: Single value (with values from one or multiple fields)\n\nThe second hierarchy level after /dapa/ describes the input geometry (if not implicitly given from the output type):\n\narea: Polygon/Bounding box\n\nposition: Point\n\nWith this definition, aggregation is automatically conducted based on the aggregate parameter to achieve\nthe output type requested (see the Parameter section below).","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#documentation","position":7},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/fields","lvl2":"Documentation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-fields","position":8},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/fields","lvl2":"Documentation"},"content":"Output fields/variables/properties/bands to be included in the request/processing/aggregation.\n\nThe fields parameter for the DAPA request can consists values either from the selected collection (e.g., all band\nnames from Sentinel-2) or declared dynamically (e.g., bands algebra NDVI=(B08-B04/B08+B04)) (see the Parameter\nsection below).","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-fields","position":9},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/cube","lvl2":"Documentation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-cube","position":10},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/cube","lvl2":"Documentation"},"content":"2d raster time-series (each with one or multiple bands)\n\nAvailable only if the collection is a multi-temporal raster dataset.\n\nParameters:\n\nbbox/geom/cell\n\ntime\n\n(fields) defaults to all fields (bands) available\n\nformat\n\nExample UC 1.1: Produce an animated video of ozone concentration from Sentinel-5p for a given time and space/collections/S5PL2/dapa/cube?time=2018-05-04T12:12:12Z/2018-06-04T12:12:12Z&bbox=11.49,48.05,11.66,48.22&fields=SO2&format=video/avi\n\nResults in an animated video.\n\nExample UC 2.1: Retrieve a raster time-series of NDVI calculated from Sentinel-2 scenes for a given time and space/collections/S2L1C/dapa/cube?time=2018-05-04T12:12:12Z/2018-06-04T12:12:12Z&bbox=11.49,48.05,11.66,48.22&fields=NDVI=(B08-B04/B08+B04)&format\n=application/metalink\n\nResults in a metalink file with download links to multiple raster files (one per time).","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-cube","position":11},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/area","lvl2":"Documentation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-area","position":12},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/area","lvl2":"Documentation"},"content":"Single 2d raster (e.g., results in TIFF with num(aggregates) x num(fields) bands)\n\nIf the collection is a multi-temporal raster dataset, aggregation over time is automatically conducted\nbased on the aggregate parameter.\n\nIf the collection is a single raster dataset, no aggregation over time is conducted.\n\nParameters:\n\nbbox/geom/cell\n\ntime\n\naggregate\n\n(fields) defaults to all fields (bands) available\n\n(format) defaults to image/tiff\n\nExample UC 1.2: Retrieve the maximum sulphor dioxide concentration in a given time span as a single coverage\n(aggregation over time)/collections/S5PL2/dapa/area?time=2018-05-04T12:12:12Z/2018-06-04T12:12:12Z&bbox=11.49,48.05,11.66,48.22&aggregate=max&fields=SO2\n\nResults in TIFF with a single field/band: SO2_max\n\nExample UC 2.2: Retrieve the minimum and maximum NDVI and NDBI in a given time span (aggregation over time)/collections/S2L2A/dapa/area?time=2018-05-04T12:12:12Z/2018-06-04T12:12:12Z&bbox=11.49,48.05,11.66,48.22&aggregate=min,max&fields=NDVI=(B04-B08)/(B04+B08),NDBI=(B01-B02)/(B01+B02)\n\nResults in TIFF with 4 fields/bands: NDVI_min, NDVI_max, NDBI_min, NDBI_max.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-area","position":13},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/timeseries","lvl2":"Documentation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-timeseries","position":14},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/timeseries","lvl2":"Documentation"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-timeseries","position":15},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"/collections/{collection}/dapa/timeseries/area","lvl3":"/collections/{collection}/dapa/timeseries","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-timeseries-area","position":16},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"/collections/{collection}/dapa/timeseries/area","lvl3":"/collections/{collection}/dapa/timeseries","lvl2":"Documentation"},"content":"1d time-series (each with values from one or multiple fields)\n\nIf the collection is a multi-temporal raster dataset, aggregation over space is automatically conducted\nbase on the aggregate parameter.\n\nCan not be used for a single raster dataset\n\nParameters:\n\nbbox/geom/cell\n\ntime\n\naggregate\n\n(fields) defaults to all fields (bands) available\n\n(format) defaults to text/csv\n\nExample UC 1.3: Retrieve the maximum sulphor dioxide concentration in a given area as a time-series (aggregation\nover space)/collections/S5PL2/dapa/timeseries/area?time=2018-05-04T12:12:12Z/2018-06-04T12:12:12Z&bbox=11.49,48.05,11.66,48.22&aggregate=max&fields=SO2\n\nResults in CSV with two columns: date and SO2_max","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-timeseries-area","position":17},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"/collections/{collection}/dapa/timeseries/position","lvl3":"/collections/{collection}/dapa/timeseries","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-timeseries-position","position":18},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"/collections/{collection}/dapa/timeseries/position","lvl3":"/collections/{collection}/dapa/timeseries","lvl2":"Documentation"},"content":"1d time-series (each with values from one or multiple fields)\n\nExtraction of a time series at a point specified in the request\n\nNo aggregation is conducted because only a single pixel is extracted\n\nCan not be used for a single raster dataset\n\nParameters:\n\npoint\n\ntime\n\n(fields) defaults to all fields (bands) available\n\n(format) defaults to text/csv\n\nExample UC 1.3: Retrieve the maximum sulphor dioxide concentration at a given point as a time-series/collections/S5PL2/dapa/timeseries/area?time=2018-05-04T12:12:12Z/2018-06-04T12:12:12Z&point=11.49,48.05&fields=SO2\n\nResults in CSV with two columns: date and SO2","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-timeseries-position","position":19},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/value","lvl2":"Documentation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-value","position":20},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"/collections/{collection}/dapa/value","lvl2":"Documentation"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-value","position":21},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"/collections/{collection}/dapa/value/area","lvl3":"/collections/{collection}/dapa/value","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-value-area","position":22},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"/collections/{collection}/dapa/value/area","lvl3":"/collections/{collection}/dapa/value","lvl2":"Documentation"},"content":"Single value (with values from one or multiple fields)\n\nIf the collection is a multi-temporal dataset, aggregation over space and time is automatically conducted base on\nthe aggregate parameter.\n\nIf the collection is a single dataset/coverage, aggregation over space is automatically conducted base on\nthe aggregate parameter.\n\nNote: If multiple methods are given in the aggregate parameter or multiple fields are given, text/plain is not\nsufficient! TODO\n\nParameters:\n\nbbox/geom/cell\n\ntime\n\naggregate\n\n(fields) defaults to all fields (bands) available\n\n(format) defaults to text/plain\n\nExample: Retrieve the minimum sulphor dioxide concentration in a given area and time span (aggregated over space and\ntime)/collections/S5PL2/value/area?time=2018-05-04T12:12:12Z/2018-06-04T12:12:12Z&bbox=11.49,48.05,11.66,48.22&aggregate=min&fields=SO2&format=text/plain\n\nResults in a single value","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-value-area","position":23},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"/collections/{collection}/dapa/value/position","lvl3":"/collections/{collection}/dapa/value","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-value-position","position":24},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"/collections/{collection}/dapa/value/position","lvl3":"/collections/{collection}/dapa/value","lvl2":"Documentation"},"content":"Single value (with values from one or multiple fields)\n\nIf the collection is a multi-temporal raster dataset, aggregation over time is automatically conducted\nbased on the aggregate parameter.\n\nIf the collection is a single raster dataset, no aggregation is conducted.\n\nNote: If multiple methods are given in the aggregate parameter or multiple fields are given, text/plain is not\nsufficient! TODO\n\nParameters:\n\npoint\n\ntime\n\naggregate\n\n(fields) defaults to all fields (bands) available\n\n(format) defaults to text/plain\n\nExample: Retrieve the minimum value of all fields (bands) of Sentinel-5p at a given point in a given time\nspan (aggregated over time)./collections/S5PL2/value/position?time=2018-05-04T12:12:12Z/2018-06-04T12:12:12Z&point=11.49,48.05&aggregate=min&format=application/json\n\nResults in JSON file with a single value for each field (band): SO2_min, O3_min, NO2_min, ...","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#id-collections-collection-dapa-value-position","position":25},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"Parameters","lvl2":"Documentation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#parameters","position":26},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"Parameters","lvl2":"Documentation"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#parameters","position":27},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"point","lvl3":"Parameters","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#point","position":28},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"point","lvl3":"Parameters","lvl2":"Documentation"},"content":"Specific location in x,y, WKT (?), or reference to point (Link to feature?) TODO\n\nExample:&point=14.2,15.3","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#point","position":29},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"bbox","lvl3":"Parameters","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#bbox","position":30},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"bbox","lvl3":"Parameters","lvl2":"Documentation"},"content":"Bounding box in minx,miny,maxx,maxy or reference to geometry (Link to feature?) TODO\n\nExample:&bbox=12.3,0.3,14.4,2.3","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#bbox","position":31},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"geom","lvl2":"Documentation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#geom","position":32},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl3":"geom","lvl2":"Documentation"},"content":"WKT geometry or reference to geometry (Link to feature?) TODO\n\nExample:&geom=POLYGON ((...))","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#geom","position":33},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"time","lvl3":"geom","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#time","position":34},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"time","lvl3":"geom","lvl2":"Documentation"},"content":"Time point or time span\n\nExamples:\n\nStart/End&time=2018-05-04T12:12:12Z/2018-06-04T12:12:12Z\n\nInstant&time=2018-05-04T12:12:12Z\n\nStart and period after (not yet supported)&time=2018-05-04T12:12:12Z/P5D\n\nEnd and period before (not yet supported)&time=P5D/2018-05-04T12:12:12Z\n\nWhole day&time=2018-05-04\n\nWhole month&time=2018-05\n\nWhole year&time=2018","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#time","position":35},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"fields","lvl3":"geom","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#fields","position":36},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"fields","lvl3":"geom","lvl2":"Documentation"},"content":"Comma-separated list of fields, derived (calculated) fields are possible\n\nSyntax:field-parameter = field-selection , { ',' , field-selection }\n\nfield-selection = identifier | ( identifier , '=' , expression )\n\nPlease note: + sign need to be URL encoded to %2B\n\nExamples:\n\nListing:&fields=B04,B08\n\nSimple aliasing:&fields=NIR=B08,RED=B04\n\nDerived field:&fields=NDVI=(B04-B08)/(B04+B08)\n\nCombined example:&fields=NIR=B08,RED=B04,NDVI=(RED-NIR)/(RED+NIR)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#fields","position":37},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"aggregate","lvl3":"geom","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#aggregate","position":38},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"aggregate","lvl3":"geom","lvl2":"Documentation"},"content":"Specify aggregation\n\nSyntax:aggregate-param = method { ',' , method }\n\nmethod = identifier  [ '(' , method-arg , ')' ]\n\nExamples:\n\nAggregation (min+max)aggregate=max,min\n\nAggregation (min+max+linear average)  (avg(linear) not yet supported - only avg)aggregate=max,min,avg(linear)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#aggregate","position":39},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"cql (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#cql-not-yet-supported","position":40},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"cql (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"content":"Metadata filter using CQL\n\nExample:cql=cloudCover < 0.5","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#cql-not-yet-supported","position":41},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"datafilter (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#datafilter-not-yet-supported","position":42},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"datafilter (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"content":"Syntax:datafilter-parameter = datafilter , { ',' , datafilter }\n\ndatafilter = boolean-expression\n\nExample:datafilter=area(NDVI > 1) >= 0.5","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#datafilter-not-yet-supported","position":43},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#format-not-yet-supported","position":44},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#format-not-yet-supported","position":45},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl5":"cube formats (~3D)","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#cube-formats-3d","position":46},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl5":"cube formats (~3D)","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"content":"AVI\n\napplication/x-netcdf\n\napplication/metalink\n\nWCS-EO DatsetSeries / CIS","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#cube-formats-3d","position":47},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl5":"coverage (~2D)","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#coverage-2d","position":48},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl5":"coverage (~2D)","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"content":"image/tiff","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#coverage-2d","position":49},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl5":"timeseries (~1D)","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#timeseries-1d","position":50},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl5":"timeseries (~1D)","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"content":"text/csv\n\napplication/json","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#timeseries-1d","position":51},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl5":"value (~0D)","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#value-0d","position":52},{"hierarchy":{"lvl1":"DAPA Evaluation Workshop: Introduction & Documentation","lvl5":"value (~0D)","lvl4":"format (not yet supported)","lvl3":"geom","lvl2":"Documentation"},"content":"text/plain\n\napplication/json","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-evaluation-workshop#value-0d","position":53},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2","position":0},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2","position":1},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Load environment variables"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#load-environment-variables","position":2},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Load environment variables"},"content":"Please make sure that the environment variable “DAPA_URL” is set in the custom.env file. You can check this by executing the following block.\n\nIf DAPA_URL is not set, please create a text file named custom.env in your home directory with the following input:\n\nDAPA_URL=YOUR-PERSONAL-DAPA-APP-URL\n\nfrom edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#load-environment-variables","position":3},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Check notebook compabtibility"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#check-notebook-compabtibility","position":4},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Check notebook compabtibility"},"content":"Please note: If you conduct this notebook again at a later time, the base image of this Jupyter Hub service can include newer versions of the libraries installed. Thus, the notebook execution can fail. This compatibility check is only necessary when something is broken.\n\nfrom edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#check-notebook-compabtibility","position":5},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Load Libraries"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#load-libraries","position":6},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Load Libraries"},"content":"Python libraries used in this tutorial will be loaded.\n\nimport os\nimport xarray as xr\nimport pandas as pd\nimport requests\nimport matplotlib\nfrom ipyleaflet import Map, Rectangle, DrawControl, basemaps, basemap_to_tiles\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#load-libraries","position":7},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Set DAPA endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#set-dapa-endpoint","position":8},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Set DAPA endpoint"},"content":"Execute the following code to check if the DAPA_URL is available in the environment variable and to set the /dapa endpoint.\n\nservice_url = None\ndapa_url = None\n\nif 'DAPA_URL' not in os.environ:\n    print('!! DAPA_URL does not exist as environment variable. Please make sure this is the case - see first block of this notebook! !!')\nelse:    \n    service_url = os.environ['DAPA_URL']\n    dapa_url = '{}/{}'.format(service_url, 'oapi')\n    print('DAPA path: {}'.format(dapa_url.replace(service_url, '')))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#set-dapa-endpoint","position":9},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Get collections supported by this endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#get-collections-supported-by-this-endpoint","position":10},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Get collections supported by this endpoint"},"content":"This request provides a list of collections. The path of each collection is used as starting path of this service.\n\ncollections_url = '{}/{}'.format(dapa_url, 'collections')\ncollections = requests.get(collections_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(collections.url.replace(service_url, '')))\ncollections.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#get-collections-supported-by-this-endpoint","position":11},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Get fields of collection Sentinel-2 L2A"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#get-fields-of-collection-sentinel-2-l2a","position":12},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Get fields of collection Sentinel-2 L2A"},"content":"The fields (or variables in other DAPA endpoints - these are the bands of the raster data) can be retrieved in all requests to the DAPA endpoint. In addition to the fixed set of fields, “virtual” fields can be used to conduct math operations (e.g., the calculation of indices).\n\ncollection = 'S2L2A'\n\nfields_url = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/fields')\nfields = requests.get(fields_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(fields.url.replace(service_url, '')))\nfields.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#get-fields-of-collection-sentinel-2-l2a","position":13},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#retrieve-data-as-multi-temporal-dataset-cube","position":14},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#retrieve-data-as-multi-temporal-dataset-cube","position":15},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#set-dapa-url-and-parameters","position":16},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"The output of this request is a multi-temporal cube (cube endpoint), which allows for subsetting spatially and temporally and conducing map algebra (e.g., calculation of the Normalized Difference Vegetation Index [NDVI] or the Normalized Difference Buildup Index [NDBI]).\n\nTo retrieve a cube, a bounding box (bbox) or polygon geometry (geom) need to be provided. The time parameter allows to aggregate data only within a specific time span. Also the band (field) to be returned by DAPA needs to be specified as well.\n\n# DAPA URL\nurl = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/cube')\n\n# Parameters for this request\nparams = {\n    'bbox': '11.49,48.05,11.66,48.22',\n    'time': '2018-05-02T00:00:00Z/2018-05-10T00:00:00Z',\n    'fields': 'B08,B04,NDVI=(B08-B04)/(B08%2BB04),NDBI=(B11-B08)/(B11%2BB08)'\n}\n\n# show point in the map\nm = Map(\n    basemap=basemap_to_tiles(basemaps.OpenStreetMap.Mapnik),\n    center=(48.14, 11.56),\n    zoom=10\n)\n\nbbox = [float(coord) for coord in params['bbox'].split(',')]\nrectangle = Rectangle(bounds=((bbox[1], bbox[0]), (bbox[3], bbox[2])))\nm.add_layer(rectangle)\n\nm\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#set-dapa-url-and-parameters","position":17},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Build request URL and conduct request","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#build-request-url-and-conduct-request","position":18},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Build request URL and conduct request","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"\n\nparams_str = \"&\".join(\"%s=%s\" % (k, v) for k,v in params.items())\nr = requests.get(url, params=params_str)\n\nprint('DAPA path: {}'.format(r.url.replace(service_url, '')))\nprint('Status code: {}'.format(r.status_code))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#build-request-url-and-conduct-request","position":19},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Write cube dataset to netCDF file","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#write-cube-dataset-to-netcdf-file","position":20},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Write cube dataset to netCDF file","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"The response of the cube endpoint is currently a netCDF4 file, which can either be saved to disk or used directly in further processing.\n\nwith open('cube_s2.nc', 'wb') as filew:\n    filew.write(r.content)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#write-cube-dataset-to-netcdf-file","position":21},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Open cube dataset with xarray","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#open-cube-dataset-with-xarray","position":22},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Open cube dataset with xarray","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"A multi-temporal netCDF4 file can be opened with xarray. The file consists of a band (data variable) for each field. Additionally, the time dimension is shown in the description of the xarray dataset.\n\nds = xr.open_dataset('cube_s2.nc')\nds\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#open-cube-dataset-with-xarray","position":23},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Plot NDVI/NDBI data","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#plot-ndvi-ndbi-data","position":24},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Plot NDVI/NDBI data","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#plot-ndvi-ndbi-data","position":25},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl4":"NDVI plot for a specific point in time","lvl3":"Plot NDVI/NDBI data","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#ndvi-plot-for-a-specific-point-in-time","position":26},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl4":"NDVI plot for a specific point in time","lvl3":"Plot NDVI/NDBI data","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"\n\nds['NDVI'].isel(time=2).plot(cmap=\"RdYlGn\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#ndvi-plot-for-a-specific-point-in-time","position":27},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl4":"NDVI plot for all times in the cube","lvl3":"Plot NDVI/NDBI data","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#ndvi-plot-for-all-times-in-the-cube","position":28},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl4":"NDVI plot for all times in the cube","lvl3":"Plot NDVI/NDBI data","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"Please note: Only clouds visible in the first and second time.\n\nds['NDVI'].plot(x='x', y='y', col='time', col_wrap=4, cmap=\"RdYlGn\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#ndvi-plot-for-all-times-in-the-cube","position":29},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl4":"NDBI (Buildup index) plot for a specific point in time","lvl3":"Plot NDVI/NDBI data","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#ndbi-buildup-index-plot-for-a-specific-point-in-time","position":30},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl4":"NDBI (Buildup index) plot for a specific point in time","lvl3":"Plot NDVI/NDBI data","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"Please note: Color scales need to be adjusted correctly in the plot to identify buildup areas. This needs to be enhanced in an upcoming version of this notebook.\n\nds['NDBI'].plot(x='x', y='y', col='time', col_wrap=4, cmap=\"RdYlGn_r\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#ndbi-buildup-index-plot-for-a-specific-point-in-time","position":31},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Output gdalinfo for NDVI band","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#output-gdalinfo-for-ndvi-band","position":32},{"hierarchy":{"lvl1":"DAPA Tutorial #1: Cube - Sentinel-2","lvl3":"Output gdalinfo for NDVI band","lvl2":"Retrieve data as multi-temporal dataset (cube)"},"content":"\n\n!gdalinfo NETCDF:\"cube_s2.nc\":NDVI","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-1-cube-sentinel-2#output-gdalinfo-for-ndvi-band","position":33},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2","position":0},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2","position":1},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Load environment variables"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#load-environment-variables","position":2},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Load environment variables"},"content":"Please make sure that the environment variable “DAPA_URL” is set in the custom.env file. You can check this by executing the following block.\n\nIf DAPA_URL is not set, please create a text file named custom.env in your home directory with the following input:\n\nDAPA_URL=YOUR-PERSONAL-DAPA-APP-URL\n\nfrom edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#load-environment-variables","position":3},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Check notebook compabtibility"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#check-notebook-compabtibility","position":4},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Check notebook compabtibility"},"content":"Please note: If you conduct this notebook again at a later time, the base image of this Jupyter Hub service can include newer versions of the libraries installed. Thus, the notebook execution can fail. This compatibility check is only necessary when something is broken.\n\nfrom edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#check-notebook-compabtibility","position":5},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Load libraries"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#load-libraries","position":6},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Load libraries"},"content":"Python libraries used in this tutorial will be loaded.\n\nimport os\nimport xarray as xr\nimport pandas as pd\nimport requests\nimport matplotlib\nfrom ipyleaflet import Map, Rectangle, DrawControl, basemaps, basemap_to_tiles\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#load-libraries","position":7},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Set DAPA endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#set-dapa-endpoint","position":8},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Set DAPA endpoint"},"content":"Execute the following code to check if the DAPA_URL is available in the environment variable and to set the /dapa endpoint.\n\nservice_url = None\ndapa_url = None\n\nif 'DAPA_URL' not in os.environ:\n    print('!! DAPA_URL does not exist as environment variable. Please make sure this is the case - see first block of this notebook! !!')\nelse:    \n    service_url = os.environ['DAPA_URL']\n    dapa_url = '{}/{}'.format(service_url, 'oapi')\n    print('DAPA path: {}'.format(dapa_url.replace(service_url, '')))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#set-dapa-endpoint","position":9},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Get collections supported by this endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#get-collections-supported-by-this-endpoint","position":10},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Get collections supported by this endpoint"},"content":"This request provides a list of collections. The path of each collection is used as starting path of this service.\n\ncollections_url = '{}/{}'.format(dapa_url, 'collections')\ncollections = requests.get(collections_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(collections.url.replace(service_url, '')))\ncollections.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#get-collections-supported-by-this-endpoint","position":11},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Get fields of collection Sentinel-2 L2A"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#get-fields-of-collection-sentinel-2-l2a","position":12},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Get fields of collection Sentinel-2 L2A"},"content":"The fields (or variables in other DAPA endpoints - these are the bands of the raster data) can be retrieved in all requests to the DAPA endpoint. In addition to the fixed set of fields, “virtual” fields can be used to conduct math operations (e.g., the calculation of indices).\n\ncollection = 'S2L2A'\n\nfields_url = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/fields')\nfields = requests.get(fields_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(fields.url.replace(service_url, '')))\nfields.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#get-fields-of-collection-sentinel-2-l2a","position":13},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Retrieve data as raster aggregated by time"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#retrieve-data-as-raster-aggregated-by-time","position":14},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Retrieve data as raster aggregated by time"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#retrieve-data-as-raster-aggregated-by-time","position":15},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve data as raster aggregated by time"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#set-dapa-url-and-parameters","position":16},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve data as raster aggregated by time"},"content":"The output of this request is a single raster (area endpoint). As the input collection (S2L2A) is a multi-temporal raster and the output format is an area, temporal aggregation is conducted for each pixel in the area.\n\nTo retrieve a single raster, a bounding box (bbox) or polygon geometry (geom) needs to be provided. The time parameter allows to aggregate data only within a specific time span. Also the band (field) to be returned by DAPA needs to be specified as well.\n\n# DAPA URL\nurl = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/area')\n\n# Parameters for this request\nparams = {\n    'bbox': '11.49,48.05,11.66,48.22',\n    'time': '2018-05-07T10:00:00Z/2018-05-07T12:00:00Z',\n    'fields': 'NDVI=(B08-B04)/(B08%2BB04),NDBI=(B11-B08)/(B11%2BB08)', # Please note: + signs need to be URL encoded -> %2B\n    'aggregate': 'avg'\n}\n\n# show point in the map\nm = Map(\n    basemap=basemap_to_tiles(basemaps.OpenStreetMap.Mapnik),\n    center=(48.14, 11.56),\n    zoom=10\n)\n\nbbox = [float(coord) for coord in params['bbox'].split(',')]\nrectangle = Rectangle(bounds=((bbox[1], bbox[0]), (bbox[3], bbox[2])))\nm.add_layer(rectangle)\n\nm\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#set-dapa-url-and-parameters","position":17},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Build request URL and conduct request","lvl2":"Retrieve data as raster aggregated by time"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#build-request-url-and-conduct-request","position":18},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Build request URL and conduct request","lvl2":"Retrieve data as raster aggregated by time"},"content":"\n\nparams_str = \"&\".join(\"%s=%s\" % (k, v) for k,v in params.items())\nr = requests.get(url, params=params_str)\n\nprint('DAPA path: {}'.format(r.url.replace(service_url, '')))\nprint('Status code: {}'.format(r.status_code))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#build-request-url-and-conduct-request","position":19},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Write raster dataset to GeoTIFF file","lvl2":"Retrieve data as raster aggregated by time"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#write-raster-dataset-to-geotiff-file","position":20},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Write raster dataset to GeoTIFF file","lvl2":"Retrieve data as raster aggregated by time"},"content":"The response of the area endpoint is currently a GeoTIFF file, which can either be saved to disk or used directly in further processing.\n\nwith open('area_avg.tif', 'wb') as filew:\n    filew.write(r.content)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#write-raster-dataset-to-geotiff-file","position":21},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Open raster dataset with xarray","lvl2":"Retrieve data as raster aggregated by time"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#open-raster-dataset-with-xarray","position":22},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Open raster dataset with xarray","lvl2":"Retrieve data as raster aggregated by time"},"content":"The GeoTIFF file can be opened with xarray. The file consists of bands related to each field and each aggregation function (see descriptions attribute in the xarray output).\n\nds = xr.open_rasterio('area_avg.tif')\nds\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#open-raster-dataset-with-xarray","position":23},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Plot NDVI image (first band)","lvl2":"Retrieve data as raster aggregated by time"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#plot-ndvi-image-first-band","position":24},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl3":"Plot NDVI image (first band)","lvl2":"Retrieve data as raster aggregated by time"},"content":"\n\nds[0].plot(cmap=\"RdYlGn\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#plot-ndvi-image-first-band","position":25},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Output gdalinfo"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#output-gdalinfo","position":26},{"hierarchy":{"lvl1":"DAPA Tutorial #2: Area - Sentinel-2","lvl2":"Output gdalinfo"},"content":"\n\n!gdalinfo -stats area_avg.tif","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-2-area-sentinel-2#output-gdalinfo","position":27},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2","position":0},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2","position":1},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Load environment variables"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#load-environment-variables","position":2},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Load environment variables"},"content":"Please make sure that the environment variable “DAPA_URL” is set in the custom.env file. You can check this by executing the following block.\n\nIf DAPA_URL is not set, please create a text file named custom.env in your home directory with the following input:\n\nDAPA_URL=YOUR-PERSONAL-DAPA-APP-URL\n\nfrom edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#load-environment-variables","position":3},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Check notebook compabtibility"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#check-notebook-compabtibility","position":4},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Check notebook compabtibility"},"content":"Please note: If you conduct this notebook again at a later time, the base image of this Jupyter Hub service can include newer versions of the libraries installed. Thus, the notebook execution can fail. This compatibility check is only necessary when something is broken.\n\nfrom edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#check-notebook-compabtibility","position":5},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Load libraries"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#load-libraries","position":6},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Load libraries"},"content":"Python libraries used in this tutorial will be loaded.\n\nimport os\nimport xarray as xr\nimport pandas as pd\nimport requests\nimport matplotlib\nfrom ipyleaflet import Map, Rectangle, Marker, DrawControl, basemaps, basemap_to_tiles\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#load-libraries","position":7},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Set DAPA endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#set-dapa-endpoint","position":8},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Set DAPA endpoint"},"content":"Execute the following code to check if the DAPA_URL is available in the environment variable and to set the /dapa endpoint.\n\nservice_url = None\ndapa_url = None\n\nif 'DAPA_URL' not in os.environ:\n    print('!! DAPA_URL does not exist as environment variable. Please make sure this is the case - see first block of this notebook! !!')\nelse:    \n    service_url = os.environ['DAPA_URL']\n    dapa_url = '{}/{}'.format(service_url, 'oapi')\n    print('DAPA path: {}'.format(dapa_url.replace(service_url, '')))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#set-dapa-endpoint","position":9},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Get collections supported by this endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#get-collections-supported-by-this-endpoint","position":10},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Get collections supported by this endpoint"},"content":"This request provides a list of collections. The path of each collection is used as starting path of this service.\n\ncollections_url = '{}/{}'.format(dapa_url, 'collections')\ncollections = requests.get(collections_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(collections.url.replace(service_url, '')))\ncollections.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#get-collections-supported-by-this-endpoint","position":11},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Get fields of collection Sentinel-2 L2A"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#get-fields-of-collection-sentinel-2-l2a","position":12},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Get fields of collection Sentinel-2 L2A"},"content":"The fields (or variables in other DAPA endpoints - these are the bands of the raster data) can be retrieved in all requests to the DAPA endpoint. In addition to the fixed set of fields, “virtual” fields can be used to conduct math operations (e.g., the calculation of indices).\n\ncollection = 'S2L2A'\n\nfields_url = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/fields')\nfields = requests.get(fields_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(fields.url.replace(service_url, '')))\nfields.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#get-fields-of-collection-sentinel-2-l2a","position":13},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#retrieve-ndvi-as-1d-time-series-extraced-for-a-single-point","position":14},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#retrieve-ndvi-as-1d-time-series-extraced-for-a-single-point","position":15},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#set-dapa-url-and-parameters","position":16},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"content":"The output of this request is a time-series requested from a point of interest (timeseries/position endpoint). As the input collection (S2L2A) is a multi-temporal raster and the requested geometry is a point, no aggregation is conducted.\n\nTo retrieve a time-series of a point, the parameter point needs to be provided. The time parameter allows to extract data only within a specific time span. The band (field) from which the point is being extracted needs to be specified as well.\n\n# DAPA URL\nurl = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/timeseries/position')\n\n# Parameters for this request\nparams = {\n    'point': '11.49,48.05',\n    'time': '2018-04-01T00:00:00Z/2018-05-01T00:00:00Z',\n    'fields': 'NDVI=(B08-B04)/(B08%2BB04)'    # Please note: + signs need to be URL encoded -> %2B\n}\n\n# show point in the map\nlocation = list(reversed([float(coord) for coord in params['point'].split(',')]))\nm = Map(\n    basemap=basemap_to_tiles(basemaps.OpenStreetMap.Mapnik),\n    center=location,\n    zoom=10\n)\n\nmarker = Marker(location=location, draggable=False)\nm.add_layer(marker)\n\nm\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#set-dapa-url-and-parameters","position":17},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Build request URL and conduct request","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#build-request-url-and-conduct-request","position":18},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Build request URL and conduct request","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"content":"\n\nparams_str = \"&\".join(\"%s=%s\" % (k, v) for k,v in params.items())\nr = requests.get(url, params=params_str)\n\nprint('DAPA path: {}'.format(r.url.replace(service_url, '')))\nprint('Status code: {}'.format(r.status_code))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#build-request-url-and-conduct-request","position":19},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Write timeseries dataset to CSV file","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#write-timeseries-dataset-to-csv-file","position":20},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Write timeseries dataset to CSV file","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"content":"The response of this request returns data as CSV including headers splitted by comma. Additional output formats (e.g., CSV with headers included) will be integrated within the testbed activtiy.\n\nYou can either write the response to file or use it as string (r.content variable).\n\n# write time-series data to CSV file\nwith open('timeseries_s2.csv', 'wb') as filew:\n    filew.write(r.content)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#write-timeseries-dataset-to-csv-file","position":21},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Open timeseries dataset with pandas","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#open-timeseries-dataset-with-pandas","position":22},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Open timeseries dataset with pandas","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"content":"Time-series data can be opened, processed, and plotted easily with the Pandas library. You only need to specify the datetime column to automatically convert dates from string to a datetime object.\n\n# read data into Pandas dataframe\nds = pd.read_csv('timeseries_s2.csv', parse_dates=['datetime'])\n\n# set index to datetime column\nds.set_index('datetime', inplace=True)\n\n# show dataframe\nds\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#open-timeseries-dataset-with-pandas","position":23},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Plot NDVI data","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#plot-ndvi-data","position":24},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Plot NDVI data","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"content":"\n\nds.plot()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#plot-ndvi-data","position":25},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Output CSV file","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#output-csv-file","position":26},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl3":"Output CSV file","lvl2":"Retrieve NDVI as 1d time-series extraced for a single point"},"content":"\n\n!cat timeseries_s2.csv\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#output-csv-file","position":27},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Time-series aggregated over area"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#time-series-aggregated-over-area","position":28},{"hierarchy":{"lvl1":"DAPA Tutorial #3: Timeseries - Sentinel-2","lvl2":"Time-series aggregated over area"},"content":"\n\n# DAPA URL\nurl = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/timeseries/area')\n\n# Parameters for this request\nparams = {\n    #'point': '11.49,48.05',\n    'bbox': '11.49,48.05,11.66,48.22',\n    'aggregate': 'min,max,avg',\n    'time': '2018-04-01T00:00:00Z/2018-05-01T00:00:00Z',\n    'fields': 'NDVI=(B08-B04)/(B08%2BB04)'    # Please note: + signs need to be URL encoded -> %2B\n}\n\nparams_str = \"&\".join(\"%s=%s\" % (k, v) for k,v in params.items())\nr = requests.get(url, params=params_str)\n\nprint('DAPA path: {}'.format(r.url.replace(service_url, '')))\nprint('Status code: {}'.format(r.status_code))\n\n# read data into Pandas dataframe\nfrom io import StringIO\nds = pd.read_csv(StringIO(r.text), parse_dates=['datetime'])\n\n# set index to datetime column\nds.set_index('datetime', inplace=True)\n\n# show dataframe\nds\n\nds.plot()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-3-timeseries-sentinel-2#time-series-aggregated-over-area","position":29},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2","position":0},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2","position":1},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Load environment variables"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#load-environment-variables","position":2},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Load environment variables"},"content":"Please make sure that the environment variable “DAPA_URL” is set in the custom.env file. You can check this by executing the following block.\n\nIf DAPA_URL is not set, please create a text file named custom.env in your home directory with the following input:\n\nDAPA_URL=YOUR-PERSONAL-DAPA-APP-URL\n\nfrom edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#load-environment-variables","position":3},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Check notebook compabtibility"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#check-notebook-compabtibility","position":4},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Check notebook compabtibility"},"content":"Please note: If you conduct this notebook again at a later time, the base image of this Jupyter Hub service can include newer versions of the libraries installed. Thus, the notebook execution can fail. This compatibility check is only necessary when something is broken.\n\nfrom edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#check-notebook-compabtibility","position":5},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Load libraries"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#load-libraries","position":6},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Load libraries"},"content":"Python libraries used in this tutorial will be loaded.\n\nimport os\nimport xarray as xr\nimport pandas as pd\nimport requests\nimport matplotlib\nfrom ipyleaflet import Map, Rectangle, Marker, DrawControl, basemaps, basemap_to_tiles\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#load-libraries","position":7},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Set DAPA endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#set-dapa-endpoint","position":8},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Set DAPA endpoint"},"content":"Execute the following code to check if the DAPA_URL is available in the environment variable and to set the /dapa endpoint.\n\nservice_url = None\ndapa_url = None\n\nif 'DAPA_URL' not in os.environ:\n    print('!! DAPA_URL does not exist as environment variable. Please make sure this is the case - see first block of this notebook! !!')\nelse:    \n    service_url = os.environ['DAPA_URL']\n    dapa_url = '{}/{}'.format(service_url, 'oapi')\n    print('DAPA path: {}'.format(dapa_url.replace(service_url, '')))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#set-dapa-endpoint","position":9},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Get collections supported by this endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#get-collections-supported-by-this-endpoint","position":10},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Get collections supported by this endpoint"},"content":"This request provides a list of collections. The path of each collection is used as starting path of this service.\n\ncollections_url = '{}/{}'.format(dapa_url, 'collections')\ncollections = requests.get(collections_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(collections.url.replace(service_url, '')))\ncollections.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#get-collections-supported-by-this-endpoint","position":11},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Get fields of collection Sentinel-2 L2A"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#get-fields-of-collection-sentinel-2-l2a","position":12},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Get fields of collection Sentinel-2 L2A"},"content":"The fields (or variables in other DAPA endpoints - these are the bands of the raster data) can be retrieved in all requests to the DAPA endpoint. In addition to the fixed set of fields, “virtual” fields can be used to conduct math operations (e.g., the calculation of indices).\n\ncollection = 'S2L2A'\n\nfields_url = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/fields')\nfields = requests.get(fields_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(fields.url.replace(service_url, '')))\nfields.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#get-fields-of-collection-sentinel-2-l2a","position":13},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Retrieve an NDVI value extraced for a single point"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#retrieve-an-ndvi-value-extraced-for-a-single-point","position":14},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl2":"Retrieve an NDVI value extraced for a single point"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#retrieve-an-ndvi-value-extraced-for-a-single-point","position":15},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve an NDVI value extraced for a single point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#set-dapa-url-and-parameters","position":16},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve an NDVI value extraced for a single point"},"content":"The output of this request is a single value requested from a point of interest (value/position endpoint). As the input collection (S2L2A) is a multi-temporal raster and the requested geometry is a point, temporal aggregation is conducted.\n\nTo retrieve a single value of a point, the parameter point needs to be provided. For the temporal aggregation, the parameter aggregate needs to include the aggregation functions splitted by comma. The time parameter allows to aggregate data only within a specific time span. The band (field) from which the point is being extracted needs to be specified as well.\n\n# DAPA URL\nurl = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/value/position')\n\n# Parameters for this request\nparams = {\n    'point': '11.49,48.05',\n    'time': '2018-04-01T00:00:00Z/2018-07-01T00:00:00Z',\n    'fields': 'NDVI=(B04-B08)/(B04%2BB08)',\n    'aggregate': 'min,max,avg'\n}\n\n# show point in the map\nlocation = list(reversed([float(coord) for coord in params['point'].split(',')]))\n\nm = Map(\n    basemap=basemap_to_tiles(basemaps.OpenStreetMap.Mapnik),\n    center=location,\n    zoom=10\n)\n\nmarker = Marker(location=location, draggable=False)\nm.add_layer(marker)\n\nm\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#set-dapa-url-and-parameters","position":17},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl3":"Build request URL and conduct request","lvl2":"Retrieve an NDVI value extraced for a single point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#build-request-url-and-conduct-request","position":18},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl3":"Build request URL and conduct request","lvl2":"Retrieve an NDVI value extraced for a single point"},"content":"\n\nparams_str = \"&\".join(\"%s=%s\" % (k, v) for k,v in params.items())\nr = requests.get(url, params=params_str)\n\nprint('DAPA path: {}'.format(r.url.replace(service_url, '')))\nprint('Status code: {}'.format(r.status_code))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#build-request-url-and-conduct-request","position":19},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl3":"Show content (one value for each aggregation method)","lvl2":"Retrieve an NDVI value extraced for a single point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#show-content-one-value-for-each-aggregation-method","position":20},{"hierarchy":{"lvl1":"DAPA Tutorial #4: Value - Sentinel-2","lvl3":"Show content (one value for each aggregation method)","lvl2":"Retrieve an NDVI value extraced for a single point"},"content":"The response of this request returns plain text with values splitted by comma. The order of the values relates to the order of the fields specified in the fields parameter in combination with the order of the aggregation functions. Additional output formats (e.g., CSV with headers included) will be integrated within the testbed activtiy.\n\nvalues = r.text\nvalues\n\nprint('%s: %s' % (params['aggregate'].split(',')[0], values.split(',')[0]))\nprint('%s: %s' % (params['aggregate'].split(',')[1], values.split(',')[1]))\nprint('%s: %s' % (params['aggregate'].split(',')[2], values.split(',')[2]))","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-4-value-sentinel-2#show-content-one-value-for-each-aggregation-method","position":21},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem","position":0},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem","position":1},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Load environment variables"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#load-environment-variables","position":2},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Load environment variables"},"content":"Please make sure that the environment variable “DAPA_URL” is set in the custom.env file. You can check this by executing the following block.\n\nIf DAPA_URL is not set, please create a text file named custom.env in your home directory with the following input:\n\nDAPA_URL=YOUR-PERSONAL-DAPA-APP-URL\n\nfrom edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#load-environment-variables","position":3},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Check notebook compabtibility"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#check-notebook-compabtibility","position":4},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Check notebook compabtibility"},"content":"Please note: If you conduct this notebook again at a later time, the base image of this Jupyter Hub service can include newer versions of the libraries installed. Thus, the notebook execution can fail. This compatibility check is only necessary when something is broken.\n\nfrom edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#check-notebook-compabtibility","position":5},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Load libraries"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#load-libraries","position":6},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Load libraries"},"content":"\n\nPython libraries used in this tutorial will be loaded.\n\nimport os\nimport xarray as xr\nimport pandas as pd\nimport requests\nimport matplotlib\nimport rasterio\nfrom rasterio.plot import show\nfrom ipyleaflet import Map, Rectangle, DrawControl, basemaps, basemap_to_tiles\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#load-libraries","position":7},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Set DAPA endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#set-dapa-endpoint","position":8},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Set DAPA endpoint"},"content":"Execute the following code to check if the DAPA_URL is available in the environment variable and to set the /dapa endpoint.\n\nservice_url = None\ndapa_url = None\n\nif 'DAPA_URL' not in os.environ:\n    print('!! DAPA_URL does not exist as environment variable. Please make sure this is the case - see first block of this notebook! !!')\nelse:    \n    service_url = os.environ['DAPA_URL']\n    dapa_url = '{}/{}'.format(service_url, 'oapi')\n    print('DAPA path: {}'.format(dapa_url.replace(service_url, '')))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#set-dapa-endpoint","position":9},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Get collections supported by this endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#get-collections-supported-by-this-endpoint","position":10},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Get collections supported by this endpoint"},"content":"This request provides a list of collections. The path of each collection is used as starting path of this service.\n\ncollections_url = '{}/{}'.format(dapa_url, 'collections')\ncollections = requests.get(collections_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(collections.url.replace(service_url, '')))\ncollections.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#get-collections-supported-by-this-endpoint","position":11},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Get fields of collection DEM"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#get-fields-of-collection-dem","position":12},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Get fields of collection DEM"},"content":"The fields (or variables in other DAPA endpoints - these are the bands of the raster data) can be retrieved in all requests to the DAPA endpoint. In addition to the fixed set of fields, “virtual” fields can be used to conduct math operations (e.g., the calculation of indices).\n\ncollection = 'DEM'\n\nfields_url = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/fields')\nfields = requests.get(fields_url, headers={'Accept': 'application/json'})\n\nprint('DAPA path: {}'.format(fields.url.replace(service_url, '')))\nfields.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#get-fields-of-collection-dem","position":13},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Retrieve a subset of an area of interest"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#retrieve-a-subset-of-an-area-of-interest","position":14},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Retrieve a subset of an area of interest"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#retrieve-a-subset-of-an-area-of-interest","position":15},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve a subset of an area of interest"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#set-dapa-url-and-parameters","position":16},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Set DAPA URL and parameters","lvl2":"Retrieve a subset of an area of interest"},"content":"The output of this request is a single raster (area endpoint). As the input collection (DEM) is a single raster as well, only subsetting is done, no aggregation method needs to be specified.\n\nTo retrieve a subset of an area of interest, a bounding box (bbox) or polygon geometry (geom) needs to be provided. Also the band (field) to be returned by DAPA needs to be specified.\n\n# DAPA URL\nurl = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/area')\n\n# Parameters for this request\nparams = {\n    'bbox': '11,48,12,48.5',\n    'fields': 'DEM'\n}\n\n# show area in the map\nm = Map(\n    basemap=basemap_to_tiles(basemaps.OpenStreetMap.Mapnik),\n    center=(48.25, 11.5),\n    zoom=9\n)\n\nbbox = [float(coord) for coord in params['bbox'].split(',')]\nrectangle = Rectangle(bounds=((bbox[1], bbox[0]), (bbox[3], bbox[2])))\nm.add_layer(rectangle)\nm\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#set-dapa-url-and-parameters","position":17},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Build request URL and conduct request","lvl2":"Retrieve a subset of an area of interest"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#build-request-url-and-conduct-request","position":18},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Build request URL and conduct request","lvl2":"Retrieve a subset of an area of interest"},"content":"\n\nparams_str = \"&\".join(\"%s=%s\" % (k, v) for k,v in params.items())\nr = requests.get(url, params=params_str)\n\nprint('DAPA path: {}'.format(r.url.replace(service_url, '')))\nprint('Status code: {}'.format(r.status_code))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#build-request-url-and-conduct-request","position":19},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Write raster dataset to GeoTIFF file","lvl2":"Retrieve a subset of an area of interest"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#write-raster-dataset-to-geotiff-file","position":20},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Write raster dataset to GeoTIFF file","lvl2":"Retrieve a subset of an area of interest"},"content":"The response of the area endpoint is currently a GeoTIFF file, which can either be saved to disk or used directly in further processing.\n\nwith open('dem_subset.tif', 'wb') as filew:\n    filew.write(r.content)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#write-raster-dataset-to-geotiff-file","position":21},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Open raster dataset with xarray","lvl2":"Retrieve a subset of an area of interest"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#open-raster-dataset-with-xarray","position":22},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Open raster dataset with xarray","lvl2":"Retrieve a subset of an area of interest"},"content":"The GeoTIFF file can be opened with xarray. As the request only specified one field and no aggregation is needed, only one band is available.\n\nds = xr.open_rasterio('dem_subset.tif')\nds\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#open-raster-dataset-with-xarray","position":23},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Plot DEM image","lvl2":"Retrieve a subset of an area of interest"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#plot-dem-image","position":24},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl3":"Plot DEM image","lvl2":"Retrieve a subset of an area of interest"},"content":"\n\nds[0].plot()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#plot-dem-image","position":25},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Output gdalinfo"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#output-gdalinfo","position":26},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Output gdalinfo"},"content":"\n\n!gdalinfo -stats dem_subset.tif\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#output-gdalinfo","position":27},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Retrieve DEM value within an area of interest aggregated spatially"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#retrieve-dem-value-within-an-area-of-interest-aggregated-spatially","position":28},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Retrieve DEM value within an area of interest aggregated spatially"},"content":"The output of this request is a single value requested from an area of interest (value/area endpoint). As the input collection (DEM) is a single raster, only spatial aggregation is conducted.\n\nTo retrieve a single value of an area of interest, a bounding box (bbox) or polygon geometry (geom) needs to be provided together with the aggregate parameter, which specifies the aggregation methods being conducted. The band (field) to be returned by DAPA needs to be specified.\n\nThe response of this request returns plain text with values splitted by comma. The order of the values relates to the order of the functions specified in the aggregate parameter. Additional output formats will be integrated within the testbed activtiy.\n\nurl = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/value/area')\nparams = {\n    'bbox': '11,48,12,48.5',\n    'fields': 'DEM',\n    'aggregate': 'min,max,avg'\n}\n\nparams_str = \"&\".join(\"%s=%s\" % (k, v) for k,v in params.items())\nr = requests.get(url, params=params_str)\n\nprint('DAPA path: {}'.format(r.url.replace(service_url, '')))\nprint('Status code: {}'.format(r.status_code))\n\nPrint values of the request\n\nvalues = r.text.split(',')\nprint('min: %s' % values[0])\nprint('max: %s' % values[1])\nprint('avg: %s' % values[2])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#retrieve-dem-value-within-an-area-of-interest-aggregated-spatially","position":29},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Retrieve DEM value at a specific point"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#retrieve-dem-value-at-a-specific-point","position":30},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Retrieve DEM value at a specific point"},"content":"The output of this request is a single value requested from a point of interest (value/position endpoint). As the input collection (DEM) is a single raster and the requested geometry is a point, no aggregation is needed.\n\nTo retrieve a single value of a point, the parameter point needs to be provided. The band (field) to be returned by DAPA needs to be specified.\n\nThe response of this request returns plain text with values splitted by comma. The order of the values relates to the order of the fields specified in the fields parameter. Additional output formats will be integrated within the testbed activtiy.\n\nurl = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/value/position')\nparams = {\n    'point': '11,48',\n    'fields': 'DEM'\n}\n\nparams_str = \"&\".join(\"%s=%s\" % (k, v) for k,v in params.items())\nr = requests.get(url, params=params_str)\n\nprint('DAPA path: {}'.format(r.url.replace(service_url, '')))\nprint('Status code: {}'.format(r.status_code))\nprint('Value: {}'.format(r.text))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#retrieve-dem-value-at-a-specific-point","position":31},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Retrieve DEM value at a specific point calculated in feet"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#retrieve-dem-value-at-a-specific-point-calculated-in-feet","position":32},{"hierarchy":{"lvl1":"DAPA Tutorial #5: DEM","lvl2":"Retrieve DEM value at a specific point calculated in feet"},"content":"You can do math operations in the fields parameter. To calculate from meter to feet you need only to specify a virtual field:\n\nFEET=DEM/0.3048\n\nurl = '{}/{}/{}/{}'.format(dapa_url, 'collections', collection, 'dapa/value/position')\nparams = {\n    'point': '11,48',\n    'fields': 'FEET=DEM/0.3048'\n}\n\nparams_str = \"&\".join(\"%s=%s\" % (k, v) for k,v in params.items())\nr = requests.get(url, params=params_str)\n\nprint('DAPA path: {}'.format(r.url.replace(service_url, '')))\nprint('Status code: {}'.format(r.status_code))\nprint('Value: {}'.format(r.text))","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/dapa/dapa-tutorial-5-dem#retrieve-dem-value-at-a-specific-point-calculated-in-feet","position":33},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2","position":0},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2","position":1},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#detect-trucks-using-sentinel-2-data","position":2},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#detect-trucks-using-sentinel-2-data","position":3},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Parallax-based truck detection"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#parallax-based-truck-detection","position":4},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Parallax-based truck detection"},"content":"\n\nThis notebook is a comprehensive script for detecting trucks with Sentinel-2 data. In order to run the detection in your area of interest you will have to modify two cells:\n\nArea of Interest (specify the aoi as bounding box)\n\nDate (specify an acquisition date)\n\nAfterwards, you may simply run all cells and check the result at the end of the script where you can also write the detections as points.\n\nEnsure that you have access to the Sentinel Hub resources for retrieving Sentinel-2 data through its API (via xcube_sh).\n\nAuthor: Henrik Fisser, 2020Explanations on the truck detection on GitHub: \n\nhttps://​github​.com​/hfisser​/Truck​_Detection​_Sentinel2​_COVID19\n\nimport os\nimport subprocess\nimport sys\n\n# installations\ndef install_package(pkg):\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\ninstall_package(\"OSMPythonTools\")\ninstall_package(\"geocube\")\n\n# OSM API\nfrom OSMPythonTools.overpass import overpassQueryBuilder, Overpass\n\nimport numpy as np\nimport xarray as xr\nimport geocube\nimport geopandas as gpd\nimport pandas as pd\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\nfrom xcube.core.maskset import MaskSet\nfrom rasterio import features\nfrom affine import Affine\nfrom shapely import geometry, coords\nfrom shapely.geometry import Polygon, Point, box\nfrom numba import jit\n\nimport IPython.display\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#parallax-based-truck-detection","position":5},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Area of Interest"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#area-of-interest","position":6},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Area of Interest"},"content":"Specify an area of interest as bounding box in format:xmin, ymin, ymax, ymax\n\nbbox = -3.85, 40.3, -3.55, 40.5 # Madrid\nIPython.display.GeoJSON(box(*bbox).__geo_interface__)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#area-of-interest","position":7},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Date"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#date","position":8},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Date"},"content":"Select a cloud-free acquisition and provide the date as “YYYY-MM-DD”.\nYou may select data e.g. here:Copernicus Open Access Hub\n\n\nhttps://​scihub​.copernicus​.eu​/dhus​/​#​/home EO Browser\n\n\nhttps://​apps​.sentinel​-hub​.com​/eo​-browser​/​?zoom​=​10​&​lat​=​41​.9​&​lng​=​12​.5​&​themeId​=​DEFAULT​-THEME\n\ndate_start = \"2020-05-18\"\ndate_end = \"2020-05-19\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#date","position":9},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Open Street Maps (OSM)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#open-street-maps-osm","position":10},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Open Street Maps (OSM)"},"content":"Trucks are only detected on roads obtained from OSM.\nYou may specify road types to include. Their descriptions can be found here:\n\nhttps://​wiki​.openstreetmap​.org​/wiki​/Key:highway\n\nosm_values = [\"motorway\", \"trunk\", \"primary\"] # all of key \"highway\"\nroads_buffer = 0.00022 # degree, OSM road vectors are buffered, for motorway, the others lower\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#open-street-maps-osm","position":11},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Processing methods"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#processing-methods","position":12},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Processing methods"},"content":"In the following cells all needed methods are defined. They will be invoked further below.\n\n# re-order bbox from W,S,E,N to S,W,N,E\ndef convert_bbox_osm(bbox):\n    offset = 0.05 # add a buffer to bbox in order to be sure cube is entirely covered\n    bbox_osm = [bbox[1], bbox[0], bbox[3], bbox[2]]\n    bbox_osm[0] -= offset # min lat\n    bbox_osm[1] -= offset # min lon\n    bbox_osm[2] += offset # max lat\n    bbox_osm[3] += offset # max lon\n    return bbox_osm\n\n# bbox List of four coords\n# osm_value String OSM value\n# osm_key String OSM key\n# element_type List of String\n# returns GeoDataFrame\ndef get_osm(bbox, \n            osm_value,\n            element_type = [\"way\", \"relation\"]):\n    osm_key = \"highway\"\n    bbox_osm = convert_bbox_osm(bbox)\n    quot = '\"'\n    select = quot+osm_key+quot + '=' + quot+osm_value+quot\n    select_link = select.replace(osm_value, osm_value + \"_link\") # also get road links\n    select_junction = select.replace(osm_value, osm_value + \"_junction\")\n    geoms = []\n    for selector in [select, select_link, select_junction]:  \n        try:\n            query = overpassQueryBuilder(bbox=bbox_osm, \n                                         elementType=element_type, \n                                         selector=selector, \n                                         out='body',\n                                         includeGeometry=True)\n            elements = Overpass().query(query, timeout=60).elements()\n            # create multiline of all elements\n            if len(elements) > 0:\n                for i in range(len(elements)):\n                    elem = elements[i]\n                    geoms.append(elem.geometry())\n        except:\n            Warning(\"Could not retrieve \" + select)\n    try:\n        lines = gpd.GeoDataFrame(crs = \"EPSG:4326\", geometry = geoms)\n        n = len(geoms)\n        lines[\"osm_value\"] = [osm_value]*n # add road type\n        return lines\n    except:\n        Warning(\"Could not merge \" + osm_value)\n        \n# buffer Float road buffer distance [m]\n# bbox List of four coords\n# bbox_id Integer processing id of bbox\n# osm_values List of String OSM values\n# osm_key String OSM key\n# roads_buffer Float buffer width\n# returns GeoDataFrame\ndef get_roads(bbox, osm_values, roads_buffer):\n    osm_key = \"highway\"\n    roads = []\n    has_error = []\n    offset = 0.00002\n    buffer_dist = \"buffer_distance\"\n    # buffer according to road type\n    m,t,p,s,ter = \"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\"\n    buffers = {m:roads_buffer, t:roads_buffer-offset, p:roads_buffer-(2*offset), s:roads_buffer-(3*offset), ter:roads_buffer-(4*offset)}\n    osm_values_int = {m:1, t:2, p:3, s:4, ter:5}\n    for osm_value in osm_values:\n        roads_osm = get_osm(bbox, osm_value)\n        try:\n            roads_osm = get_osm(bbox, osm_value)\n            roads_osm[buffer_dist] = [buffers[osm_value]] * len(roads_osm)\n            roads_osm[\"osm_value_int\"] = osm_values_int[osm_value]\n            roads.append(roads_osm)\n        except:\n            has_error.append(1)\n            print(\"'get_osm'\" + \"failed for bbox_id osm_value \" + osm_value + \"osm_key\" + osm_key)\n    if len(roads) > len(has_error):\n        roads_merge = gpd.GeoDataFrame(pd.concat(roads, ignore_index=True), crs=roads[0].crs)\n        buffered = roads_merge.buffer(distance=roads_merge[buffer_dist])\n        roads_merge.geometry = buffered\n        return roads_merge\n\n# osm geodataframe of polygons\n# reference_raster xarray with lat and lon\n# returns numpy array\ndef rasterize_osm(osm, reference_raster):\n    osm_values = list(set(osm[\"osm_value\"]))\n    nan_placeholder = 100\n    road_rasters = []\n    for osm_value in osm_values:\n        osm_subset = osm[osm[\"osm_value\"] == osm_value]\n        raster = rasterize(osm_subset, reference_raster.lat, reference_raster.lon)\n        cond = np.isfinite(raster)\n        raster_osm = np.where(cond, list(osm_subset.osm_value_int)[0], nan_placeholder) # use placeholder instead of nan first\n        raster_osm = raster_osm.astype(np.float)\n        road_rasters.append(raster_osm)        \n    # merge road types in one layer\n    road_raster_np = np.array(road_rasters).min(axis=0) # now use the lowest value (highest road level) because some intersect\n    road_raster_np[road_raster_np == nan_placeholder] = 0\n    return road_raster_np # 0=no_road 1=motorway, 2=trunk, ...\n\ndef transform_lat_lon(lat, lon):\n    lat = np.asarray(lat)\n    lon = np.asarray(lon)\n    trans = Affine.translation(lon[0], lat[0])\n    scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n    return trans * scale\n\ndef rasterize(polygons, lat, lon, fill=np.nan):\n    transform = transform_lat_lon(lat, lon)\n    out_shape = (len(lat), len(lon))\n    raster = features.rasterize(polygons.geometry, out_shape=out_shape,\n                                fill=fill, transform=transform,\n                                dtype=float)\n    return xr.DataArray(raster, coords={\"lat\":lat, \"lon\":lon}, dims=(\"lat\", \"lon\"))\n\n# TruckDetector detects trucks at acquisition-level\nclass TruckDetector():   \n    def __init__(self, band_stack):\n        is_none = band_stack is None\n        self.band_stack = band_stack.chunk(band_stack.dims[\"lat\"], band_stack.dims[\"lon\"]) if not is_none else None\n        self.no_truck_mask = None\n        self.trucks = None\n    \n    def detect(self):\n        B02 = self.band_stack.B02.persist().values\n        B03 = self.band_stack.B03.persist().values\n        B04 = self.band_stack.B04.persist().values\n        B08 = self.band_stack.B08.persist().values\n        B11 = self.band_stack.B11.persist().values\n        no_truck_mask = calc_no_trucks(B02, B03, B04, B08, B11)\n        trucks = detect_trucks(B02, B03, B04, no_truck_mask)\n        lon_lat = {\"lat\":self.band_stack.lat, \"lon\":self.band_stack.lon}\n        self.no_truck_mask = xr.DataArray(no_truck_mask, coords=lon_lat, dims=(\"lat\", \"lon\"))\n        self.trucks = xr.DataArray(trucks, coords=lon_lat, dims=(\"lat\", \"lon\")).astype(np.int)\n        self.filter_trucks()\n                            \n    def filter_trucks(self):\n        self.trucks = filter_spatial_3x3_extended(self.trucks)\n        \n# take xarray and ensure each value with 1 in data has no neighbor with 1 in an extended 3x3 block. Extended means: horizontally and vertically\n# it is also checked for the second-next pixel\n# Method checks only surrounding of values equal 1\n# arr xarray DataArray with values and lat lon\ndef filter_spatial_3x3_extended(arr):\n    values = arr.values\n    lon = arr.lon\n    lat = arr.lat\n    valid = np.where(arr == 1)\n    for y,x in zip(valid[0], valid[1]):\n        y_above = y - 1\n        y_above_next = y - 2\n        x_left = x - 1\n        x_right = x + 1\n        x_left_next = x - 2\n        space_left = x_left >= 0\n        space_right = x_right >= 0 and x_right < len(lon)\n        space_above = y_above >= 0\n        val_left_above = values[y_above, x_left] if space_left and space_above else 0\n        val_right_above = values[y_above, x_right] if space_right and space_above else 0\n        val_left = values[y, x_left] if space_left else 0\n        val_above = values[y_above, x] if space_above else 0\n        val_left_next = values[y, x_left_next] if x_left_next >= 0 else 0\n        val_above_next = values[y_above_next, x] if y_above_next >= 0 else 0\n        # if any of the values left, above and left above has 1 set current value 0\n        if (val_left_above + val_right_above + val_left + val_above + val_left_next + val_above_next) >= 1:\n            values[y,x] = 0\n    arr.values = values\n    return arr\n\n# extracts coordinates at value in np array and returns points as GeoDataFrame\n# data 2d np array\n# match_value Float value in data where point coordinates are extracted\n# lon_lat dict of:\n### \"lon\": np array longitude values\"\n### \"lat\": np array latitude values\"\n# crs String EPSG:XXXX\ndef points_from_np(data, match_value, lon_lat, crs):\n    indices = np.argwhere(data == match_value)\n    if len(indices) > 0:\n        lat_indices = indices[:,[0]]\n        lon_indices = indices[:,[1]]\n        lat_coords = lon_lat[\"lat\"][lat_indices]\n        lon_coords = lon_lat[\"lon\"][lon_indices]\n        points = gpd.GeoDataFrame(geometry = gpd.points_from_xy(lon_coords, lat_coords))\n        points.crs = crs\n        return points\n    \ndef raster_to_points(raster, lon_lat, field_name, crs):\n    points_list = []\n    match_values = np.unique(raster[(raster != 0) * ~np.isnan(raster)]) # by pixel value\n    for x in match_values:\n        points = points_from_np(raster, x, lon_lat, crs=crs)\n        points[field_name] = [x] * len(points)\n        points_list.append(points)\n    return gpd.GeoDataFrame(pd.concat(points_list, ignore_index=True))\n        \n# Calculate a binary mask where pixels that are definitely no trucks are represented as 0.\n# thresholds Dict with at least:\n### max_ndvi Float above this val: no trucks. For Vegetation\n### max_ndwi Float above this val: no trucks. For Water\n### max_ndsi Float above this val: no_trucks. For Snow\n### min_rgb Float above this val: no_trucks. For dark surfaces, e.g. shadows\n### max_blue Float above this val: no_trucks\n### max_green Float above this val: no trucks\n### max_red Float above this val: no trucks\n### min_b11 Float below this val: no trucks. For dark surfaces, e.g. shadows\n### max_b11 Float below this val: no trucks. For bright (sealed) surfaces, e.g. buildings\n@jit(nopython=True, parallel=True)\ndef calc_no_trucks(B02, B03, B04, B08, B11):\n    th = {\"min_blue\":0.06, \n          \"min_green\":0.04, \n          \"min_red\":0.04,\n          \"max_red\":0.15,\n          \"max_green\":0.15,\n          \"max_blue\":0.2,\n          \"max_ndvi\":0.5,\n          \"max_ndwi\":0.0001,\n          \"max_ndsi\":0.0001,\n          \"min_blue_green_ratio\":0.03,\n          \"min_blue_red_ratio\":0.05, \n          \"max_blue_green_ratio\":0.17, \n          \"max_blue_red_ratio\":0.2}\n    ndvi_mask = ratio(B08, B04) < th[\"max_ndvi\"]\n    ndwi_mask = ratio(B02, B11) < th[\"max_ndwi\"]\n    ndsi_mask = ratio(B03, B11) < th[\"max_ndsi\"]\n    low_rgb_mask = (B02 > th[\"min_blue\"]) * (B03 > th[\"min_green\"]) * (B04 > th[\"min_red\"])\n    high_rgb_mask = (B02 < th[\"max_blue\"]) * (B03 < th[\"max_green\"]) * (B04 < th[\"max_red\"])\n    no_truck_mask = ndvi_mask * ndwi_mask * ndsi_mask * low_rgb_mask * high_rgb_mask\n    return no_truck_mask\n\n# Calculate a binary mask where trucks are represented as 1 and no trucks as 0.\n# thresholds Dict with at least:\n### min_green_ratio Float, minimum value of blue-green ratio\n### min_red_ratio Float, minimum value of blue-red ratio\n@jit(nopython=True, parallel=True)\ndef detect_trucks(B02, B03, B04, no_truck_mask):\n    th = {\"min_blue\":0.06, \n          \"min_green\":0.04, \n          \"min_red\":0.04,\n          \"max_red\":0.15,\n          \"max_green\":0.15,\n          \"max_blue\":0.2,\n          \"max_ndvi\":0.5,\n          \"max_ndwi\":0.0001,\n          \"max_ndsi\":0.0001,\n          \"min_blue_green_ratio\":0.03,\n          \"min_blue_red_ratio\":0.05, \n          \"max_blue_green_ratio\":0.17, \n          \"max_blue_red_ratio\":0.2}\n    bg_ratio = ratio(B02, B03)\n    br_ratio = ratio(B02, B04)\n    bg = bg_ratio > th[\"min_blue_green_ratio\"]\n    br = br_ratio > th[\"min_blue_red_ratio\"]\n    bg_max = bg_ratio < th[\"max_blue_green_ratio\"]\n    br_max = br_ratio < th[\"max_blue_red_ratio\"]\n    trucks = (bg * br * bg_max * br_max) * no_truck_mask\n    return trucks\n\n@jit(nopython=True, parallel=True)\ndef ratio(a, b):\n    return (a-b)/(a+b)\n\n# AcquisitionProcessor processes all valid pixels of a single acquisition in cube\nclass AcquisitionProcessor():\n    def __init__(self, date_np64, cube):\n        self.date_np64 = date_np64\n        self.cube = cube\n        self.band_stack = cube.sel(time = date_np64)\n        self.detector = None\n        self.no_clouds = None\n        self.osm_mask = None\n           \n    def mask_clouds(self):\n        cloud_masking_thresholds = {\"rgb\":0.25,\"blue_green\":0.2,\"blue_red\":0.2}\n        scl = MaskSet(self.band_stack.SCL)\n        high_prob = scl.clouds_high_probability\n        med_prob = scl.clouds_medium_probability\n        cirrus = scl.cirrus\n        no_data = scl.no_data\n        rgb_cloud_mask = calc_rgb_cloud_mask(self.band_stack, cloud_masking_thresholds)\n        self.no_clouds = (high_prob + med_prob + cirrus + no_data + rgb_cloud_mask) == 0\n        self.band_stack = self.band_stack.where(self.no_clouds)\n    \n    def mask_with_osm(self, osm_mask):\n        self.osm_mask = osm_mask\n        self.band_stack = self.band_stack.where(self.osm_mask != 0)\n                \n    def do_detection(self):\n        self.detector = TruckDetector(self.band_stack)\n        self.detector.detect()\n        \ndef calc_rgb_cloud_mask(band_stack, cloud_masking_thresholds):\n    B02, B03, B04 = band_stack.B02, band_stack.B03, band_stack.B04\n    c = cloud_masking_thresholds[\"rgb\"]\n    clouds_rgb = ((B02 > c) + (B03 > c) + (B04 > c)) >= 1\n    # attempt to mask haze without masking out truck pixels (similar! higher blue than red and green)\n    blue_green_ratio = (B02-B03) / (B02+B03)\n    blue_red_ratio = (B02-B04) / (B02+B04)\n    clouds_blue_green = blue_green_ratio > cloud_masking_thresholds[\"blue_green\"]\n    clouds_blue_red = blue_red_ratio > cloud_masking_thresholds[\"blue_red\"]\n    clouds = (clouds_rgb + clouds_blue_green + clouds_blue_red) >= 1\n    return clouds\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#processing-methods","position":13},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Get Sentinel-2 L2A xcube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#get-sentinel-2-l2a-xcube","position":14},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Get Sentinel-2 L2A xcube"},"content":"\n\nconfig = CubeConfig(dataset_name = \"S2L2A\",\n                    band_names = [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"SCL\"],\n                    tile_size = [512, 512],\n                    geometry = bbox,\n                    spatial_res = 0.00009,\n                    time_range = [date_start, date_end])\ncube = open_cube(config)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#get-sentinel-2-l2a-xcube","position":15},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Acquisition","lvl2":"Get Sentinel-2 L2A xcube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#acquisition","position":16},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Acquisition","lvl2":"Get Sentinel-2 L2A xcube"},"content":"\n\nacquisition = AcquisitionProcessor(cube.time.values[0], cube)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#acquisition","position":17},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Plot RGB","lvl2":"Get Sentinel-2 L2A xcube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#plot-rgb","position":18},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Plot RGB","lvl2":"Get Sentinel-2 L2A xcube"},"content":"\n\nrgb_bands = [\"B04\", \"B03\", \"B02\"]\ncoords, dims = [rgb_bands, cube.lat, cube.lon], [\"bands\", \"lat\", \"lon\"]\nrgb = np.vstack([cube.B04.persist().values, cube.B03.persist().values, cube.B02.persist().values])\nrgb_xr = xr.DataArray(rgb, coords=coords, dims=dims)\nrgb_xr.plot.imshow(figsize=[12,10], rgb=\"bands\", vmin=0, vmax=0.4)\nrgb, rgb_xr = None, None\n\nRGB reflectance\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#plot-rgb","position":19},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Get OSM roads"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#get-osm-roads","position":20},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Get OSM roads"},"content":"\n\nosm_roads = get_roads(bbox, osm_values, roads_buffer)\nosm_roads.plot(figsize=[12,10])\n\nThe OSM road vectors are buffered, hence we see polygons here.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#get-osm-roads","position":21},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Rasterize OSM roads to S2 cube","lvl2":"Get OSM roads"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#rasterize-osm-roads-to-s2-cube","position":22},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Rasterize OSM roads to S2 cube","lvl2":"Get OSM roads"},"content":"\n\nosm_roads_np = rasterize_osm(osm_roads, cube.B02)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#rasterize-osm-roads-to-s2-cube","position":23},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Mask"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#mask","position":24},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Mask"},"content":"In case there are clouds in the imagery, they are masked out here. Furthermore, the data is constrained to the OSM roads.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#mask","position":25},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Clouds","lvl2":"Mask"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#clouds","position":26},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"Clouds","lvl2":"Mask"},"content":"\n\nacquisition.mask_clouds()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#clouds","position":27},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"To OSM roads","lvl2":"Mask"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#to-osm-roads","position":28},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl3":"To OSM roads","lvl2":"Mask"},"content":"Only pixels within the buffered OSM roads are considered.\n\nacquisition.mask_with_osm(osm_roads_np)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#to-osm-roads","position":29},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Detect trucks"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#detect-trucks","position":30},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Detect trucks"},"content":"This is the actual detection being invoked in the “do_detection” wrapper. The output is an xarray DataArray, which is afterwards converted to a GeoDataFrame of points.\n\nacquisition.do_detection()\n# raster detections to points\ntruck_points = raster_to_points(acquisition.detector.trucks.values, {\"lon\":cube.lon.values, \"lat\":cube.lat.values}, \"trucks\", \"EPSG:4326\")\ntruck_points.plot(figsize=[12,10])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#detect-trucks","position":31},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Write detections"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#write-detections","position":32},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data","lvl2":"Write detections"},"content":"If you would like to write the truck points, simply modify the file path here\n\ntruck_points.to_file(\"trucks.gpkg\", driver=\"GPKG\")","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/detect-trucks-sentinel2#write-detections","position":33},{"hierarchy":{"lvl1":"Drought impact monitoring platform"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring","position":0},{"hierarchy":{"lvl1":"Drought impact monitoring platform"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring","position":1},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"EO based Digital Twin precursor of a spatio-temporal drought impact monitoring system in Europe"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#eo-based-digital-twin-precursor-of-a-spatio-temporal-drought-impact-monitoring-system-in-europe","position":2},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"EO based Digital Twin precursor of a spatio-temporal drought impact monitoring system in Europe"},"content":"Eva Ivits1, Lars Eklundh2, Roel Van Hoolst3, Bruno Smets3, Hongxiao, Zhanzhang3, Grega Milcinski4, Anja Vrecko4, Maxim Lamare5\n\n1: European Environment Agency;\n2: Lund University;\n3: VITO;\n4: Sinergise;\n5: Sentinel Hub\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#eo-based-digital-twin-precursor-of-a-spatio-temporal-drought-impact-monitoring-system-in-europe","position":3},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Introduction"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#introduction","position":4},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Introduction"},"content":"This Jupyter Notebook presents the workflow developped within the ESA funded Drought impact monitoring platform pilot project. The aim of the project was to develop a pan-European scale drought impact monitoring platform using the new CLMS service High Resolution Vegetation Phenology and Productivity (HR-VPP) derived from Sentinel 2 images. The 10m spatial resolution seasonal trajectories and phenology and productivity parameters were used for studying vegetation dynamics as a response to soil moisture deficit during the period 2017-2020 in Europe. The project was initially based on the workflow developed within the framework of the EEA Drought Impact Indicator (EEA 2021).  However, during the development phase of the project, the scientific principles governing the algorithms were consolidated and an entirely new workflow was proposed.\n\nThis Jupyter Notebook demonstrates how to derive the following variables based on the MR-VPP and HR-VPP datasets:\n\nSoil moisture anomaly\n\nLong Term Average soil moisture anomaly\n\nMonthly drought hazard\n\nDrought pressure\n\nDrought pressure month\n\nDrought pressure intensity\n\nLong Term Average drought pressure intensity\n\nLINT anomaly\n\nDrought impact\n\nDrought impact mask\n\nDrought impact intensity\n\nDrought impact intensity mask\n\nTPROD anomaly\n\nSPROD anomaly\n\nTotal drought impact\n\nSeasonal drought impact\n\nNumber of Seasons\n\nThe variable are generated as raster files, accompanied by statistics aggregated by:\n\nAdminstrative area (NUTS3 regions)\n\nLand Cover type\n\nLand Cover flow\n\nThe workflow is designed to be run at the continental scale. However, for demonstration purposes, this example shows the workflow executed for a single NUTS3 region (Cádiz, Spain).\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#introduction","position":5},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Processing workflow"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#processing-workflow","position":6},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Processing workflow"},"content":"The following figure shows the processing workflow that is implemented in this Jupyter Notebook.\n\nDark green boxes represent raster inputs.\n\nLight green boxes represent raster outputs.\n\nDark grey boxes with a thick frame represent JSON outputs (statistics).\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#processing-workflow","position":7},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Step 1: MR-VPP annual and monthly products"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#step-1-mr-vpp-annual-and-monthly-products","position":8},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Step 1: MR-VPP annual and monthly products"},"content":"In a first step, we will compute the annual and monthly drought products based on Medium Resolution Vegetation Phenology and Productivity (MR-VPP).\n\n# Sentinel Hub\nfrom sentinelhub import (SHConfig, Geometry, SentinelHubRequest, DataCollection, MimeType, BBox, SentinelHubBatch, BatchRequestStatus)\n\n# Geospatial\nimport geopandas as gpd\nfrom shapely.geometry import shape, GeometryCollection\n\n# Utilities\nimport json\nimport time\nimport datetime as dt\nimport os\nimport urllib3\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#step-1-mr-vpp-annual-and-monthly-products","position":9},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Credentials","lvl2":"Step 1: MR-VPP annual and monthly products"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#credentials","position":10},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Credentials","lvl2":"Step 1: MR-VPP annual and monthly products"},"content":"We recommend the use of EDC built-in credentials for Sentinel Hub services.\n\n# Set the Sentinel Hub credentials based on EDC managed credentials\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n# Change endpoint\nconfig.sh_base_url  = \"https://creodias.sentinel-hub.com\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#credentials","position":11},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Read AOI","lvl2":"Step 1: MR-VPP annual and monthly products"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#read-aoi","position":12},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Read AOI","lvl2":"Step 1: MR-VPP annual and monthly products"},"content":"In the following cells we will specify the geoJSON of the AOI for Batch Processing. Here we will use the NUTS3 region of Cádiz in southern Spain.\n\n# Open Json\nfullaoi = gpd.read_file(\"https://raw.githubusercontent.com/eurodatacube/notebooks/master/notebooks/contributions/example_data/drought_monitoring/Cadiz.geojson\")\n\n# Buffer 500m to make sure the entire AOI is covered\nbuffered_aoi = fullaoi.iloc[0].geometry.buffer(500)\n\n# Check number of vertices (Sentinel Hub can only process geometries with < 1500 nodes)\nnodes = 0\nfor x in buffered_aoi.geoms:\n    nodes += len(x.exterior.coords)\n\n# If too many nodes, progressively simplify\nsim_nr = 100\n\nwhile nodes >= 1500:\n    \n    # Simplify geometry\n    buffered_aoi = fullaoi.iloc[0].geometry.buffer(500).simplify(sim_nr)\n    sim_nr += 100\n\n    # Recompute nodes\n    nodes = 0\n    for x in buffered_aoi.geoms:\n        nodes += len(x.exterior.coords)\n\ncadiz_aoi = Geometry(buffered_aoi, crs=\"EPSG:3035\")\n\n# Show the geometry\nbuffered_aoi\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#read-aoi","position":13},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Evalscript for MR-VPP 500m products"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#evalscript-for-mr-vpp-500m-products","position":14},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Evalscript for MR-VPP 500m products"},"content":"The workflow was written as an \n\nEvalscript to enable large-scale processing using Batch API.\n\nHere we will import the Evalscript and format it in a way suitable for use with Python:\n\nthe variables YEAR0 and YEAR1 will be replaced by {0} and {1} for Python to pass the parameters\n\nthe { and } in the Evalscript will be escaped to {{ and }}\n\n# Open evalscript\nhttp = urllib3.PoolManager()\nresponse = http.request('GET', \"https://raw.githubusercontent.com/eurodatacube/notebooks/master/notebooks/contributions/example_data/drought_monitoring/mrvpp_500m_monthly_annual_raster_stats.js\")\nevalscript_mrvpp = response.data.decode('utf-8')\n\n# Make replacements\nevalscript_mrvpp = evalscript_mrvpp.replace('{', '{{')\nevalscript_mrvpp = evalscript_mrvpp.replace('}', '}}')\nevalscript_mrvpp = evalscript_mrvpp.replace('YEAR0', '{0}')\nevalscript_mrvpp = evalscript_mrvpp.replace('YEAR1', '{1}')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#evalscript-for-mr-vpp-500m-products","position":15},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Run first Batch request"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#run-first-batch-request","position":16},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Run first Batch request"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#run-first-batch-request","position":17},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Set CreoDIAS bucket name","lvl2":"Run first Batch request"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#set-creodias-bucket-name","position":18},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Set CreoDIAS bucket name","lvl2":"Run first Batch request"},"content":"Set the name of the bucket (that was \n\ncorrectly setup) where the results will be saved.\n\nBUCKET_NAME = '<BUCKET-NAME>'\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#set-creodias-bucket-name","position":19},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Set input data collection IDs","lvl2":"Run first Batch request"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#set-input-data-collection-ids","position":20},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Set input data collection IDs","lvl2":"Run first Batch request"},"content":"For the first step, we will three input layers that are hosted on CreoDIAS / WEkEO.\n\nSoil moisture index and anomaly\n\nMR-VPP\n\nStatistical indices: a combination of \n\nNUTS3, \n\nCLCA, and \n\nLand Cover Flow 2000-2018.\n\nPlease contact us if you need access to these data collections: info@sentinel-hub.com.\n\n# Set collection IDs for the input layers\nsoil_moisture_id = \"<ID>\"\nmrvpp_timesat_id = \"<ID>\"\nstatistical_areas_id = \"<ID>\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#set-input-data-collection-ids","position":21},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Requests for Batch","lvl2":"Run first Batch request"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#requests-for-batch","position":22},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Requests for Batch","lvl2":"Run first Batch request"},"content":"In the next cell we prepare a function to run Batch Processing so that we can easily trigger over many years.\n\ndef run_batch_year(thisyear, aoi, evalscript, foldername, myconfig):\n    \n    print(f\"Running Year {thisyear}\")\n        \n    # Set timesat dates\n    timesat_start_date = dt.date(thisyear, 1, 1)\n    timesat_end_date = dt.date(thisyear, 1, 1)\n\n    # Automatically calculate Soil moisture dates\n    sm_start_date = timesat_start_date.replace(year=timesat_start_date.year-1)\n    sm_end_date = dt.date(timesat_end_date.year, 12, 31)\n    \n    # Batch object\n    batch = SentinelHubBatch(config=myconfig)\n    \n    # Make the outputs\n    shresponses = [SentinelHubRequest.output_response(f'Monthly_Drought_Hazard_{x}_{y}', MimeType.TIFF) for y in range(1,12+1) for x in [str(thisyear-1), thisyear]]\n    shresponses.append(SentinelHubRequest.output_response(f'Annual_Soil_Moisture_{thisyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Annual_Drought_Pressure_{thisyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Drought_Pressure_Month_{thisyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Annual_Drought_Pressure_Intensity_{thisyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'LINT_anomaly_{thisyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Drought_Impact_{thisyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Drought_Impact_Mask_{thisyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Drought_Impact_Intensity_{thisyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Drought_Impact_Intensity_Mask_{thisyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'userdata', MimeType.JSON))\n\n    \n    # Make the request for Batch\n    request_for_batch = SentinelHubRequest(\n        evalscript=evalscript.format(str(thisyear-1), str(thisyear)),\n        input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc(soil_moisture_id),          \n            identifier=\"SM\",\n            time_interval=(sm_start_date, sm_end_date),          \n        ),\n       SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc(mrvpp_timesat_id),          \n            identifier=\"TIMESAT\",\n            time_interval=(timesat_start_date, timesat_end_date),          \n        ),\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc(mrvpp_timesat_id),          \n            identifier=\"TIMESATLONG\",\n            time_interval=(dt.date(2000, 1, 1), dt.date(2021, 1, 1)),          \n        ),\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc(statistical_areas_id),          \n            identifier=\"INDICES\",\n            time_interval=(dt.date(2018, 1, 1), dt.date(2018, 1, 1)),          \n        ),\n    ],\n        responses=shresponses,\n        geometry=aoi,\n        config=myconfig\n    )\n    \n    # Create Batch request\n    batch_request = batch.create(\n        request_for_batch,\n        tiling_grid=SentinelHubBatch.tiling_grid(\n            grid_id=6,\n            resolution=500,\n            buffer=(0, 0)\n        ),\n        description=f'EEA MRVPP FULL 500m year {thisyear}',\n        output = SentinelHubBatch.output(\n        defaultTilePath = f\"s3://{BUCKET_NAME}/{foldername}\",\n        cog_output = True,\n        create_collection = False,\n        cog_parameters = {\"resamplingAlgorithm\": \"nearest\"}\n        )\n    )\n    \n    time.sleep(15)\n    \n    batch_request = batch.get_request(batch_request)\n    \n    batch.start_analysis(batch_request)\n    \n    batch_request = batch.get_request(batch_request)\n    \n   \n   \n    batch_request = batch.get_request(batch_request)\n    status = 0\n    cnt = 0\n    \n    while status == 0:\n\n        time.sleep(15)\n        \n        batch_request = batch.get_request(batch_request)\n\n        if batch_request.status == BatchRequestStatus.ANALYSIS_DONE:\n            status = 1\n            failed = False\n            print(\"Analysis done\")\n        elif batch_request.status == BatchRequestStatus.FAILED:\n            status = 1\n            failed = True\n            print(\"Failed\")\n        elif batch_request.status == BatchRequestStatus.ANALYSING:\n            status = 0\n            print(\"Still analysing\")\n            time.sleep(5)\n        else:\n            status = 0\n            time.sleep(5)\n            cnt += 1\n            print(f\"Ping number: {cnt}\")\n        \n    if not failed:\n        batch_request = batch.get_request(batch_request)\n        batch.start_job(batch_request)\n        print(f\"Running {batch_request.request_id}\")\n    else:\n        raise RuntimeError(\"Batch failed to analyse\")\n    batch_request = batch.get_request(batch_request)    \n    return batch_request.request_id\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#requests-for-batch","position":23},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Run the Batch Processing","lvl2":"Run first Batch request"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#run-the-batch-processing","position":24},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Run the Batch Processing","lvl2":"Run first Batch request"},"content":"\n\n# Collect information about the Batch Process in a list\nids = []\n\n# Loop from 2000 to 2003 for this example\nfor x in list(range(2000, 2022)):\n    ids.append(run_batch_year(x, cadiz_aoi, evalscript_mrvpp, \"MRVPP_FULL_ANNUAL_MONTHLY\", config))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#run-the-batch-processing","position":25},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Step 2: MR-VPP long term average products"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#step-2-mr-vpp-long-term-average-products","position":26},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Step 2: MR-VPP long term average products"},"content":"In a second step, we will compute the long term average drought products based on the Medium Resolution Vegetation Phenology and Productivity (MR-VPP) products.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#step-2-mr-vpp-long-term-average-products","position":27},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Set input data collection IDs","lvl2":"Step 2: MR-VPP long term average products"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#set-input-data-collection-ids-1","position":28},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Set input data collection IDs","lvl2":"Step 2: MR-VPP long term average products"},"content":"For the second step, we will reuse three input layers defined in step 1.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#set-input-data-collection-ids-1","position":29},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Evalscript for MR-VPP 500m products","lvl2":"Step 2: MR-VPP long term average products"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#evalscript-for-mr-vpp-500m-products-1","position":30},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Evalscript for MR-VPP 500m products","lvl2":"Step 2: MR-VPP long term average products"},"content":"The workflow was written as an \n\nEvalscript to enable large-scale processing using Batch API.\n\nHere we will import the Evalscript:\n\n# Open evalscript\nhttp = urllib3.PoolManager()\nresponse = http.request('GET', \"https://raw.githubusercontent.com/eurodatacube/notebooks/master/notebooks/contributions/example_data/drought_monitoring/mrvpp_500m_lta_raster_stats.js\")\nevalscript_mrvpp_lta = response.data.decode('utf-8')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#evalscript-for-mr-vpp-500m-products-1","position":31},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Create Batch Request","lvl2":"Step 2: MR-VPP long term average products"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#create-batch-request","position":32},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Create Batch Request","lvl2":"Step 2: MR-VPP long term average products"},"content":"\n\n# Set dates for full range\nstart_date = dt.date(2000, 1, 1)\nend_date = dt.date(2021, 1, 1)\n\n# Batch object\nbatch = SentinelHubBatch(config=config)\n\nrequest_for_batch = SentinelHubRequest(\n    evalscript=evalscript_mrvpp_lta,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc(soil_moisture_id),          \n            identifier=\"SM\",\n            time_interval=(start_date, end_date),          \n        ),\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc(mrvpp_timesat_id),          \n            identifier=\"TIMESAT\",\n            time_interval=(start_date, end_date),          \n        ),\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc(statistical_areas_id),          \n            identifier=\"INDICES\",\n            time_interval=(dt.date(2018, 1, 1), dt.date(2018, 1, 1)),          \n        ),\n    ],\n    responses=[SentinelHubRequest.output_response('Long_Term_Soil_Moisture', MimeType.TIFF),\n               SentinelHubRequest.output_response('Long_Term_Drought_Pressure_Intensity', MimeType.TIFF),\n               SentinelHubRequest.output_response(f'userdata', MimeType.JSON)\n              ],\n    geometry=andalusia_aoi,\n    config=config\n)\n\n# Create Batch request\nbatch_request = batch.create(\n    request_for_batch,\n    tiling_grid=SentinelHubBatch.tiling_grid(\n        grid_id=6,\n        resolution=500,\n        buffer=(0, 0)\n    ),\n    description=f'EEA 500m Long Term Average',\n    output = SentinelHubBatch.output(\n    defaultTilePath = f\"s3://{BUCKET_NAME}/MRVPP_FULL_LTA\",\n    cog_output = True,\n    create_collection = False,\n    cog_parameters = {\"resamplingAlgorithm\": \"nearest\"}\n    )\n)\n\nbatch_request = batch.get_request(batch_request)\n\nprint(batch_request)\n\n# Analyse the request\nbatch.start_analysis(batch_request)\n\ntime.sleep(45)\n\nbatch_request = batch.get_request(batch_request)\nprint(batch_request)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#create-batch-request","position":33},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Run Batch Request","lvl2":"Step 2: MR-VPP long term average products"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#run-batch-request","position":34},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Run Batch Request","lvl2":"Step 2: MR-VPP long term average products"},"content":"\n\nbatch.start_job(batch_request)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#run-batch-request","position":35},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Step 3: HR-VPP products"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#step-3-hr-vpp-products","position":36},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Step 3: HR-VPP products"},"content":"In the third step, we will compute the products derived from the High Resolution Vegetation Phenology and Productivity (HR-VPP) layers at 10m resolution. The products are derived from a combination of HR-VPP, and the products computed in the previous steps.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#step-3-hr-vpp-products","position":37},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Set input data collection IDs","lvl2":"Step 3: HR-VPP products"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#set-input-data-collection-ids-2","position":38},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Set input data collection IDs","lvl2":"Step 3: HR-VPP products"},"content":"For the last step, we will use four input layers that are hosted on CreoDIAS / WEkEO.\n\nHR-VPP season 1: the data for the first season of each year.\n\nHR-VPP season 2: the data for the second season of each year.\n\nStatistical indices: a combination of \n\nNUTS3, \n\nCLCA, and \n\nLand Cover Flow 2000-2018.\n\nPrevious Yearly MR-VPP results. After running the first steps, the results need to be ingested as \n\nBYOC layers in CreoDIAS / WEkEO.\n\nPlease contact us if you need access to these data collections: info@sentinel-hub.com.\n\n# Set collection IDs for the input layers\nhrvpp_s1_id = \"<ID>\"\nhrvpp_s2_id = \"<ID>\"\nstatistical_areas_id = \"<ID>\"\nmrvpp_outputs_id = \"<ID>\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#set-input-data-collection-ids-2","position":39},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Evalscript for MR-VPP 500m products"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#evalscript-for-mr-vpp-500m-products-2","position":40},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl2":"Evalscript for MR-VPP 500m products"},"content":"The workflow was written as an \n\nEvalscript to enable large-scale processing using Batch API.\n\nHere we will import the Evalscript and format it in a way suitable for use with Python:\n\nthe variables YEAR0 will be replaced by {0} for Python to pass the parameters\n\nthe { and } in the Evalscript will be escaped to {{ and }}\n\n# Open evalscript\nhttp = urllib3.PoolManager()\nresponse = http.request('GET', \"https://raw.githubusercontent.com/eurodatacube/notebooks/master/notebooks/contributions/example_data/drought_monitoring/hrvpp_10m_raster_stats.js\")\nevalscript_hrvpp = response.data.decode('utf-8')\n\n# Make replacements\nevalscript_hrvpp = evalscript_mrvpp.replace('{', '{{')\nevalscript_hrvpp = evalscript_mrvpp.replace('}', '}}')\nevalscript_hrvpp = evalscript_mrvpp.replace('YEAR0', '{0}')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#evalscript-for-mr-vpp-500m-products-2","position":41},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Requests for Batch","lvl2":"Evalscript for MR-VPP 500m products"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#requests-for-batch-1","position":42},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Requests for Batch","lvl2":"Evalscript for MR-VPP 500m products"},"content":"In the next cell we prepare a function to run Batch Processing so that we can easily trigger over many years.\n\ndef run_batch_year(inyear, aoi, evalscript, BUCKET_NAME, FOLDER_NAME, myconfig):\n        \n    # Set timesat dates\n    start_date = dt.date(2017, 1, 1)\n    end_date = dt.date(2021, 1, 1)\n\n    # Batch object\n    batch = SentinelHubBatch(config=myconfig)\n    \n    # Test make the outputs for Process API\n    shresponses = [SentinelHubRequest.output_response(f'TPROD_minmax_{inyear}', MimeType.TIFF)]\n    shresponses.append(SentinelHubRequest.output_response(f'SPROD_minmax_{inyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Total_Drought_Impact_{inyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Seasonal_Drought_Impact_{inyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Season_Length_{inyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'Nb_Seasons_{inyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response(f'MR_drought_impact_{inyear}', MimeType.TIFF))\n    shresponses.append(SentinelHubRequest.output_response('userdata', MimeType.JSON))\n\n    \n    # Make the request for Batch\n    request_for_batch = SentinelHubRequest(\n        evalscript=evalscript.format(inyear),\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.define_byoc(mrvpp_outputs_id),          \n                identifier=\"MRVPP\",\n                time_interval=(f'{inyear}-01-01', f'{inyear}-01-01'),          \n            ),\n           SentinelHubRequest.input_data(\n                data_collection=DataCollection.define_byoc(hrvpp_s1_id),          \n                identifier=\"VPP1\",\n                time_interval=(start_date, end_date),          \n            ),\n           SentinelHubRequest.input_data(\n                data_collection=DataCollection.define_byoc(hrvpp_s2_id),          \n                identifier=\"VPP2\",\n                time_interval=(start_date, end_date),          \n            ),\n            SentinelHubRequest.input_data(\n                    data_collection=DataCollection.define_byoc(statistical_areas_id),          \n                    identifier=\"INDICES\",\n                    time_interval=('2018-01-01', '2018-01-01'),          \n                ),\n        ],\n        responses=shresponses,\n        geometry=aoi,\n        config=config\n    )\n\n    # Create Batch request\n    batch_request = batch.create(\n        request_for_batch,\n        tiling_grid=SentinelHubBatch.tiling_grid(\n            grid_id=7,\n            resolution=10,\n            buffer=(0, 0)\n        ),\n        description=f'EEA FULL RUN 10m year {inyear}',\n        output = SentinelHubBatch.output(\n        defaultTilePath = f\"s3://{BUCKET_NAME}/{FOLDER_NAME}\",\n        cog_output = True,\n        create_collection = False,\n        cog_parameters = {\"resamplingAlgorithm\": \"nearest\"}\n        )\n    )\n    \n    time.sleep(15)\n    \n    batch_request = batch.get_request(batch_request)\n\n    print(batch_request)\n    \n    batch.start_analysis(batch_request)\n    \n    batch_request = batch.get_request(batch_request)\n    \n   \n   \n    batch_request = batch.get_request(batch_request)\n    status = 0\n    \n    \n    while status == 0:\n\n        time.sleep(15)\n        \n        batch_request = batch.get_request(batch_request)\n\n        if batch_request.status == BatchRequestStatus.ANALYSIS_DONE:\n            status = 1\n            failed = False\n            print(\"Analysis done\")\n        elif batch_request.status == BatchRequestStatus.FAILED:\n            status = 1\n            failed = True\n            print(\"Failed\")\n        elif batch_request.status == BatchRequestStatus.ANALYSING:\n            status = 0\n            print(\"Still analysing\")\n            time.sleep(5)\n        else:\n            print(\"Other status\")\n            status = 0\n            time.sleep(5)\n        \n    if not failed:\n        batch_request = batch.get_request(batch_request)\n        batch.start_job(batch_request)\n        print(f\"Running {batch_request.request_id}\")\n    else:\n        raise RuntimeError(\"Batch failed to analyse\")\n    batch_request = batch.get_request(batch_request)    \n    return batch_request.request_id\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#requests-for-batch-1","position":43},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Run the Batch Processing","lvl2":"Evalscript for MR-VPP 500m products"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#run-the-batch-processing-1","position":44},{"hierarchy":{"lvl1":"Drought impact monitoring platform","lvl3":"Run the Batch Processing","lvl2":"Evalscript for MR-VPP 500m products"},"content":"\n\n# Collect information about the Batch Process in a list\nids = []\n\n# Loop from 2017 to 2020 for this example\nfor x in list(range(2017, 2021)):\n    ids.append(run_batch_year(x, andalusia_aoi, evalscript_hrvpp_avg, BUCKET_NAME, \"HRVPP_FULL\", config))","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/drought-monitoring#run-the-batch-processing-1","position":45},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest","position":0},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest","position":1},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#custom-script-contest-urban-growth-in-africa","position":2},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa"},"content":"\n\nPrepared by: William Ray, Maxim Lamare, and Max Kampen; Sentinel Hub.\n\nWe are pleased to present the next special edition of the Sentinel Hub Custom Script Contest – \n\nUrban Growth in Africa – with a focus on observing change detection and growth of urban areas. The Contest started on 3rd May 2021.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#custom-script-contest-urban-growth-in-africa","position":3},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Getting started with data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#getting-started-with-data","position":4},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Getting started with data"},"content":"In this demonstration Jupyter Notebook, steps to access all the multi-temporal and multi-resolution data available for the contest will be detailed, along with basic processing examples.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#getting-started-with-data","position":5},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Available datasets"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#available-datasets","position":6},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Available datasets"},"content":"Data from the following satellite products are available for this contest. To jump directly to the section of interest, just click on one of the following products:\n\nSentinel-1 \n\nCARD4L\n\nSentinel-1 \n\nGRD\n\nSentinel-2 \n\nL1C & \n\nL2A\n\nLandsat-8 \n\nCollection 2 Level 1 & 2\n\nAirbus \n\nSPOT 6/7\n\nAirbus \n\nPléiades\n\nPlanet \n\nPlanetScope\n\nMaxar \n\nWorldview & GeoEye\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#available-datasets","position":7},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Configuration"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#configuration","position":8},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Configuration"},"content":"Before accessing the data, we will start by importing the necessary Python libraries (already configured in your EDC workspace), and generate credentials automatically to access the services.\n\n# EDC libraries\nfrom edc import setup_environment_variables\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.sentinelhub import SentinelHub\nfrom xcube.core.geom import mask_dataset_by_geometry\n\n# Sentinel Hub\nfrom sentinelhub import BBox, SentinelHubRequest, bbox_to_dimensions, DataCollection, MimeType, SHConfig, geometry\n\n# Utilities\nimport IPython.display\nfrom os import environ\nimport matplotlib.pyplot as plt\nimport datetime as dt\n\n# Numerical computation\nimport xarray as xr\nimport numpy as np\nimport scipy.ndimage as ndi\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#configuration","position":9},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"BYOC access points","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#byoc-access-points","position":10},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"BYOC access points","lvl2":"Configuration"},"content":"Sentinel-1 CARD4L and the Very High Resolution Commercial collections are provided as pre-processed \n\nBYOC collections. These collections are accessible via a collectionID that will be provided to participants after the registration process.\n\nTo be used in this Jupyter Notebook the collectionIDs need to be set in the custom.env file. You can check if the variables are set by executing the next code cell.\n\nIf the following env variables are not set, please create a text file named custom.env in your home directory with the following input:pleiades_collection = \"<collectionIDstring>\"\ns1grd_collection = \"<collectionIDstring>\"\nspot_collection = \"<collectionIDstring>\"\nplanet_collection = \"<collectionIDstring>\"\nmaxar_collection = \"<collectionIDstring>\"\n\nIn the text file, the <collectionIDstring> should be replaced by the collectionID of the BYOC dataset that will be provided to you.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#byoc-access-points","position":11},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Credentials generation","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#credentials-generation","position":12},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Credentials generation","lvl2":"Configuration"},"content":"The credentials for Sentinel Hub services are automatically set by the Euro Data Cube libraries in the following cell.\n\n# Fetch credentials as environement variables\nsetup_environment_variables()\n\n# Pass Sentinel Hub credentials to dictionnary\nsh_credentials = dict(client_id=environ[\"SH_CLIENT_ID\"],\n                      client_secret=environ[\"SH_CLIENT_SECRET\"])\n\n# Assign BYOC env variables to variables\npleiades_collection = environ[\"pleiades_collection\"]\ns1grd_collection = environ[\"s1grd_collection\"]\nspot_collection = environ[\"spot_collection\"]\nplanet_collection = environ[\"planet_collection\"]\nmaxar_collection = environ[\"maxar_collection\"]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#credentials-generation","position":13},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Sentinel-1-CARD4L"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#sentinel-1-card4l","position":14},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Sentinel-1-CARD4L"},"content":"Sentinel-1 images are offered as CARD4L datasets, as well as being accessible as standard datasets (see following \n\nsection).\n\nCARD4L stands for “CEOS Analysis Ready Data for Land”, and offers satellite data “processed to a minimum set of requirements and organized into a form that allows immediate analysis with a minimum of additional user effort and interoperability both through time and with other datasets” (\n\nhttps://​ceos​.org​/ard/).\n\nMission information\n\nThe Sentinel-1 imagery is provided by two polar-orbiting satellites, operating day and night performing C-band synthetic aperture radar imaging, enabling them to acquire imagery regardless of the weather. More information about the sensor and its characteristics can be found on the \n\nSentinel Hub documentation page.\n\nThe bands available in the Sentinel-1 CARD4L product are the following:\n\nName\n\nDescription\n\nResolution\n\nVH\n\nVV polarisation\n\n20m\n\nVV\n\nVH polarisation\n\n20m\n\nAREA\n\nThe normalized scattering area for each output pixel.\n\n20m\n\nMASK\n\nFlags output pixels which are in or near radar shadow.\n\n20m\n\nANGLE\n\nThe local incidence angle for each output pixel.\n\n20m\n\nData availability\n\nFor practical reasons, the Sentinel-1 CARD4L datasets have been pre-processed and ingested as a \n\nBYOC collection.\n\nData were ingested for the time-range: 2017-01-01 to 2021-04-15.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#sentinel-1-card4l","position":15},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest","position":16},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Sentinel-1-CARD4L"},"content":"In the following example, we will set our AOI (covering the Mbeubeuss pond, Dakar, Senegal) using a bounding box expressed as [min_x, min_y, max_x, max_y]. Here the coordinates are in \n\nWGS 84 (EPSG 4326), with units in degrees.\n\n# Bbox\ndakar_large_bbox = [-17.336723, 14.792808, -17.288553, 14.823096]\n\n# Bbox EPSG number\ndakar_epsg = 4326\n\n# Plot the geometry on a map\nIPython.display.GeoJSON(BBox(dakar_large_bbox, crs=dakar_epsg).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest","position":17},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube","position":18},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Sentinel-1-CARD4L"},"content":"In the following cell we will specify the input parameters needed to build the xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call CUSTOM because Sentinel-1 CARD4L images are available as a BYOC collection.\n\nband_names: the band names to be used in the xcube array. Here, we will call the VV and Incidence angle bands (VV and ANGLE respectively).\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 20 meters, we set the resolution to 0.00018 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned.\n\ntime_period: Necessary when requesting a BYOC collection. The Time period string denotes the temporal aggregation period to be used. Here 1d means that if several images are available for 1 given date, they will be aggregated.\n\ncollection_id: the Sentinel Hub BYOC collection ID for Sentinel-1 CARD4L.\n\n# Setup xcube for S1-CARD4L\ncube_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=['VV', 'ANGLE'],\n                         bbox=dakar_large_bbox,\n                         spatial_res=0.00018,\n                         time_range=['2021-01-01', '2021-04-15'],\n                         time_period=\"1d\",\n                         collection_id=s1grd_collection)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube","position":19},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube","position":20},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Sentinel-1-CARD4L"},"content":"In the following cell we open the cube, then filter out the dates that do not contain any data (this is not performed automatically for BYOC datasets in the current version of xcube).\n\nNote: Given the large number of acquisitions, this step takes around 1 minute 30.\n\n%%time\n# Open cube\nS1_cube = open_cube(cube_config, **sh_credentials)\n\n# Drop empty time slices\nS1_cube = S1_cube.dropna(dim=\"time\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube","position":21},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Explore the xcube","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#explore-the-xcube","position":22},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Explore the xcube","lvl2":"Sentinel-1-CARD4L"},"content":"We will first explore the variables and metadata contained in the xcube by printing its contents. You can explore the attributes by clicking on the buttons to the right (in the executed version).\n\nS1_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#explore-the-xcube","position":23},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot a timeslice from the xcube","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-a-timeslice-from-the-xcube","position":24},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot a timeslice from the xcube","lvl2":"Sentinel-1-CARD4L"},"content":"In a second step we will plot the ANGLE band (local incidence angle) for a time slice by specifying the desired date. If you are not sure of the exact acquisition date, you can fetch the closest time slice to a given date, as shown below.\n\nNote: The format of your date string can be a bit tricky. Here we are matching the format of the dates in the cube for the command to work without having to use datetime.\n\nS1_cube.ANGLE.sel(time='2021-02-01T12:00:00.000000000', method='nearest').plot.imshow(figsize=(12,8), cmap=\"Greys_r\")\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-a-timeslice-from-the-xcube","position":25},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Extract a subset to work on a smaller region","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#extract-a-subset-to-work-on-a-smaller-region","position":26},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Extract a subset to work on a smaller region","lvl2":"Sentinel-1-CARD4L"},"content":"If you would like to work on a subset, e.g. because the region of interest is smaller than the specified bounding box, you can use a WKT polygon or Shapefile to mask the region of interest. Please note however that the WKT / shapefile must be in the same coordinate reference system as the existing xcube.\n\nTwo methods of selection are possible:\n\nBy masking - this keeps only the data of the WKT Polygon or shapefile\n\nBy clipping - this creates a new bounding box, which ensures that the area of interest is within the subset but keeps the surrounding data.\n\nIn this example, we will mask our cube, using the geometry of the Mbeubeuss dump specified in the cell below.\n\nNote: \n\nhttp://geojson.io/ is a useful tool to extract geometries from a map.\n\nmbeubeuss_dump_coordinates = {\n  \"type\": \"Polygon\",\n  \"coordinates\": [[[-17.321186, 14.799613], [-17.321068, 14.79856], [-17.320848, 14.798166], [-17.320107, 14.797798],\n                   [-17.319863, 14.797461], [-17.319952, 14.797059], [-17.320483, 14.796498], [-17.320354, 14.795941],\n                   [-17.319777, 14.795313], [-17.315692, 14.79981], [-17.314877, 14.799753], [-17.3139, 14.800282], [-17.312661, 14.800168],\n                   [-17.312505, 14.800422], [-17.311535, 14.800461], [-17.31044, 14.801169], [-17.310301, 14.802082], [-17.309753, 14.801926],\n                   [-17.308949, 14.802144], [-17.308542, 14.802476], [-17.308499, 14.802637], [-17.308402, 14.80273], [-17.308198, 14.802733],\n                   [-17.308064, 14.802792], [-17.307911, 14.802743], [-17.307823, 14.80286], [-17.307925, 14.802963], [-17.307833, 14.803306],\n                   [-17.307882, 14.803409], [-17.308316, 14.804696], [-17.308112, 14.804779],[-17.307898, 14.804862], [-17.307565, 14.805816],\n                   [-17.308038, 14.8065], [-17.308596, 14.806521], [-17.309154, 14.806729], [-17.309905, 14.806231], [-17.310742, 14.806314],\n                   [-17.311407, 14.806521], [-17.312051, 14.806272], [-17.312244, 14.805795], [-17.312953, 14.806065], [-17.313339, 14.8065],\n                   [-17.314412, 14.806853], [-17.314927, 14.806957], [-17.315291, 14.806832 ], [-17.315656,  14.806169], [-17.31645, 14.805691],\n                   [-17.316922, 14.804675], [-17.317394, 14.804654], [-17.318231,14.804322],[-17.31851,14.803077],\n                   [-17.318854, 14.802974], [-17.319304, 14.8026], [-17.319314,14.80204],\n                   [-17.319057, 14.801833], [-17.319218, 14.801522], [-17.319743, 14.801304], [-17.319914, 14.801122],\n                   [-17.320038, 14.800567], [-17.320612, 14.800422], [-17.321186, 14.799613]]]}\n\n# Mask the cube\nMbeubeuss_dump = mask_dataset_by_geometry(S1_cube, geometry=mbeubeuss_dump_coordinates)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#extract-a-subset-to-work-on-a-smaller-region","position":27},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot the masked cube","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-the-masked-cube","position":28},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot the masked cube","lvl2":"Sentinel-1-CARD4L"},"content":"In the cell below, we will check the output of the previous operation by plotting the VV band for the first time slice isel(time=0).\n\n# Plot the masked cube\nMbeubeuss_dump.VV.isel(time=0).plot.imshow(cmap='Greys', vmin=0, vmax=1, figsize=(10, 10))\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-the-masked-cube","position":29},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"VV change over time for a given area of interest","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#vv-change-over-time-for-a-given-area-of-interest","position":30},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"VV change over time for a given area of interest","lvl2":"Sentinel-1-CARD4L"},"content":"In the following cells, the change in VV backscatter will be assessed (for demonstration purposes only) by showing the boxplots of the Mbeubeuss dump for 3 different dates.\n\nThe following cell contains a function to convert the long timestamps from the xcube to a more readable format.\n\ndef to_datetime(datestring):\n    \"\"\"Convert string to datetime.\n    Takes a date in the form of a string and returns a datetime object.\n    The string should be in the format YYYY-MM-DD.\n    \"\"\"\n    return dt.datetime.strptime(datestring, \"%Y-%m-%d\")    \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#vv-change-over-time-for-a-given-area-of-interest","position":31},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Data preparation","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#data-preparation","position":32},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Data preparation","lvl2":"Sentinel-1-CARD4L"},"content":"In the following cell, we will prepare the data for plotting in 3 steps:\n\nwe will extract the data from 3 acquisitions that are the closest to 1st January 2021, 1st February 2021 and 1st March 2021.\n\nwe remove the nan values from the arrays.\n\nthe timestamps are extracted and converted to a more readable format.\n\n# Make a list of 3 different dates of interest.\ndates_of_interest = [to_datetime(\"2021-01-01\"), to_datetime(\"2021-01-01\"), to_datetime(\"2021-03-01\")]\n\n# Fetch a cube based on the dates\nMbeubeuss_sub_dates = Mbeubeuss_dump.VV.sel(time=dates_of_interest, method=\"nearest\")\n\n# Convert to list for plotting\nboxplot_data = [Mbeubeuss_sub_dates.compute().data[0, :, :], Mbeubeuss_sub_dates.compute().data[1, :, :], Mbeubeuss_sub_dates.compute().data[2, :, :]]\n\n# Remove nan values from the data for plotting\nboxplot_data = [x[~np.isnan(x)] for x in boxplot_data]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#data-preparation","position":33},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Data plotting","lvl2":"Sentinel-1-CARD4L"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#data-plotting","position":34},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Data plotting","lvl2":"Sentinel-1-CARD4L"},"content":"In the following cell, we will plot the VV backscatter distribution over the Mbeubeuss dump for 3 selected dates as \n\nboxplots.\n\n# Create figure\nfig, ax = plt.subplots(1, figsize=(12,8))\n\n# Plot boxplots\nax.boxplot(boxplot_data)\n\n# Set ticks to times\nplt.xticks([1, 2, 3], Mbeubeuss_sub_dates.time.values.astype('datetime64[D]'))\n\n# Plot setup\nax.set_ylabel(\"VV backscatter\")\nax.set_ylim(0, 1)\nplt.suptitle(\"VV backscatter evolution for Mbeubeuss dump, 2021.\")\nplt.draw()\nplt.show()\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#data-plotting","position":35},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Sentinel-1 GRD"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#sentinel-1-grd","position":36},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Sentinel-1 GRD"},"content":"Mission information\n\nThe Sentinel-1 imagery is provided by two polar-orbiting satellites, operating day and night performing C-band synthetic aperture radar imaging, enabling them to acquire imagery regardless of the weather. Main applications are for monitoring sea ice, oil spills, marine winds, waves & currents, land-use change, land deformation among others, and to respond to emergencies such as floods and earthquakes.\n\nS1 GRD\n\nSentinel Hub currently supports Sentinel-1 Level-1 GRD (Ground Range Detected) products only. For more information about the sensor’s properties and the data available, you can visit the \n\nSentinel Hub documentation page.\n\nData availability\n\nFebruary 2015 to today.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#sentinel-1-grd","position":37},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Sentinel-1 GRD"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-1","position":38},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Sentinel-1 GRD"},"content":"In the following example, we will set our AOI (covering a large part of Dakar, Senegal) using a bounding box expressed as [min_x, min_y, max_x, max_y]. Here the coordinates are in \n\nWGS 84 (EPSG 4326), with units in degrees.\n\n# Bbox\ndakar_bbox = [-17.546573, 14.645375, -17.392724, 14.783846]\n\n# Bbox EPSG\ndakar_epsg = 4326\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(dakar_bbox,crs=dakar_epsg).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-1","position":39},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Sentinel-1 GRD"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#check-sentinel-1-grd-available-bands","position":40},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Sentinel-1 GRD"},"content":"Using EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset.\n\n# Create a Sentinel Hub class, using our Sentinel Hub credentials\nSH = SentinelHub(**sh_credentials)\n\n# List bands for S1-GRD\nSH.band_names('S1GRD')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#check-sentinel-1-grd-available-bands","position":41},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build an xcube","lvl2":"Sentinel-1 GRD"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-an-xcube","position":42},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build an xcube","lvl2":"Sentinel-1 GRD"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S1GRD for Sentinel-1 GRD. All available dataset can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call the VV, HH, VH and HV polarisation bands.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-1 GRD data is available from February 2015 onwards. In this example, we will fetch data for all of 2019.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30M corresponds to 30 minutes, thus avoiding duplicate datasets.\n\nNote: the return _coerce_scalar_to_timedelta_type(arg, unit=unit, errors=errors) warning can be safely ignored.\n\n# Setup xcube\ncube_config = CubeConfig(dataset_name='S1GRD',\n                         band_names=['VV', 'VH'],\n                         bbox=dakar_bbox,\n                         spatial_res=0.000089,\n                         time_range=['2019-01-01', '2019-12-31'],\n                         time_tolerance='30M')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-an-xcube","position":43},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Sentinel-1 GRD"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-1","position":44},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Sentinel-1 GRD"},"content":"In the following cell we open the cube and display it’s contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube.\n\n# Open cube (on the fly)\ncube = open_cube(cube_config, **sh_credentials)\n\n# Display contents\ncube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-1","position":45},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Visualising Urban areas using SAR","lvl2":"Sentinel-1 GRD"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#visualising-urban-areas-using-sar","position":46},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Visualising Urban areas using SAR","lvl2":"Sentinel-1 GRD"},"content":"We are going to base the visualisation of the Sentinel-1 GRD data on this \n\ncustom script authored by Monja Šebela. Firstly, new variables need to be defined and generated. A specific date can then be called, and then stacked and visualised in a plot.\n\nNext, to produce the visualisation we need to define and generate Red, Green and Blue channels in the visualisation, calling the VH and VV bands in the cube and adapting them to highlight certain features for visualisation purposes. We do this by defining the new variable and attributing it a “long_name” and “units”.\n\n# Define the Red visualisation\ncube['Red'] = 5.5 * cube.VH\ncube['Red'].attrs['long_name']='Red'\ncube['Red'].attrs['units']='unitless'\n\n# Define the Green visualisation\ncube['Green'] = cube.VV\ncube['Green'].attrs['long_name']='Green'\ncube['Green'].attrs['units']='unitless'\n\n# Define the Blue visualisation\ncube['Blue'] = 8 * cube.VH\ncube['Blue'].attrs['long_name']='Blue'\ncube['Blue'].attrs['units']='unitless'\n\nSecondly, we want to call the new variables that we have named as Red, Green and Blue and stack them into an array that we can then plot. In the example below, we are selecting the time slice closest to the time stamp of “2019-05-23 10:00:00”. Lastly, we define the plot and visualise it.\n\nNote: The plotting is slow because until you use the data, xcube doesn’t perform any computations. A nifty feature to save processing time! As it was the case for the previous data collection, please note that the time parameter has to match the format of that found in the xcube.\n\n# Select the bands and stack them\nGreen = cube.Green.sel(time='2019-05-23 10:00:00', method='nearest')\nRed = cube.Red.sel(time='2019-05-23 10:00:00', method='nearest')\nBlue = cube.Blue.sel(time='2019-05-23 10:00:00', method='nearest')\n\n# Stack the three arrays into an RGB image\nrgb = np.dstack((Green, Red, Blue))\n\n# Create plot\nfig, ax = plt.subplots(1, figsize=(12,8))\nax.imshow(rgb)\nax.set_title(f\"Visualisation using False color SAR to map urban areas: {str(cube.time.sel(time='2019-05-23 10:00:00', method='nearest').data).split('T')[0]}\")\nplt.show()\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#visualising-urban-areas-using-sar","position":47},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Sentinel-2 L1C"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#sentinel-2-l1c","position":48},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Sentinel-2 L1C"},"content":"Mission information\n\nSENTINEL-2 is a European wide-swath, high-resolution, multi-spectral imaging mission. Its high-resolution optical images have many applications, including land monitoring, emergency response and security services assistance. The satellite’s multispectral imager provides a versatile set of 13 spectral bands spanning from the visible and near infrared to the shortwave infrared.\n\nLevel 1C\n\nLevel 1C offers Top of the atmosphere (TOA) reflectance data. For more information about the sensor’s properties and the data available, you can visit the \n\nSentinel Hub documentation page.\n\nData availability\n\nJune 2015 to today.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#sentinel-2-l1c","position":49},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Sentinel-2 L1C"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-2","position":50},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Sentinel-2 L1C"},"content":"In the following example, we will set our AOI (covering a large part of Dakar, Senegal) using a bounding box expressed as [min_x, min_y, max_x, max_y]. Here the coordinates are in \n\nWGS 84 (EPSG 4326), with units in degrees.\n\n# Bbox\ndakar_bbox = [-17.546573, 14.645375, -17.392724, 14.783846]\n\n# Bbox EPSG\ndakar_epsg = 4326\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(dakar_bbox,crs=dakar_epsg).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-2","position":51},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Check Sentinel-2 L1C available bands","lvl2":"Sentinel-2 L1C"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#check-sentinel-2-l1c-available-bands","position":52},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Check Sentinel-2 L1C available bands","lvl2":"Sentinel-2 L1C"},"content":"Using EDC inbuilt functions that query Sentinel Hub services, we can list the available bands for a given dataset.\n\n# Create a Sentinel Hub class\nSH = SentinelHub(**sh_credentials)\n\n# List bands for S2-L1C\nSH.band_names('S2L1C')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#check-sentinel-2-l1c-available-bands","position":53},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Sentinel-2 L1C"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-1","position":54},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Sentinel-2 L1C"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S2L1C for Sentinel-2 Level 1C. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call the Red and Near Infrared bands (B04 and B08 respectively).\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-2 L1C data is available from November 2015 onwards. In this example, we will fetch data from June to August 2019.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30M corresponds to 30 minutes, thus avoiding duplicate datasets.\n\nNote: the return _coerce_scalar_to_timedelta_type(arg, unit=unit, errors=errors) warning can be safely ignored.\n\n# Setup xcube\ncube_config = CubeConfig(dataset_name='S2L1C',\n                         band_names=['B04', 'B08'],\n                         bbox=dakar_bbox,\n                         spatial_res=0.000089,\n                         time_range=['2019-06-01', '2019-08-31'],\n                         time_tolerance='30M')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-1","position":55},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Sentinel-2 L1C"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-2","position":56},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Sentinel-2 L1C"},"content":"In the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube.\n\n# Open cube (on the fly)\ncube = open_cube(cube_config, **sh_credentials)\n\n# Display contents\ncube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-2","position":57},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Compute an additional band","lvl2":"Sentinel-2 L1C"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#compute-an-additional-band","position":58},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Compute an additional band","lvl2":"Sentinel-2 L1C"},"content":"In the following cell we will compute a new band based on existing bands in the xcube. In this example we will compute the Normalized difference vegetation index (NDVI) for each existing timestamp. \n\nNDVI is a commonly used index to quantify green vegetation, and is derived from Sentinel-2 bands 4 and 8.\n\nFirstly, we define the NDVI formula:\n\n# Define NDVI equation\ncube['NDVI'] = (cube.B08 - cube.B04) / (cube.B04 + cube.B08)\n\n# Set band attributes\ncube['NDVI'].attrs['long_name'] = 'Normalized Difference Vegetation Index'\ncube['NDVI'].attrs['units'] = 'unitless'\n\n# Display the calculated NDVI band\ncube.NDVI\n\nNow we have generated this new band, let’s visualise the values for a pixel over the time period. In this example, the coordinates of a point located in an Urban reserve (Réserve Naturelle Urbaine de la Grande Niaye de Pikine et Dépendance) were selected.\n\nNote: Because the function goes through all the time slices, it may take some time to compute the data.\n\n%%time\n# Set latitude and longitude of point to query\npoint_lat = 14.7678\npoint_lon = -17.4023\n\n# Get timeseries\ntimeseriesNDVI = cube.NDVI.sel(lat=point_lat, lon=point_lon, method='nearest').to_series()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#compute-an-additional-band","position":59},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot NDVI timeseries for a given location","lvl2":"Sentinel-2 L1C"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-ndvi-timeseries-for-a-given-location","position":60},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot NDVI timeseries for a given location","lvl2":"Sentinel-2 L1C"},"content":"Using matplotlib we can visualise how NDVI changes over time.\n\n# Plot NDVI timeseries\nfig, ax = plt.subplots(1, figsize=(15, 6))\nax.plot(timeseriesNDVI, color=\"green\", marker=\"o\", linewidth=0.5)\nax.set_title(f\"NDVI timeseries. Latitude: {point_lat}, Longitude: {point_lon}.\")\nplt.show()\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-ndvi-timeseries-for-a-given-location","position":61},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Sentinel-2 L2A"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#sentinel-2-l2a","position":62},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Sentinel-2 L2A"},"content":"Mission information\n\nSENTINEL-2 is a European wide-swath, high-resolution, multi-spectral imaging mission. Its high-resolution optical images have many applications, including land monitoring, emergency response and security services assistance. The satellite’s multispectral imager provides a versatile set of 13 spectral bands spanning from the visible and near infrared to the shortwave infrared.\n\nLevel 2A\n\nLevel 2A offers Bottom of the atmosphere (BOA) reflectance data. For more information about the sensor’s properties and the data available, you can visit the \n\nSentinel Hub documentation page.\n\nData availability\n\nJanuary 2017 to today.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#sentinel-2-l2a","position":63},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Sentinel-2 L2A"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-3","position":64},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Sentinel-2 L2A"},"content":"In the following example, we will set our AOI (covering a large part of Dakar, Senegal) using a bounding box expressed as [min_x, min_y, max_x, max_y]. Here the coordinates are in \n\nWGS 84 (EPSG 4326), with units in degrees.\n\n# Bbox\ndakar_bbox = [-17.546573, 14.645375, -17.392724, 14.783846]\n\n# Bbox EPSG\ndakar_epsg = 4326\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(dakar_bbox,crs=dakar_epsg).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-3","position":65},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Check Sentinel-2 L2A available bands","lvl2":"Sentinel-2 L2A"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#check-sentinel-2-l2a-available-bands","position":66},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Check Sentinel-2 L2A available bands","lvl2":"Sentinel-2 L2A"},"content":"Using EDC inbuilt functions that query Sentinel Hub services, we can list the available bands for a given dataset.\n\n# Create a Sentinel Hub class\nSH = SentinelHub(**sh_credentials)\n\n# List bands for S2-L2A\nSH.band_names('S2L2A')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#check-sentinel-2-l2a-available-bands","position":67},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Sentinel-2 L2A"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-2","position":68},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Sentinel-2 L2A"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S2L2A for Sentinel-2 Level 2A. All available dataset can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call the Red and Near Infrared bands (B04 and B08 respectively).\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set. For an example with a different coordinate system, see the section for \n\nAirbus SPOT 6/7.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-2 L2A data is available from January 2017 onwards. In this example, we will fetch data for May 2019.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30M corresponds to 30 minutes, thus avoiding duplicate datasets.\n\nNote: the return _coerce_scalar_to_timedelta_type(arg, unit=unit, errors=errors) warning can be safely ignored.\n\n# Setup xcube\ncube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B04', 'B08'],\n                         bbox=dakar_bbox,\n                         spatial_res=0.000089,\n                         time_range=['2019-05-01', '2019-05-31'],\n                         time_tolerance='30M')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-2","position":69},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Sentinel-2 L2A"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-3","position":70},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Sentinel-2 L2A"},"content":"In the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube.\n\n# Open cube (on the fly)\ncube = open_cube(cube_config, **sh_credentials)\n\n# Display contents\ncube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-3","position":71},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Compute and visualise an additional band","lvl2":"Sentinel-2 L2A"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#compute-and-visualise-an-additional-band","position":72},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Compute and visualise an additional band","lvl2":"Sentinel-2 L2A"},"content":"In the following cell we will compute a new band based on existing bands in the xcube. In this example we will compute the Normalized difference vegetation index (NDVI) for each existing timestamp. \n\nNDVI is a commonly used index to quantify green vegetation, and is derived from Sentinel-2 bands 4 and 8.\n\nFirstly, we define the NDVI formula and create a new variable attributing a “long_name” and “units”.\n\n# Define NDVI equation and set as band\ncube['NDVI'] = (cube.B08 - cube.B04) / (cube.B04 + cube.B08)\ncube['NDVI'].attrs['long_name'] = 'Normalized Difference Vegetation Index'\ncube['NDVI'].attrs['units'] = 'unitless'\n\nSecondly, we will call this variable for a specific date and then visualise it. In this example, we will specify a date of interest and fetch the closest acquisition in time available. We also filter out values smaller than 0, using the where function.\n\n# Plot NDVI in shades of Green where NDVI is greater than 0. \ncube.NDVI.sel(time='2019-05-23 10:00:00', method='nearest').where(cube.NDVI.sel(time='2019-05-23 10:00:00', method='nearest') > 0).plot.imshow(vmin=0, vmax=1, cmap='Greens', figsize=(18, 15))\nplt.show()\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#compute-and-visualise-an-additional-band","position":73},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Landsat-8 Collection 2"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#landsat-8-collection-2","position":74},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Landsat-8 Collection 2"},"content":"Mission information\n\nLandsat 8 is the most recently launched Landsat satellite (provided by NASA/USGS) and carries the Operational Land Imager (OLI) and the Thermal Infrared Sensor (TIRS) instruments. These two sensors provide seasonal coverage of the global landmass. Landsat-8 Level-1 provides global top-of-atmosphere reflectance and brightness-temperature, whereas Level-2 provides global surface reflectance and surface temperature science products. Landsat Level-2 science products are generated from Collection 2 Level-1 inputs that meet the <76 degrees Solar Zenith Angle constraint and include the required auxiliary data inputs to generate a scientifically viable product.\n\nCollection 2\n\nFor more information about the sensor’s properties and the data available, you can visit the Sentinel Hub documentation pages for \n\nLevel 1 and \n\nLevel2. Additional information about Collection 2 can be found on the \n\ndedicated USGS page.\n\nData availability\n\nSince February 2013.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#landsat-8-collection-2","position":75},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Fetch an image from Landsat-8 Collection 2 Level 1 and Level 2","lvl2":"Landsat-8 Collection 2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#fetch-an-image-from-landsat-8-collection-2-level-1-and-level-2","position":76},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Fetch an image from Landsat-8 Collection 2 Level 1 and Level 2","lvl2":"Landsat-8 Collection 2"},"content":"Below we define the cells to retrieve data for Landsat 8 Collection 2.\n\nFirst, we need to set the input parameters. Currently, Collection 2 data is not available through the xcube package. Therefore, in this example, we will access the data from Sentinel Hub using the \n\nsentinelhub-py library.\n\n# Sentinel Hub configuration for the Python package\nconfig = SHConfig()\nconfig.sh_client_id = environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = environ[\"SH_CLIENT_SECRET\"]\n\nThe Collection 2 is only recently available through Sentinel Hub services and the sentinelhub-py package has not yet been updated to contain the settings for the Collection 2 by default. This means that the DataCollection object has to be specified manually, as shown below.\n\n# Define a new DataCollection for Level-1 data\nDataCollection.define_from(\n            DataCollection.LANDSAT8,\n            \"LOTL1\",\n            service_url=\"https://services-uswest2.sentinel-hub.com\",\n            wfs_id=\"DSS12\",  # https://www.sentinel-hub.com/develop/api/ogc/standard-parameters/wfs/\n            api_id=\"LOTL1\",\n            catalog_id=\"landsat-8-l1c\",\n            processing_level=\"L1C\",\n            bands=(\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B09\", \"B10\", \"B11\", \"BQA\", \"QA_RADSAT\", \"VAA\", \"VZA\", \"SAA\", \"SZA\", \"dataMask\"),\n)\n\n# Define a new DataCollection for Level-2 data\nDataCollection.define_from(\n            DataCollection.LANDSAT8,\n            \"LOTL2\",\n            service_url=\"https://services-uswest2.sentinel-hub.com\",\n            wfs_id=\"DSS13\",  # https://www.sentinel-hub.com/develop/api/ogc/standard-parameters/wfs/\n            api_id=\"LOTL2\",\n            catalog_id=\"landsat-8-l2a\",\n            processing_level=\"L2A\",\n            bands=(\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B10\", \"BQA\", \"QA_RADSAT\", \"SR_QA_AEROSOL\", \"ST_QA\", \n                   \"ST_TRAD\", \"ST_URAD\", \"ST_DRAD\", \"ST_ATRAN\", \"ST_EMIS\", \"ST_EMSD\", \"ST_CDIST\", \"dataMask\"),\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#fetch-an-image-from-landsat-8-collection-2-level-1-and-level-2","position":77},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Landsat-8 Collection 2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-4","position":78},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Landsat-8 Collection 2"},"content":"In the following example, we will set our AOI (covering a large part of Dakar, Senegal) using a bounding box expressed as [min_x, min_y, max_x, max_y]. Here the coordinates are in \n\nWGS 84 (EPSG 4326), with units in degrees. We also calculate the AOI in pixels based upon the resolution of Landsat 8 which is 30m.\n\nNote: with sentinelhub-py , the size of the image cannot be more than 2500px * 2500px, else the request will fail.\n\ndakar_bbox = [-17.546573, 14.645375, -17.392724, 14.783846]\ndakar_epsg = 4326\n\nresolution = 30\ndakar_bbox = BBox(bbox=dakar_bbox, crs=dakar_epsg)\ndakar_size = bbox_to_dimensions(dakar_bbox, resolution=resolution)\n\nprint(f'Image shape at {resolution} m resolution: {dakar_size} pixels')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-4","position":79},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define an evalscript","lvl2":"Landsat-8 Collection 2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-an-evalscript","position":80},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define an evalscript","lvl2":"Landsat-8 Collection 2"},"content":"Now that the input parameters are defined we will use an \n\nevalscript to visualise the data that we are requesting. In this example, we are requesting Band 3, 4 & 5 (Green, Red, NIR) and returning them in a 3-band image.\n\nevalscript_false_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B05\", \"B04\", \"B03\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B05, sample.B04, sample.B03];\n    }\n\"\"\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-an-evalscript","position":81},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Create a Sentinel Hub request for Level 1 and Level 2 data","lvl2":"Landsat-8 Collection 2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#create-a-sentinel-hub-request-for-level-1-and-level-2-data","position":82},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Create a Sentinel Hub request for Level 1 and Level 2 data","lvl2":"Landsat-8 Collection 2"},"content":"Based on the parameters set in the previous cells, we will build a Sentinel Hub request for Landsat-8 Collection 2 Level 1 and Level 2, that will return False Colour RGB png images. For more information on using sentinelhub-py, you can refer to the \n\ndocumentation.\n\nl8_l1c = SentinelHubRequest(\n    evalscript=evalscript_false_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.LOTL1,\n            time_interval=('2020-05-01', '2020-08-30'),\n            other_args = {\"dataFilter\":{\"mosaickingOrder\":\"leastCC\"}}\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=dakar_bbox,\n    size=dakar_size,\n    config=config\n)\n\nl8_l2a = SentinelHubRequest(\n    evalscript=evalscript_false_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.LOTL2,\n            time_interval=('2020-05-01', '2020-08-30'),\n            other_args = {\"dataFilter\":{\"mosaickingOrder\":\"leastCC\"}}\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=dakar_bbox,\n    size=dakar_size,\n    config=config\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#create-a-sentinel-hub-request-for-level-1-and-level-2-data","position":83},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Run the requests","lvl2":"Landsat-8 Collection 2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#run-the-requests","position":84},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Run the requests","lvl2":"Landsat-8 Collection 2"},"content":"\n\nfalse_colour_l1c = l8_l1c.get_data()\nfalse_colour_l2a = l8_l2a.get_data()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#run-the-requests","position":85},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot the false colour RGB images","lvl2":"Landsat-8 Collection 2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-the-false-colour-rgb-images","position":86},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot the false colour RGB images","lvl2":"Landsat-8 Collection 2"},"content":"In the next cell, we will use a plotting function for the request results (\n\nexamples/utils.py).\n\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    \"\"\"\n    Utility function for plotting RGB images.\n    \"\"\"\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 12))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    plt.show()\n\nLastly, let’s visualise the Level 1 and 2 images! The image type is UINT8 which means that the image bands have values of 0-255. To visualise them on a scale of 0 to 1 we need to divide by 255 first. You can also adjust the factor to brighten the image if you wish.\n\n# Level 1\nimage_l1c = false_colour_l1c[0]\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 2.5 to increase brightness\nplot_image(image_l1c, factor=2.5/255, clip_range=(0,1))\n\n# Level 2\nimage_l2a = false_colour_l2a[0]\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 2.5 to increase brightness\nplot_image(image_l2a, factor=2.5/255, clip_range=(0,1))\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-the-false-colour-rgb-images","position":87},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"AIRBUS SPOT 6/7"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#airbus-spot-6-7","position":88},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"AIRBUS SPOT 6/7"},"content":"\n\nSPOT 6/7 is a satellite constellation providing very high-resolution optical imagery and is owned by \n\nAirbus.\n\nMission information\n\nSPOT 6/7 is composed of two twin satellites orbiting the Earth 180° apart. The following table lists the bands available through Sentinel Hub services and their resolution:\n\nName\n\nDescription\n\nResolution\n\nB0\n\nBlue, 454-519 nm\n\n6m\n\nB1\n\nGreen, 527-587 nm\n\n6m\n\nB2\n\nRed, 624-694 nm\n\n6m\n\nB3\n\nNear Infrared, 756-880 nm\n\n6m\n\nPAN\n\nPanchromatic, 455-744 nm\n\n1.5m\n\ndataMask\n\nThe mask of data/no data pixels\n\nN/A\n\nData availability\n\nSPOT 6/7 data can be accessed as a \n\nBYOC collection, i.e. by specifying a collection_ID.\n\nImages acquired on the following dates are available within the collection:\n\n2012-10-17\n\n2012-10-27\n\n2012-12-06\n\n2012-12-08\n\n2012-12-15\n\n2012-12-18\n\n2012-12-20\n\n2012-12-27\n\n2013-03-13\n\n2014-10-19\n\n2015-02-21\n\n2015-04-20\n\n2015-12-23\n\n2016-04-24\n\n2017-03-22\n\n2017-04-17\n\n2018-03-01\n\n2018-10-22\n\n2019-10-20\n\n2020-10-18\n\n2021-02-25\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#airbus-spot-6-7","position":89},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"AIRBUS SPOT 6/7"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-5","position":90},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"AIRBUS SPOT 6/7"},"content":"In the following example, we will set our AOI (covering the port of Dakar) using a GeoJSON polygon geometry. Here the coordinates are in \n\nWGS 84 / Pseudo-Mercator (EPSG 3857), with units in meters.\n\n# Bbox\ndakar_geometry = {\n  \"type\": \"Polygon\",\n  \"coordinates\": [\n    [\n      [\n        -1939522.159759,\n        1654269.238697\n      ],\n      [\n        -1939187.64469,\n        1653887.045024\n      ],\n      [\n        -1939331.024194,\n        1653724.663382\n      ],\n      [\n        -1939206.791642,\n        1653437.99502\n      ],\n      [\n        -1939025.229553,\n        1652922.092265\n      ],\n      [\n        -1939178.405172,\n        1651173.533333\n      ],\n      [\n        -1940544.740602,\n        1651555.800865\n      ],\n      [\n        -1940994.026067,\n        1652434.969169\n      ],\n      [\n        -1941127.720775,\n        1652883.886191\n      ],\n      [\n        -1940410.934574,\n        1654020.886953\n      ],\n      [\n        -1939503.012807,\n        1654718.303547\n      ],\n      [\n        -1939455.256746,\n        1654555.916536\n      ],\n      [\n        -1939522.159759,\n        1654269.238697\n      ]\n    ]\n  ]\n}\n\n# Bbox EPSG number and code (see https://docs.sentinel-hub.com/api/latest/api/process/crs/)\ndakar_epsg= 3857\ndakar_projection = \"http://www.opengis.net/def/crs/EPSG/0/3857\"\n\n# Build a Sentinel Hub geometry object from the input polygon\ndakar_geom = geometry.Geometry(dakar_geometry,crs=dakar_epsg)\n\n# Plot the geometry on a map\nIPython.display.GeoJSON(dakar_geom.transform(4326).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-5","position":91},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Query two images using Sentinel Hub services","lvl2":"AIRBUS SPOT 6/7"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#query-two-images-using-sentinel-hub-services","position":92},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Query two images using Sentinel Hub services","lvl2":"AIRBUS SPOT 6/7"},"content":"In addition to xcube, you can also use Sentinel Hub services to query images and analyse them. This approach is recommended if you want to compare a small amount of images spread over a large period of time.\n\nIn the following example, we will retrieve RGB images for 2 dates, on the 17th October 2012 and on 25th February 2021 over Dakar’s industrial harbour.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#query-two-images-using-sentinel-hub-services","position":93},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl4":"Input parameters","lvl3":"Query two images using Sentinel Hub services","lvl2":"AIRBUS SPOT 6/7"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#input-parameters","position":94},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl4":"Input parameters","lvl3":"Query two images using Sentinel Hub services","lvl2":"AIRBUS SPOT 6/7"},"content":"To call a BYOC collection, we first need to setup the input parameters for the request:\n\nwe start by defining the DataCollection based on the collectionID\n\nwe set the \n\nEvalscript, which tells Sentinel Hub services how to process the data and what product to return: here we will return the R,G,B product (B2, B1, B0 bands) as UINT16 images and a fourth band (dataMask) representing the nodata values (outside our area of interest) and plotted as an alpha band.\n\nwe build a SentinelHubRequest for each acquisition, that also include:\n\nThe date that interest us in the time_interval parameter\n\nThe output file format (not important here as we will not save the data)\n\nThe geometry set previously\n\nThe resolution (in the units of the CRS)\n\nA config file that contains credentials (reused from the Landsat example, so make sure the cells above are executed first).\n\n# Define DataCollection\nspot_col = DataCollection.define_byoc(spot_collection)\n\n# Evalscript to return RGB True Color\ntc_eval = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B0\", \"B1\", \"B2\", \"dataMask\"],\n    output: { bands: 4, sampleType: \"UINT16\" }, \n  };\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.B2, sample.B1, sample.B0, sample.dataMask * 65535];\n}\n\"\"\"\n\n# Build request for the first time step\nrequest_t1 = SentinelHubRequest(\n    evalscript=tc_eval,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=spot_col,\n            time_interval=('2012-10-17')\n        )],\n    responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n    geometry=dakar_geom,\n    resolution=(6, 6),\n    config=config\n    )\n\n# Build a request for the second time step\nrequest_t2 = SentinelHubRequest(\n    evalscript=tc_eval,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=spot_col,\n            time_interval=('2021-02-25')\n        )],\n    responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n    geometry=dakar_geom,\n    resolution=(6, 6),\n    config=config\n    )\n\n# Run the requests\nt1_rgb = request_t1.get_data()[0]\nt2_rgb = request_t2.get_data()[0]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#input-parameters","position":95},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Basic processing example: NDWI change"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#basic-processing-example-ndwi-change","position":96},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Basic processing example: NDWI change"},"content":"In the following cells, the change in Normalized Difference Water Index (\n\nNDWI) will be assessed (for demonstration purposes only).","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#basic-processing-example-ndwi-change","position":97},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot RGB images","lvl2":"Basic processing example: NDWI change"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-rgb-images","position":98},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot RGB images","lvl2":"Basic processing example: NDWI change"},"content":"In a first step we will plot the True Color RGB of Dakar harbor for each date side-by-side.\n\nTo visualise RGB images, we need to normalise the bands between 0 and 1. SPOT data are expressed in DN as DN = reflectance * 10000. The typical range for a SPOT image is 0 - 4000. Therefore we will normalise 0 - 4000 to 0 - 1 for visualisation purposes.\n\n# Plot RGB images together\nfig, (ax, ax2) = plt.subplots(1,2, figsize=(12,8))\n\n# Set ticks to times\nax.imshow(t1_rgb / 4000)\nax2.imshow(t2_rgb / 4000)\n\n# Set dates as titles\nax.set_title(\"Date: 2012-10-17\")\nax2.set_title(\"Date: 2021-02-25\")\n\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-rgb-images","position":99},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot change in NDWI","lvl2":"Basic processing example: NDWI change"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-change-in-ndwi","position":100},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot change in NDWI","lvl2":"Basic processing example: NDWI change"},"content":"To monitor change in NDWI, and potentially detect areas encroached on the ocean, we will plot the difference in NDWI between the two available dates. Looking at the RGB images and the NDWI change map (large red zone), we can see a new area in the port that was built out over the ocean.\n\n# Evalscript to return NDWI\nndwi_eval = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B1\", \"B3\"],\n    output: { bands: 1, sampleType: \"FLOAT32\" }, \n  };\n}\n\nfunction evaluatePixel(sample) {\n  let ndwi = (sample.B1 - sample.B3) / (sample.B1 + sample.B3)\n  return [ndwi];\n}\n\"\"\"\n\n# Build request for the first time step\nrequest_t1_ndwi = SentinelHubRequest(\n    evalscript=ndwi_eval,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=spot_col,\n            time_interval=('2012-10-17')\n        )],\n    responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n    geometry=dakar_geom,\n    resolution=(6, 6),\n    config=config\n    )\n\n# Build a request for the second time step\nrequest_t2_ndwi = SentinelHubRequest(\n    evalscript=ndwi_eval,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=spot_col,\n            time_interval=('2021-02-25')\n        )],\n    responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n    geometry=dakar_geom,\n    resolution=(6, 6),\n    config=config\n    )\n\n# Calculate NDWI\nndwi_t1 = request_t1_ndwi.get_data()[0]\nndwi_t2 = request_t2_ndwi.get_data()[0]\n\n# Compute change between two dates\nndwi_change = ndwi_t2 - ndwi_t1\n\n# Plot NDWI change\nfig, ax = plt.subplots(1, figsize=(12,8))\n\n# Set ticks to times\nchange = ax.imshow(ndwi_change[:,:], cmap=\"RdBu\",) #vmin=-0.5, vmax=0.5)\nplt.colorbar(change)\nax.set_title(\"NDWI change between 2012 and 2021\")\n\nplt.show()\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-change-in-ndwi","position":101},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"AIRBUS Pleiades"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#airbus-pleiades","position":102},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"AIRBUS Pleiades"},"content":"\n\nPléiades is a satellite constellation providing very high-resolution optical imagery and is owned by \n\nAirbus.\n\nMission information\n\nPléiades is composed of two twin satellites orbiting the Earth 180° apart. The satellites deliver 0.5 m optical imagery and offer a daily revisit capability to any point on the globe. The following table lists the bands available through Sentinel Hub services and their resolution:\n\nName\n\nDescription\n\nResolution\n\nB0\n\nBlue, 430-550 nm\n\n2m\n\nB1\n\nGreen, 490-610 nm\n\n2m\n\nB2\n\nRed, 600-720 nm\n\n2m\n\nB3\n\nNear Infrared, 750-950 nm\n\n2m\n\nPAN\n\nPanchromatic, 480-830 nm\n\n0.5m\n\ndataMask\n\nThe mask of data/no data pixels\n\nN/A\n\nData availability\n\nPléiades data can be accessed as a \n\nBYOC collection, i.e. by specifying a collection_ID.\n\nImages acquired on the following dates are available within the collection:\n\n2012-03-13\n\n2012-05-06\n\n2012-10-02\n\n2013-02-23\n\n2013-10-20\n\n2014-10-14\n\n2015-11-07\n\n2016-03-10\n\n2016-12-08\n\n2017-10-09\n\n2017-10-15\n\n2019-03-06\n\n2019-12-24\n\n2020-06-24\n\n2020-10-18\n\nMore acquisitions will be added during the contest, stay tuned for news!\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#airbus-pleiades","position":103},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"AIRBUS Pleiades"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-6","position":104},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"AIRBUS Pleiades"},"content":"In the following example, we will set our AOI (covering the Mbao industrial area, Dakar, Senegal - see \n\nhttp://www.sar.sn/) using a GeoJSON polygon geometry. Here the coordinates are in \n\nWGS 84 / UTM zone 28N (EPSG 32628), with units in meters.\n\n# Bbox\nmbao_geometry = {\n  \"type\": \"Polygon\",\n  \"coordinates\": [\n    [\n      [\n        246910.013036,\n        1630461.326004\n      ],\n      [\n        246752.787159,\n        1631786.114943\n      ],\n      [\n        248484.369728,\n        1631997.760134\n      ],\n      [\n        248751.899486,\n        1631930.66922\n      ],\n      [\n        248656.087821,\n        1631614.745376\n      ],\n      [\n        248804.78545,\n        1630340.550845\n      ],\n      [\n        248371.768609,\n        1630501.232138\n      ],\n      [\n        248252.122139,\n        1630121.242429\n      ],\n      [\n        246910.013036,\n        1630461.326004\n      ]\n    ]\n  ]\n}\n\n# Bbox EPSG number and code (see https://docs.sentinel-hub.com/api/latest/api/process/crs/)\nmbao_epsg = 32628\nmbao_projection= \"http://www.opengis.net/def/crs/EPSG/0/32628\"\n\n# Build a Sentinel Hub geometry object from the input polygon\nmbao_geom = geometry.Geometry(mbao_geometry,crs=mbao_epsg)\n\n# Plot the geometry on a map\nIPython.display.GeoJSON(mbao_geom.transform(4326).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-6","position":105},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"AIRBUS Pleiades"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-3","position":106},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"AIRBUS Pleiades"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call CUSTOM because Pléiades images are available as a BYOC collection.\n\nband_names: the band names to be used in the xcube array. Here, we will call the Blue, Green, Red and Panchromatic bands (B0, B1, B2, PAN respectively).\n\nbbox: the bounding box that sets the extent of the AOI. The bounding box covering the input geometry can be directly called from the sentinelhub.geometry object created above.\n\ncrs: if the coordinate reference system isn’t in WGS84 (EPSG:4326) as the default value, it is specified using an \n\nopengis URL. Here, we are using EPSG:32628.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in meters. Since we are also requesting the panchromatic band, and will perform pan-sharpening, we will request the cube at 0.5 meters resolution.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. For this example, we will request a single date.\n\ntime_period: Necessary when requesting a BYOC collection. The time period string denotes the temporal aggregation period to be used. Here 1d means that if several images are available for 1 given date (not the case), they will be aggregated.\n\ncollection_id: the Sentinel Hub BYOC collection ID for Airbus Pléiades.\n\n# Setup xcube for Pléiades\ncube_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=['B0', 'B1', 'B2', 'PAN'],\n                         bbox=mbao_geom.bbox,\n                         crs=mbao_projection,\n                         spatial_res=0.5,\n                         time_range=['2019-12-24', '2019-12-24'],\n                         time_period=\"1d\",\n                         collection_id=pleiades_collection)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-3","position":107},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open cube","lvl2":"AIRBUS Pleiades"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-cube","position":108},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open cube","lvl2":"AIRBUS Pleiades"},"content":"\n\nPleiades_cube = open_cube(cube_config, **sh_credentials)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-cube","position":109},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Explore the xcube","lvl2":"AIRBUS Pleiades"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#explore-the-xcube-1","position":110},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Explore the xcube","lvl2":"AIRBUS Pleiades"},"content":"We will first explore the variables and metadata contained in the xcube by printing its contents.\n\nPleiades_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#explore-the-xcube-1","position":111},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot a timeslice from the xcube","lvl2":"AIRBUS Pleiades"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-a-timeslice-from-the-xcube-1","position":112},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot a timeslice from the xcube","lvl2":"AIRBUS Pleiades"},"content":"In a second step we will plot Band PAN (panchromatic) for a time slice by selecting it’s number (0...n; 0 being the first slice and n the last). Here we only have 1 date in our cube, so we will plot time=0. Please note that in this step the cube is being requested on the fly for the first time, therefore this step will be a bit slow.\n\n%%time\nPleiades_cube.PAN.isel(time=0).plot.imshow(cmap='Greys_r', vmin=0, vmax=4000, figsize=(10, 10))\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-a-timeslice-from-the-xcube-1","position":113},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Extract a subset to work on a smaller region"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#extract-a-subset-to-work-on-a-smaller-region-1","position":114},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Extract a subset to work on a smaller region"},"content":"If you would like to work on a subset, e.g. because the region of interest is smaller than the specified bounding box, you can use a WKT polygon or Shapefile to mask the region of interest. Please note however that the WKT / shapefile must be in the same coordinate reference system as the existing xcube.\n\nTwo methods of selection are possible:\n\nBy masking - this keeps only the data of the WKT Polygon or shapefile\n\nBy clipping - this creates a new bounding box, which ensures that the area of interest is within the subset but keeps the surrounding data.\n\nIn this example, we will mask our cube, using the geometry specified earlier.\n\n# Mask the cube\nMbao_cube = mask_dataset_by_geometry(Pleiades_cube, geometry=mbao_geom.get_geojson())\n\n# Plot the masked cube\nMbao_cube.PAN.isel(time=0).plot.imshow(cmap='Greys_r', vmin=0, vmax=4000, figsize=(12, 10))\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#extract-a-subset-to-work-on-a-smaller-region-1","position":115},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Basic processing example: create a pan-sharpened RGB visualisation"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#basic-processing-example-create-a-pan-sharpened-rgb-visualisation","position":116},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Basic processing example: create a pan-sharpened RGB visualisation"},"content":"The Red, Green and Blue bands of Pléiades have a resolution of 2m, whereas the panchromatic band has a resolution of 0.5m. By combining the bands, using a method called \n\npan-sharpening, we can visualise a “sharpened” RGB True Color image at a resolution of 0.5 meters.\n\nSeveral methods can be used to pan-sharpen a Pléiades RGB image. In this example, we will use the Brovey algorithm (eq.2-3 in this \n\npaper).\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#basic-processing-example-create-a-pan-sharpened-rgb-visualisation","position":117},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Calculate pansharpened R, G, and B bands","lvl2":"Basic processing example: create a pan-sharpened RGB visualisation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#calculate-pansharpened-r-g-and-b-bands","position":118},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Calculate pansharpened R, G, and B bands","lvl2":"Basic processing example: create a pan-sharpened RGB visualisation"},"content":"In a first step we will calculate pan-sharpened bands for the Red, Green and Blue channels, using the panchromatic band as input. The bands will be stored in the cube for later re-use if needed. Note that the bands are not computed until use, meaning that this step is very fast.\n\nMbao_cube[\"PAN_RED\"] = (Mbao_cube.B2 / (Mbao_cube.B0 + Mbao_cube.B1 + Mbao_cube.B2)) * Mbao_cube.PAN;\nMbao_cube[\"PAN_GREEN\"] = (Mbao_cube.B1 / (Mbao_cube.B0 + Mbao_cube.B1 + Mbao_cube.B2)) * Mbao_cube.PAN\nMbao_cube[\"PAN_BLUE\"] = (Mbao_cube.B0 / (Mbao_cube.B0 + Mbao_cube.B1 + Mbao_cube.B2)) * Mbao_cube.PAN\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#calculate-pansharpened-r-g-and-b-bands","position":119},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot pan-sharpened RGB true color of Pléiades","lvl2":"Basic processing example: create a pan-sharpened RGB visualisation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-pan-sharpened-rgb-true-color-of-pl-iades","position":120},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot pan-sharpened RGB true color of Pléiades","lvl2":"Basic processing example: create a pan-sharpened RGB visualisation"},"content":"In the following cell, the bands calculated above are used for the first time, and therefore only computed in this step. The first execution of this cell will be thus be slower than the previous steps.\n\n# Plot RGB images together\nfig, ax = plt.subplots(1, figsize=(12,10))\n\n# Build rgb combination and plot\nrgb_tc = np.dstack((Mbao_cube.PAN_RED.isel(time=0), Mbao_cube.PAN_GREEN.isel(time=0), Mbao_cube.PAN_BLUE.isel(time=0)))\nax.imshow(rgb_tc / 2000)\n\n# Set date as title\nax.set_title(f\"Date: {str(Mbao_cube.time[0].data).split('T')[0]}\")\n\nplt.show()\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-pan-sharpened-rgb-true-color-of-pl-iades","position":121},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Planet PlanetScope"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#planet-planetscope","position":122},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Planet PlanetScope"},"content":"\n\nThe PlanetScope satellite constellation consists of more than 130 small satellites called Doves. Each Dove satellite is a CubeSat made of three cubic units and thus measures only 10 cm x 10 cm x 30 cm.\n\nMission information\n\nPlanetScope satellite deliver optical imagery with an almost daily coverage worldwide at a spatial resolution of 3.7-4.1 m. The following table lists the bands available through Sentinel Hub services and their resolution:\n\nName\n\nDescription\n\nResolution\n\nB1\n\nBlue, 455 - 515 nm\n\n3m (resampled)\n\nB2\n\nGreen, 500 - 590 nm\n\n3m (resampled)\n\nB3\n\nRed, 590 - 670 nm\n\n3m (resampled)\n\nB4\n\nNear Infrared, 780 - 860 nm\n\n3m (resampled)\n\nUDM\n\nUnusable Data Mask (see \n\ndocs)\n\n3m (resampled)\n\ndataMask\n\nThe mask of data/no data pixels\n\nN/A\n\nData availability\n\nPléiades data can be accessed as a \n\nBYOC collection, i.e. by specifying a collection_ID.\n\nThe images available for this contest were obtained under the “Hectares under management” model, meaning that you will have access to all images between 1st January 2017 and mid-May 2021 covering the eastern part of Dakar (of interest for Urban expansion).\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#planet-planetscope","position":123},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Planet PlanetScope"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-7","position":124},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Planet PlanetScope"},"content":"In the following example, we will set our AOI (north of Rufisque) using a bounding box expressed as [min_x, min_y, max_x, max_y]. Here the coordinates are in \n\nUTM Zone 28 N (EPSG 32628), with units in meters.\n\n# Bbox\ndakar_large_bbox = [249984, 1636430, 251910, 1638457]\n\n# Bbox EPSG number\ndakar_epsg = 32628\n\n# Plot the geometry on a map\nIPython.display.GeoJSON(BBox(dakar_large_bbox, crs=dakar_epsg).transform(4326).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-7","position":125},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Planet PlanetScope"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-4","position":126},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Planet PlanetScope"},"content":"In the following cell we will specify the input parameters needed to build the xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call CUSTOM because PlanetScope images are available as a BYOC collection.\n\nband_names: the band names to be used in the xcube array. Here, we will call the 4 bands: Blue, Green, Red, Near Infrared (B1, B2, B3, and B4 respectively).\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using a UTM coordinate system here, the CRS parameter will have to be set.\n\ncrs: if the coordinate reference system isn’t in WGS84 (EPSG:4326) as the default value, it is specified using an \n\nopengis URL. Here, we are using EPSG:32628.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in meters.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned.\n\ntime_period: Necessary when requesting a BYOC collection. The Time period string denotes the temporal aggregation period to be used. Here 1d means that if several images are available for 1 given date, they will be aggregated.\n\ncollection_id: the Sentinel Hub BYOC collection ID for PlanetScope.\n\n# Setup xcube for S1-CARD4L\ncube_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=['B1', 'B2', 'B3', 'B4'],\n                         bbox=dakar_large_bbox,\n                         crs=\"http://www.opengis.net/def/crs/EPSG/0/32628\",\n                         spatial_res=3,\n                         time_range=['2017-04-21', '2017-04-24'],\n                         time_period=\"1d\",\n                         collection_id=planet_collection)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-4","position":127},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Planet PlanetScope"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-4","position":128},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Planet PlanetScope"},"content":"In the following cell we open the cube and explore its contents.\n\n# Open cube\nPlanet_cube = open_cube(cube_config, **sh_credentials)\n\n# Drop empty time slices\nPlanet_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-4","position":129},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot two acquisitions within the xcube","lvl2":"Planet PlanetScope"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-two-acquisitions-within-the-xcube","position":130},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Plot two acquisitions within the xcube","lvl2":"Planet PlanetScope"},"content":"In the following cell we will compare the acquisitions of two dates contained within the xcube, that show rubbish-burning events occuring in the Mbeubeuss dump. To plot the False Colour composite, we will stack the NIR, Red and Green bands (divided by 10000 to obtain reflectance and multiplied by a factor of 3 for better visualisation).\n\n# Define factor for viewing the reflectance\nf = 10000 / 3\n\n# Stack bands for each acquisition\nrgb_t1 = np.dstack((Planet_cube.B4.isel(time=0) / f, Planet_cube.B3.isel(time=0)  / f, Planet_cube.B2.isel(time=0) / f))\nrgb_t2 = np.dstack((Planet_cube.B4.isel(time=3) / f, Planet_cube.B3.isel(time=3)  / f, Planet_cube.B2.isel(time=3) / f))\n\n# Create plot\nfig, (ax, ax2) = plt.subplots(1, 2, figsize=(10, 10))\nax.imshow(rgb_t1)\nax2.imshow(rgb_t2)\n\n# Plot options\nax.set_xticks([])\nax.set_yticks([])\nax.set_title(Planet_cube.time.isel(time=0).values.astype('datetime64[D]'))\nax2.set_xticks([])\nax2.set_yticks([])\nax2.set_title(Planet_cube.time.isel(time=3).values.astype('datetime64[D]'))\nfig.suptitle(\"Planetscope False Colour Composite\", y=0.75)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-two-acquisitions-within-the-xcube","position":131},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Compute a mask and overlay on the RGB False Colour Composite","lvl2":"Planet PlanetScope"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#compute-a-mask-and-overlay-on-the-rgb-false-colour-composite","position":132},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Compute a mask and overlay on the RGB False Colour Composite","lvl2":"Planet PlanetScope"},"content":"For demonstration purposes, the following cells will show how to perform morphological operations and apply masks on an image. A simple approach will be used to identify the smoke plume in the images: since smoke scatters light strongly in the blue wavelengths of the light spectrum, we will first attempt to identify the smoke plume by applying an empirical threshold to Band 1.\n\n# Set threshold\nthresh = 1800\n\n# Create a mask by first setting 0 where the threshold insn't met, \n# then setting 1 where the threshold is met\nPlanet_cube[\"bright\"] = Planet_cube.B1.where(Planet_cube.B1 > thresh, 0)\nPlanet_cube[\"bright\"] = Planet_cube[\"bright\"].where(Planet_cube[\"bright\"] == 0 , 1)\n\nPlanet_cube[\"bright\"].isel(time=0).plot.imshow()\nplt.show()\n\nThe simple thresholding seems to perform quite well on the first image, as shown in the plot above. However a number of smaller false positive patches appear. To remove them, we can apply an \n\nerosion-dilation step (also called binary opening) to the image using the scipy libraries.\n\n# Generate a structure for the filter\nstruct = np.ones((5,5))\n\n# Perform cleaning step on each time step\nclean_t1 = ndi.morphology.binary_opening(Planet_cube[\"bright\"].isel(time=0), struct)\nclean_t2 = ndi.morphology.binary_opening(Planet_cube[\"bright\"].isel(time=3), struct)\n\n# Plot the masks\nfig, (ax, ax2) = plt.subplots(1,2, figsize=(10, 10))\nax.imshow(clean_t1)\nax2.imshow(clean_t2)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#compute-a-mask-and-overlay-on-the-rgb-false-colour-composite","position":133},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Plot masked image"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-masked-image","position":134},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Plot masked image"},"content":"In the last step we plot the masked False Colour composite, using the cleaned smoke layer.\n\nfig, (ax, ax2) = plt.subplots(1,2, figsize=(10, 10))\n\nax.imshow(rgb_t1)\nax.imshow(np.ma.masked_where(clean_t1!=1, clean_t1), cmap=\"YlGn\")\nax2.imshow(rgb_t2)\nax2.imshow(np.ma.masked_where(clean_t2!=1, clean_t2), cmap=\"YlGn\")\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-masked-image","position":135},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Conclusions","lvl2":"Plot masked image"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#conclusions","position":136},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Conclusions","lvl2":"Plot masked image"},"content":"The approach shown here is too simplistic to be used for any analysis. Indeed, the darker (grey) parts of the smoke plume are not detected, and some bright surfaces are misinterpreted as smoke. However, large parts of the smoke plume are detected, and the method could be refined to perform in a more robust manner.\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#conclusions","position":137},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Maxar WorldView / GeoEye"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#maxar-worldview-geoeye","position":138},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Maxar WorldView / GeoEye"},"content":"\n\nThe WorldView constellations consists of four active satellites: WorldView-1 (data not available in Sentinel Hub), GeoEye-1 (GE01), WorldView-2 (WV02), and WorldView-3 (WV03). The WorldView-4 (WV04) satellite was operational from November 2016 to January 2019 and the data it acquired is available in Sentinel Hub.\n\nMission information\n\nWorldview satellites deliver optical imagery with a revisit time of 1 day to 3 days depending on the satellite. Note that the data is in general not acquired systematically. Archive data is available sporadically over an area of interest. The resolution of images available in Sentinel Hub is 0.5 m for the panchromatic band and 2 m for multispectral bands. The following table lists the bands available through Sentinel Hub services and their resolution:\n\nName\n\nDescription\n\nResolution\n\nBlue\n\nBlue, 450 - 510 nm\n\n2m\n\nGreen\n\nGreen, 510 - 580 nm\n\n2m\n\nRed\n\nRed, 630 - 690 nm for WV02 and WV03, 655 - 690 nm for GE01 and WV04\n\n2m\n\nNearIR1\n\nNear Infrared, 770 - 895 nm for WV02 and WV03, 780 - 920 nm for GE01 and WV04\n\n2m\n\nPAN\n\nPanchromatic, 450 - 800 nm\n\n0.5m\n\ndataMask\n\nThe mask of data/no data pixels\n\nN/A\n\nData availability\n\nMaxar data can be accessed as a \n\nBYOC collection, i.e. by specifying a collection_ID.\n\nData is available for the following dates / date ranges:\n\n2013-02-26\n\n2015-03-04\n\n2017-04-15 / 2017-04-25\n\n2019-03-01 / 2019-03-03\n\n2021-04-09 / 2021-04-23\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#maxar-worldview-geoeye","position":139},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Maxar WorldView / GeoEye"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-8","position":140},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Define area of interest","lvl2":"Maxar WorldView / GeoEye"},"content":"In the following example, we will set our AOI (Keur Ndiaye Lo, north of Rufisque) using a bounding box expressed as [min_x, min_y, max_x, max_y]. Here the coordinates are in \n\nUTM Zone 28 N (EPSG 32628), with units in meters.\n\n# Bbox\nKeur_Ndiaye = [259051, 1631160, 259563, 1631603]\n\n# Bbox EPSG number\ndakar_epsg = 32628\n\n# Plot the geometry on a map\nIPython.display.GeoJSON(BBox(Keur_Ndiaye, crs=dakar_epsg).transform(4326).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#define-area-of-interest-8","position":141},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Maxar WorldView / GeoEye"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-5","position":142},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Build xcube","lvl2":"Maxar WorldView / GeoEye"},"content":"In the following cell we will specify the input parameters needed to build the xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call CUSTOM because Maxar images are available as a BYOC collection.\n\nband_names: the band names to be used in the xcube array. Here, we will call the panchromatic band (PAN).\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using a UTM coordinate system here, the CRS parameter will have to be set.\n\ncrs: if the coordinate reference system isn’t in WGS84 (EPSG:4326) as the default value, it is specified using an \n\nopengis URL. Here, we are using EPSG:32628.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in meters.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned.\n\ntime_period: Necessary when requesting a BYOC collection. The Time period string denotes the temporal aggregation period to be used. Here 1d means that if several images are available for 1 given date, they will be aggregated.\n\ncollection_id: the Sentinel Hub BYOC collection ID for Maxar.\n\n# Setup xcube for S1-CARD4L\ncube_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=['PAN'],\n                         bbox=Keur_Ndiaye,\n                         crs=\"http://www.opengis.net/def/crs/EPSG/0/32628\",\n                         spatial_res=0.5,\n                         time_range=['2013-02-26', '2021-04-09'],\n                         time_period=\"1d\",\n                         collection_id=maxar_collection)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#build-xcube-5","position":143},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Maxar WorldView / GeoEye"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-5","position":144},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Open the xcube","lvl2":"Maxar WorldView / GeoEye"},"content":"In the following cell we open the cube and explore its contents.\n\n# Open cube\nmaxar_cube = open_cube(cube_config, **sh_credentials)\n\n# Drop empty time slices\nmaxar_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#open-the-xcube-5","position":145},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Filter the cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#filter-the-cube","position":146},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Filter the cube"},"content":"If we look at the cube in the cell above, we can see 2964 time slices (many of which are empty). Since we know the dates that we would like to keep in our xcube, we will create a subset based on the list of dates and overwrite our cube on the fly.\n\n# List of dates of interest\ndates_of_interest = [\"2013-02-26\", \"2015-03-04\", \"2017-04-15\", \"2019-03-01\", \"2021-04-09\"]\n\n# Subset\nmaxar_cube = maxar_cube.where(maxar_cube.time.dt.date.isin(np.array(dates_of_interest, dtype='datetime64')), drop=True)\n\n# Check the cube again\nmaxar_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#filter-the-cube","position":147},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Plot the panchromatic band for each time stamp"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-the-panchromatic-band-for-each-time-stamp","position":148},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl2":"Plot the panchromatic band for each time stamp"},"content":"Now we have our subset determined, we will make an RGB image for each timestamp and plot the urban expansion over the years using the automatic plotting funtion over time.\n\n# Stack bands for each acquisition\npan_plot = maxar_cube[\"PAN\"].plot.imshow(figsize=(12,8), x=\"x\", y=\"y\", col=\"time\", col_wrap=3, cmap=\"Greys_r\", vmin=500, vmax=4000)\nplt.show()\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#plot-the-panchromatic-band-for-each-time-stamp","position":149},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Now it’s your turn...","lvl2":"Plot the panchromatic band for each time stamp"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#now-its-your-turn","position":150},{"hierarchy":{"lvl1":"Custom Script Contest – Urban Growth in Africa","lvl3":"Now it’s your turn...","lvl2":"Plot the panchromatic band for each time stamp"},"content":"With the examples provided above, you should have all the elements needed to access the data and start coding away. We look forward to your results!","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-africa-cube-africa-custom-contest#now-its-your-turn","position":151},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo","position":0},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"GEODB\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo","position":1},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo#demonstration-of-eurocrops-data-use-in-geodb","position":2},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB"},"content":"This notebook demonstrates how the \n\nEurocrops data can be used for analysis, using the geoDB.\n\nfrom xcube_geodb.core.geodb import GeoDBClient\nimport time\n\ngeodb = GeoDBClient()\n\n# Setting the database name; this database contains the Eurocrops data collections\ndb = 'geodb_b34bfae7-9265-4a3e-b921-06549d3c6035'\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo#demonstration-of-eurocrops-data-use-in-geodb","position":3},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB","lvl2":"Demo #1"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo#demo-1","position":4},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB","lvl2":"Demo #1"},"content":"This step computes the area growing wheat in NRW (Germany), and measures the time needed to do that. Within the collection ‘DE_NRW_2021_EC21’, the crop types are identified by different codes stored in the column ‘code’; the values 112 and 115 identify wheat, therefore the respective query is 'or=(code.eq.112,code.eq.115)'. The sizes of the fields are stored in the column 'area_ha'.\n\ntic = time.perf_counter()\ndf = geodb.get_collection('DE_NRW_2021_EC21', query='or=(code.eq.112,code.eq.115)', database=db)\narea_acc = df['area_ha'].sum()\ntoc = time.perf_counter()\nprint(f\"Computed the area growing wheat in NRW (Germany): {area_acc:0.0f} ha, within {toc - tic} seconds\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo#demo-1","position":5},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB","lvl2":"Demo #2"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo#demo-2","position":6},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB","lvl2":"Demo #2"},"content":"This step computes the area growing wheat in Belgium, and measures the time needed to do that. Within the collection ‘BE_VLG_2021_EC21’, the crop types are identified by different codes stored in the column ‘gwscod_h’; the values 311 and 312 identify wheat, therefore the respective query is 'or=(gwscod_h.eq.311,gwscod_h.eq.312)'. The sizes of the fields are stored in the column 'graf_opp'\n\ntic = time.perf_counter()\ndf = geodb.get_collection('BE_VLG_2021_EC21', query='or=(gwscod_h.eq.311,gwscod_h.eq.312)', database=db)\narea_acc = df['graf_opp'].sum()\ntoc = time.perf_counter()\nprint(f\"Computed the area growing wheat in Belgium (VLG): {area_acc:0.0f} ha, within {toc - tic} seconds\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo#demo-2","position":7},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB","lvl2":"Demo #3"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo#demo-3","position":8},{"hierarchy":{"lvl1":"Demonstration of Eurocrops data use in geoDB","lvl2":"Demo #3"},"content":"This step extracts 1000 fields growing wheat in Austria. Within the collection ‘AT_2021_EC21’, the crop types are identified by different codes stored in the column ‘snar_code’; the values 140, 168 and 170 identify wheat, and the column 'sl_flaeche' stores the sizes of the fields.\n\ntic = time.perf_counter()\ndf = geodb.get_collection('AT_2021_EC21', query='and=(or(snar_code.eq.140,snar_code.eq.168,snar_code.eq.170),sl_flaeche.gt.1)', database=db, limit=1000)\ntoc = time.perf_counter()\nprint(f\"Extracted 1000 areas in Austria growing wheat, larger than 1 ha, within {toc - tic} seconds\")","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo#demo-3","position":9},{"hierarchy":{"lvl1":"Important notes"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification","position":0},{"hierarchy":{"lvl1":"Important notes"},"content":"from edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification","position":1},{"hierarchy":{"lvl1":"Important notes"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#important-notes","position":2},{"hierarchy":{"lvl1":"Important notes"},"content":"This notebook requires:\n\nPOSTGIS database (with access information exposed as environment variables) having sample LPIS data ingested -> please find further information \n\nhere\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#important-notes","position":3},{"hierarchy":{"lvl1":"LPIS Use case: Crop-type classification (AUT)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#lpis-use-case-crop-type-classification-aut","position":4},{"hierarchy":{"lvl1":"LPIS Use case: Crop-type classification (AUT)"},"content":"This notebook demonstrates how Euro Data Cube (EDC) tools can be utilized for exploratory analysis and manipulation of data in Land Parcel Identification System (LPIS). The most important part is the example of using satellite imagery and machine learning algorithms for crop type classification, which should be a valuable support for decisions related with LPIS controls.\nThe described workflow consists of several parts:\n\nPrepare and explore LPIS data and satellite imagery\n\nRun Machine Learning and create a model for crop type classification\n\nVisualize results and extract information to support LPIS controls\n\nClassify on parcel level per LPIS ID\n\nPersist results in database\n\n# This notebook uses the EO-Learn ML library which requires configuration passed via the 'sentinel.config' tool\n!sentinelhub.config --sh_base_url 'https://services.sentinel-hub.com'\n!sentinelhub.config --sh_client_id $SH_CLIENT_ID\n!sentinelhub.config --sh_client_secret $SH_CLIENT_SECRET\n!sentinelhub.config --instance_id $SH_INSTANCE_ID\n\n# see section Important Notes above\nimport os\ndb_conn_params = {\n    'host': os.getenv('DB_HOST'),\n    'database': os.getenv('DB_NAME'),\n    'user': os.getenv('DB_USER'),\n    'password': os.getenv('DB_PASSWORD')\n}\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#lpis-use-case-crop-type-classification-aut","position":5},{"hierarchy":{"lvl1":"LPIS Use case: Crop-type classification (AUT)","lvl2":"Import packages"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#import-packages","position":6},{"hierarchy":{"lvl1":"LPIS Use case: Crop-type classification (AUT)","lvl2":"Import packages"},"content":"\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Jupyter notebook related\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n# Built-in modules\nimport pickle\nimport sys\nimport datetime\nimport time\nimport itertools\nimport math\nimport subprocess\nimport fiona\nimport fiona.crs\nfrom enum import Enum\n\n# Basics of Python data handling and visualization\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom shapely.geometry import Polygon\nfrom tqdm import tqdm_notebook as tqdm\n\n# Machine learning \nimport lightgbm as lgb\nfrom sklearn.externals import joblib\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\n# Imports from eo-learn and sentinelhub-py\nfrom eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, \\\n    LoadTask, SaveTask, EOExecutor\nfrom eolearn.core.core_tasks import AddFeature\nfrom eolearn.io import S2L1CWCSInput, ExportToTiff\nfrom eolearn.mask import AddCloudMaskTask, get_s2_pixel_cloud_detector, AddValidDataMaskTask\nfrom eolearn.geometry import VectorToRaster, PointSamplingTask, ErosionTask\nfrom eolearn.features import LinearInterpolation, SimpleFilterTask\nfrom sentinelhub import BBoxSplitter, BBox, CRS, CustomUrlParam, UtmGridSplitter\n\n# OAuth2\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# DB and raw geometry\nimport psycopg2\nfrom psycopg2._psycopg import AsIs\nfrom psycopg2.extensions import register_adapter\nimport shapely.wkt\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom geopandas import GeoDataFrame\n\n\n# imports for xcube\nimport xarray as xr\nfrom shapely.ops import cascaded_union\n\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.observers import Observers\nfrom xcube_sh.config import CubeConfig\n\nfrom xcube.core.geom import mask_dataset_by_geometry\n\n# Amazon S3\nimport boto3\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#import-packages","position":7},{"hierarchy":{"lvl1":"Database loading and mapping functionality"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#database-loading-and-mapping-functionality","position":8},{"hierarchy":{"lvl1":"Database loading and mapping functionality"},"content":"\n\n## mapping of crop type groups into 24 classes that are to be predicted\n\n# AT: vector to raster needs uint8 values \nctToctnuml4aMapping = {\n    1: [1010], #SOMMERGETREIDE\n    2: [1020], #WINTERGETREIDE\n    3: [1030], #MENGGETREIDE_AEHNLICHES\n    4: [1040], #MAIS_AEHNLICHES\n    5: [1050], #SOMMERRAPS_AEHNLICHES\n    6: [1060], #WINTERRAPS_AEHNLICHES\n    7: [1070], #SONNENBLUME\n    8: [1080], #HANF\n    9: [1090], #LEGUMINOSEN_AEHNLICHES\n    10: [1100], #WINTERLEGUMINOSE\n    11: [1110], #KARTOFFELN_AEHNLICHES\n    12: [1120], #RUEBEN\n    13: [1130], #GEMUESE_AEHNLICHES\n    14: [1140], #GEWUERZE_AEHNLICHES\n    15: [1150], #WINTERGEWUERZE_AEHNLICHES   \n    16: [1160], #KUERBIS\n    17: [1170], #BRACHE\n    18: [1180], #DAUERKULTUR\n    19: [1190], #GEWAECHSHAUS\n    20: [1200], #WEIN\n    21: [1210], #GRUENLAND\n    22: [1220], #PRO_RATA\n    23: [1230], #LAGERFLAECHEN\n    24: [1240] #SONSTIGES\n}\nctnuml4aToctMapping = {ctnuml4a: ctid for ctid, ctnuml4aList in ctToctnuml4aMapping.items() for ctnuml4a in ctnuml4aList}\n\n# needed for DB mapping\nregister_adapter(np.int64, AsIs)\nregister_adapter(Polygon, AsIs)\nregister_adapter(MultiPolygon, AsIs)\n\ndef loadFromDatabase(db_conn, taskName, tableName, bbox, dateFilterMin, dateFilterMax, mappedColumnName = None, mappingLambdaFunc = None):\n    columns = [\"ogd_id\", \"ctnuml4a\", \"geometry\"]\n    geometries = []\n\n    if (mappedColumnName and mappingLambdaFunc):\n        columns.append(mappedColumnName)\n    \n    with db_conn.cursor() as cur:\n        sql = '''\n            SELECT ogd_id, ctnuml4a, ST_AsText(ST_Transform(geometry, {targetCrs})) \n            FROM {tableName}\n            WHERE ST_Intersects(geometry, ST_Transform(ST_GeomFromText('{bbox}', {targetCrs}), 31287))\n                AND ref_date >= '{dateFilterMin}' AND ref_date <= '{dateFilterMax}'\n            '''\n        \n        sql = sql.format(tableName = tableName, targetCrs = bbox.crs.value, \n            dateFilterMin = dateFilterMin, dateFilterMax = dateFilterMax,\n            bbox = bbox.geometry.wkt)\n        #print(sql)\n\n        cur.execute(sql)\n        for row in cur:\n            properties = {\"ogd_id\": row[0], \"ctnuml4a_id\": row[1]}\n            if (mappedColumnName and mappingLambdaFunc):\n                properties[mappedColumnName] = mappingLambdaFunc(row[1])\n\n            geometry = shapely.wkt.loads(row[2]);\n            geometries.append({\"geometry\": geometry, \"properties\": properties})\n        print(taskName + \": \" + str(len(geometries)) + ' DB records for bbox = ' + str(bbox) + ' ' + str(bbox.crs.value))        \n        crs = {\"init\": \"epsg:{}\".format(bbox.crs.value)}\n        gdf = GeoDataFrame.from_features(geometries, crs = crs, columns = columns)\n        return gdf\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#database-loading-and-mapping-functionality","position":9},{"hierarchy":{"lvl1":"Part 1: Exploratory Analysis"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-1-exploratory-analysis","position":10},{"hierarchy":{"lvl1":"Part 1: Exploratory Analysis"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-1-exploratory-analysis","position":11},{"hierarchy":{"lvl1":"Part 1: Exploratory Analysis","lvl2":"Define the Area-of-Interest (AOI):"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-the-area-of-interest-aoi","position":12},{"hierarchy":{"lvl1":"Part 1: Exploratory Analysis","lvl2":"Define the Area-of-Interest (AOI):"},"content":"The whole territory of a country is splited into patches which makes the processing more efficient. The process is run on are of 3x3 patches for demonstration purposes.  AOI can be selected as the id of the patch in the middle.\n\nMain steps in this part of the notebook:\n\nLoad a geographical shape of Austria\n\nConvert it to selected CRS: taken to be the CRS of central UTM tile (UTM_33N)\n\nSplit it into smaller, manageable, non-overlapping rectangular tiles (patches)\n\nSelect a small 3x3 area for classification\n\nBe sure that your choice of CRS is the same as the CRS of your reference data.\n\nIn the case that you are having problems with empty data being downloaded, try changing the CRS to something that suits the location of the AOI better.\n\n# Folder where data for running the notebook is stored\nDATA_FOLDER = os.path.join('example_data')\n\n# Load geojson file containing the outline of the country\ncountry = gpd.read_file(os.path.join(DATA_FOLDER, 'at_not_buffered.geojson'))\n\n# Convert CRS to UTM_33N\ncountry_crs = CRS.UTM_33N\ncountry = country.to_crs(crs={'init': CRS.ogc_string(country_crs)})\n\n# Get the country's shape in polygon format\ncountry_shape = country.geometry.values[-1]\n\n# Define bounds and select middle patch ID\nuse_smaller_patches = True\n\nID = 13311 if use_smaller_patches else 1606\n\nbounds = [15.5242, 48.7574, 15.5391, 48.7698]  if use_smaller_patches else [15.4191, 48.653, 15.7335, 48.8102]\n\nbbox_splitter_large = BBoxSplitter([country_shape], country_crs, (25 * 3, 17 * 3))\nbbox_splitter_small = BBoxSplitter([country_shape], country_crs, (25 * 9, 17 * 9))\n\nbbox_splitter = bbox_splitter_small if use_smaller_patches else bbox_splitter_large\nbbox_list_aligned = [BBox((10 * math.floor(bbox.min_x / 10), 10 * math.floor(bbox.min_y / 10), \n                           10 * math.floor(bbox.max_x / 10), 10 * math.floor(bbox.max_y / 10)), country_crs) \n                     for bbox in bbox_splitter.get_bbox_list()]\n\nbbox_list = np.array(bbox_list_aligned)\ninfo_list = np.array(bbox_splitter.get_info_list())\n\nall_patches_gdf = gpd.GeoDataFrame(\n    {\n        \"index_x\": [info['index_x'] for info in info_list],\n        \"index_y\": [info['index_y'] for info in info_list],\n    },\n    crs={'init': CRS.ogc_string(country_crs)},\n    geometry=[Polygon(bbox.get_polygon()) for bbox in bbox_list]\n)\n\n# Obtain surrounding patches\npatchIDs = []\nfor idx, [bbox, info] in enumerate(zip(bbox_list, info_list)):\n    if (abs(info['index_x'] - info_list[ID]['index_x']) <= 1 and\n        abs(info['index_y'] - info_list[ID]['index_y']) <= 1):\n        patchIDs.append(idx)\n\n# Check if final size is 3x3\nif len(patchIDs) != 9:\n    print('Warning! Use a different central patch ID, this one is on the border.')\n    \n# Change the order of the patches (used for plotting later)\npatchIDs = np.transpose(np.fliplr(np.array(patchIDs).reshape(3, 3))).ravel()\n    \n# Prepare info of selected EOPatches\ngeometry = [Polygon(bbox.get_polygon()) for bbox in bbox_list[patchIDs]]\nidxs_x = [info['index_x'] for info in info_list[patchIDs]]\nidxs_y = [info['index_y'] for info in info_list[patchIDs]]\n\ngdf = gpd.GeoDataFrame({'index_x': idxs_x, 'index_y': idxs_y}, \n                       crs={'init': CRS.ogc_string(country_crs)}, \n                       geometry=geometry)\n\n# save to shapefile\nshapefile_name = './selected_3x3_bboxes_at_small.shp' if use_smaller_patches \\\n    else './selected_3x3_bboxes_at_large.shp'\ngdf.to_file(shapefile_name)\n\n# Visualize the selection\npoly = gdf['geometry'][0]\nx1, y1, x2, y2 = poly.bounds\naspect_ratio = (y1 - y2) / (x1 - x2)\n\nfontdict = {'family': 'monospace', 'weight': 'normal', 'size': 11}\n\n# if bboxes have all same size, estimate offset\nxl, yl, xu, yu = gdf.geometry[0].bounds\nxoff, yoff = (xu - xl) / 3, (yu - yl) / 5\n\n# figure\nfig, ax = plt.subplots(figsize=(20, 20));\ngdf.plot(ax=ax,facecolor='w',edgecolor='r',alpha=0.5);\ncountry.plot(ax=ax, facecolor='w',edgecolor='b',alpha=0.5);\nax.set_title('Selected 3x3 patches within the border of Austria');\nplt.axis('off');\n\n# Rearange selected EOPatches into bbox, which can be used for xcube definition\npatches_geometries = [Polygon(bbox.transform(CRS.WGS84).get_polygon()) for bbox in bbox_list[patchIDs]]\nbbox_of_patches = gpd.GeoSeries(cascaded_union(patches_geometries))\n\nx1 = bbox_of_patches.bounds['minx'][0].item()\ny1 = bbox_of_patches.bounds['miny'][0].item()\nx2 = bbox_of_patches.bounds['maxx'][0].item()\ny2 = bbox_of_patches.bounds['maxy'][0].item()\nbbox_wgs84 = x1, y1, x2, y2\n\n## Plot time series of satellite images for bbox\nx1, y1, x2, y2 = bbox\nspatial_res_meters = 10\npixx = (x2-x1)/spatial_res_meters; pixy = (y2-y1)/spatial_res_meters;\nx1, y1, x2, y2 = bbox_wgs84\nspatial_res = float(np.mean([(x2-x1)/pixx, (y2-y1)/pixy]))\n\ncube_config = CubeConfig(dataset_name='S2L1C',\n                         band_names=[\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"B12\"],\n                         chunk_size=[512, 512],\n                         geometry=bbox_wgs84,\n                         spatial_res=spatial_res,\n                         time_range=['2018-01-01', '2018-09-30'],\n                         time_period='4D')  \n\n# So we can print some SentinelHub usage stats\nrequest_collector = Observers.request_collector()\ncube = open_cube(cube_config, request_collector)\n\n# Add Indecies\n## NDVI\nb_red = cube.B04\nb_nir = cube.B08\nndvi = (b_nir - b_red) / (b_nir + b_red)\nndvi.attrs['long_name'] = 'Normalized Difference Vegetation Index'\nndvi.attrs['units'] = 'unitless'\ncube[\"ndvi\"] = ndvi\n\n## NDWI\nb_green = cube.B03\nb_nir = cube.B08\nndwi = (b_green - b_nir) / (b_green + b_nir)\nndwi.attrs['long_name'] = 'Normalized Difference Water Index'\nndwi.attrs['units'] = 'unitless'\ncube[\"ndwi\"] = ndwi\n\ncube.time\n\nselected_time = '2018-08-03' #User's input. Must be a value in cube.time\n\n# True color image\n\nfactor = 2.5\nR = cube.B04.sel(time=selected_time)*factor\nG = cube.B03.sel(time=selected_time)*factor\nB = cube.B02.sel(time=selected_time)*factor\nRGB = np.dstack([R, G, B])\nrgb_array = xr.DataArray(RGB, dims=('lat', 'lon', 'b'), coords=dict(lat=cube.B04.lat, lon=cube.B04.lon))\nrgb_array.plot.imshow(rgb='b', figsize=(16, 16))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-the-area-of-interest-aoi","position":13},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-2-crop-type-prediction-with-machine-learning","position":14},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-2-crop-type-prediction-with-machine-learning","position":15},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Set some of the inputs for prediction with ML"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#set-some-of-the-inputs-for-prediction-with-ml","position":16},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Set some of the inputs for prediction with ML"},"content":"\n\nselected_date_for_reference_data = '2018-06-30'\nselected_date_interval_for_satellite_imagery = ['2018-01-01', '2018-09-30']\nselected_max_cc = 0.8\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#set-some-of-the-inputs-for-prediction-with-ml","position":17},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Fill EOPatches with data:"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#fill-eopatches-with-data","position":18},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Fill EOPatches with data:"},"content":"Now it’s time to create EOPatches and fill them with Sentinel-2 data using Sentinel Hub services. We will add the following data to each EOPatch:\n\nL1C custom list of bands [B02, B03, B04, B08, B11, B12], which corresponds to [B, G, R, NIR, SWIR1, SWIR2] wavelengths.\n\nSentinelHub’s cloud probability map and cloud mask\n\nAdditionally, we will add:\n\nCalculated NDVI, NDWI, euclidean NORM information\n\nA mask of validity, based on acquired data from Sentinel and cloud coverage. Valid pixel is if:\n\nIS_DATA == True\n\nCLOUD_MASK == 0 (1 indicates that pixel was identified to be covered with cloud)\n\nAn EOPatch is created and manipulated using EOTasks, which are chained in an EOWorkflow. In this example the final workflow is executed on all patches, which are saved to the specified directory.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#fill-eopatches-with-data","position":19},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Define some needed custom EOTasks","lvl2":"Fill EOPatches with data:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-some-needed-custom-eotasks","position":20},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Define some needed custom EOTasks","lvl2":"Fill EOPatches with data:"},"content":"\n\nclass SentinelHubValidData:\n    \"\"\"\n    Combine Sen2Cor's classification map with `IS_DATA` to define a `VALID_DATA_SH` mask\n    The SentinelHub's cloud mask is asumed to be found in eopatch.mask['CLM']\n    \"\"\"\n    def __call__(self, eopatch):        \n        return np.logical_and(eopatch.mask['IS_DATA'].astype(np.bool), \n                              np.logical_not(eopatch.mask['CLM'].astype(np.bool)))\n    \nclass CountValid(EOTask):   \n    \"\"\"\n    The task counts number of valid observations in time-series and stores the results in the timeless mask.\n    \"\"\"\n    def __init__(self, count_what, feature_name):\n        self.what = count_what\n        self.name = feature_name\n        \n    def execute(self, eopatch):\n        eopatch.add_feature(FeatureType.MASK_TIMELESS, self.name, np.count_nonzero(eopatch.mask[self.what],axis=0))\n        \n        return eopatch\n\n\nclass NormalizedDifferenceIndex(EOTask):   \n    \"\"\"\n    The tasks calculates user defined Normalised Difference Index (NDI) between two bands A and B as:\n    NDI = (A-B)/(A+B).\n    \"\"\"\n    def __init__(self, feature_name, band_a, band_b):\n        self.feature_name = feature_name\n        self.band_a_fetaure_name = band_a.split('/')[0]\n        self.band_b_fetaure_name = band_b.split('/')[0]\n        self.band_a_fetaure_idx = int(band_a.split('/')[-1])\n        self.band_b_fetaure_idx = int(band_b.split('/')[-1])\n        \n    def execute(self, eopatch):\n        band_a = eopatch.data[self.band_a_fetaure_name][..., self.band_a_fetaure_idx]\n        band_b = eopatch.data[self.band_b_fetaure_name][..., self.band_b_fetaure_idx]\n        \n        ndi = (band_a - band_b) / (band_a  + band_b)\n        \n        eopatch.add_feature(FeatureType.DATA, self.feature_name, ndi[..., np.newaxis])\n        \n        return eopatch\n\n    \nclass EuclideanNorm(EOTask):   \n    \"\"\"\n    The tasks calculates Euclidian Norm of all bands within an array:\n    norm = sqrt(sum_i Bi**2),\n    where Bi are the individual bands within user-specified feature array.\n    \"\"\"\n    def __init__(self, feature_name, in_feature_name):\n        self.feature_name = feature_name\n        self.in_feature_name = in_feature_name\n    \n    def execute(self, eopatch):\n        arr = eopatch.data[self.in_feature_name]\n        norm = np.sqrt(np.sum(arr**2, axis=-1))\n        \n        eopatch.add_feature(FeatureType.DATA, self.feature_name, norm[..., np.newaxis])\n        return eopatch\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-some-needed-custom-eotasks","position":21},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Define the workflow tasks","lvl2":"Fill EOPatches with data:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-the-workflow-tasks","position":22},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Define the workflow tasks","lvl2":"Fill EOPatches with data:"},"content":"\n\n# TASK FOR BAND DATA\n# add a request for B(B02), G(B03), R(B04), NIR (B08), SWIR1(B11), SWIR2(B12) \n# from default layer 'ALL_BANDS' at 10m resolution\n# Here we also do a simple filter of cloudy scenes. A detailed cloud cover \n# detection is performed in the next step\ncustom_script = 'return [B02, B03, B04, B08, B11, B12];'\nadd_data = S2L1CWCSInput(\n    layer='BANDS-S2-L1C', \n    feature=(FeatureType.DATA, 'BANDS'), # save under name 'BANDS'\n    custom_url_params={CustomUrlParam.EVALSCRIPT: custom_script}, # custom url for 6 specific bands\n    resx='10m', # resolution x\n    resy='10m', # resolution y\n    maxcc=selected_max_cc # maximum allowed cloud cover of original ESA tiles\n)\n\n# TASK FOR CLOUD INFO\n# cloud detection is performed at 80m resolution \n# and the resulting cloud probability map and mask \n# are scaled to EOPatch's resolution\ncloud_classifier = get_s2_pixel_cloud_detector(average_over=2, dilation_size=1, all_bands=False)\nadd_clm = AddCloudMaskTask(cloud_classifier, 'BANDS-S2CLOUDLESS', cm_size_y='80m', cm_size_x='80m', \n                           cmask_feature='CLM', # cloud mask name\n                           cprobs_feature='CLP' # cloud prob. map name\n                          )\n\n# TASKS FOR CALCULATING NEW FEATURES\n# NDVI: (B08 - B04)/(B08 + B04)\n# NDWI: (B03 - B08)/(B03 + B08)\n# NORM: sqrt(B02^2 + B03^2 + B04^2 + B08^2 + B11^2 + B12^2)\nndvi = NormalizedDifferenceIndex('NDVI', 'BANDS/3', 'BANDS/2')\nndwi = NormalizedDifferenceIndex('NDWI', 'BANDS/1', 'BANDS/3')\nnorm = EuclideanNorm('NORM','BANDS')\n\n# TASK FOR VALID MASK\n# validate pixels using SentinelHub's cloud detection mask and region of acquisition \nadd_sh_valmask = AddValidDataMaskTask(SentinelHubValidData(), \n                                      'IS_VALID' # name of output mask\n                                     )\n\n# TASK FOR COUNTING VALID PIXELS\n# count number of valid observations per pixel using valid data mask \ncount_val_sh = CountValid('IS_VALID', # name of existing mask\n                          'VALID_COUNT' # name of output scalar\n                         )\n\n# TASK FOR SAVING TO OUTPUT (if needed)\npath_out = './eopatches_small' if use_smaller_patches else './eopatches_large'\nif not os.path.isdir(path_out):\n    os.makedirs(path_out)\nsave = SaveTask(path_out, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-the-workflow-tasks","position":23},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Reference map task","lvl2":"Fill EOPatches with data:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#reference-map-task","position":24},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Reference map task","lvl2":"Fill EOPatches with data:"},"content":"For this example the LPIS Data from the austrian Open Government Data portal \n\ndata.gv.at is used: \n\nINVEKOS Schläge Österreich\nThe crop types are grouped into 23 groups for classification:\n\nclass CTGROUPS(Enum):\n    NO_DATA                   = (0, \"NO_DATA\", \"#ffffff\")\n    SOMMERGETREIDE            = (1, \"SOMMERGETREIDE\", \"#7bf500\")\n    WINTERGETREIDE            = (2, \"WINTERGETREIDE\", \"#a8ff2b\")\n    MENGGETREIDE_AEHNLICHES   = (3, \"MENGGETREIDE_AEHNLICHES\", \"#daff1f\")\n    MAIS_AEHNLICHES           = (4, \"MAIS_AEHNLICHES\", \"#fff200\")\n    SOMMERRAPS_AEHNLICHES     = (5, \"SOMMERRAPS_AEHNLICHES\", \"#ffd701\")\n    WINTERRAPS_AEHNLICHES     = (6, \"WINTERRAPS_AEHNLICHES\", \"#ffbc0c\")\n    SONNENBLUME               = (7, \"SONNENBLUME\", \"#ff7005\")\n    HANF                      = (8, \"HANF\", \"#ff2a00\")\n    LEGUMINOSEN_AEHNLICHES    = (9, \"LEGUMINOSEN_AEHNLICHES\", \"#ff0046\")\n    WINTERLEGUMINOSE          = (10, \"WINTERLEGUMINOSE\", \"#ff00f8\")\n    KARTOFFELN_AEHNLICHES     = (11, \"KARTOFFELN_AEHNLICHES\", \"#b325ff\")\n    RUEBEN                    = (12, \"RUEBEN\", \"#cd61f4\")\n    GEMUESE_AEHNLICHES        = (13, \"GEMUESE_AEHNLICHES\", \"#ef96f1\")\n    GEWUERZE_AEHNLICHES       = (14, \"GEWUERZE_AEHNLICHES\", \"#f6c9f7\")\n    WINTERGEWUERZE_AEHNLICHES = (15, \"WINTERGEWUERZE_AEHNLICHES\", \"#000080\")\n    KUERBIS                   = (16, \"KUERBIS\", \"#004821\")\n    BRACHE                    = (17, \"BRACHE\", \"#00288a\")\n    DAUERKULTUR               = (18, \"DAUERKULTUR\", \"#0046ff\")\n    GEWAECHSHAUS              = (19, \"GEWAECHSHAUS\", \"#00c5ff\")\n    WEIN                      = (20, \"WEIN\", \"#00f6f8\")\n    GRUENLAND                 = (21, \"GRUENLAND\", \"#26ef00\")\n    PRO_RATA                  = (22, \"PRO_RATA\", \"#67d400\")\n    LAGERFLAECHEN             = (23, \"LAGERFLAECHEN\", \"#aaaaaa\")\n    SONSTIGES                 = (24, \"SONSTIGES\", \"#555555\")\n\n    \n    def __init__(self, val1, val2, val3):\n        self.id = val1\n        self.class_name = val2\n        self.color = val3\n\n\n#Reference colormap things\nct_cmap = mpl.colors.ListedColormap([entry.color for entry in CTGROUPS])\nct_norm = mpl.colors.BoundaryNorm(np.arange(-0.5, 24, 1), ct_cmap.N)\n\nThe main point of this task is to create a raster mask from the vector polygons and add it to the eopatch. With this procedure, any kind of a labeled shapefile can be transformed into a raster reference map. This result is achieved with the existing task VectorToRaster from the eolearn.geometry package. All polygons belonging to the each of the classes are separately burned to the raster mask.\n\n# user param\nLPISRecordsDateMin = selected_date_for_reference_data \nLPISRecordsDateMax = selected_date_for_reference_data\n\nclass LoadFromDatabaseTask(EOTask):\n    def __init__(self, feature, taskName, crs, tableName, dateFilterMin, dateFilterMax, mappedColumnName = None, mappingLambdaFunc = None):\n        self.feature_type, self.feature_name = next(self._parse_features(feature)())\n        self.taskName = taskName\n        self.crs = crs\n        self.tableName = tableName\n        self.dateFilterMin = dateFilterMin\n        self.dateFilterMax = dateFilterMax\n        self.mappedColumnName = mappedColumnName\n        self.mappingLambdaFunc = mappingLambdaFunc\n\n    def execute(self, eopatch, db_conn):\n        eopatch[self.feature_type][self.feature_name] = loadFromDatabase(db_conn, \n            self.taskName, self.tableName, eopatch.bbox, \n            self.dateFilterMin, self.dateFilterMax, \n            self.mappedColumnName, self.mappingLambdaFunc)\n        return eopatch\n    \n\n# LPIS\nct_use_db_task = LoadFromDatabaseTask((FeatureType.VECTOR_TIMELESS, 'CROP_TYPE_GDF'), \n    \"crop type\", CRS.UTM_33N, \"lpis_at\", LPISRecordsDateMin, LPISRecordsDateMax, \n    \"ct\", lambda ct_id: ctnuml4aToctMapping[ct_id] if ct_id in ctnuml4aToctMapping else 0)\n\n\nct_rasterization_task = VectorToRaster((FeatureType.VECTOR_TIMELESS, 'CROP_TYPE_GDF'), (FeatureType.MASK_TIMELESS, 'CROP_TYPE'),\n    values_column='ct', raster_shape=(FeatureType.MASK, 'IS_VALID'),\n    raster_dtype=np.uint8)\n\nct_export_tiff = ExportToTiff((FeatureType.MASK_TIMELESS, 'CROP_TYPE'))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#reference-map-task","position":25},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Define the workflow","lvl2":"Fill EOPatches with data:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-the-workflow","position":26},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Define the workflow","lvl2":"Fill EOPatches with data:"},"content":"All the tasks that were defined so far create and fill the EOPatches. The tasks need to be put in some order and executed one by one. This can be achieved by manually executing the tasks, or more conveniently, defining an EOWorkflow which does this for you.\n\nThe following workflow is created and executed:\n\nCreate EOPatches with band data\n\nAdd cloud info\n\nCalculate and add NDVI, NDWI, NORM\n\nAdd mask of valid pixels\n\nAdd scalar feature representing the cound of valid pixels\n\nSave eopatches\n\nAn EOWorkflow can be linear or more complex, but it should be acyclic. Here we will use the linear case of the EOWorkflow, available as LinearWorkflow\n\nDefine the workflow\n\n# Define the workflow\nworkflow = LinearWorkflow(\n    add_data,\n    add_clm,\n    ndvi,\n    ndwi,\n    norm,\n    add_sh_valmask,\n    count_val_sh,\n    ct_use_db_task,\n    ct_rasterization_task,\n    ct_export_tiff,\n    save\n)\n\n# Let's visualize it\nworkflow.dependency_graph()\n\nThis may take some time, so go grab a cup of coffee ...\n\n%%time\n\n# Execute the workflow\n\nsource_tiff_location = './source_tiff'\nif not os.path.isdir(source_tiff_location):\n    os.makedirs(source_tiff_location)\n\n# define additional parameters of the workflow\nwith psycopg2.connect(**db_conn_params) as db_conn: # must use single DB connection for all the tasks\n    execution_args = []\n    for idx, bbox in enumerate(bbox_list[patchIDs]):       \n        execution_args.append({\n            add_data: {'bbox': bbox, 'time_interval': selected_date_interval_for_satellite_imagery},\n            ct_use_db_task: {'db_conn': db_conn},\n            ct_export_tiff: {'filename': '{}/crop_type_eopatch_{}_original.tiff'.format(source_tiff_location, idx)},\n            save: {'eopatch_folder': 'eopatch_{}'.format(idx)}\n        })\n\nexecutor = EOExecutor(workflow, execution_args, save_logs=True)\nexecutor.run(workers=9, multiprocess=False)\n\nexecutor.make_report()\n\nIn this case, all patches come from a small region, so all of them have the same dates of acquisition for at least a few dates, so we can inspect the area without interpolation at this point.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-the-workflow","position":27},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Visualize the true color image"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#visualize-the-true-color-image","position":28},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Visualize the true color image"},"content":"\n\n# Draw the RGB image\npath_out = './eopatches_small' if use_smaller_patches else './eopatches_large/'\nfig = plt.figure(figsize=(20, 20 * aspect_ratio))\n\npbar = tqdm(total=9)\nfor i in range(9):\n    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(np.clip(eopatch.data['BANDS'][0][..., [2, 1, 0]] * 3.5, 0, 1))\n    plt.xticks([])\n    plt.yticks([])\n    ax.set_aspect(\"auto\")\n    pbar.update(1)\n    del eopatch\n\nfig.subplots_adjust(wspace=0, hspace=0)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#visualize-the-true-color-image","position":29},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Visualize the reference map"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#visualize-the-reference-map","position":30},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Visualize the reference map"},"content":"\n\npath_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\n\nfig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n\npbar = tqdm(total=9)\nfor i, ax in enumerate(axes.flat):\n    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n    im = ax.imshow(eopatch.mask_timeless['CROP_TYPE'].squeeze(), cmap=ct_cmap, norm=ct_norm)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_aspect(\"auto\")\n    pbar.update(1)\n    del eopatch\n\nfig.subplots_adjust(wspace=0, hspace=0)\n\ncb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\ncb.ax.tick_params(labelsize=20) \ncb.set_ticks([entry.id for entry in CTGROUPS])\ncb.ax.set_xticklabels([entry.class_name for entry in CTGROUPS], rotation=90, fontsize=15)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#visualize-the-reference-map","position":31},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Prepare the training data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#prepare-the-training-data","position":32},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Prepare the training data"},"content":"We will create a new workflow that processes the data:\n\nRemove too cloudy scenes\n\nCheck the ratio of the valid data for each patch and for each time frame\n\nKeep only time frames with > 80 % valid coverage (no clouds)\n\nConcatenate BAND, NDVI, NDWI, NORM info into a single feature called FEATURES\n\nPerform temporal interpolation (filling gaps and resampling to the same dates)\n\nCreate a task for linear interpolation in the temporal dimension\n\nProvide the cloud mask to tell the interpolating function which values to update\n\nPerform erosion\n\nThis removes artefacts with a width of 1 px, and also removes the edges between polygons of different classes\n\nRandom spatial sampling of the EOPatches\n\nRandomly take a subset of pixels from a patch to use in the machine learning training\n\nSplit patches for training/validation\n\nSplit the patches into a training and validation set\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#prepare-the-training-data","position":33},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Define EOTasks","lvl2":"Prepare the training data"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-eotasks","position":34},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Define EOTasks","lvl2":"Prepare the training data"},"content":"\n\nclass ConcatenateData(EOTask):\n    \"\"\" Task to concatenate data arrays along the last dimension\n    \"\"\"\n    def __init__(self, feature_name, feature_names_to_concatenate):\n        self.feature_name = feature_name\n        self.feature_names_to_concatenate = feature_names_to_concatenate\n\n    def execute(self, eopatch):\n        arrays = [eopatch.data[name] for name in self.feature_names_to_concatenate]\n\n        eopatch.add_feature(FeatureType.DATA, self.feature_name, np.concatenate(arrays, axis=-1))\n\n        return eopatch\n    \n    \nclass ValidDataFractionPredicate:\n    \"\"\" Predicate that defines if a frame from EOPatch's time-series is valid or not. Frame is valid, if the \n    valid data fraction is above the specified threshold.\n    \"\"\"\n    def __init__(self, threshold):\n        self.threshold = threshold\n        \n    def __call__(self, array):\n        coverage = np.sum(array.astype(np.uint8)) / np.prod(array.shape)\n        return coverage > self.threshold\n    \n# TASK TO LOAD EXISTING EOPATCHES\nload = LoadTask(path_out)\n\n# TASK FOR CONCATENATION\nconcatenate = ConcatenateData('FEATURES', ['BANDS', 'NDVI', 'NDWI', 'NORM'])\n\n# TASK FOR FILTERING OUT TOO CLOUDY SCENES\n# keep frames with > 80 % valid coverage\nvalid_data_predicate = ValidDataFractionPredicate(0.8)\nfilter_task = SimpleFilterTask((FeatureType.MASK, 'IS_VALID'), valid_data_predicate)\n\n# TASK FOR LINEAR INTERPOLATION\n# linear interpolation of full time-series and date resampling\nselected_date_interval_for_interpolation = selected_date_interval_for_satellite_imagery + [16] \n# TODO: replace fixed number of times with fixed time difference\n#resampled_range = tuple(selected_date_interval_for_satellite_imagery)\nresampled_range = (\n    selected_date_interval_for_interpolation[0].replace(\"-\", \"\"),\n    selected_date_interval_for_interpolation[1].replace(\"-\", \"\"),\n    selected_date_interval_for_interpolation[2]\n)\nlinear_interp = LinearInterpolation(\n    'FEATURES', # name of field to interpolate\n    mask_feature=(FeatureType.MASK, 'IS_VALID'), # mask to be used in interpolation\n    copy_features=[(FeatureType.MASK_TIMELESS, 'CROP_TYPE')], # features to keep\n    resample_range=resampled_range, # set the resampling range\n    bounds_error=False # extrapolate with NaN's\n)\n\n# TASK FOR EROSION\n# erode each class of the reference map\nerosion = ErosionTask(mask_feature=(FeatureType.MASK_TIMELESS,'CROP_TYPE','CROP_TYPE_ERODED'), disk_radius=1)\n\n# TASK FOR SPATIAL SAMPLING\n# Uniformly sample about pixels from patches\nn_samples = int(4e4) if use_smaller_patches else int(1e5) # no. of pixels to sample\nref_labels = list(range(11)) # reference labels to take into account when sampling\nspatial_sampling = PointSamplingTask(\n    n_samples=n_samples, \n    ref_mask_feature='CROP_TYPE_ERODED', \n    ref_labels=ref_labels, \n    sample_features=[  # tag fields to sample\n        (FeatureType.DATA, 'FEATURES'),\n        (FeatureType.MASK_TIMELESS, 'CROP_TYPE_ERODED')\n    ])\n\npath_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\nif not os.path.isdir(path_out_sampled):\n    os.makedirs(path_out_sampled)\nsave = SaveTask(path_out_sampled, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n\n# Define the workflow\nworkflow = LinearWorkflow(\n    load,\n    concatenate,\n    filter_task,\n    linear_interp,\n    erosion,\n    spatial_sampling,\n    save\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-eotasks","position":35},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Run the EOWorkflow over all EOPatches","lvl2":"Prepare the training data"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#run-the-eoworkflow-over-all-eopatches","position":36},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl3":"Run the EOWorkflow over all EOPatches","lvl2":"Prepare the training data"},"content":"\n\n%%time\n   \nexecution_args = []\nfor idx in range(len(patchIDs)):\n    execution_args.append({\n        load: {'eopatch_folder': 'eopatch_{}'.format(idx)},\n        save: {'eopatch_folder': 'eopatch_{}'.format(idx)}\n    })\n    \nexecutor = EOExecutor(workflow, execution_args, save_logs=True)\nexecutor.run(workers=1, multiprocess=True)\n\nexecutor.make_report()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#run-the-eoworkflow-over-all-eopatches","position":37},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Model construction and training"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#model-construction-and-training","position":38},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Model construction and training"},"content":"The patches are split into a train and test subset, where we take the patch with ID = 1 for testing, since it seems a good representative of the area.\n\nThe test sample is hand picked because of the small set of patches, otherwise with a larged overall set, the training and testing patches should be randomly chosen.\n\nThe sampled features and labels are loaded and reshaped into n \\times m, where n represents the number of training pixels, and m = f \\times t the number of all features, with f the size of bands and band combinations (in this example 9) and t the length of the resampled time-series\n\nLightGBM is used as a ML model. It is a fast, distributed, high performance gradient boosting framework based on decision tree algorithms, used for many machine learning tasks.\n\nThe default hyper-parameters are used in this example. For more info on parameter tuning, check the \n\nReadTheDocs of the package.\n\n# load sampled eopatches\neopatches = []\npath_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n\nfor i in range(9):\n    eopatches.append(EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True))    \n\neopatches = np.array(eopatches)\n\n# Definition of the train and test patch IDs\ntrain_ID = [0,2,3,4,5,6,7,8] if use_smaller_patches else [0,1,3,4,5,6,7,8]\ntest_ID = [1] if use_smaller_patches else [2]\n\n# Set the features and the labels for train and test sets\nfeatures_train = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[train_ID]])\nlabels_train = np.array([eopatch.mask_timeless['CROP_TYPE_ERODED_SAMPLED'] for eopatch in eopatches[train_ID]])\nfeatures_test = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[test_ID]])\nlabels_test = np.array([eopatch.mask_timeless['CROP_TYPE_ERODED_SAMPLED'] for eopatch in eopatches[test_ID]])\n\n# get shape\np1, t, w, h, f = features_train.shape\np2, t, w, h, f = features_test.shape\np = p1 + p2\n\n# reshape to n x m\nfeatures_train = np.moveaxis(features_train, 1, 3).reshape(p1 * w * h, t * f)\nlabels_train = np.moveaxis(labels_train, 1, 2).reshape(p1 * w * h, 1).squeeze()\nfeatures_test = np.moveaxis(features_test, 1, 3).reshape(p2 * w * h, t * f)\nlabels_test = np.moveaxis(labels_test, 1, 2).reshape(p2 * w * h, 1).squeeze()\n\n# remove points with no reference from training (so we dont train to recognize \"no data\")\nmask_train = labels_train == 0\nfeatures_train = features_train[~mask_train]\nlabels_train = labels_train[~mask_train]\n\n# remove points with no reference from test (so we dont validate on \"no data\", which doesn't make sense)\nmask_test = labels_test == 0\nfeatures_test = features_test[~mask_test]\nlabels_test = labels_test[~mask_test]\n\n# Set up training classes\nlabels_unique = np.unique(labels_train)\n\n%%time\n\n# Set up training classes\nlabels_unique = np.unique(labels_train)\n\n# Set up the model\nmodel = lgb.LGBMClassifier(\n    objective='multiclass', \n    num_class=len(labels_unique), \n    metric='multi_logloss'\n)\n\n# train the model\nmodel.fit(features_train, labels_train)\n\n# uncomment to save the model\nmodel_base_name = 'model_AT_CT_smaller' if use_smaller_patches else 'model_AT_CT_larger'\njoblib.dump(model, './{}.pkl'.format(model_base_name))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#model-construction-and-training","position":39},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Validation"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#validation","position":40},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Validation"},"content":"\n\nValidation of the model is a crucial step in data science. All models are wrong, but some are less wrong than others, so model evaluation is important.\n\nIn order to validate the model, we use the training set to predict the classes, and then compare the predicted set of labels to the “ground truth”.\n\nUnfortunately, ground truth in the scope of EO is a term that should be taken lightly. Usually, it is not 100 % reliable due to several reasons:\n\nLabels are determined at specific time, but crop types change.\n\nSome classes can have an overlap or similar definitions (part of a continuum, and not discrete distributions)\n\nHuman error (_mistakes made within the decleration)\n\nThe validation is performed by evaluating various metrics, such as accuracy, precision, recall, F_1 score, some of which are nicely described \n\nin this blog post\n\n# uncomment to load the model and replace with your file, usually just correct the date\nmodel_path = './model_AT_CT_smaller.pkl' if use_smaller_patches else './model_AT_CT_larger.pkl'\nmodel = joblib.load(model_path)\n\n# predict the test labels\nplabels_test = model.predict(features_test)\n\nGet the overall accuracy (OA) and the weighted F_1 score\n\nprint('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(labels_test, plabels_test)))\nprint('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(labels_test, plabels_test, average='weighted')))\n\nF_1 score, precision, and recall for each class separately\n\nclass_labels_test = set(np.unique(labels_test))\nclass_labels_train = set(np.unique(labels_train))\nclass_labels = list(class_labels_test.union(class_labels_train))\nclass_names = [entry.class_name for entry in CTGROUPS]\n\nf1_scores = metrics.f1_score(labels_test, plabels_test, labels=class_labels, average=None)\nrecall = metrics.recall_score(labels_test, plabels_test, labels=class_labels, average=None)\nprecision = metrics.precision_score(labels_test, plabels_test, labels=class_labels, average=None) \n\nprint('             Class              =  F1  | Recall | Precision')\nprint('         --------------------------------------------------')\nfor idx, ct in enumerate([class_names[idx] for idx in class_labels]):\n    print('         * {0:30s} = {1:2.1f} |  {2:2.1f}  | {3:2.1f}'.format(ct, \n                                                                         f1_scores[idx] * 100, \n                                                                         recall[idx] * 100, \n                                                                         precision[idx] * 100))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#validation","position":41},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Plot the standard and transposed Confusion Matrix"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#plot-the-standard-and-transposed-confusion-matrix","position":42},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Plot the standard and transposed Confusion Matrix"},"content":"\n\n# Define the plotting function\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues, ylabel='True label', xlabel='Predicted label', filename=None):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    np.set_printoptions(precision=2, suppress=True)\n    \n    if normalize:\n        cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + np.finfo(np.float).eps)\n\n        plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n    plt.title(title, fontsize=20)\n    # plt.colorbar()\n    tick_marks = np.arange(len(classes)+1)-0.5\n    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n    plt.yticks(tick_marks, classes, fontsize=15)\n    \n    \n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\",\n                 fontsize=12)\n\n    plt.tight_layout()\n    plt.ylabel(ylabel, fontsize=15)\n    plt.xlabel(xlabel, fontsize=15)\n\nfig = plt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 1)\nconf_matrix_gbm = metrics.confusion_matrix(labels_test, plabels_test)\nplot_confusion_matrix(conf_matrix_gbm, \n                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n                      normalize=True, \n                      ylabel='Truth (crop type group)', \n                      xlabel='Predicted (GBM)',\n                      title='Confusion matrix');\n\nplt.subplot(1, 2, 2)\nconf_matrix_gbm = metrics.confusion_matrix(plabels_test, labels_test)\nplot_confusion_matrix(conf_matrix_gbm, \n                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n                      normalize=True, \n                      xlabel='Truth (crop type group)', \n                      ylabel='Predicted (GBM)',\n                      title='Transposed Confusion matrix');\n\nplt.tight_layout()\n\nfig = plt.figure(figsize=(20, 5))\nlabel_ids, label_counts = np.unique(labels_train, return_counts=True)\n\nplt.bar(range(len(label_ids)), label_counts/100)\nplt.xticks(range(len(label_ids)), [class_names[i] for i in label_ids], rotation=90, fontsize=20);\nplt.yticks(fontsize=20);\nplt.ylabel(\"Area [ha] \", size=18)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#plot-the-standard-and-transposed-confusion-matrix","position":43},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Predict Crop Type"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#predict-crop-type","position":44},{"hierarchy":{"lvl1":"Part 2: Crop Type prediction with Machine Learning","lvl2":"Predict Crop Type"},"content":"\n\n# Define Tasks\n\nclass PredictPatch(EOTask):\n    \"\"\"\n    Task to make model predictions on a patch. Provide the model and the feature, \n    and the output names of labels and scores (optional)\n    \"\"\"\n    def __init__(self, model, features_feature, predicted_labels_name, predicted_scores_name=None):\n        self.model = model\n        self.features_feature = features_feature\n        self.predicted_labels_name = predicted_labels_name\n        self.predicted_scores_name = predicted_scores_name\n        \n    def execute(self, eopatch):\n        ftrs = eopatch[self.features_feature[0]][self.features_feature[1]]\n        \n        t, w, h, f = ftrs.shape\n        ftrs = np.moveaxis(ftrs, 0, 2).reshape(w * h, t * f)\n        \n        plabels = self.model.predict(ftrs)\n        plabels = plabels.reshape(w, h)\n        plabels = plabels[..., np.newaxis]\n\n        eopatch.add_feature(FeatureType.MASK_TIMELESS, self.predicted_labels_name, plabels)\n        \n        if self.predicted_scores_name:\n            pscores = self.model.predict_proba(ftrs)\n            _, d = pscores.shape\n            pscores = pscores.reshape(w, h, d)\n            eopatch.add_feature(FeatureType.DATA_TIMELESS, self.predicted_scores_name, pscores)\n        \n        return eopatch\n\nclass MaskNoDataInPrediction(EOTask):\n    \"\"\"\n    Mask No Data in prediction\n    \"\"\"\n    \n    def __init__(self, src_layer, no_data_value, predicted_labels_name):\n        self.src_layer = src_layer\n        self.no_data_value = no_data_value\n        self.predicted_labels_name = predicted_labels_name\n    \n    def execute(self, eopatch):\n        NO_DATA = eopatch.mask_timeless[self.src_layer] == self.no_data_value\n        eopatch.mask_timeless[self.predicted_labels_name][NO_DATA] = self.no_data_value\n        \n        return eopatch\n\n# TASK TO LOAD EXISTING EOPATCHES\nload = LoadTask(path_out_sampled)\n\n# TASK FOR PREDICTION\npredict = PredictPatch(model, (FeatureType.DATA, 'FEATURES'), 'LBL_GBM', 'SCR_GBM')\n\n# Mask No Data in Prediction\nmask_no_data = MaskNoDataInPrediction(\"CROP_TYPE\", 0, \"LBL_GBM\")\n\n# TASK FOR SAVING\nsave = SaveTask(str(path_out_sampled), overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n\n# TASK TO EXPORT TIFF\nexport_tiff = ExportToTiff((FeatureType.MASK_TIMELESS, 'LBL_GBM'))\ntiff_location = './predicted_tiff'\nif not os.path.isdir(tiff_location):\n    os.makedirs(tiff_location)\n\nworkflow = LinearWorkflow(\n    load,\n    predict,\n    mask_no_data,\n    export_tiff,\n    save\n)\n\n# create a list of execution arguments for each patch\nexecution_args = []\nfor i in range(len(patchIDs)):\n    execution_args.append(\n        {\n            load: {'eopatch_folder': 'eopatch_{}'.format(i)},\n            export_tiff: {'filename': '{}/prediction_eopatch_{}_original.tiff'.format(tiff_location, i)},\n            save: {'eopatch_folder': 'eopatch_{}'.format(i)}\n        }\n    )\n\n# run the executor on 2 cores\nexecutor = EOExecutor(workflow, execution_args)\n\n# uncomment below save the logs in the current directory and produce a report!\n#executor = EOExecutor(workflow, execution_args, save_logs=True)\n\nexecutor.run(workers=1, multiprocess=False)\nexecutor.make_report()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#predict-crop-type","position":45},{"hierarchy":{"lvl1":"Part 3: Visualize the prediction"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-3-visualize-the-prediction","position":46},{"hierarchy":{"lvl1":"Part 3: Visualize the prediction"},"content":"\n\npath_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n\nfig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n\npbar = tqdm(total=9)\nfor i, ax in enumerate(axes.flat):\n    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True)\n    im = ax.imshow(eopatch.mask_timeless['LBL_GBM'].squeeze(), cmap=ct_cmap, norm=ct_norm)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_aspect(\"auto\")\n    pbar.update(1)\n\nfig.subplots_adjust(wspace=0, hspace=0)\n\ncb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\ncb.ax.tick_params(labelsize=20) \ncb.set_ticks([entry.id for entry in CTGROUPS])\ncb.ax.set_xticklabels([entry.class_name for entry in CTGROUPS], rotation=90, fontsize=15)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-3-visualize-the-prediction","position":47},{"hierarchy":{"lvl1":"Part 3: Visualize the prediction","lvl2":"Visual inspection of patches"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#visual-inspection-of-patches","position":48},{"hierarchy":{"lvl1":"Part 3: Visualize the prediction","lvl2":"Visual inspection of patches"},"content":"Here is just a simple piece of code that allows a closer inspection of the predicted labels.\n\nRandom subsets of patches are chosen, where prediction and ground truth are compared. For visual aid the mask of differences and the true color image are also provided.\n\nIn majority of the cases, differences seem to lie on the border of different structures.\n\n# Draw the Reference map\n\nfig = plt.figure(figsize=(20, 20))\nidx = np.random.choice(range(9))\ninspect_size = 100\n\neopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, idx), lazy_loading=True)\n\nw, h = eopatch.mask_timeless['CROP_TYPE'].squeeze().shape\n\nw_min = np.random.choice(range(w - inspect_size))\nh_min = np.random.choice(range(h - inspect_size))\n\nax = plt.subplot(2, 2, 1)\nplt.imshow(eopatch.mask_timeless['CROP_TYPE'].squeeze()[w_min: w_min + inspect_size, h_min : h_min + inspect_size],\n           cmap=ct_cmap, norm=ct_norm)\nplt.xticks([])\nplt.yticks([])\nax.set_aspect(\"auto\")\nplt.title('Ground Truth', fontsize=20)\n\nax = plt.subplot(2, 2, 2)\nplt.imshow(eopatch.mask_timeless['LBL_GBM'].squeeze()[w_min: w_min + inspect_size, h_min: h_min + inspect_size],\n           cmap=ct_cmap, norm=ct_norm)\nplt.xticks([])\nplt.yticks([])\nax.set_aspect(\"auto\")\nplt.title('Prediction', fontsize=20)\n\nax = plt.subplot(2, 2, 3)\nmask = eopatch.mask_timeless['LBL_GBM'].squeeze() != eopatch.mask_timeless['CROP_TYPE'].squeeze()\nplt.imshow(mask[w_min: w_min + inspect_size, h_min: h_min + inspect_size], cmap='gray')\nplt.xticks([])\nplt.yticks([]);\nax.set_aspect(\"auto\")\nplt.title('Difference', fontsize=20)\n\nax = plt.subplot(2, 2, 4)\nimage = np.clip(eopatch.data['FEATURES'][8][..., [2, 1, 0]] * 3.5, 0, 1)\nplt.imshow(image[w_min: w_min + inspect_size, h_min: h_min + inspect_size])\nplt.xticks([])\nplt.yticks([]);\nax.set_aspect(\"auto\")\nplt.title('True Color', fontsize=20)\n\nfig.subplots_adjust(wspace=0.1, hspace=0.1)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#visual-inspection-of-patches","position":49},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-4-classification-per-lpis-id","position":50},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID"},"content":"Here classification for a specific parcel identified with the unique ID from the OGD Dataset can be carried out.\n\nLPIS reference dates and time intervall for satellite imagery have to correspond to the timestamps used for classification.\n\n# Specify OGD ID\n\nlpis_id = 126939\n\nmodel_path = './model_AT_CT_smaller.pkl'\nmodel = joblib.load(model_path)\n\n\n# LPIS reference date\ndateFilterMin = '2018-06-30'\ndateFilterMax = '2018-06-30'\n\n# Satellite imagery time series\nselected_date_interval_for_satellite_imagery = ['2018-01-01', '2018-09-30']\n\ntarget_crs = CRS.UTM_33N.epsg\ntableName = \"lpis_at\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-4-classification-per-lpis-id","position":51},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl2":"Load Parcel"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#load-parcel","position":52},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl2":"Load Parcel"},"content":"\n\ndef lpis_geom_by_id(tableName, lpis_id, target_crs, dateFilterMin, dateFilterMax):\n\n    with psycopg2.connect(**db_conn_params) as db_conn:\n        sql = '''\n            SELECT \n                ctnuml4a, \n                ST_Transform(geometry, {targetCrs}) as geometry\n            FROM {tableName}\n            WHERE \n                ogd_id = {lpis_id}\n            AND \n                ref_date >= '{dateFilterMin}' \n            AND ref_date <= '{dateFilterMax}'\n            '''\n\n        sql = sql.format(tableName = tableName, \n                         targetCrs = target_crs,\n                         lpis_id = lpis_id,\n                         dateFilterMin = dateFilterMin, \n                         dateFilterMax = dateFilterMax)\n        return gpd.GeoDataFrame.from_postgis(sql, db_conn, geom_col='geometry')\n\n# load parcel\nlpis_df = lpis_geom_by_id(tableName, lpis_id, target_crs, dateFilterMin, dateFilterMax)\n\n# remap ids\nlpis_df[\"ct\"] = lpis_df[\"ctnuml4a\"].apply(lambda x: ctnuml4aToctMapping[x])\n\n# Visualize the parcel shape\nlpis_df.plot()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#load-parcel","position":53},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl2":"Define workflow"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-workflow","position":54},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl2":"Define workflow"},"content":"Workflow for classifiaction of the single parcel:\n\npath_out = './eopatches_lpis'\n\nif not os.path.isdir(path_out):\n    os.makedirs(path_out)\n\nbbox = BBox(lpis_df.iloc[0].geometry.bounds, crs=target_crs)    \nadd_parcel = AddFeature((FeatureType.VECTOR_TIMELESS, \"CROP_TYPE_GDF\"))\nmask_no_data = MaskNoDataInPrediction(\"CROP_TYPE_ERODED\", 0, \"LBL_GBM\")\nerosion = ErosionTask(mask_feature=(FeatureType.MASK_TIMELESS,'CROP_TYPE','CROP_TYPE_ERODED'), disk_radius=1)\npredict = PredictPatch(model, (FeatureType.DATA, 'FEATURES'), 'LBL_GBM', 'SCR_GBM')\nsave = SaveTask(path_out, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n\nworkflow = LinearWorkflow(\n    add_data,\n    add_clm,\n    ndvi,\n    ndwi,\n    norm,\n    add_sh_valmask,\n    add_parcel,\n    ct_rasterization_task,\n    concatenate,\n    filter_task,\n    linear_interp,\n    erosion,\n    predict,\n    mask_no_data,\n    save\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-workflow","position":55},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl2":"Execute workflow"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#execute-workflow","position":56},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl2":"Execute workflow"},"content":"\n\n%%time\n\nexecution_args = []\n\nexecution_args.append({\n    add_data: {'bbox': bbox, 'time_interval': selected_date_interval_for_satellite_imagery},\n    add_parcel: {'data': lpis_df},\n    save: {'eopatch_folder': 'eopatch_{}'.format(lpis_id)}\n})\n    \nexecutor = EOExecutor(workflow, execution_args, save_logs=True)\nexecutor.run(workers=1, multiprocess=True)\n\nexecutor.make_report()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#execute-workflow","position":57},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl2":"Classification Result"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#classification-result","position":58},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl2":"Classification Result"},"content":"\n\neopatch = EOPatch.load('./eopatches_lpis/eopatch_{}'.format(lpis_id))\n\nfig = plt.figure(figsize=(10, 10))\nimage = np.clip(eopatch.data['FEATURES'][8][..., [2, 1, 0]] * 3.5, 0, 1)\nplt.imshow(image)\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#classification-result","position":59},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl3":"Declaration","lvl2":"Classification Result"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#declaration","position":60},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl3":"Declaration","lvl2":"Classification Result"},"content":"\n\nfig = plt.figure(figsize=(10, 10))\nplt.imshow(eopatch.mask_timeless['CROP_TYPE_ERODED'].squeeze(), cmap=ct_cmap, norm=ct_norm)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#declaration","position":61},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl3":"Prediction","lvl2":"Classification Result"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#prediction","position":62},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl3":"Prediction","lvl2":"Classification Result"},"content":"\n\nfig = plt.figure(figsize=(10, 10))\naxes = plt.gca()\n\n\nim = plt.imshow(eopatch.mask_timeless['LBL_GBM'].squeeze(), cmap=ct_cmap, norm=ct_norm)\nplt.xticks([])\nplt.yticks([])\n\n\ncb = fig.colorbar(im, ax=axes, orientation='horizontal', pad=0.01, aspect=100)\ncb.ax.tick_params(labelsize=20) \ncb.set_ticks([entry.id for entry in CTGROUPS])\ncb.ax.set_xticklabels([entry.class_name for entry in CTGROUPS], rotation=90, fontsize=15)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#prediction","position":63},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl3":"Accuracy of classification","lvl2":"Classification Result"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#accuracy-of-classification","position":64},{"hierarchy":{"lvl1":"Part 4: Classification per LPIS ID","lvl3":"Accuracy of classification","lvl2":"Classification Result"},"content":"\n\nmask = (eopatch.mask_timeless['CROP_TYPE_ERODED'] != 0).squeeze()\n\nREF = eopatch.mask_timeless['CROP_TYPE'].squeeze()[mask]\nLBL_GBM = eopatch.mask_timeless['LBL_GBM'].squeeze()[mask]\n\n# classification is class with most pixels\nunique = np.unique(LBL_GBM, return_counts=True)\nclassification_id = unique[0][unique[1].argmax()]\n\n# remap to original id\nclassification_id_mapped = ctToctnuml4aMapping[classification_id][0]\n\n# precentage of pixels in prediction classified same as lpis\naccuracy = sum(REF == LBL_GBM) / len(LBL_GBM)\n\nprint(\"Parcel with ID {} classified as class {} with an accuracy of {:.2%}\".format(lpis_id, classification_id_mapped, accuracy))\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#accuracy-of-classification","position":65},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-5-persist-classification-results-in-database","position":66},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#part-5-persist-classification-results-in-database","position":67},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl2":"Add the model configuration to the db"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#add-the-model-configuration-to-the-db","position":68},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl2":"Add the model configuration to the db"},"content":"\n\nmodel_name = \"default_3x3_noe\"\n\nmodel_config = {\n\n  \"reference\": {\n      \"table\": \"lpis_at\",\n      \"column\": \"ctnuml4a\",\n      \n  },\n    \n  \"classifiier\": \"lgbm\",\n    \n  \"model_parameters\":\n    {\n      \"boosting_type\": \"gbdt\",\n      \"num_leaves\": 31, \n      \"max_depth\": -1, \n      \"learning_rate\": 0.1\n    },\n    \n  \"valid_data_threshold\": 0.8,\n    \n  \"interpolation_range\": {\n    \"start\": \"2018-01-01\",\n    \"end\": \"2018-09-30\",\n    \"interval\": 16\n  },\n    \n  \"erosion_radius\": 1,\n    \n  \"features\": \n  [\n    \"B02\",\n    \"B03\",\n    \"B04\",\n    \"B08\",\n    \"B11\",\n    \"B12\",\n    \"NDVI\",\n    \"NDWI\",\n    \"NORM\"\n  ],\n    \n  \"training_bounds\": bounds\n}\n\ninsert_model = \"\"\"\nINSERT INTO model_at (name, ref_date, training_time, configuration)\nVALUES (\n    '{model_name}', \n    '2018-06-30', \n        (\n            SELECT CURRENT_TIMESTAMP\n        ),\n    '{config}'\n        \n    ); \n\"\"\".format(\n    config = str(model_config).replace(\"'\", \"\\\"\"),\n    model_name = model_name\n)\n\nwith psycopg2.connect(**db_conn_params) as db_conn:\n    with db_conn.cursor() as cur:\n        cur.execute(insert_model)\n        db_conn.commit()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#add-the-model-configuration-to-the-db","position":69},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl2":"Add all classification results for parcels within definded bounds"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#add-all-classification-results-for-parcels-within-definded-bounds","position":70},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl2":"Add all classification results for parcels within definded bounds"},"content":"\n\n# change this bounding box depending on where the classification should be carried out\nbounds_for_classification = bounds\nmodel_name = \"default_3x3_noe\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#add-all-classification-results-for-parcels-within-definded-bounds","position":71},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"EOTasks","lvl2":"Add all classification results for parcels within definded bounds"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#eotasks","position":72},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"EOTasks","lvl2":"Add all classification results for parcels within definded bounds"},"content":"\n\nclass AddPredictionToDatabase(EOTask):\n    def __init__(self, ref_date, model_id, target_table, db_conn_params):\n        self.ref_date = ref_date\n        self.model_id = model_id\n        self.target_table = target_table\n        self.db_conn_params = db_conn_params\n\n        \n    def execute(self, eopatch, parcel_id):\n        \n        mask = (eopatch.mask_timeless['CROP_TYPE_ERODED'] != 0).squeeze()\n\n        # scores per pixel\n        scores_pixel = eopatch.data_timeless[\"SCR_GBM\"][mask]\n\n        # averaged scores for each class form pixels to parcel\n        scores_parcel = np.nanmean(scores_pixel, axis=0)\n\n        # ranking\n        ranking = np.argsort(scores_parcel)\n\n        # probabilities ordered descending by ranking\n        scores_parcel = scores_parcel[ranking][::-1]\n\n        # ranked classes ordered descending by ranking\n        classes_parcel = model.classes_[ranking[::-1]]\n\n        # mapped back to original\n        classes_parcel_original = np.vectorize(lambda x: ctToctnuml4aMapping[x][0])(classes_parcel)\n        \n        prediction = [\n            dict(\n                crop_id=crop_id, \n                probability=round(probability, 2) if not np.isnan(probability) else 0\n            )\n\n            for crop_id, probability in zip(classes_parcel_original, scores_parcel)\n        ]\n        \n        \n        sql = \"\"\"\n        INSERT INTO {target_table} (parcel_id, ref_date, model_id, prediction)\n        VALUES (\n             {parcel_id}, \n            '{ref_date}', \n             {model_id},\n            '{prediction}'\n            )\n            \n        -- skip existing entries\n        ON CONFLICT DO NOTHING \n        ; \n        \"\"\"\n\n        sql = sql.format(\n            target_table = self.target_table,\n            parcel_id = parcel_id,\n            ref_date = self.ref_date,\n            model_id = self.model_id,\n            prediction = str(prediction).replace(\"'\", \"\\\"\")\n        )\n        with psycopg2.connect(**self.db_conn_params) as db_conn:\n            with db_conn.cursor() as cur:\n                cur.execute(sql)\n                db_conn.commit()\n                \n        return eopatch\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#eotasks","position":73},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"Get Model ID","lvl2":"Add all classification results for parcels within definded bounds"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#get-model-id","position":74},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"Get Model ID","lvl2":"Add all classification results for parcels within definded bounds"},"content":"\n\nsql = \"SELECT id from model_at where name = '{}';\".format(model_name)\n\nwith psycopg2.connect(**db_conn_params) as db_conn:\n    with db_conn.cursor() as cur:\n        cur.execute(sql)\n        model_id = cur.fetchall()[0][0]\n        \nprint(\"model_id: \", model_id)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#get-model-id","position":75},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"Define workflow","lvl2":"Add all classification results for parcels within definded bounds"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-workflow-1","position":76},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"Define workflow","lvl2":"Add all classification results for parcels within definded bounds"},"content":"\n\nclassification_to_db = AddPredictionToDatabase('2018-06-30', model_id, 'classification_at', db_conn_params)\nadd_parcel = AddFeature((FeatureType.VECTOR_TIMELESS, \"CROP_TYPE_GDF\"))\nmask_no_data = MaskNoDataInPrediction(\"CROP_TYPE_ERODED\", 0, \"LBL_GBM\")\npredict = PredictPatch(model, (FeatureType.DATA, 'FEATURES'), 'LBL_GBM', 'SCR_GBM')\n\nworkflow = LinearWorkflow(\n    add_data,\n    add_clm,\n    ndvi,\n    ndwi,\n    norm,\n    add_sh_valmask,\n    add_parcel,\n    ct_rasterization_task,\n    concatenate,\n    filter_task,\n    linear_interp,\n    erosion,\n    predict,\n    mask_no_data,\n    classification_to_db\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#define-workflow-1","position":77},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"List of parcels to process","lvl2":"Add all classification results for parcels within definded bounds"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#list-of-parcels-to-process","position":78},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"List of parcels to process","lvl2":"Add all classification results for parcels within definded bounds"},"content":"\n\nwith psycopg2.connect(**db_conn_params) as db_conn:\n\n    sql = '''\n    SELECT\n        ogd_id,\n        {column},\n        ST_Transform(geometry, {targetCrs}) as geometry\n\n    FROM\n        {tableName}\n    WHERE\n        ref_date >= '{dateFilterMin}'\n    AND \n        ref_date <= '{dateFilterMax}'\n    AND\n        ST_INTERSECTS(\n            ST_Transform(geometry, 4326),\n            ST_SetSRID(\n                ST_MakeBox2D(\n                        ST_Point({min_x}, {min_y}),\n                        ST_Point({max_x}, {max_y})\n                ),\n                4326\n            )\n        );\n    '''\n\n    sql = sql.format(tableName = model_config[\"reference\"][\"table\"],\n                     column = model_config[\"reference\"][\"column\"],\n                     targetCrs = target_crs,\n                     dateFilterMin = dateFilterMin, \n                     dateFilterMax = dateFilterMax,\n                     min_x = bounds_for_classification[0],\n                     min_y = bounds_for_classification[1],\n                     max_x = bounds_for_classification[2],\n                     max_y = bounds_for_classification[3],\n                    )\n    \n    parcels_to_process = gpd.GeoDataFrame.from_postgis(sql, db_conn, geom_col='geometry', )\n\n\n# remap id\nparcels_to_process[\"ct\"] = parcels_to_process[\"ctnuml4a\"].apply(lambda x: ctnuml4aToctMapping[x])\n\nparcels_to_process\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#list-of-parcels-to-process","position":79},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"Execute workflow","lvl2":"Add all classification results for parcels within definded bounds"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#execute-workflow-1","position":80},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl3":"Execute workflow","lvl2":"Add all classification results for parcels within definded bounds"},"content":"classification data is added to the database\n\nexecution_args = []\n\nfor i in range(len(parcels_to_process)):\n    \n    # Data Frame for current parcel\n    parcel_df = parcels_to_process[parcels_to_process.index == i]\n    parcel = parcel_df.iloc[0]\n    \n    bbox = BBox(parcel.geometry.bounds, crs=target_crs)    \n\n    execution_args.append({\n        add_data: {'bbox': bbox, 'time_interval': selected_date_interval_for_satellite_imagery},\n        add_parcel: {'data': parcel_df},\n        classification_to_db: {'parcel_id': int(parcel.ogd_id)}\n    })\n\n\nexecutor = EOExecutor(workflow, execution_args, save_logs=True)\nexecutor.run(workers=1, multiprocess=False)\n\nexecutor.make_report()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#execute-workflow-1","position":81},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl2":"Show classification results"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#show-classification-results","position":82},{"hierarchy":{"lvl1":"Part 5: Persist classification results in database","lvl2":"Show classification results"},"content":"First 20 classified parcels within the defined bounding box\n\n\nwith psycopg2.connect(**db_conn_params) as db_conn:\n    with db_conn.cursor() as cur:\n\n        sql = '''\n            SELECT \n                parcel_id,\n                ref_date,\n                model_id,\n                prediction -> 0,\n                prediction -> 1,\n                prediction -> 2\n            FROM classification_at\n            WHERE\n                model_id = {model_id} AND\n                ref_date = '2018-06-30'\n            LIMIT 20\n        '''.format(model_id=model_id)\n\n        cur.execute(sql)\n        result = cur.fetchall()\n\npd.DataFrame(result, columns=[\"ogd_id\", \"ref_date\", \"model_id\", \"1st_classification\", \"2nd_classification\", \"3rd_classification\"])","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification#show-classification-results","position":83},{"hierarchy":{"lvl1":"xcube-gen and xcube-geodb Hands-On Workshop Φ-Week 2020"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2","position":0},{"hierarchy":{"lvl1":"xcube-gen and xcube-geodb Hands-On Workshop Φ-Week 2020"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2022.02\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2","position":1},{"hierarchy":{"lvl1":"xcube-gen and xcube-geodb Hands-On Workshop Φ-Week 2020"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#xcube-gen-and-xcube-geodb-hands-on-workshop-week-2020","position":2},{"hierarchy":{"lvl1":"xcube-gen and xcube-geodb Hands-On Workshop Φ-Week 2020"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#xcube-gen-and-xcube-geodb-hands-on-workshop-week-2020","position":3},{"hierarchy":{"lvl1":"xcube-gen and xcube-geodb Hands-On Workshop Φ-Week 2020","lvl2":"Alicja Balfanz and Helge Dzierzon from Brockmann Consult"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#alicja-balfanz-and-helge-dzierzon-from-brockmann-consult","position":4},{"hierarchy":{"lvl1":"xcube-gen and xcube-geodb Hands-On Workshop Φ-Week 2020","lvl2":"Alicja Balfanz and Helge Dzierzon from Brockmann Consult"},"content":"\n\nIn this Notebook we present how to:\n\nAccess data via xcube-sh with a short excursion to the xcube Generator User Interface\n\nUse xcube-geodb\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#alicja-balfanz-and-helge-dzierzon-from-brockmann-consult","position":5},{"hierarchy":{"lvl1":"1) Data access via xcube-sh"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#id-1-data-access-via-xcube-sh","position":6},{"hierarchy":{"lvl1":"1) Data access via xcube-sh"},"content":"\n\nPlease Note!\n\nThe following example shows the use of xcube and xcube Generator User Interface by accissing Sentinel-2 data from SentinelHub. However, SentinelHub is not the only available source!\nCurrently there are three Datastores accessible:\n\nClimate Data Store\n\nSENTINEL Hub\n\nESA CCI Open Data Portal\n\nStep 1: Import packages for xcube-sh\n\n# xcube_sh imports\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\n\n# various utilities\nimport json\nimport xarray as xr\nimport shapely.geometry\nimport IPython.display\nimport zarr\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')\n\n%matplotlib inline\n\nStep 2: Setting CubeConfig parameters for generating S2 cubes\n\ndataset_name = 'S2L2A' # dataset name\nband_names = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B08', 'SCL', 'CLD'] # band names\ntile_size = [500, 500] # tile size \n# geometry (bounding box for the area covering Hamburg)\nx1 = 9.86\ny1 = 53.45\nx2 = 10.14\ny2 = 53.62\nbbox = x1, y1, x2, y2\nspatial_res = 0.00018 # spatial resolution (approx. 20 m in degree)\ntime_tolerance='2H'\n\nA description about the dataset and the bands may be found here: \n\nhttps://​docs​.sentinel​-hub​.com​/api​/latest​/data​/sentinel​-2​-l2a/ .\n\nStep 3: Setting cube configurations for 2018 summer season (May - August)\n\ncube_config_2018 = CubeConfig(dataset_name = dataset_name,\n                              band_names = band_names,\n                              tile_size = tile_size, \n                              bbox = bbox,\n                              spatial_res = spatial_res,\n                              time_range = ['2018-05-01', '2018-08-31'],\n                              time_tolerance = time_tolerance)\n\nStep 4: View bounding box to check seleceted area\n\nIPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)\n\nStep 5: Open data cube\n\ncube_S2_2018 = open_cube(cube_config_2018)\ncube_S2_2018\n\nStep 6: Plot a single scene for a specific timestamp and band\n\ncube_S2_2018.B04.sel(time='2018-07-25 12:00:00', method='nearest').plot.imshow(vmin=0, vmax=0.2, cmap='Greys_r', figsize=(14, 10))\n\nStep 7: Plot a timeseries for a certain location\n\ncube_S2_2018.B04.sel(lat=53.56, lon=10.00, method='nearest').plot()\n\nIf one wants a subest, e.g. because the region of interest is smaler, this can be achieved by using xcube python api:\n\n# xcube imports\nfrom xcube.core.compute import compute_cube\nfrom xcube.core.maskset import MaskSet\nfrom xcube.core.geom import mask_dataset_by_geometry\nfrom xcube.core.geom import clip_dataset_by_geometry\n\nThere are two ways of selecting the area of interest:\n\nBy masking - this keeps only the data of the WKT Polygon or shapefile\n\nBy clipping - this creates a new bounding box, which ensures that the area of interest is within the subset but keeps the surrounding data (this is commented out in the following cells)\n\n# Great tool to quickly generate WKT Polygons: https://arthur-e.github.io/Wicket/sandbox-gmaps3.html\npolygon = \"POLYGON((9.994461289534694 53.580963332925194,10.0002977763511 53.57280950628081,9.995147935042507 53.5625130540729,9.987766495833522 53.55374380185022,9.993946305403835 53.55088830422569,10.002529374251491 53.5553754282651,10.016605607161647 53.56190130476089,10.018493882308132 53.568528117753054,10.00853752244485 53.57535774603685,10.016090623030788 53.578211592240635,10.013000718245632 53.579740359179034,10.00682090867532 53.579230776342285,10.003387681136257 53.58249200035297,9.994461289534694 53.580963332925194))\"\n\ncube_S2_2018_masked = mask_dataset_by_geometry(cube_S2_2018, geometry=polygon)\n# cube_S2_2018_clipped = clip_dataset_by_geometry(cube_S2_2018, geometry=polygon)\n\ncube_S2_2018_masked\n# cube_S2_2018_clipped\n\ncube_S2_2018_masked.B04.sel(time='2018-07-25 12:00:00', method='nearest').plot.imshow(vmin=0, vmax=0.2, cmap='Greys_r', figsize=(14, 10))\n# cube_S2_2018_clipped.B04.sel(time='2018-07-25 12:00:00', method='nearest').plot.imshow(vmin=0, vmax=0.2, cmap='Greys_r', figsize=(14, 10))\n\nSave cube as zarr:\n\n# cube_S2_2018_masked.to_zarr('Alster_cube_2018_masked.zarr')\n# cube_S2_2018_clipped.to_zarr('Alster_cube_2018.zarr')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#id-1-data-access-via-xcube-sh","position":7},{"hierarchy":{"lvl1":"How to generate a datacube with the help of xcube Generator user interface"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#how-to-generate-a-datacube-with-the-help-of-xcube-generator-user-interface","position":8},{"hierarchy":{"lvl1":"How to generate a datacube with the help of xcube Generator user interface"},"content":"\n\nThis section is not hands-on!\n\nIf you want to check out the xcube Generator yourself later, please take a look at the \n\nxcube Generator User Guide to give you more detail.\n\nOpen a cube from s3 bucket:The below cell shows how to open a generated datacube which is stored in a public bucket with the help of xcube\n\nfrom xcube.core.dsio import open_cube\ncube = open_cube('https://s3.eu-central-1.amazonaws.com/edc-phi-week-2020/xcube-gen-1b11e7c1-94f9-4246-833e-a2a12d301a3e.zarr', \n                 s3_kwargs={\n                     'anon': True\n                 })\n\ncube\n\nOpen a cube stored loccaly, here in the workspace:\n\n#cube = xr.open_zarr('Alster_cube_2018.zarr')\n\nDiscover, which flags are available within the datacube:\n\nmask = MaskSet(cube.SCL)\nmask\n\nmask.clouds_high_probability\n\nMake a datacube with all clouds masked out:\n\ncube_wo_clouds = cube.where(np.logical_not(mask.cloud_shadows | mask.snow_or_ice | \n                                           mask.saturated_or_defective | mask.cirrus | \n                                           mask.clouds_low_probability_or_unclassified | \n                                           mask.clouds_medium_probability | mask.clouds_high_probability))\n\nKeep only the waterbodies of the datacube:\n\ncube_water_wo_clouds = cube_wo_clouds.where(mask.water)\n\nIf you want to take a look at the water mask, please uncomment the following line:\n\n# mask.water.sel(time='2018-07-20 12:00:00', method='nearest').plot.imshow(figsize=(14, 10))\n\nTake a look at a time stamp without any masking:\n\ncube.B04.sel(time='2018-07-19 12:00:00', method='nearest').plot.imshow(vmin=0, vmax=0.2, cmap='Greys_r', figsize=(14, 10))\n\nTake a look at a time stamp of the waterbodies and all clouds masked out:\n\ncube_water_wo_clouds.B04.sel(time='2018-07-19 12:00:00', method='nearest').plot.imshow(vmin=0, vmax=.2, figsize=(14, 10))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#how-to-generate-a-datacube-with-the-help-of-xcube-generator-user-interface","position":9},{"hierarchy":{"lvl1":"2) Using the xcube-geodb"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#id-2-using-the-xcube-geodb","position":10},{"hierarchy":{"lvl1":"2) Using the xcube-geodb"},"content":"The xcube-geodb consists of a Restful service and a Python client. Let’s import the Python dependencies to access the geodb service.\n\nStep 1: Import the geodb client\n\nfrom xcube_geodb.core.geodb import GeoDBClient\n\nStep 2: Instantiate the client\n\ngeodb = GeoDBClient()\n\nStep 3: As a subscriber a user name is associated with you. Check your user name.\n\ngeodb.whoami\n\nStep 4: Let’s see what collections you have access to\n\nds = geodb.get_my_collections()\nds\n\nStep 5: In the next step you will create a collection. The properties are defined using OGC standards for properties. However, types are given using postgresql types.\n\ngeodb.drop_collection(\"alster\")\n\ncollections = {\n        \"alster\": \n        {\n            \"crs\": 4326,\n            \"properties\": \n            {\n                \"date\": \"date\", \n                \"chl\": \"float\",\n                \"chl_min\": \"float\",\n                \"chl_max\": \"float\",\n                \"status\": \"text\"\n            }\n        }\n    }\n\n\ngeodb.create_collections(collections)\n\nStep 6: Let’s check whether the collection has been created\n\nds = geodb.get_my_collections()\nds\n\nStep 7: No collection is useful without data. We have created a sample dataset for you which you no load from an S3 AWS object store and open it into a GeoDataFrame. The data is obtained from a local water authority (HU).\n\nimport geopandas\nimport pandas\ngdf = geopandas.read_file('https://edc-phi-week-2020.s3.eu-central-1.amazonaws.com/hands-on/alster.geojson')\ngdf = gdf.where(pandas.notnull(gdf), None)\ngdf\n\ngdf=gdf.dropna()\n\ngeodb.insert_into_collection('alster', gdf)\n\nStep 8: Load the inserted data from the geoDB\n\n# geodb.get_collection('alster', database='phi_week')\n\ngdf = geodb.get_collection('alster')\ngdf['date'] = pandas.to_datetime(gdf['date'])\ngdf\n\nfeat = gdf['geometry'][0]\n\nStep 9: Combine data from Sentinel\n\ncube_S2_2018['B3o1'] = cube_S2_2018.B03/ cube_S2_2018.B01\ncube_S2_2018['B3o2'] = cube_S2_2018.B03/ cube_S2_2018.B02\ncube_S2_2018\n\ncube_S2_2018_point_low = cube_S2_2018.where((cube_S2_2018.B3o1 < 10) & (cube_S2_2018.SCL==6)).sel(lat=feat.y, lon=feat.x, method='nearest')\ncube_S2_2018_point_high = cube_S2_2018.where((cube_S2_2018.B3o2 < 10) & (cube_S2_2018.SCL==6)).sel(lat=feat.y, lon=feat.x, method='nearest')\n\nStep 10: Group point time series data by date\n\nagg = gdf.query(\"date >= '2018-05-01' and date <= '2018-09-01'\").groupby(['date']).mean()\nagg\n\nStep 11: Plot result\n\nimport matplotlib.pyplot as plt\n\nfig, ax1 = plt.subplots(constrained_layout=True, figsize=(10, 10))\nax1.set_ylabel('Sentinel 2 colour ratio', color='red')  \nax1.plot(cube_S2_2018_point_low.time, cube_S2_2018_point_low.B3o1.values, label = \"B3o1\", color='red', marker='.', linestyle = 'None', markersize=10)\nax1.plot(cube_S2_2018_point_high.time, cube_S2_2018_point_high.B3o2.values, label = \"B3o2\", color='red', marker='.', linestyle = 'None', markersize=10)\n\nax2 = ax1.twinx()  \nax2.plot(agg.index, agg.chl_max, label = \"Chlorophyll max. (tot) [µg/l]\", color='green', marker='.', linestyle = 'None',  markersize=10)\nax2.set_ylabel('in-situ chl max', color='green')  \n\n\nfig.legend()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-demo-phi-week-v2#id-2-using-the-xcube-geodb","position":11},{"hierarchy":{"lvl1":"EDC Sentinel Hub - data access using xcube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration","position":0},{"hierarchy":{"lvl1":"EDC Sentinel Hub - data access using xcube"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration","position":1},{"hierarchy":{"lvl1":"EDC Sentinel Hub - data access using xcube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration#edc-sentinel-hub-data-access-using-xcube","position":2},{"hierarchy":{"lvl1":"EDC Sentinel Hub - data access using xcube"},"content":"This notebook shows the various ways to open data cubes from Sentinel Hub (SH) for a given time range, region, and spatial resolution:\n\nA temporarily regular Sentinel-2 cube with aggregated observations that fall into equal-size time periods;\n\nA NDVI time series\n\nA custom collection (CORINE)\n\n# xcube_sh imports\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.observers import Observers\nfrom xcube_sh.sentinelhub import SentinelHub\nfrom xcube_sh.viewer import ViewerServer\n\n# xcube imports\nfrom xcube.core.maskset import MaskSet\nfrom xcube.core.geom import mask_dataset_by_geometry\nfrom xcube.core.geom import clip_dataset_by_geometry\n\n# Various utilities\nimport json\nimport matplotlib\nimport pandas as pd\nimport numpy as np\nimport xarray as xr\nimport shapely.geometry\nimport IPython.display\nimport zarr\nfrom io import StringIO\n\n%matplotlib inline\n\n# Oslo\nx1 = 10.5  # degree\ny1 = 59.85  # degree\nx2 = 11.25  # degree\ny2 = 60.05  # degree\n\nbbox = x1, y1, x2, y2\n\nVisualize the bounding box.\n\nIPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)\n\nLater in this NB we are going to compute some indexes from bands atmospherically corrected bands B04, B05, B06, B11 of Sentinel-2 (S2L2A)\nOur time range covers two and a half month of last year’s summer: 2018-05-14 to 2018-07-31\n\nThe desired resolution is roughly 20 meters per pixel:\n\nspatial_res = 0.00018   # = 20.038 meters in degree>\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration#edc-sentinel-hub-data-access-using-xcube","position":3},{"hierarchy":{"lvl1":"Example 1: Visualizing a band"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration#example-1-visualizing-a-band","position":4},{"hierarchy":{"lvl1":"Example 1: Visualizing a band"},"content":"Sentinel-2 L2A with aggregated observations that fall into equal-size time_period of 2 days:\n\ncube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B04', 'B05', 'B08', 'B11', 'SCL', 'CLD'],\n                         tile_size=[512, 512],\n                         bbox=bbox,\n                         spatial_res=spatial_res,\n                         time_range=['2018-05-14', '2018-07-31'],\n                         time_period='2D')\n\nWe define a request_collector as an observer for SH requests made, so we can show SH usage stats. This is a developer tool, useful for demonstration purposes too. Otherwise, this is not needed.\n\nrequest_collector = Observers.request_collector()\n\nOpen a data cube:\n\ncube = open_cube(cube_config, observer=request_collector)\ncube\n\nNo requests have been made yet. Requests are made only if data is actually required.\n\nrequest_collector.stats\n\nNote, the cube’s time coordinates are monotonically increasing and the distance between two time steps is varying:\n\ncube.time.diff(dim='time').plot.line()\n\ncube.B04\n\ncube.B04.isel(time=3).plot(figsize=[15,6], vmax=0.2);\n\nNow SentinelHub data requests have been made\n\nrequest_collector.stats\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration#example-1-visualizing-a-band","position":5},{"hierarchy":{"lvl1":"Example 2: Visualizing a NDVI time series"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration#example-2-visualizing-a-ndvi-time-series","position":6},{"hierarchy":{"lvl1":"Example 2: Visualizing a NDVI time series"},"content":"\n\ncube.SCL\n\nmasked = cube.where(np.logical_or(cube.SCL < 8, cube.SCL > 10)) # clouds\nndvi = (masked.B08 - masked.B04)/(masked.B08 + masked.B04)\n# agricultural area near Oslo\nndvi.sel(lat=59.979800, lon=10.982700, method=\"nearest\").plot.line()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration#example-2-visualizing-a-ndvi-time-series","position":7},{"hierarchy":{"lvl1":"Example 3: CORINE"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration#example-3-corine","position":8},{"hierarchy":{"lvl1":"Example 3: CORINE"},"content":"The \n\nCORINE collection is available on the CREODIAS deployment of Sentinel Hub.\n\nCorine land cover nomenclature\n\ncube_config = CubeConfig(collection_id = \"cbdba844-f86d-41dc-95ad-b3f7f12535e9\",\n                         tile_size=[512, 512],\n                         bbox=bbox,\n                         spatial_res=spatial_res*5, # 100m\n                         time_range=[\"1990-01-01\", \"2018-12-31\"],\n                         time_period=None\n)\ncorine = open_cube(cube_config, api_url=\"https://creodias.sentinel-hub.com\")  # \n\ncorine.CLC\n\ndf = pd.read_csv(StringIO(\"\"\"\nvalue,color_code,label\n1,#e6004d,111 - Continuous urban fabric\n2,#ff0000,112 - Discontinuous urban fabric\n3,#cc4df2,121 - Industrial or commercial units\n4,#cc0000,122 - Road and rail networks and associated land\n5,#e6cccc,123 - Port areas\n6,#e6cce6,124 - Airports\n7,#a600cc,131 - Mineral extraction sites\n8,#a64d00,132 - Dump sites\n9,#ff4dff,133 - Construction sites\n10,#ffa6ff,141 - Green urban areas\n11,#ffe6ff,142 - Sport and leisure facilities\n12,#ffffa8,211 - Non-irrigated arable land\n13,#ffff00,212 - Permanently irrigated land\n14,#e6e600,213 - Rice fields\n15,#e68000,221 - Vineyards\n16,#f2a64d,222 - Fruit trees and berry plantations\n17,#e6a600,223 - Olive groves\n18,#e6e64d,231 - Pastures\n19,#ffe6a6,241 - Annual crops associated with permanent crops\n20,#ffe64d,242 - Complex cultivation patterns\n21,#e6cc4d,243 - Land principally occupied by agriculture with significant areas of natural vegetation\n22,#f2cca6,244 - Agro-forestry areas\n23,#80ff00,311 - Broad-leaved forest\n24,#00a600,312 - Coniferous forest\n25,#4dff00,313 - Mixed forest\n26,#ccf24d,321 - Natural grasslands\n27,#a6ff80,322 - Moors and heathland\n28,#a6e64d,323 - Sclerophyllous vegetation\n29,#a6f200,324 - Transitional woodland-shrub\n30,#e6e6e6,331 - Beaches - dunes - sands\n31,#cccccc,332 - Bare rocks\n32,#ccffcc,333 - Sparsely vegetated areas\n33,#000000,334 - Burnt areas\n34,#a6e6cc,335 - Glaciers and perpetual snow\n35,#a6a6ff,411 - Inland marshes\n36,#4d4dff,412 - Peat bogs\n37,#ccccff,421 - Salt marshes\n38,#e6e6ff,422 - Salines\n39,#a6a6e6,423 - Intertidal flats\n40,#00ccf2,511 - Water courses\n41,#80f2e6,512 - Water bodies\n42,#00ffa6,521 - Coastal lagoons\n43,#a6ffe6,522 - Estuaries\n44,#e6f2ff,523 - Sea and ocean\n48,#ffffff,999 - NODATA\n\"\"\"))\ncmap, norm = matplotlib.colors.from_levels_and_colors(df.value.values, df.color_code.values, extend=\"max\")\n\nimgplot = corine.CLC.isel(time=3).plot.imshow(\n    figsize=[10,6], cbar_kwargs={\"orientation\":\"horizontal\"}, vmin=df.value.min(), vmax=df.value.max(), norm=norm\n);\nimgplot.set_cmap(cmap)\nimgplot.colorbar.set_ticks(df.value, labels = df.label, horizontalalignment=\"left\", rotation=300)\n\ncorine.CLC.sel(lat=59.979800, lon=10.982700, method=\"nearest\").plot.line()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/fairicube/fairicube-data-access-demonstration#example-3-corine","position":9},{"hierarchy":{"lvl1":"<b>Urban delineation<b>"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation","position":0},{"hierarchy":{"lvl1":"<b>Urban delineation<b>"},"content":"from eoxhub import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"GEODB\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation","position":1},{"hierarchy":{"lvl1":"Urban delineation"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#urban-delineation","position":2},{"hierarchy":{"lvl1":"Urban delineation"},"content":"This notebook implements a GHSL settlement model algorithm as defined by the stage I of the Degree of Urbanisation (European Commission & Statistical Office of the European Union, 2021) and recommended by the UN STAT COM.\nModel uses the population and built-up surface grid - European Commission, Joint Research Centre (JRC)\nThe method here implemented is described in detail bellow.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#urban-delineation","position":3},{"hierarchy":{"lvl1":"Urban delineation","lvl2":" GHSL - settlement model "},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#ghsl-settlement-model","position":4},{"hierarchy":{"lvl1":"Urban delineation","lvl2":" GHSL - settlement model "},"content":"Delineate and classify settlement by typologies\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#ghsl-settlement-model","position":5},{"hierarchy":{"lvl1":"Urban delineation","lvl2":"Setlment L1 nomenclature:"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#setlment-l1-nomenclature","position":6},{"hierarchy":{"lvl1":"Urban delineation","lvl2":"Setlment L1 nomenclature:"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#setlment-l1-nomenclature","position":7},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Urban Centre - High Density Cluster (HDC)","lvl2":"Setlment L1 nomenclature:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#urban-centre-high-density-cluster-hdc","position":8},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Urban Centre - High Density Cluster (HDC)","lvl2":"Setlment L1 nomenclature:"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#urban-centre-high-density-cluster-hdc","position":9},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Urban Cluster - Moderate Density Cluster (MDC)","lvl2":"Setlment L1 nomenclature:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#urban-cluster-moderate-density-cluster-mdc","position":10},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Urban Cluster - Moderate Density Cluster (MDC)","lvl2":"Setlment L1 nomenclature:"},"content":"\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#urban-cluster-moderate-density-cluster-mdc","position":11},{"hierarchy":{"lvl1":"Urban delineation","lvl2":"Setlment L2 nomenclature:"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#setlment-l2-nomenclature","position":12},{"hierarchy":{"lvl1":"Urban delineation","lvl2":"Setlment L2 nomenclature:"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#setlment-l2-nomenclature","position":13},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Urban Centre - High Density Cluster (HDC)","lvl2":"Setlment L2 nomenclature:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#urban-centre-high-density-cluster-hdc-1","position":14},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Urban Centre - High Density Cluster (HDC)","lvl2":"Setlment L2 nomenclature:"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#urban-centre-high-density-cluster-hdc-1","position":15},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Dense Urban Cluster (DUC)","lvl2":"Setlment L2 nomenclature:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#dense-urban-cluster-duc","position":16},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Dense Urban Cluster (DUC)","lvl2":"Setlment L2 nomenclature:"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#dense-urban-cluster-duc","position":17},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"SemiDense Urban Cluster (SDUC)","lvl2":"Setlment L2 nomenclature:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#semidense-urban-cluster-sduc","position":18},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"SemiDense Urban Cluster (SDUC)","lvl2":"Setlment L2 nomenclature:"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#semidense-urban-cluster-sduc","position":19},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Peri-Urban Cluster (PUC)","lvl2":"Setlment L2 nomenclature:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#peri-urban-cluster-puc","position":20},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Peri-Urban Cluster (PUC)","lvl2":"Setlment L2 nomenclature:"},"content":"\n\n\n\n\nGHSL data packages for settlement model:\n\nbuilt-up:\n\n\nhttps://​ghsl​.jrc​.ec​.europa​.eu​/download​.php​?ds​=bu\n\npopulation:\n\n\nhttps://​ghsl​.jrc​.ec​.europa​.eu​/download​.php​?ds​=​pop\n\n\nReference years: from 1975 to 2020, 5 years interval\nResolution: 1km\nCoord. system: Mollweide\nComplete information about GHSL open data are available at:\n\n\nhttps://​ghsl​.jrc​.ec​.europa​.eu​/documents​/GHSL​_Data​_Package​_2022​.pdf​?t​=​1655995832\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#peri-urban-cluster-puc","position":21},{"hierarchy":{"lvl1":"Urban delineation","lvl2":"Parameters by definition of GHSL settlement model L1 and L2"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#parameters-by-definition-of-ghsl-settlement-model-l1-and-l2","position":22},{"hierarchy":{"lvl1":"Urban delineation","lvl2":"Parameters by definition of GHSL settlement model L1 and L2"},"content":"Threshold for total population per square kilometer : HDC_Pdens / MDC_Pdens\n\nThreshold for population per cluster : HDC_Pmin / MDC_Pmin\n\nThreshold for % of built-up area : HDC_Bdens\n\nCluster connectivity : HDC_Tcon / MDC_Tcon\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#parameters-by-definition-of-ghsl-settlement-model-l1-and-l2","position":23},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Constants : Pdens, Bdens, Pmin, Tcon","lvl2":"Parameters by definition of GHSL settlement model L1 and L2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#constants-pdens-bdens-pmin-tcon","position":24},{"hierarchy":{"lvl1":"Urban delineation","lvl3":"Constants : Pdens, Bdens, Pmin, Tcon","lvl2":"Parameters by definition of GHSL settlement model L1 and L2"},"content":"\n\n# local population density (HDC: 1500 people/km2, MDC: 300 people/km2)\nHDC_Pdens=1500\nMDC_Pdens =300\n\n# built-up area share > then\nHDC_Bdens=500000 # (share of built-up area/km2: 0.5 => 500000 m2/km2)\n\n# cluster populatin > then   (HDC: 50000 people, MDC: 5000 people)\nHDC_Pmin=50000\nMDC_Pmin=5000\n\n# connectivity clusters\n# Tcon=1 for 4-connectivity clusters, Tcon=2 for 8-connectivity clusters\nHDC_Tcon=1 \nMDC_Tcon=2 \n\n# gap filling (<15km2)\nHDC_GAPfill=15\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#constants-pdens-bdens-pmin-tcon","position":25},{"hierarchy":{"lvl1":"Urban delineation","lvl2":"Load libraries:"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#load-libraries","position":26},{"hierarchy":{"lvl1":"Urban delineation","lvl2":"Load libraries:"},"content":"\n\nfrom xcube.core.store import new_data_store\n\nimport os\nfrom glob import glob\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport geopandas as gpd\nfrom shapely.geometry import shape, box\n\nimport xarray as xr\nimport rioxarray as rxr\n\nimport rasterio\nimport rasterio.features\nfrom rasterio.features import shapes\n\nfrom skimage import measure, morphology\nfrom skimage.morphology import square\nimport scipy\n\nimport ipywidgets as widgets\nimport matplotlib.pyplot as plt\n\nimport folium\nfrom folium import plugins\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#load-libraries","position":27},{"hierarchy":{"lvl1":"Select reference year and area of interest: "},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#select-reference-year-and-area-of-interest","position":28},{"hierarchy":{"lvl1":"Select reference year and area of interest: "},"content":"Before starts, the reference year and the area of interest needs to be defined.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#select-reference-year-and-area-of-interest","position":29},{"hierarchy":{"lvl1":"Select reference year and area of interest: ","lvl2":"Reference year "},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#reference-year","position":30},{"hierarchy":{"lvl1":"Select reference year and area of interest: ","lvl2":"Reference year "},"content":"\n\n# Select reference year:\n# from 1975 to 2020, 5 years interval:\n# valid values are: 1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015, 2020\n\nREFyear=2020\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#reference-year","position":31},{"hierarchy":{"lvl1":"Select reference year and area of interest: ","lvl2":"Area of interest "},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#area-of-interest","position":32},{"hierarchy":{"lvl1":"Select reference year and area of interest: ","lvl2":"Area of interest "},"content":"\n\n# Select AOI by lat/lon coordinates -  example for area of Poland, Czechia and Slovakia:\nx1 = 10  # degree (E-W)\ny1 = 47 # degree (N-S)\nx2 = 25  # degree (E-W)\ny2 = 55 # degree (N-S)\n\naoi_centre = [(y2+y1)/2,(x2+x1)/2]\nprint(aoi_centre)\n\nbbox = x1, y1, x2, y2\nprint(bbox)\n\ngeom = box(*bbox)\nAOI = gpd.GeoDataFrame({\"id\":1,\"geometry\":[geom]})\nAOI.set_crs(epsg=4326, inplace=True)  # WGS84\nAOI54009 = AOI.to_crs(crs='ESRI:54009')\n\nfrom branca.element import Figure\nfig = Figure(width=600, height=600)\n\nm = folium.Map(aoi_centre, zoom_start=5, tiles='cartodbpositron')  # ,width=500, height=500\nlat_interval = 1\nlon_interval = 1\n\n# parallels:\nfor lat in range(-90, 91, lat_interval):\n     folium.PolyLine([[lat, -180],[lat, 180]], weight=0.5).add_to(m)\n# meridianss:\nfor lon in range(-180, 181, lon_interval):\n    folium.PolyLine([[-90, lon],[90, lon]], weight=0.5).add_to(m)\n\nAOI54009.explore(m=m,style_kwds=dict(color='blue',fillColor='None', opacity=0.7))\nfig.add_child(m)\nm\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#area-of-interest","position":33},{"hierarchy":{"lvl1":"Input data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#input-data","position":34},{"hierarchy":{"lvl1":"Input data"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#input-data","position":35},{"hierarchy":{"lvl1":"Input data","lvl2":"Open GHS built-up surface"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#open-ghs-built-up-surface","position":36},{"hierarchy":{"lvl1":"Input data","lvl2":"Open GHS built-up surface"},"content":"\n\nBTU_data_store = new_data_store(\"s3\", root=\"xcube-dcfs/GHSL/GHS-BUILT-S/\",\n                            storage_options=dict(anon=True) # anon=True - anonymous access (default False)\n                           )\n\nBTU_data_store_info = list(BTU_data_store.get_data_ids())\nBTU_data_store_info\n\n# Select built-up data for Reference year\nBTU_REFyear= '\\n'.join(s for s in BTU_data_store_info if str(REFyear) in s)\n# BTU_REFyear\n\n# Info about built-up data for Reference year\nBTU_data_store.describe_data(BTU_REFyear).to_dict()\n\n# # Info about population data for Reference year\n# print(BTU_data_store.open_data(BTU_REFyear).num_levels, '\\n')\n# print(BTU_data_store.open_data(BTU_REFyear).datasets, '\\n')\n# BTU_data_store.open_data(BTU_REFyear).grid_mapping\n\nlevel = 0   # this is the highest resolution, which corresponds to 1km\n\n# Build-up dataset for selected Reference year - clipped by AOI\nBTU_ds_0 = BTU_data_store.open_data(BTU_REFyear).get_dataset(level).rio.clip(AOI54009.geometry, AOI54009.crs)\nBTU_ds_0 = BTU_ds_0.rename({\"band_1\": \"built-up\"})\n#BTU_ds_0\n\n# # Info AOI coordinates in the world projection Mollweide (ESRI:54009)\n# print(BTU_ds_0.x.min().values, BTU_ds_0.x.max().values)\n# print(BTU_ds_0.y.min().values, BTU_ds_0.y.max().values)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#open-ghs-built-up-surface","position":37},{"hierarchy":{"lvl1":"Input data","lvl2":"Open GHS population grid"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#open-ghs-population-grid","position":38},{"hierarchy":{"lvl1":"Input data","lvl2":"Open GHS population grid"},"content":"\n\nPOP_data_store = new_data_store(\"s3\", \n                            root=\"xcube-dcfs/GHSL/GHS-POP/\",\n                            storage_options=dict(anon=True)\n                           )\n\nOP_data_store info:\n\nPOP_data_store_info=list(POP_data_store.get_data_ids())\nPOP_data_store_info\n\n# Select population data for Reference year\nPOP_REFyear= '\\n'.join(s for s in POP_data_store_info if str(REFyear) in s)\n#POP_REFyear\n\n# Info about built-up data for Reference year\nPOP_data_store.describe_data(POP_REFyear).to_dict()\n\n# # Info about population data for Reference year\n# print(POP_data_store.open_data(POP_REFyear).num_levels, '\\n')\n# print(POP_data_store.open_data(POP_REFyear).datasets, '\\n')\n# POP_data_store.open_data(POP_REFyear).grid_mapping\n\nlevel = 0   # this is the highest resolution, which corresponds to 1km\n\n# Population dataset  for selected Reference year - clipped by AOI\nPOP_ds_0 = POP_data_store.open_data(POP_REFyear).get_dataset(level).rio.clip(AOI54009.geometry, AOI54009.crs)\nPOP_ds_0 = POP_ds_0.rename({\"band_1\": \"population_grid\"})\n#POP_ds_0\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#open-ghs-population-grid","position":39},{"hierarchy":{"lvl1":"Input data","lvl2":"Dataset to DataArray"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#dataset-to-dataarray","position":40},{"hierarchy":{"lvl1":"Input data","lvl2":"Dataset to DataArray"},"content":"\n\nBTU_da=(BTU_ds_0['built-up']).squeeze()\nBTU_da = BTU_da.load()\nBTU_da=BTU_da.where(BTU_da != BTU_da.attrs['_FillValue']).fillna(0)\nBTU_da\n\nPOP_da=(POP_ds_0['population_grid']).squeeze()\nPOP_da = POP_da.load()\nPOP_da=POP_da.where(POP_da != POP_da.attrs['_FillValue']).fillna(0)\nPOP_da\n\n# # Info about  DataArray\n# print(type(POP_da),'\\n')\n# print(type(POP_da.data))\n# print(POP_da.name), print()\n# print(\"The shape of data is:\\n\", POP_da.shape,'\\n')\n# print(POP_da.coords), print()\n# print(\"the minimum raster value is:\\n\", np.nanmin(POP_da.values))\n# print(\"the maximum raster value is:\\n\", np.nanmax(POP_da.values),'\\n')\n# print('dim:',POP_da.dims,'\\n')\n# print('attributes/metadata:\\n',POP_da.attrs,'\\n')\n# print('----------------')\n# # View generate metadata associated with the raster file\n# # World Mollweide  ESRI:54009, \n# print(\"The crs of data is:\\n\", POP_da.rio.crs,'\\n')\n# print('transform:\\n',POP_da.rio.transform(),'\\n')\n# print(\"The spatial extent is:\\n\", POP_da.rio.bounds(),'\\n')\n# print(\"The nodatavalue of data is:\\n\", POP_da.rio.nodata,'\\n')\n# print(\"The spatial resolution of data is:\\n\", POP_da.rio.resolution(),'\\n')\n\n# print(BTU_da.data.min(), BTU_da.data.max())\n# print(POP_da.data.min(), POP_da.data.max().round(0))\n# POP_da.data\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#dataset-to-dataarray","position":41},{"hierarchy":{"lvl1":"L1: Urban Centre (HDC) and Urban Cluster (MDC)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l1-urban-centre-hdc-and-urban-cluster-mdc","position":42},{"hierarchy":{"lvl1":"L1: Urban Centre (HDC) and Urban Cluster (MDC)"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l1-urban-centre-hdc-and-urban-cluster-mdc","position":43},{"hierarchy":{"lvl1":"L1: Urban Centre (HDC) and Urban Cluster (MDC)","lvl2":"step1: built-up and population data - binary masks  by model definition"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step1-built-up-and-population-data-binary-masks-by-model-definition","position":44},{"hierarchy":{"lvl1":"L1: Urban Centre (HDC) and Urban Cluster (MDC)","lvl2":"step1: built-up and population data - binary masks  by model definition"},"content":"\n\n# HDC\n# built-up area\nHDC_BTU_mask = 1 * np.ones_like(BTU_da) * (BTU_da > HDC_Bdens).astype(np.int8)  # HDC_Bdens (share of built-up area/km2: 0.5 => 500000 m2/km2)\n# population\nHDC_POP_mask = 1 * np.ones_like(POP_da) * (POP_da > HDC_Pdens).astype(np.int8) # HDC_Pdens >=1500 inh/km2\nHDC_UC01_mask = HDC_BTU_mask + HDC_POP_mask\n\n# MDC\nMDC_POP_mask = 1 * np.ones_like(POP_da) * (POP_da > MDC_Pdens).astype(np.int8) # MDC_Pdens >=300  inh/km2\n\n# BINARY MASK:\nHDC_UC01_mask = 1 * np.ones_like(HDC_UC01_mask) * (HDC_UC01_mask> 0).astype(np.int8)\nMDC_UC01_mask = MDC_POP_mask\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step1-built-up-and-population-data-binary-masks-by-model-definition","position":45},{"hierarchy":{"lvl1":"L1: Urban Centre (HDC) and Urban Cluster (MDC)","lvl2":"step2: cluster connectivity"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step2-cluster-connectivity","position":46},{"hierarchy":{"lvl1":"L1: Urban Centre (HDC) and Urban Cluster (MDC)","lvl2":"step2: cluster connectivity"},"content":"https://​scikit​-image​.org​/docs​/dev​/api​/skimage​.measure​.html​#skimage​.measure​.label\n\n# 4/8-connectivity regions:\n# HDC_Tcon=1 for 4-connectivity clusters\n# MDC_Tcon=2 for 8-connectivity clusters\n\nHDC_UC02_4conn = measure.label(HDC_UC01_mask, background=0, return_num=False, connectivity=HDC_Tcon)\n# print('HDC number of regions:', HDC_UC02_4conn.max())\n\nMDC_UC02_8conn = measure.label(MDC_UC01_mask, background=0, return_num=False, connectivity=MDC_Tcon)\n# print('MDC number of regions:', MDC_UC02_8conn.max())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step2-cluster-connectivity","position":47},{"hierarchy":{"lvl1":"L1: Urban Centre (HDC) and Urban Cluster (MDC)","lvl2":"step3: total population in cluster"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step3-total-population-in-cluster","position":48},{"hierarchy":{"lvl1":"L1: Urban Centre (HDC) and Urban Cluster (MDC)","lvl2":"step3: total population in cluster"},"content":"\n\nHDC_UC03=np.zeros_like(HDC_POP_mask).astype('int')\n\nPOPregionIDsum=[]\nPOPregionSUM=[]\nfor regionID in range(1, HDC_UC02_4conn.max()):\n    POPregionID=((HDC_UC02_4conn == regionID).astype('int')) * POP_da.data    \n    # threshold for population in cluster > 50000\n    if POPregionID.sum() > HDC_Pmin:\n        POPregionSUM.append(int(round(POPregionID.sum())))\n        POPregionIDsum.append(regionID)\n        HDC_UC03=HDC_UC03+np.where(HDC_UC02_4conn == regionID, HDC_UC02_4conn, 0)\n\nMDC_UC03=np.zeros_like(MDC_POP_mask).astype('int')\n\nPOPregionIDsum=[]\nPOPregionSUM=[]\nfor regionID in range(1, MDC_UC02_8conn.max()):\n    POPregionID=((MDC_UC02_8conn == regionID).astype('int')) * POP_da.data    \n    # threshold for population in cluster > 5000\n    if POPregionID.sum() > MDC_Pmin:\n        POPregionSUM.append(int(round(POPregionID.sum())))\n        POPregionIDsum.append(regionID)\n        MDC_UC03=MDC_UC03+np.where(MDC_UC02_8conn == regionID, MDC_UC02_8conn, 0)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step3-total-population-in-cluster","position":49},{"hierarchy":{"lvl1":"L1: Urban Center (HDC)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l1-urban-center-hdc","position":50},{"hierarchy":{"lvl1":"L1: Urban Center (HDC)"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l1-urban-center-hdc","position":51},{"hierarchy":{"lvl1":"L1: Urban Center (HDC)","lvl2":"step4: Urban Centre (HDC) - gaps filling < 15km2"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step4-urban-centre-hdc-gaps-filling-15km2","position":52},{"hierarchy":{"lvl1":"L1: Urban Center (HDC)","lvl2":"step4: Urban Centre (HDC) - gaps filling < 15km2"},"content":"\n\ninverse raster / gaps\n\nHDC_UC03_BIN=np.where(HDC_UC03 > 0, 1, 0)\nHDC_UC03_INV=np.where(HDC_UC03_BIN == 1, 0, 1)\n\nHDC_UC03_INV = measure.label(HDC_UC03_INV, background=0, connectivity=2) # 8-connectivity\n# number of holes\n# HDC_UC03_INV.max()\n\ngaps filling\n\nunique, counts = np.unique(HDC_UC03_INV, return_counts=True,)\ngaps=list(zip(unique, counts)) \n#print(gaps)\n\nfor gap in gaps:\n    if gap[1] < HDC_GAPfill:\n        gapID=(HDC_UC03_INV == gap[0]).astype(int)        \n        HDC_UC03_BIN=HDC_UC03_BIN+gapID\n\nregions where POP > 50000 with filled gaps < 15km2\n\nHDC_UC03_4conn = measure.label(HDC_UC03_BIN, background=0, connectivity=HDC_Tcon)  # connectivity=HDC_Tcon\nprint(HDC_UC03_4conn.min(),HDC_UC03_4conn.max())\n\n# binary raster\nHDC_UC04_BIN=np.where(HDC_UC03_4conn >= 1, 1, 0)\nprint(HDC_UC04_BIN.sum())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step4-urban-centre-hdc-gaps-filling-15km2","position":53},{"hierarchy":{"lvl1":"L1: Urban Center (HDC)","lvl2":"step5: Urban Centre (HDC) - morphology"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step5-urban-centre-hdc-morphology","position":54},{"hierarchy":{"lvl1":"L1: Urban Center (HDC)","lvl2":"step5: Urban Centre (HDC) - morphology"},"content":"\n\nclosing, erosion, dilatation\n\nHDC_UC04=np.zeros_like(HDC_UC03_BIN).astype('int')\n# regiony sa vyhodnocuju sekvencne v cykle:\nPOPregionIDsum=[]\nPOPregionSUM=[]\nfor regionID in range(1, HDC_UC03_4conn.max()):\n    # mask 0-1 for region, # POP in region\n    POPregionID=((HDC_UC03_4conn == regionID).astype('int'))  \n    #print(POPregionID.min(), POPregionID.max(), POPregionID.sum())\n    POPregionID = morphology.binary_closing(POPregionID, square(3))\n    POPregionID= morphology.binary_dilation(POPregionID)\n    POPregionID= morphology.binary_erosion(POPregionID)\n    #POPregionID = skimage.morphology.binary_closing(POPregionID, square(3))\n    HDC_UC04=HDC_UC04+POPregionID\n    #print(HDC_UC05.sum())\n\n# gaps filling after morphology:\nHDC_UC04_INV=np.where(HDC_UC04 == 1, 0, 1)\nHDC_UC04_INV = measure.label(HDC_UC04_INV, background=0, connectivity=2)\n# number of holes\nHDC_UC04_INV.max()\n\nunique1, counts1 = np.unique(HDC_UC04_INV, return_counts=True,)\ngaps1 = [x for x in zip(unique1, counts1) if x[1] < HDC_GAPfill]\n#print(gaps1)\n\nfor gap1 in gaps1:\n    gapID1=(HDC_UC04_INV == gap1[0]).astype(int)\n    HDC_UC04=HDC_UC04+gapID1\n\nHDC_UC04_4conn = measure.label(HDC_UC04, background=0, connectivity=HDC_Tcon)\nHDC_UC04_4conn.max()\n\n# binary raster\nHDC_UC04_4conn_BIN=np.where(HDC_UC04_4conn >= 1, 1, 0)\nHDC_UC04_4conn_BIN.sum()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step5-urban-centre-hdc-morphology","position":55},{"hierarchy":{"lvl1":"L1: Urban Cluster (MDC)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l1-urban-cluster-mdc","position":56},{"hierarchy":{"lvl1":"L1: Urban Cluster (MDC)"},"content":"\n\n# binary\nMDC_UC03=np.where(MDC_UC03 > 0, 1, 0)\n# \nMDC_UC04=MDC_UC03-HDC_UC04\nMDC_UC04=np.where(MDC_UC04 == 1, 1, 0)\n\nMDC_UC04_8conn = measure.label(MDC_UC04, background=0, connectivity=MDC_Tcon)\nprint(MDC_UC04_8conn.min(),MDC_UC04_8conn.max())\n\nHDC and MDC to vector\n\nHDC:  numpy.ndarray to DataArray\n\nHDC_UC05 = xr.DataArray(\n    data=HDC_UC04_4conn,\n    dims=BTU_da.dims,\n    coords=BTU_da.coords,\n    name='urban_centre',\n    )\n\nHDC_UC05=HDC_UC05.astype(np.int16)\nHDC_UC05\n\n# # Info about HDC DataArray\n# print('type:',type(HDC_UC05))\n# print('name:',HDC_UC05.name)\n# print('shape:',HDC_UC05.shape)\n# #print(HDC_UC05.coords)\n# print('dim:',HDC_UC05.dims,'\\n')\n# # World Mollweide  ESRI:54009\n# print(\"The crs is: \", HDC_UC05.rio.crs)\n# print('transform: ',HDC_UC05.rio.transform())\n# print(\"The spatial extent is: \", HDC_UC05.rio.bounds())\n# print(\"The nodatavalue of data is: \", HDC_UC05.rio.nodata)\n# print(\"The shape of data is: \", HDC_UC05.shape)\n# print(\"The spatial resolution of data is: \", HDC_UC05.rio.resolution())\n# print(\"the minimum raster value is: \", np.nanmin(HDC_UC05.values))\n# print(\"the maximum raster value is: \", np.nanmax(HDC_UC05.values))\n# print(\"The metadata of data is: \", HDC_UC05.attrs)\n\nHDC: export to vector\n\n# mask=None\nmask=HDC_UC05.data != 0\nwith HDC_UC05 as src:\n    image = src.data # first band\n    results = (\n    {'properties': {'raster_val': v}, 'geometry': s}\n    for i, (s, v) \n    in enumerate(\n        shapes(image, mask=mask, connectivity=4, transform=HDC_UC05.rio.transform())))\n\ngeoms = list(results)\n# first feature\n# print(geoms[0])\n\nHDC_UrbanCentre  = gpd.GeoDataFrame.from_features(geoms)\nHDC_UrbanCentre.crs=HDC_UC05.rio.crs\nHDC_UrbanCentre.raster_val=HDC_UrbanCentre.raster_val.astype('int')\nHDC_UrbanCentre.rename(columns={'raster_val':'hdcid'}, inplace=True)\nHDC_UrbanCentre['area_km2'] = HDC_UrbanCentre['geometry'].area/ 10**6\nHDC_UrbanCentre['code']=3\nHDC_UrbanCentre.sort_values(['area_km2'],ascending=False).head(3)\n\nMDC:  numpy.ndarray to DataArray\n\nMDC_UC05 = xr.DataArray(\n    data=MDC_UC04_8conn,\n    dims=BTU_da.dims,\n    coords=BTU_da.coords,\n    name='urban_cluster',\n    )\n\nMDC_UC05=MDC_UC05.astype(np.int16)\nMDC_UC05\n\n# # BASIC INFO\n# print('type:',type(MDC_UC05))\n# print('name:',MDC_UC05.name)\n# print('shape:',MDC_UC05.shape)\n# #print(MDC_UC05.coords)\n# print('dim:',MDC_UC05.dims,'\\n')\n# # View generate metadata associated with the raster file\n# # World Mollweide  ESRI:54009\n# print(\"The crs is: \", MDC_UC05.rio.crs)\n# print('transform: ',MDC_UC05.rio.transform())\n# print(\"The spatial extent is: \", MDC_UC05.rio.bounds())\n# print(\"The nodatavalue of data is: \", MDC_UC05.rio.nodata)\n# print(\"The shape of data is: \", MDC_UC05.shape)\n# print(\"The spatial resolution of data is: \", MDC_UC05.rio.resolution())\n# print(\"the minimum raster value is: \", np.nanmin(MDC_UC05.values))\n# print(\"the maximum raster value is: \", np.nanmax(MDC_UC05.values))\n# print(\"The metadata of data is: \", MDC_UC05.attrs,'\\n')\n# print(MDC_UC05.data.max())\n\nMDC: export to vector\n\n# mask=None\nmask=MDC_UC05.data != 0\nwith MDC_UC05 as src:\n    image = src.data # first band\n    results = (\n    {'properties': {'raster_val': v}, 'geometry': s}\n    for i, (s, v) \n    in enumerate(\n        shapes(image, mask=mask, connectivity=8, transform=MDC_UC05.rio.transform())))\n\ngeoms = list(results)\n\nMDC_UrbanCluster  = gpd.GeoDataFrame.from_features(geoms)\nMDC_UrbanCluster.crs=MDC_UC05.rio.crs\nMDC_UrbanCluster.raster_val=MDC_UrbanCluster.raster_val.astype('int')\nMDC_UrbanCluster.rename(columns={'raster_val':'mdcid'}, inplace=True)\nMDC_UrbanCluster[\"area_km2\"] = MDC_UrbanCluster['geometry'].area/ 10**6\nMDC_UrbanCluster['code']=2\nMDC_UrbanCluster.sort_values(['area_km2'],ascending=False).head(3)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l1-urban-cluster-mdc","position":57},{"hierarchy":{"lvl1":"HDC and MDC export to shapefiles"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#hdc-and-mdc-export-to-shapefiles","position":58},{"hierarchy":{"lvl1":"HDC and MDC export to shapefiles"},"content":"\n\n# Create folder for GHSL_results, if it doesn't exist:\nPath(os.path.realpath('GHSL_results')).mkdir(parents=True, exist_ok=True) \n\n# EXPORT 2 shapefile World Mollweide (ESRI:54009)\nHDC_UrbanCentre.to_file(os.path.join(os.path.realpath('GHSL_results'),'HDC_UrbanCentre_'+str(REFyear)+'.shp'))\n# Export to shapefile WGS84 (EPSG:4326 )\n# HDC_UrbanCentre.to_crs(epsg=4326).to_file(os.path.join(os.path.realpath('GHSL_results'),'HDC_UrbanCentre_4326_'+str(REFyear)+'.shp'))\n\n# EXPORT 2 shapefile World Mollweide (ESRI:54009)\nMDC_UrbanCluster.to_file(os.path.join(os.path.realpath('GHSL_results'),'MDC_UrbanCluster_'+str(REFyear)+'.shp'))\n# Export to shapefile WGS84 (EPSG:4326 )\n# MDC_UrbanCentre.to_crs(epsg=4326).to_file(os.path.join(os.path.realpath('GHSL_results'),'MDC_UrbanCluster_4326_'+str(REFyear)+'.shp'))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#hdc-and-mdc-export-to-shapefiles","position":59},{"hierarchy":{"lvl1":"L1: Visualization of results"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l1-visualization-of-results","position":60},{"hierarchy":{"lvl1":"L1: Visualization of results"},"content":"\n\nfig = Figure(width=600, height=600)\n\nm = AOI54009.explore(style_kwds={'fillColor':'None','color':'blue','weight': 1}, name='aoi')\n\n# parallels:\nfor lat in range(-90, 91, lat_interval):\n     folium.PolyLine([[lat, -180],[lat, 180]], weight=0.5).add_to(m)\n# meridianss:\nfor lon in range(-180, 181, lon_interval):\n    folium.PolyLine([[-90, lon],[90, lon]], weight=0.5).add_to(m)\n\nMDC_UrbanCluster.explore(m=m,style_kwds={'fillColor':'orange','color':'orange','weight': 1}, name='MDC_UrbanCluster')\nHDC_UrbanCentre.explore(m=m,style_kwds={'fillColor':'red','color':'red','weight': 1.5}, name='HDC_UrbanCentre')\n\nfolium.LayerControl('topright',collapsed=True).add_to(m)\nminimap = plugins.MiniMap(height=90, width=90, zoom_level_offset=-7)\nm.add_child(minimap)\n\nfig.add_child(m)\nm\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l1-visualization-of-results","position":61},{"hierarchy":{"lvl1":"L2: Dense Urban Cluster (DUC), Semi-Dense Urban Cluster (SDUC) and  Peri-Urban Cluster (PUC)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l2-dense-urban-cluster-duc-semi-dense-urban-cluster-sduc-and-peri-urban-cluster-puc","position":62},{"hierarchy":{"lvl1":"L2: Dense Urban Cluster (DUC), Semi-Dense Urban Cluster (SDUC) and  Peri-Urban Cluster (PUC)"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l2-dense-urban-cluster-duc-semi-dense-urban-cluster-sduc-and-peri-urban-cluster-puc","position":63},{"hierarchy":{"lvl1":"step1: Dense Urban Cluster (DUC)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step1-dense-urban-cluster-duc","position":64},{"hierarchy":{"lvl1":"step1: Dense Urban Cluster (DUC)"},"content":"\n\n# MASK\nDUC_mask=HDC_UC01_mask  \n#print(DUC_mask.sum())\n\n# CONNECTIVITY\nDUC_4conn = measure.label(DUC_mask, background=0, return_num=False, connectivity=HDC_Tcon) #.squeeze()\nprint('DUC number of regions:', DUC_4conn.max())\n\n# TOTAL POPULATION IN CLUSTER\nDUC_UC03=np.zeros_like(HDC_POP_mask).astype('int')\n\nPOPregionIDsum=[]\nPOPregionSUM=[]\nfor regionID in range(1, DUC_4conn.max()):\n    POPregionID=((DUC_4conn == regionID).astype('int')) * POP_da.data    \n    # threshold for population in cluster > 5000\n    if POPregionID.sum() > MDC_Pmin:\n        POPregionSUM.append(int(round(POPregionID.sum())))\n        POPregionIDsum.append(regionID)\n        DUC_UC03=DUC_UC03+np.where(DUC_4conn == regionID, DUC_4conn, 0)\n\n\n\n# SUBTRACTION OF HDC\nDUC_UC03_BIN=np.where(DUC_UC03 > 0, 1, 0)\nDUC_UC03_BIN=DUC_UC03_BIN-HDC_UC04_4conn_BIN\nDUC_UC03_BIN=np.where(DUC_UC03_BIN >0, 1, 0)\nprint(DUC_UC03_BIN.sum())\n\n# CONNECTIVITY\nDUC_UC04_4conn = measure.label(DUC_UC03_BIN, background=0, connectivity=HDC_Tcon)  # connectivity=HDC_Tcon\nprint(DUC_UC04_4conn.min(),DUC_UC04_4conn.max())\n\n# BINARY MASK\nDUC_UC04_4conn_BIN=np.where(DUC_UC04_4conn > 0, 1, 0)\nDUC_UC04_4conn_BIN.sum()\n\nDUC:  numpy.ndarray to DataArray\n\nDUC_UC05 = xr.DataArray(\n    data=DUC_UC04_4conn,\n    dims=BTU_da.dims,\n    coords=BTU_da.coords,\n    name='dense_urban_cluster',\n    )\n\nDUC_UC05=DUC_UC05.astype(np.int16)\nDUC_UC05\n\nDUC: export to vector\n\n# mask=None\nmask=DUC_UC05.data != 0\nwith DUC_UC05 as src:\n    image = src.data # first band\n    results = (\n    {'properties': {'raster_val': v}, 'geometry': s}\n    for i, (s, v) \n    in enumerate(\n        shapes(image, mask=mask, connectivity=4, transform=DUC_UC05.rio.transform())))\n\ngeoms = list(results)\n\nDUC_DenseUrbanCluster  = gpd.GeoDataFrame.from_features(geoms)\nDUC_DenseUrbanCluster.crs=DUC_UC05.rio.crs\nDUC_DenseUrbanCluster.raster_val=DUC_DenseUrbanCluster.raster_val.astype('int')\nDUC_DenseUrbanCluster.rename(columns={'raster_val':'ducid'}, inplace=True)\nDUC_DenseUrbanCluster['code']=23\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step1-dense-urban-cluster-duc","position":65},{"hierarchy":{"lvl1":"step2: Semi-Dense Urban Cluster (SDUC)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step2-semi-dense-urban-cluster-sduc","position":66},{"hierarchy":{"lvl1":"step2: Semi-Dense Urban Cluster (SDUC)"},"content":"\n\n# MASK\nSDUC_mask=MDC_UC01_mask \nprint(DUC_mask.sum())\n\n# CONNECTIVITY\nSDUC_8conn = measure.label(SDUC_mask, background=0, return_num=False, connectivity=MDC_Tcon) # 8-connectivity cluster\nprint('SDUC number of regions:', SDUC_8conn.max())\n\n# TOTAL POPULATION IN CLUSTER\nSDUC_UC03=np.zeros_like(HDC_POP_mask).astype('int')\n\nPOPregionIDsum=[]\nPOPregionSUM=[]\nfor regionID in range(1, SDUC_8conn.max()):\n    POPregionID=((SDUC_8conn == regionID).astype('int')) * POP_da.data    \n    # threshold for population in cluster > 5000\n    if POPregionID.sum() > MDC_Pmin:\n        POPregionSUM.append(int(round(POPregionID.sum())))\n        POPregionIDsum.append(regionID)\n        SDUC_UC03=SDUC_UC03+np.where(SDUC_8conn == regionID, SDUC_8conn, 0)\n\n# Minus HDC and DUC\nSDUC_UC03_BIN=np.where(SDUC_UC03 > 0, 1, 0)\nSDUC_UC03_BIN=SDUC_UC03_BIN - HDC_UC04_4conn_BIN - DUC_UC04_4conn_BIN\nSDUC_UC03_BIN=np.where(SDUC_UC03_BIN >0, 1, 0)\nprint(SDUC_UC03_BIN.sum())\n\nSDUC_UC04_8conn = measure.label(SDUC_UC03_BIN, background=0, connectivity=MDC_Tcon)  # connectivity=HDC_Tcon\nprint(SDUC_UC04_8conn.min(),SDUC_UC04_8conn.max())\n\nSDUC_UC05 = xr.DataArray(\n    data=SDUC_UC04_8conn,\n    dims=BTU_da.dims,\n    coords=BTU_da.coords,\n    name='semidense_urban_cluster',\n    )\n\nSDUC_UC05=SDUC_UC05.astype(np.int16)\nSDUC_UC05\n\nSDUC: export to vector\n\n# mask=None\nmask=SDUC_UC05.data != 0\nwith SDUC_UC05 as src:\n    image = src.data # first band\n    results = (\n    {'properties': {'raster_val': v}, 'geometry': s}\n    for i, (s, v) \n    in enumerate(\n        shapes(image, mask=mask, connectivity=8, transform=SDUC_UC05.rio.transform())))\n\ngeoms = list(results)\n# first feature\n# print(geoms[0])\n\nSDUC_SemiDenseUrbanCluster_temp  = gpd.GeoDataFrame.from_features(geoms)\nSDUC_SemiDenseUrbanCluster_temp.crs=SDUC_UC05.rio.crs\nSDUC_SemiDenseUrbanCluster_temp.raster_val=SDUC_SemiDenseUrbanCluster_temp.raster_val.astype('int')\nSDUC_SemiDenseUrbanCluster_temp.rename(columns={'raster_val':'sducid'}, inplace=True)\nSDUC_SemiDenseUrbanCluster_temp['code']=22\n\n# HDC & DUC - BUFFER 3km \nres_union_buffer = gpd.overlay(HDC_UrbanCentre[['geometry']], DUC_DenseUrbanCluster[['geometry']], how='union',keep_geom_type=True).buffer(3000).unary_union\n\nres_union_buffer =gpd.GeoSeries(res_union_buffer)\nres_union_buffer = gpd.GeoDataFrame(geometry=gpd.GeoSeries(res_union_buffer))\nres_union_buffer.crs=HDC_UrbanCentre.crs\nres_union_buffer[['buff3']]=1\n\n# sjoin with buffer\nSDUC_SemiDenseUrbanCluster_temp = gpd.sjoin(SDUC_SemiDenseUrbanCluster_temp, res_union_buffer[['buff3', 'geometry']], how='left',predicate='intersects')\nSDUC_SemiDenseUrbanCluster_temp.drop(columns =['index_right'],inplace=True)\nSDUC_SemiDenseUrbanCluster_temp['code'] = np.where(SDUC_SemiDenseUrbanCluster_temp['buff3'] == 1, 21, 22)\n# print(SDUC_SemiDenseUrbanCluster_temp.tail(2))\n\n# SDUC_SemiDenseUrbanCluster\nSDUC_SemiDenseUrbanCluster = SDUC_SemiDenseUrbanCluster_temp[SDUC_SemiDenseUrbanCluster_temp.code == 22].drop(columns=['buff3'])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step2-semi-dense-urban-cluster-sduc","position":67},{"hierarchy":{"lvl1":"step3: Peri-Urban Cluster (PUC)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step3-peri-urban-cluster-puc","position":68},{"hierarchy":{"lvl1":"step3: Peri-Urban Cluster (PUC)"},"content":"\n\n# PUC_PeriUrbanCluster\nPUC_PeriUrbanCluster = SDUC_SemiDenseUrbanCluster_temp[SDUC_SemiDenseUrbanCluster_temp.code == 21].drop(columns=['buff3'])\nPUC_PeriUrbanCluster.rename(columns={'sducid':'pucid'},inplace=True)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#step3-peri-urban-cluster-puc","position":69},{"hierarchy":{"lvl1":"DUC, SDUC and PUC export to shapefile"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#duc-sduc-and-puc-export-to-shapefile","position":70},{"hierarchy":{"lvl1":"DUC, SDUC and PUC export to shapefile"},"content":"\n\nDUC: export to shapefile\n\n# EXPORT 2 shapefile World Mollweide (ESRI:54009)\nDUC_DenseUrbanCluster.to_file(os.path.join(os.path.realpath('GHSL_results'),'DUC_DenseUrbanCluster_'+str(REFyear)+'.shp'))\n\n# Export to shapefile WGS84 (EPSG:4326 )\n# DUC_DenseUrbanCluster.to_crs(epsg=4326).to_file(os.path.join(os.path.realpath('GHSL_results'),'DUC_DenseUrbanCluster_4326_'+str(REFyear)+'.shp'))\n\nSDUC: export to shapefile\n\n# EXPORT 2 shapefile World Mollweide (ESRI:54009)\nSDUC_SemiDenseUrbanCluster.to_file(os.path.join(os.path.realpath('GHSL_results'),'SDUC_SemiDenseUrbanCluster_'+str(REFyear)+'.shp'))\n\n# Export to shapefile WGS84 (EPSG:4326 )\n# SDUC_SemiDenseUrbanCluster.to_crs(epsg=4326).to_file(os.path.join(os.path.realpath('GHSL_results'),'SDUC_SemiDenseUrbanCluster_4326_'+str(REFyear)+'.shp'))\n\nPUC: export to shapefile\n\n# EXPORT 2 shapefile World Mollweide (ESRI:54009)\nPUC_PeriUrbanCluster.to_file(os.path.join(os.path.realpath('GHSL_results'),'PUC_PeriUrbanCluster_'+str(REFyear)+'.shp'))\n\n# Export to shapefile WGS84 (EPSG:4326 )\n# PUC_PeriUrbanCluster.to_crs(epsg=4326).to_file(os.path.join(os.path.realpath('GHSL_results'),'PUC_PeriUrbanCluster_4326'+str(REFyear)+'.shp'))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#duc-sduc-and-puc-export-to-shapefile","position":71},{"hierarchy":{"lvl1":"L2: Visualization of results"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l2-visualization-of-results","position":72},{"hierarchy":{"lvl1":"L2: Visualization of results"},"content":"\n\nfig = Figure(width=600, height=600)\n\nm = AOI54009.explore(style_kwds={'fillColor':'None','color':'blue','weight': 1}, name='aoi')\n\n# parallels:\nfor lat in range(-90, 91, lat_interval):\n     folium.PolyLine([[lat, -180],[lat, 180]], weight=0.5).add_to(m)\n# meridianss:\nfor lon in range(-180, 181, lon_interval):\n    folium.PolyLine([[-90, lon],[90, lon]], weight=0.5).add_to(m)\n\nPUC_PeriUrbanCluster.explore(m=m,style_kwds={'fillColor':'yellow','color':'yellow','weight': 1.5}, name='PUC_PeriUrbanCluster')\nSDUC_SemiDenseUrbanCluster.explore(m=m,style_kwds={'fillColor':'darkgoldenrod','color':'darkgoldenrod','weight': 1.5}, name='SDUC_SemiDenseUrbanCluster')\nDUC_DenseUrbanCluster.explore(m=m,style_kwds={'fillColor':'brown','color':'brown','weight': 1.5}, name='DUC_DenseUrbanCluster')\n\nMDC_UrbanCluster.explore(m=m,style_kwds={'fillColor':'orange','color':'orange','weight': 1}, name='MDC_UrbanCluster', show = False)\nHDC_UrbanCentre.explore(m=m,style_kwds={'fillColor':'red','color':'red','weight': 1.5}, name='HDC_UrbanCentre')\n\nfolium.LayerControl('topright',collapsed=True).add_to(m)\nminimap = plugins.MiniMap(height=90, width=90, zoom_level_offset=-7)\nm.add_child(minimap)\n\nfig.add_child(m)\nm\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ghsl-urban-delineation#l2-visualization-of-results","position":73},{"hierarchy":{"lvl1":"GPU-Support on EOxHub"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub","position":0},{"hierarchy":{"lvl1":"GPU-Support on EOxHub"},"content":"GPU support is established via CUDA drivers for users subscribed to EOxHub GPU Plan.\n\n!nvidia-smi\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub","position":1},{"hierarchy":{"lvl1":"GPU-Support on EOxHub","lvl2":"PyTorch"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub#pytorch","position":2},{"hierarchy":{"lvl1":"GPU-Support on EOxHub","lvl2":"PyTorch"},"content":"\n\nimport torch\nassert torch.cuda.is_available()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub#pytorch","position":3},{"hierarchy":{"lvl1":"GPU-Support on EOxHub","lvl3":"CPU","lvl2":"PyTorch"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub#cpu","position":4},{"hierarchy":{"lvl1":"GPU-Support on EOxHub","lvl3":"CPU","lvl2":"PyTorch"},"content":"\n\nx = torch.rand(10000, 256)\n\n%%timeit\nH = x.mm( (x.t().mm(x)).inverse() ).mm(x.t())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub#cpu","position":5},{"hierarchy":{"lvl1":"GPU-Support on EOxHub","lvl3":"GPU","lvl2":"PyTorch"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub#gpu","position":6},{"hierarchy":{"lvl1":"GPU-Support on EOxHub","lvl3":"GPU","lvl2":"PyTorch"},"content":"\n\ndevice = torch.device(\"cuda\")\nx = torch.rand(10000, 256, device=device)\nx = x.to(device)\n\n%%timeit\nH = x.mm( (x.t().mm(x)).inverse() ).mm(x.t())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub#gpu","position":7},{"hierarchy":{"lvl1":"GPU-Support on EOxHub","lvl2":"Tensorflow"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub#tensorflow","position":8},{"hierarchy":{"lvl1":"GPU-Support on EOxHub","lvl2":"Tensorflow"},"content":"\n\nimport tensorflow as tf\nimport datetime\nfrom tensorflow.python.client import device_lib\nassert tf.test.is_gpu_available(cuda_only=True)\ntf.config.list_physical_devices('GPU')","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gpu-support-eoxhub#tensorflow","position":9},{"hierarchy":{"lvl1":"Pre-requisites"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example","position":0},{"hierarchy":{"lvl1":"Pre-requisites"},"content":"from eoxhub import check_compatibility\ncheck_compatibility(\"user-2022.10-14\", dependencies=[\"SH\"])\n\n\n\n\n\nThe Global Earth Monitor (GEM) project is addressing the challenge of continuous monitoring of large areas in a sustainable cost-effective way. The goal of the project is to establish a new disruptive Earth Observation Data - Exploitation model which will dramatically enhance the exploitation of Copernicus data.\n\nRead more about the project, and subscribe to our newsletter \n\nhere.\n\nThis project has received funding from the European Union’s Horizon 2020 research and innovation programme under Grant Agreement No. 101004112.\n\nThe example in this notebook shows how a typical Earth Observation workflow can be run using \n\neo-grow.\n\nThe workflow is depicted in the image below:\n\n\nand skips the ML part for the sake of ease. The full example, with instructions on how to run it on large scale is given in \n\neo-grow-examples.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example","position":1},{"hierarchy":{"lvl1":"Pre-requisites"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#pre-requisites","position":2},{"hierarchy":{"lvl1":"Pre-requisites"},"content":"EOxHub Workspace subscription\n\nSentinel Hub subscription","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#pre-requisites","position":3},{"hierarchy":{"lvl1":"Configuration"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#configuration","position":4},{"hierarchy":{"lvl1":"Configuration"},"content":"To set up the workspace,first import the neccessary python libraries. These libraries are pre-installed in EOxHub Workspace. Additionally import environment variables which automatically includes Sentinel Hub credentials that will be used to configure Sentinel Hub API.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#configuration","position":5},{"hierarchy":{"lvl1":"Configuration","lvl2":"Imports"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#imports","position":6},{"hierarchy":{"lvl1":"Configuration","lvl2":"Imports"},"content":"\n\n%matplotlib inline\n\nimport os\nfrom typing import Any, Dict\nimport warnings\nimport shutil\n\nimport IPython\n\nfrom eogrow.core.config import RawConfig, interpret_config_from_dict, recursive_config_join\nfrom eogrow.core.storage import StorageManager\nfrom eogrow.core.area import UtmZoneAreaManager\nfrom eogrow.pipelines.download import DownloadEvalscriptPipeline\nfrom eogrow.pipelines.features import FeaturesPipeline\nfrom eogrow.pipelines.prediction import RegressionPredictionPipeline\nfrom eogrow.pipelines.export_maps import ExportMapsPipeline\nfrom eogrow.pipelines.byoc import IngestByocTilesPipeline\n\nfrom sentinelhub import SHConfig\n\nwarnings.filterwarnings('ignore')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#imports","position":7},{"hierarchy":{"lvl1":"Configuration","lvl2":"Some helper functions"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#some-helper-functions","position":8},{"hierarchy":{"lvl1":"Configuration","lvl2":"Some helper functions"},"content":"\n\ndef prepare_config(global_config: Dict[str, Any], pipeline_config: Dict[str, Any]) -> RawConfig:\n    joint_config = recursive_config_join(pipeline_config, global_config)\n    return interpret_config_from_dict(joint_config)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#some-helper-functions","position":9},{"hierarchy":{"lvl1":"Configuration","lvl2":"Credentials"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#credentials","position":10},{"hierarchy":{"lvl1":"Configuration","lvl2":"Credentials"},"content":"\n\nSentinel Hub credentials SH_CLIENT_ID and SH_CLIENT_SECRET are already imported as envornment variables. In the next step pass the credentials to SHConfig() object:\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\nconfig.save()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#credentials","position":11},{"hierarchy":{"lvl1":"Running the pipelines"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#running-the-pipelines","position":12},{"hierarchy":{"lvl1":"Running the pipelines"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#running-the-pipelines","position":13},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Prepare project data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#prepare-project-data","position":14},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Prepare project data"},"content":"\n\nFirst, let’s get some data and set up the project folder\n\nPROJECT_FOLDER = './gem_project'\n\nif os.path.exists(PROJECT_FOLDER):\n    print(\"Local project already exists!\")\nelse:\n    shutil.copytree(\n        os.path.join(os.environ['EDC_PATH'], \"notebooks/contributions/eogrow/project\"), \n        PROJECT_FOLDER\n    )\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#prepare-project-data","position":15},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Define area of interest (AOI)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#define-area-of-interest-aoi","position":16},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Define area of interest (AOI)"},"content":"\n\nFor this example the AOI is covering area around Porto Novo (Benin) and Lagos (Nigeria), as can be seen below.The AOI is stored in project/input-data/demo-aoi.geojson, and is specified as input parameter in the AreaManager part of the global config (below).\n\nIPython.display.GeoJSON(filename=f'{PROJECT_FOLDER}/input-data/demo-aoi.geojson')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#define-area-of-interest-aoi","position":17},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Config with global parameters"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#config-with-global-parameters","position":18},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Config with global parameters"},"content":"\n\nThe main configuration parameters are defined here: a folder, where everything (data, model, results, ...) will be stored. In this case, the project folder is local path; it could also be a path on object storage (AWS S3). As it is local, one can also copy the notebook and corresponding files under project to local machine and run things there.\n\nstorage_config = {\n    \"manager\": \"eogrow.core.storage.StorageManager\",\n    \"project_folder\": PROJECT_FOLDER,\n    \"structure\": {\n      \"data\": \"data\",\n      \"features\": \"features\",\n      \"predictions\": \"predictions\",\n      \"models\": \"models\",\n      \"maps\": \"maps\"\n    }\n}\n\narea_config = {\n    \"manager\": \"eogrow.core.area.utm.UtmZoneAreaManager\",\n    \"area_filename\": \"demo-aoi.geojson\",\n    \"patch_size_x\": 256*120,\n    \"patch_size_y\": 256*120,\n}\n\nlogging_config = {\n    \"manager\": \"eogrow.core.logging.LoggingManager\",\n    \"save_logs\": True,\n    \"show_logs\": True,\n    \"capture_warnings\": False\n}\n\nglobal_config = {\n    \"storage\": storage_config,\n    \"area\": area_config,\n    \"eopatch\": {\"manager\": \"eogrow.core.eopatch.EOPatchManager\"},\n    \"logging\": logging_config,\n    \"use_ray\": False,\n    \"workers\": 1\n}\n\nstorage_manager = StorageManager.from_raw_config(storage_config)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#config-with-global-parameters","position":19},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Download pipeline"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#download-pipeline","position":20},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Download pipeline"},"content":"\n\nAs for this demonstration we are not using object storage (AWS S3), we will be requesting data through Sentinel Hub ProcessingAPI. When relying on object storage, we could have used the BatchAPI and corresponding eogrow.pipelines.batch_download.BatchDownloadPipeline.\n\nThis pipeline takes care of the first step in literally any EO workflow: getting the data.\n\nevalscript_path = os.path.join(storage_manager.get_input_data_folder(full_path=True), 'evalscript.js')\n\ndownload_config = {\n  \"pipeline\": \"eogrow.pipelines.download.DownloadEvalscriptPipeline\",\n  \"data_collection\": {\n    \"name\": \"BYOC_484d8dbb-9e3e-41f2-b96b-35189d3ae37f\",\n  },\n  \"time_period\": [\"2020-01-01\", \"2021-01-01\"],\n  \"resolution\": 120,\n  \"resampling_type\": \"BILINEAR\",\n  \"skip_existing\": True,\n  \"output_folder_key\": \"data\",\n  \"features\": [[\"data\", \"BANDS\"], [\"mask\", \"QUALITY_MASK\"]],\n  \"postprocessing\": {\n      \"rescale_schemas\": [{\n          \"rescale_factor\": 0.0001,\n          \"dtype\": \"float\",\n          \"features_to_rescale\": [[\"data\", \"BANDS\"]],\n      }],\n  },\n  \"evalscript_path\": evalscript_path\n}\n\ndownload_pipeline = DownloadEvalscriptPipeline.from_raw_config(prepare_config(global_config, download_config))\n\ndownload_pipeline.run()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#download-pipeline","position":21},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Features pipeline"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#features-pipeline","position":22},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Features pipeline"},"content":"\n\nIn this pipeline we are computing a (trivial) set of indices. With SentinelHub we could have easily retrieved them via apropriately tailored evalscript, reducing also the amout of requested data.\n\nfeatures_config = {\n  \"pipeline\": \"eogrow.pipelines.features.FeaturesPipeline\",\n  \"input_folder_key\": \"data\",\n  \"output_folder_key\": \"features\",\n  \"bands_feature_name\": \"BANDS\",\n  \"data_preparation\": {\n    \"valid_data_feature_name\": \"QUALITY_MASK\" # because we won't do any filtering this features plays no role\n  },\n  \"ndis\": {\n    \"NDVI\": [7,3],\n    \"NDWI\": [2,7],\n    \"NDBI\": [10,7]\n  },\n  \"output_feature_name\": \"FEATURES\",\n  \"dtype\": \"float\",\n  \"skip_existing\": True\n}\n\nfeatures_pipeline = FeaturesPipeline.from_raw_config(prepare_config(global_config, features_config))\n\nfeatures_pipeline.run()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#features-pipeline","position":23},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Prediction pipeline"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#prediction-pipeline","position":24},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Prediction pipeline"},"content":"\n\nAs specified, this workflow is a slimmed down version of the full example, available on eo-grow-examples. As such, we are skipping the training part, and will continue straight with the prediction pipeline, using the model that is the result from the full example. For ease of use, the model is included in this example at project/models/.\n\nprediction_config = {\n  \"pipeline\": \"eogrow.pipelines.prediction.RegressionPredictionPipeline\",\n  \"input_folder_key\": \"features\",\n  \"model_folder_key\": \"models\",\n  \"output_folder_key\": \"predictions\",\n  \"input_features\": [[\"data\", \"FEATURES\"]],\n  \"output_feature_name\": \"test_prediction\",\n  \"dtype\": \"float32\",\n  \"model_filename\": \"gem-example_model.gz\",\n  \"clip_predictions\": [0, 100],\n  \"skip_existing\": True\n}\n\nprediction_pipeline = RegressionPredictionPipeline.from_raw_config(prepare_config(global_config, prediction_config))\n\nprediction_pipeline.run()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#prediction-pipeline","position":25},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Export predictions to maps pipeline"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#export-predictions-to-maps-pipeline","position":26},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Export predictions to maps pipeline"},"content":"\n\nThis pipeline takes care of exporting final results as cloud-optimised-geotiffs (see parameter cofigy=True in config below).\n\nexport_map_config = {\n  \"pipeline\": \"eogrow.pipelines.export_maps.ExportMapsPipeline\",\n  \"input_folder_key\": \"predictions\",\n  \"output_folder_key\": \"maps\",\n  \"feature\": [\"data_timeless\", \"test_prediction\"],\n  \"map_name\": \"result.tiff\",\n  \"map_dtype\": \"uint8\",\n  \"band_indices\": [0],\n  \"cogify\": True,\n  \"workers\": 1\n}\n\nexport_pipeline = ExportMapsPipeline.from_raw_config(prepare_config(global_config, export_map_config))\n\nexport_pipeline.run()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#export-predictions-to-maps-pipeline","position":27},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Ingest results to BYOD on Sentinel Hub"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#ingest-results-to-byod-on-sentinel-hub","position":28},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Ingest results to BYOD on Sentinel Hub"},"content":"\n\nThe following code would ingest the results back to the Sentinel Hub services (using \n\nBring Your Own Data) if we were using object storage (AWS S3 bucket) for project’s storage.ingestion_config = {\n  \"pipeline\": \"eogrow.pipelines.byoc.IngestByocTilesPipeline\",\n  \"byoc_tile_folder_key\": \"maps\",\n  \"new_collection_name\": \"GEM eo-grow example predictions over Lagos\",\n  \"sensing_time\": \"2020-12-31\",\n  \"cover_geometry_folder_key\": \"input_data\",\n  \"cover_geometry\": \"demo-aoi.geojson\"\n}\n\ningestion_pipeline = IngestByocTilesPipeline.from_raw_config(prepare_config(global_config, ingestion_config))\ningestion_pipeline.run()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#ingest-results-to-byod-on-sentinel-hub","position":29},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Visualize the results"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#visualize-the-results","position":30},{"hierarchy":{"lvl1":"Running the pipelines","lvl2":"Visualize the results"},"content":"\n\nAs we cannot use BYOC functinality in this (non object storage based) example, we’ll rely on eo-learn and matplotlib to quickly visualize the results of built-up areas in the AOI.\n\nimport matplotlib.pyplot as plt\nfrom eolearn.core import EOPatch\nfrom tqdm.auto import tqdm as tqdm\n\n%matplotlib inline\n\n%matplotlib inline\n\nfig, axs = plt.subplots(nrows=2, ncols=3, figsize=(30, 20))\n\nfor eop_name in tqdm(download_pipeline.eopatch_manager.get_eopatch_filenames()):\n    eopatch_path = os.path.join(storage_manager.get_folder('predictions', full_path=True), eop_name)\n    eopatch = EOPatch.load(eopatch_path, lazy_loading=True)\n\n    j, i = int(eop_name.split(\"-\")[4]), int(eop_name.split(\"-\")[6])\n    ax = axs[1-i][j]\n    ax.imshow(eopatch.data_timeless[\"test_prediction\"].squeeze(), vmin=5, vmax=80, cmap='Reds')\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_aspect(\"auto\")\n    ax.set_axis_off()\n    del eopatch\n\nfig.subplots_adjust(wspace=0, hspace=0)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/globalearthmonitor-example#visualize-the-results","position":31},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek","position":0},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek","position":1},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#side-event-2-euro-data-cube-hands-on-tutorial-and-training-session","position":2},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nIn the previous part of the session, you have already gained experience in navigating around the Euro Data Cube interface and using GeoDB. Now, we are going to show a use case example to demonstrate how you can combine some of what you have learnt with Sentinel Hub Services!\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#side-event-2-euro-data-cube-hands-on-tutorial-and-training-session","position":3},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Use Case Example: Deforestation in the Gran Chaco Region","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#use-case-example-deforestation-in-the-gran-chaco-region","position":4},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Use Case Example: Deforestation in the Gran Chaco Region","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"In this Jupyter Notebook we are going to investigate deforestation events happening in the Gran Chaco region that spans across parts of eastern Bolivia, western Paraguay, northern Argentina and a small part of the Brazilian state of Mato Grosso. The region has one of the highest rates of deforestation in the world, mainly linked to the expansion of cattle farming.\n\nThe following articles provide more context information on the subject: \n\nDeforestation in Argentina’s Gran Chaco\n, \n\nDeforestation in Paraguay, \n\nWWF: Gran Chaco.\n\n\n\nDeforested areas in the rainforest, Brazil, on August 24, 2019. Carlos Fabal – AFP/Getty Images\n\n\n\nThroughout the following examples we will see how to:\n\nrequest satellite imagery using the Python wrapper to the Sentinel Hub API service\n\neasily request metadata concerning images over a given area and time frame\n\nextract basic statistical information for a given area and time frame\n\nFirst, we will access the \n\nGlobal Forest Watch dataset (saved as a GeoDB in EDC) on deforestation in Gran Chaco. The original version can be downloaded \n\nhere. The dataset, that runs from 2011 to early 2018, represents deforested areas as polygons, derived manually using 30-meter resolution Landsat images for the 55 scenes that cover the Gran Chaco.\n\nTo check the temporal and spatial accuracy of the polygons, we will select a small test subset in Paraguay and compare the polygons representing deforestation events in January 2018 to higher resolution Sentinel-2 images. In this section, we will see how to query data using Sentinel Hub’s python package, and how to get metadata from the Catalog API to select the correct images without wasting resources/time.\n\nWe will then show you how to use the brand-new data fusion capabilities of Sentinel Hub services to mitigate the drawbacks of using optical sensors for deforestation detection.\n\nFinally, we will investigate the time-series of Sentinel-2 images, deriving NDVI (Normalized Difference Vegetation Index) to see if the deforestation event can be automatically detected.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#use-case-example-deforestation-in-the-gran-chaco-region","position":5},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Load necessary libraries","lvl3":"Use Case Example: Deforestation in the Gran Chaco Region","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#load-necessary-libraries","position":6},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Load necessary libraries","lvl3":"Use Case Example: Deforestation in the Gran Chaco Region","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\n# EDC\nfrom edc import setup_environment_variables\nfrom xcube_geodb.core.geodb import GeoDBClient\n\n# Sentinel Hub Py\nfrom sentinelhub import (SHConfig, BBox, bbox_to_dimensions, CRS, SentinelHubRequest, DataCollection, MimeType, FisRequest)\nfrom sentinelhub.geometry import Geometry\n\n# Utilities\nfrom pathlib import Path\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\nfrom datetime import datetime as dt\nimport pandas as pd\nimport numpy as np\nimport tarfile\n\n# Geographical libraries\nimport geopandas\nfrom pyproj import Proj, transform\nfrom shapely.geometry import shape, box\nfrom shapely.ops import unary_union\n\n# Plotting\nimport IPython\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as ticker\nimport matplotlib.gridspec as gridspec\nfrom matplotlib import colors\nimport matplotlib.patches as mpatches\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes\n\n# Rasterio\nimport rasterio\nfrom rasterio.plot import show\nimport rasterio.features\nfrom scipy.ndimage import morphology\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#load-necessary-libraries","position":7},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Setup environment variables","lvl3":"Use Case Example: Deforestation in the Gran Chaco Region","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#setup-environment-variables","position":8},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Setup environment variables","lvl3":"Use Case Example: Deforestation in the Gran Chaco Region","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nThere are several options to set up your Sentinel Hub credentials, depending on how you want to access the services. In this workflow, as we will be working with the sentinelhub-py package to run requests in Python, we set up an SHConfig object that will take care of identification with the services for us. Therefore, we assign the identification parameters provided by EDC to the SHConfig object.\n\n# Get identification parameters from EDC\nsetup_environment_variables()\n\n# Assign environement variables for later use\nsh_client_id = %env SH_CLIENT_ID\nsh_client_secret = %env SH_CLIENT_SECRET\nsh_instance_id = %env SH_INSTANCE_ID\n\n# Setup SH services access\nconfig = SHConfig()\n\nconfig.sh_client_id = sh_client_id\nconfig.sh_client_secret = sh_client_secret\nconfig.instance_id = sh_instance_id\n\nNext, we set up access to the GeoDB, using GeoDBClient as shown in the previous section of this training session.\n\ngeodb = GeoDBClient()\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#setup-environment-variables","position":9},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#request-a-truecolor-image-as-overview-of-the-selected-area","position":10},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Now that the credentials are set up, it is possible to request satellite images.\n\nWe will start by plotting an overview True Color RBG image from Sentinel-2 of the area that we will be working on.\n\nThe Sentinel Hub Process API will need the following information for a valid request:\n\nAn AOI (area of interest): that contains the location’s coordinates (polygon or bounding box). The image size is pre-calculated according to the resolution desired.\n\nEvalscript in which you specify the data products and their visualisation\n\nRequest body with parameters about the location and time\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#request-a-truecolor-image-as-overview-of-the-selected-area","position":11},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Define coordinates for area of interest and create a bbox object","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#define-coordinates-for-area-of-interest-and-create-a-bbox-object","position":12},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Define coordinates for area of interest and create a bbox object","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\n# Select the coordinates (lower-left, upper right) of our AOI\naoi_bbox = [-60.28157336, -21.27560428, -60.12293070, -21.18495133]\n\n# Set AOI overview bbox\nresolution = 10\naoi_overview = BBox(bbox=aoi_bbox, crs=CRS.WGS84)  # Make a BBox object of the list of coordinates\naoi_overview_size = bbox_to_dimensions(aoi_overview, resolution=resolution)  # Automatically calculate the output size in px\n\nprint(f\"Output image size: {aoi_overview_size[0]} * {aoi_overview_size[1]} px\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#define-coordinates-for-area-of-interest-and-create-a-bbox-object","position":13},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Evalscript creation","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#evalscript-creation","position":14},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Evalscript creation","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"An \n\nEvalscript is a piece of Javascript code that allows you to define the input and output parameters of the data you would like to query, as well as specifying the processing to be applied to the satellite images.\n\nFor the evalscript you must specify at least the two following functions:\n\nsetup function: this sets up the input (i.e. which bands to call) and output settings (number of bands to return, format, etc...).\n\nevaluatePixel function - this function is where you specify the processing (to derive new information from the images, or for visualisation) to be applied to the images.\n\nIn the following Evalscript, we want to return an RGB True Color image. In the setup function, we will specify that we want to use the Red (B04), Green (B03) and Blue (B02) bands of Sentinel-2. Since we want a three-channel image (RGB), we specify that our output will have three bands. We use the convenient AUTO sample type for the returned data, as we are just going to visualise it. With AUTO values should range from 0-1, which will then automatically be stretched from the interval [0, 1] to [0, 255] and written into a UINT8 raster.\n\nBecause the image would be too dark if we return directly the band values scaled from 0 to 255, we apply a gain (multiplying the values by 3.5). This is just for visualisation purposes.\n\nevalscript_true_color = \"\"\"\n//VERSION=3\n\n// Set up the input and output settings\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\"],  //define input bands\n    output: { bands: 3, sampleType: SampleType.AUTO}  //define amount of channels in output image (RGB = 3)\n  };\n}\n\n// Map the input bands to the values in the output raster\n\nfunction evaluatePixel(sample) {\n  let gain = 3.5;\n  return [gain * sample.B04, gain * sample.B03, gain * sample.B02];    //map bands 4, 3, 2 to RGB channels and multiply by 3.5 for enhanced truecolor visualisation\n}\n\"\"\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#evalscript-creation","position":15},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Request body creation","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#request-body-creation","position":16},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Request body creation","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"The run the Evalscript, we need to define the payload, or data parameters to send to Sentinel Hub Services. The Sentinel Hub python package simplifies the writing of the payload, by using the SentinelHubRequest class to pass the following input parameters:\n\nthe created evalscript\n\ninput data (data source and time interval)\n\ndefine the output (name and format)\n\ndefine bbox\n\nsize of the requested image\n\nidentification with the SHConfig object\n\nrequest = SentinelHubRequest(evalscript=evalscript_true_color,\n                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n                                                                       time_interval=(\"2017-12-31\",\n                                                                                      \"2017-12-31\"))],\n                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n                            bbox=aoi_overview,  \n                            size=aoi_overview_size,\n                            config=config)\n\nNow that the request is created, we just need to run it using the get_data method.\n\noverview = request.get_data()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#request-body-creation","position":17},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the requested image","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-requested-image","position":18},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the requested image","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"By using get_data without any additional parameters saved the results to the overview variable. Let’s plot it to look at the returned data.\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\nax.imshow(overview[0])\n\n# Plot configuration\nax.set_xticks([])\nax.set_yticks([])\nax.set_title(\"2017-12-31\")\n\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-requested-image","position":19},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Quizz: can you figure out how to request a falsecolor infrared image?","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#quizz-can-you-figure-out-how-to-request-a-falsecolor-infrared-image","position":20},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Quizz: can you figure out how to request a falsecolor infrared image?","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Try to fill in the gaps in the evalscript below.\n\nHint: To receive a falsecolor infrared image you need to map Sentinel-2 Band 8 (NIR) to the red channel, Band 4 (RED) to the green channel, and Band 3 (GREEN) to the blue channel.\n\nevalscript_false_color = \"\"\"\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"\", \"\", \"\"],\n    output: { bands: 3 }\n  };\n}\n\nfunction evaluatePixel(sample) {\n  let gain = 2.5;\n  return [ , , ];\n}\n\"\"\"\n\nUncomment the following cell for the solution. Make sure to run the following cell twice, one time for fetching the solution and a second time for running the Evalscript.\n\n# %load https://raw.githubusercontent.com/sentinel-hub/code-snippets/master/phiweek2020/Solution.py\n\nNow that we have the Evalscript, let’s run the request:\n\nrequest = SentinelHubRequest(evalscript=evalscript_false_color,\n                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n                                                                       time_interval=(\"2017-12-31\",\n                                                                                      \"2017-12-31\"))],\n                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n                            bbox=aoi_overview,  \n                            size=aoi_overview_size,\n                            config=config)\n\noverview_fc = request.get_data()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#quizz-can-you-figure-out-how-to-request-a-falsecolor-infrared-image","position":21},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the False Color image","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-false-color-image","position":22},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the False Color image","lvl3":"Request a truecolor image as overview of the selected area","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,10))\nax.imshow(overview_fc[0])\n\n# Plot configuration\nax.set_xticks([])\nax.set_yticks([])\nax.set_title(\"2017-12-31\")\n\nplt.show()\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-false-color-image","position":23},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Get the collection from GeoDB and data preparation","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#get-the-collection-from-geodb-and-data-preparation","position":24},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Get the collection from GeoDB and data preparation","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"In the next step we retrieve the prepared gran_chaco collection from GeoDB.\n\nAs a reminder, you can explore the original dataset \n\nhere.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#get-the-collection-from-geodb-and-data-preparation","position":25},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Check available collections in GeoDB","lvl3":"Get the collection from GeoDB and data preparation","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#check-available-collections-in-geodb","position":26},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Check available collections in GeoDB","lvl3":"Get the collection from GeoDB and data preparation","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nUsing the geodb client, let’s look at what collections are available.\n\n# Lets get already existing collections\ngeodb.get_my_collections()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#check-available-collections-in-geodb","position":27},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Query the collection by bbox to retrieve only the area we are interested in","lvl3":"Get the collection from GeoDB and data preparation","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#query-the-collection-by-bbox-to-retrieve-only-the-area-we-are-interested-in","position":28},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Query the collection by bbox to retrieve only the area we are interested in","lvl3":"Get the collection from GeoDB and data preparation","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"We are interested in the gran_chaco GeoDB collection. However, we will not query it entirely in this exercise since we are only interested in a specific AOI that we defined further up. Therefore, not needing the whole dataset, we only retrieve the polygons that are contained in our area of interest by querying the dataset with our defined bbox.\n\ngran_chaco = geodb.get_collection_by_bbox('gran_chaco', database=\"phi_week\", bbox=aoi_bbox, bbox_crs=4326, comparison_mode=\"contains\")\n\nLet’s preview the collection subset that we have just queried.\n\ngran_chaco\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#query-the-collection-by-bbox-to-retrieve-only-the-area-we-are-interested-in","position":29},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Data preparation","lvl3":"Get the collection from GeoDB and data preparation","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#data-preparation","position":30},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Data preparation","lvl3":"Get the collection from GeoDB and data preparation","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"As we can see above, in the subset of the GeoDB that we queried, there are deforestation events detected in 2011, 2014, 2015, 2016, 2017 and 2018. Let’s narrow down the dataset a little further and only select the polygons in 2018.\n\nIn the following cell, we convert the date strings to datetime objects to make the querying easier.\n\n# Convert the dates to datetime objects and store in a new column\ngran_chaco[\"datetime\"] = pd.to_datetime(gran_chaco[\"date\"])\n\n# Select only polygons from 2018\ngran_chaco_subset_2018 = gran_chaco[gran_chaco[\"datetime\"].dt.year == 2018]\n\nNow, we can preview the subset that we have selected based on the year 2018.\n\ngran_chaco_subset_2018\n\n# Plot all selected polygons\nIPython.display.GeoJSON(gran_chaco_subset_2018.__geo_interface__)\n\nFun fact: thanks to Ipython, it is easy to zoom out to have an idea of the location of the polygons. Furthermore, you can click on an individual polygon to list the attributes of that specific shape in the dataframe.\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#data-preparation","position":31},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Query Catalog API for dates with  available Sentinel-2 data before and after the registered deforestation event","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#query-catalog-api-for-dates-with-available-sentinel-2-data-before-and-after-the-registered-deforestation-event","position":32},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Query Catalog API for dates with  available Sentinel-2 data before and after the registered deforestation event","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"For our selected AOI, we will check if the registered deforestation date in the dataset that we are querying is correct. To do so, we will look at the closest cloud-free Sentinel images before and after the date assigned to the polygon (here, 2018-01-31).\n\nRather than query all the Sentinel-2 images in a given period around the date of interest, which would be a waste of resources particularly in cloudy areas, we can use the Catalog API service to list metadata about the images that will guide our choice in the selection. The Catalog service allows us to return the dates of images intersecting the AOI, but other essential parameters, such as the scene’s overall cloud cover.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#query-catalog-api-for-dates-with-available-sentinel-2-data-before-and-after-the-registered-deforestation-event","position":33},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Create an OAuth2 session and create a token for it","lvl3":"Query Catalog API for dates with  available Sentinel-2 data before and after the registered deforestation event","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#create-an-oauth2-session-and-create-a-token-for-it","position":34},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Create an OAuth2 session and create a token for it","lvl3":"Query Catalog API for dates with  available Sentinel-2 data before and after the registered deforestation event","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"In order to send a request to the Catalog API we need to create a token first. Let’s start by creating an OAuth session.\n\n# Create a session\nclient = BackendApplicationClient(client_id=sh_client_id)\noauth = OAuth2Session(client=client)\n\nThe token acts like an ID we provide the API with to verify us as a registered user. This token is temporary (about 1h) for security reasons. If when running a Catalog request an authentification error is thrown, just execute the following cell again to obtain a new token.\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_id=sh_client_id, client_secret=sh_client_secret)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#create-an-oauth2-session-and-create-a-token-for-it","position":35},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Create the Catalog API request","lvl3":"Query Catalog API for dates with  available Sentinel-2 data before and after the registered deforestation event","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#create-the-catalog-api-request","position":36},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Create the Catalog API request","lvl3":"Query Catalog API for dates with  available Sentinel-2 data before and after the registered deforestation event","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"We specify the service endpoint URL, set the Content-Type to ‘application/json’ because we only want to receive a list of dates with available Sentinel-2 data within the selected period. We also set the collection that we want to query (here Sentinel-2 L1C), and the time range we are interested in.\n\n# Set the Catalog API url\ncatalog_url = \"https://services.sentinel-hub.com/api/v1/catalog/\"\n\n# Set the header\nheaders = {\n  'Content-Type': 'application/json'\n}\n\n# Set the Catalog request parameters\ncollections = \"sentinel-2-l1c\"\ndatetime= \"2017-10-01T00:00:00Z/2018-02-15T23:59:59Z\"  # We set a wide time range to get an idea of the available data\n\n# Run the catalog request\nresponse = oauth.request(\"GET\", f\"https://services.sentinel-hub.com/api/v1/catalog/collections/{collections}/items?bbox={aoi_bbox[0]},{aoi_bbox[1]},{aoi_bbox[2]},{aoi_bbox[3]}&datetime={datetime}&limit=20\", headers=headers)\ncatalog_results = response.json()\n\n# Fetch the dates and cloud cover values\navailable_data = []\nfor entry in catalog_results[\"features\"]:\n    available_data.append((entry[\"properties\"][\"datetime\"], entry[\"properties\"][\"eo:cloud_cover\"]))\n    \nprint(available_data)\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#create-the-catalog-api-request","position":37},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Filter the available dates","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#filter-the-available-dates","position":38},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Filter the available dates","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"We now have a list of images and their respective cloud cover available, we can filter out for the closest dates to the deforestation event marked in our database, taking in account the cloud cover.\n\nLet’s select the images with less than 10% cloud cover over the entire scene.\n\n# Set the date of interest. Since all the dates are the same in our subset, we take the first one.\ndeforestation_date = dt.strptime(gran_chaco_subset_2018.date.values[0], \"%Y-%m-%d\")\n\n# Cloud cover percentage filter\ncc = 10\n\n# We want to select the dates that have less than the set % of cloud cover\navailable_datetimes = [dt.strptime(x[0], \"%Y-%m-%dT%H:%M:%SZ\") for x in available_data if x[1] <= cc]\n\n# Find the index before and after our date of interest\npast_dates = [date for date in available_datetimes if date < deforestation_date]\nfuture_dates = [date for date in available_datetimes if date >= deforestation_date]\n\nbefore_ind = available_datetimes.index(max(past_dates))\nafter_ind = available_datetimes.index(min(future_dates))\n\nprint(f\"Closest date with less than {cc}% cloud cover. Before: {available_datetimes[before_ind]}; After: {available_datetimes[after_ind]}\")\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#filter-the-available-dates","position":39},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Query Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#query-sentinel-2-images","position":40},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Query Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Now we have the dates that we are interested in, we will query the images using sentinelhub-py, as we did for the True Color and False Color RGB images.\n\nFirst we set the bounding box to cover our selected field based on the geometry of the object in the database. We will set a buffer to make sure that we cover the entire set of polygons. Note that the buffer values are in degrees since the coordinates are in WGS84.\n\n# Set AOI bounding box for our example polygons and image size according to desired resolution\nresolution = 10\naoi = BBox(bbox=box(*gran_chaco_subset_2018.total_bounds).buffer(0.001).bounds, crs=CRS.WGS84)\naoi_size = bbox_to_dimensions(aoi, resolution=resolution)\n\nIn our request, we will do things a little differently from the previous requests. Indeed, to be able to plot the extent of the fields in our image, we need it to be georeferenced. Therefore, using the numpy array returned when calling the request is not sufficient. To get a georeferenced image, we will save the response as a geotiff locally, then open it with a geospatial library later (here we will use rasterio).\n\nWe will make two requests: one for the date before the event, that we selected earlier, and one after. Before each request, we make a directory to save the geotiffs and set the save_data parameter to True in the get_data method. Note, make sure that you delete any previous requests in the folders (if they exist).\n\n# Make a directory to save the response\nPath('./results/before').mkdir(parents=True, exist_ok=True)\n  \nrequest = SentinelHubRequest(evalscript=evalscript_true_color,\n                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n                                                                       time_interval=(dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\"),\n                                                                                      dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\")))],\n                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n                            bbox=aoi,  \n                            size=aoi_size,\n                            data_folder='./results/before/',\n                            config=config)\n\ntrue_color_before = request.get_data(save_data=True)\n\n# Make a directory to save the response\nPath('./results/after').mkdir(parents=True, exist_ok=True)\n  \nrequest = SentinelHubRequest(evalscript=evalscript_true_color,\n                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n                                                                       time_interval=(dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\"),\n                                                                                      dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\")))],\n                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n                            bbox=aoi,  \n                            size=aoi_size,\n                            data_folder='./results/after/',\n                            config=config)\n\ntrue_color_after = request.get_data(save_data=True)\n\nNow that we have downloaded the data, let’s fetch the path to the resulting geotiffs and open them with rasterio.\n\n# Get folder name created\nfld_a = [f for f in Path(\"./results/before/\").iterdir() if f.is_dir()][0]\nfld_b = [f for f in Path(\"./results/after/\").iterdir() if f.is_dir()][0]\n\n# Open raster with Rasterio\nraster_before = rasterio.open(str(fld_a.joinpath(\"response.tiff\")))\nraster_after = rasterio.open(str(fld_b.joinpath(\"response.tiff\")))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#query-sentinel-2-images","position":41},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the raster images saved locally and show the outline of the selected polygons in the database","lvl3":"Query Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-raster-images-saved-locally-and-show-the-outline-of-the-selected-polygons-in-the-database","position":42},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the raster images saved locally and show the outline of the selected polygons in the database","lvl3":"Query Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Here will plot the georeferenced rasterio rasters and add the parcel outlines over the images.\n\nfig, (ax, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(18, 10))\n\n# Plot images before and after\nshow(raster_before, ax=ax)\nshow(raster_after, ax=ax1)\n\n# Plot the field outline over the images\ngran_chaco_subset_2018.plot(ax=ax, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\ngran_chaco_subset_2018.plot(ax=ax1, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n\n# Plot configuration\nfor axs in [ax, ax1]:\n    axs.set_xticks([])\n    axs.set_yticks([])\n\nax.set_title(dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\"))\nax1.set_title(dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\"))\n\nplt.show()\n\nIn the image above, we notice several points:\n\nFor some of the smaller polygons we can see that the deforestation happened between the 31st December 2017 and 4th February 2018. Due to cloud coverage, we cannot narrow down the date any more. But we will get back to this point later in the process.\n\nThe larger polygons that were identified as deforested in January 2018 in the dataset were already partly deforested in December 2017.\n\nCertain areas delimited manually based on the Landsat images seems shifted compared to the Sentinel-2 images: i.e. the large polygon top centre. This shift may be due to the difference in resolution or slight geolocalisation differences between the sensors.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-raster-images-saved-locally-and-show-the-outline-of-the-selected-polygons-in-the-database","position":43},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Compare with Landsat imagery","lvl3":"Query Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#compare-with-landsat-imagery","position":44},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Compare with Landsat imagery","lvl3":"Query Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"To see the field delination on a Landsat image, we can query a Landsat image as we did for Sentinel.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#compare-with-landsat-imagery","position":45},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Quizz: what is the easiest way to write an Evalscript for Landsat True Color?","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#quizz-what-is-the-easiest-way-to-write-an-evalscript-for-landsat-true-color","position":46},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Quizz: what is the easiest way to write an Evalscript for Landsat True Color?","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Based on Landsat \n\nbands available, how would you return a True Color image using the Evalscript?\n\nevalscript_landsat_true_color = \"\"\"\"\"\"\n\n# Adjust the image size for the change in resolution\naoi_size_landsat = bbox_to_dimensions(aoi, resolution=30)\n\nUncomment the following cell for the solution. Make sure to run the following cell twice, one time for fetching the solution and a second time for running the Evalscript.\n\n# %load https://raw.githubusercontent.com/sentinel-hub/code-snippets/master/phiweek2020/Solution2.py\n\nBonus question: how would you improve the resolution of the True Color image?\n\nevalscript_landsat_true_color_improved = \"\"\"\"\"\"\n\nUncomment the following cell for the solution. Make sure to run the following cell twice, one time for fetching the solution and a second time for running the Evalscript.\n\n# %load https://raw.githubusercontent.com/sentinel-hub/code-snippets/master/phiweek2020/Solution3.py\n\nRun the query (using the Evalscript of your choice) for two dates that were preselected.\n\n# Make a directory to save the request\nPath('./results/landsat/before').mkdir(parents=True, exist_ok=True)\n  \nrequest = SentinelHubRequest(evalscript=evalscript_landsat_true_color,\n                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.LANDSAT8,\n                                                                       time_interval=(\"2017-12-16\",\n                                                                                      \"2017-12-16\"))],\n                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n                            bbox=aoi,  \n                            size=aoi_size_landsat,\n                            data_folder='./results/landsat/before',\n                            config=config)\n\ntrue_color_landsat= request.get_data(save_data=True)\n\n# Make a directory to save the request\nPath('./results/landsat/after').mkdir(parents=True, exist_ok=True)\n  \nrequest = SentinelHubRequest(evalscript=evalscript_landsat_true_color,\n                             input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.LANDSAT8,\n                                                                       time_interval=(\"2018-01-17\",\n                                                                                      \"2018-01-17\"))],\n                            responses=[SentinelHubRequest.output_response('default', MimeType.TIFF)],\n                            bbox=aoi,  \n                            size=aoi_size_landsat,\n                            data_folder='./results/landsat/after',\n                            config=config)\n\ntrue_color_landsat= request.get_data(save_data=True)\n\nAs we did for Sentinel-2, fetch the latest folder and open the image with Rasterio.\n\n# Get folder name created\nfld_lb = [f for f in Path(\"./results/landsat/before\").iterdir() if f.is_dir()][0]\nfld_la = [f for f in Path(\"./results/landsat/after\").iterdir() if f.is_dir()][0]\n\n# Open raster with Rasterio\nraster_landsat_before = rasterio.open(str(fld_lb.joinpath(\"response.tiff\")))\nraster_landsat_after = rasterio.open(str(fld_la.joinpath(\"response.tiff\")))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#quizz-what-is-the-easiest-way-to-write-an-evalscript-for-landsat-true-color","position":47},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the Landsat scene saved locally and show the outline of the selected field in the database","lvl3":"Quizz: what is the easiest way to write an Evalscript for Landsat True Color?","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-landsat-scene-saved-locally-and-show-the-outline-of-the-selected-field-in-the-database","position":48},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the Landsat scene saved locally and show the outline of the selected field in the database","lvl3":"Quizz: what is the easiest way to write an Evalscript for Landsat True Color?","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nfig, (ax, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(18, 10))\n\n# Plot images before and after\nshow(raster_landsat_before, ax=ax)\nshow(raster_landsat_after, ax=ax1)\n\n# Plot the field outline over the images\ngran_chaco_subset_2018.plot(ax=ax, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\ngran_chaco_subset_2018.plot(ax=ax1, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n\n# Plot configuration\nfor axs in [ax, ax1]:\n    axs.set_xticks([])\n    axs.set_yticks([])\n\nax.set_title(\"2017-12-16\")\nax1.set_title(\"2018-01-17\")\n\nplt.show()\n\nLooking at the Landsat images in December 2017 and January 2018, provides more information on how the polygons were delineated. Indeed, owing to the revisit time of Landsat (14 days) and cloud cover, some of the deforestation events that happened end of December 2017 (as we saw in the Sentinel-2 images) were missed. The Landsat acquisition on 17th January 2018 provides more insight into the timing of the deforestation. Nevertheless, two of the polygon were already partly deforested in December 2017, which could mean that the dataset contains operator errors. The images also show that the 31st January 2018 indicated in the dataset is an arbitrary date representing the entire month of January.\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-landsat-scene-saved-locally-and-show-the-outline-of-the-selected-field-in-the-database","position":49},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#filling-in-the-gaps-or-how-to-use-data-fusion-to-mitigate-gaps-in-optical-imagery-time-series","position":50},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"In the previous section, we were able to fetch Sentinel-2 images to observe deforestation events. However, in January all the scenes acquired were completely cloud covered. As a recap, let’s just look at cloud cover for that time of year using the previous catalog request.\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 10))\n\n# Plot the cloud cover for available dates\nax.plot([dt.strptime(x[0], \"%Y-%m-%dT%H:%M:%SZ\") for x in available_data], [x[1] for x in available_data], marker='o',\n        markersize=12, linestyle=\"none\", color=\"black\")\n\n# Highlight January\nax.fill_between((dt.strptime(\"2018-01-01\", \"%Y-%m-%d\"), dt.strptime(\"2018-01-31\", \"%Y-%m-%d\")), (0,0), (100,100), color=\"red\", alpha=0.3)\n\n# Plot 10% level\nax.plot([dt.strptime(x[0], \"%Y-%m-%dT%H:%M:%SZ\") for x in available_data], [10 for x in available_data], linestyle=\"--\", linewidth=2, color=\"black\")\n\n# Plot configuration\nax.set_ylim(0,100)\nax.set_ylabel(\"Cloud cover percentage\")\nax.set_xlabel(\"Date\")\n\nplt.show()\n\nWe also know that the deforestation happened before the 17th January 2018, when looking at the Landsat image. But is there any way of checking with another satellite platform that isn’t affected by clouds?\n\nBy combining optical imagery with SAR (Synthetic Aperture Radar), the shortcomings of cloud cover can be (partly) mitigated. In this example, we will use Sentinel-1 images. Although the revisit frequency of Sentinel-1 is similar to Sentinel-2 (approximately 6 days at the equator), the additional data may be used to increase the temporal resolution of time-series regardless of local atmospheric conditions.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#filling-in-the-gaps-or-how-to-use-data-fusion-to-mitigate-gaps-in-optical-imagery-time-series","position":51},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Datafusion","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#datafusion","position":52},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Datafusion","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"We recently wrote a \n\nblog post about the new datafusion capabilities of Sentinel Hub services. Here, we will combine Sentinel-2 and Sentinel-1 images to detect deforestation event that happened in January.\n\nFirst we will use the Catalog API service again to obtain the list of available Sentinel-1 acquisitions in January 2018.\n\n# Set the Catalog API url\ncatalog_url = \"https://services.sentinel-hub.com/api/v1/catalog/\"\n\n# Set the header\nheaders = {\n  'Content-Type': 'application/json'\n}\n\n# Set the Catalog request parameters\ncollections = \"sentinel-1-grd\"  # This time, we use the Sentinel 1 collection\ndatetime= \"2018-01-01T00:00:00Z/2018-01-31T23:59:59Z\"  # Time range over January 2018\n\n# Run the catalog request\nresponse = oauth.request(\"GET\", f\"https://services.sentinel-hub.com/api/v1/catalog/collections/{collections}/items?bbox={aoi_bbox[0]},{aoi_bbox[1]},{aoi_bbox[2]},{aoi_bbox[3]}&datetime={datetime}&limit=20\", headers=headers)\ncatalog_results = response.json()\n\n# Fetch the dates and write to a list\ns1_dates = []\n\nfor entry in catalog_results[\"features\"]:\n    s1_dates.append(entry[\"properties\"][\"datetime\"])\n    \nprint(s1_dates)\n\nWith the Catalog service API, we see that there are 6 images available for January 2018.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#datafusion","position":53},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Evalscript","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#evalscript","position":54},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Evalscript","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"In the following Evalscript we will perform the following steps for each pixel in the image:\n\ncheck if the pixel’s NDVI (see below) value has dropped between December and February. If it hasn’t, we will assume there was no deforestation in January and return the Sentinel-2 True Color RGB.\n\nif the NDVI has dropped from above 0.4 to below 0.4 (an empirical threshold that we set), we then look at the backscatter between different Sentinel-1 dates.\n\nif the drop in backscatter from a date to another is larger than a given value (once again empirically determined), then we return a colour according to the date.\n\nTo perform the operations in the list above, we need:\n\nthe closest cloud-free Sentinel-2 image before January\n\nthe closest cloud-free Sentinel-2 image after January\n\nall Sentinel-1 images in January\n\nNDVI (Normalized difference vegetation index)\n\nThe well known and widely used NDVI is a simple, but effective index for quantifying green vegetation. It normalizes green leaf scattering in Near Infra-red wavelengths with chlorophyll absorption in red wavelengths.\n\nThe value range of the NDVI is -1 to 1. Negative values of NDVI (values approaching -1) correspond to water. Values close to zero (-0.1 to 0.1) generally correspond to barren areas of rock, sand, or snow. Low, positive values represent shrub and grassland (approximately 0.2 to 0.4), while high values indicate temperate and tropical rainforests (values approaching 1).\n\nHere we color coded the changes as follows:\n\n2018-01-01 -> 2018-01-02 = ORANGE\n\n2018-01-02 -> 2018-01-13 = WHITE\n\n2018-01-13 -> 2018-01-14 = BLUE\n\n2018-01-14 -> 2018-01-25 = GREEN\n\n2018-01-25 -> 2018-01-26 = RED\n\nevalscript_data_fusion = \"\"\"\n//VERSION=3\n\nfunction setup (){\n  return {\n    input: [\n      {datasource: \"s1\", bands:[\"VH\"]},\n      {datasource: \"s2_before\", bands:[\"B02\", \"B03\", \"B04\", \"B08\"]},\n      {datasource: \"s2_after\", bands:[\"B02\", \"B03\", \"B04\", \"B08\"]}],\n    output: [\n      {id: \"default\", bands: 3}\n    ],\n    mosaicking: \"ORBIT\"\n  };\n}\n  \n// visualizes decibels from -20 to 0\nfunction toDb(linear) {\n  // the following commented out lines are simplified below\n  // var log = 10 * Math.log(linear) / Math.LN10\n  // var val = Math.max(0, (log + 20) / 20)\n  return Math.max(0, Math.log(linear) * 0.21714724095 + 1)\n}\n  \nfunction evaluatePixel(samples, scenes) {\n\n  // Get samples from different specified datasources\n  var s1 = samples.s1;\n  var s2before = samples.s2_before[0];\n  var s2after = samples.s2_after[0];\n \n  // Calculate NDVI before January and after\n  let ndvi_before = index(s2before.B08, s2before.B04);\n  let ndvi_after = index(s2after.B08, s2after.B04);\n  \n  // Gain for RGB images\n  var gain = 3;\n\n  // If NDVI drop between dates is more than 0.4, query S1 data,\n  // otherwise return True Color\n  if (ndvi_before > 0.4 && ndvi_after < 0.4){\n  \n    // Db difference threshold\n    let threshold_bc = 0.2;\n      \n    // Return different dates by color\n    if (toDb(s1[5].VH) - toDb(s1[4].VH) > threshold_bc){\n      return[255/255, 153/255, 51/255]\n    } else if (toDb(s1[4].VH) - toDb(s1[3].VH)  > threshold_bc){\n      return [255/255, 255/255, 255/255]\n    } else if (toDb(s1[3].VH) - toDb(s1[2].VH)  > threshold_bc){\n      return [0, 0, 255/255]\n    } else if (toDb(s1[2].VH) - toDb(s1[1].VH)  > threshold_bc){\n      return [0, 255/255, 0]\n    } else if (toDb(s1[1].VH) - toDb(s1[0].VH)  > threshold_bc){\n      return [255/255, 0, 0] // RED\n    } else {\n      return [s2after.B04 * gain, s2after.B03 * gain, s2after.B02 * gain];\n    }\n  } else {\n    return [s2after.B04 * gain, s2after.B03 * gain, s2after.B02 * gain];\n  }\n}\n\"\"\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#evalscript","position":55},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Building the request body","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#building-the-request-body","position":56},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Building the request body","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"When calling multiple sources of satellite data, the request body is written slightly differently to a request using a single sensor. In the following request, we need to specify as inputs: the Sentinel-1 images during January, the Sentinel-2 images before and after January. The latter are called as two separate data sources to save the number of images queried.\n\nIn the input data section we show you two different ways of selecting the input parameters for the different data sources:\n\nas a dictionary, which allows more control over the parameters\n\nas a SentinelHubRequest.input_data object\n\nrequest = SentinelHubRequest(\n  evalscript=evalscript_data_fusion,\n  input_data=[\n    {'type': 'S1GRD',\n     \"id\": \"s1\",\n     \"dataFilter\": {\n          \"timeRange\": {\n            \"from\": \"2018-01-01T00:00:00Z\",\n            \"to\": \"2018-01-31T23:59:59Z\"\n          }\n        },\n     \"processing\": {\n                    \"orthorectify\": \"true\"\n                   }\n    },\n    SentinelHubRequest.input_data(\n      data_collection=DataCollection.SENTINEL2_L2A,\n      time_interval=('2017-12-31', '2017-12-31'),        \n      other_args = {\"id\":\"s2_before\"}\n    ),\n    SentinelHubRequest.input_data(\n      data_collection=DataCollection.SENTINEL2_L2A,\n      time_interval=('2018-02-04', '2018-02-04'),        \n      other_args = {\"id\":\"s2_after\"}\n    ),\n    \n  ],\n  responses=[\n    SentinelHubRequest.output_response('default', MimeType.TIFF),\n    \n  ],\n  bbox=aoi,  \n  size=aoi_size,\n  config=config\n)\ndatafusion_results = request.get_data() \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#building-the-request-body","position":57},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the resulting image","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-resulting-image","position":58},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the resulting image","lvl3":"“Filling in the Gaps” or how to use data fusion to mitigate gaps in optical imagery time series","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18, 10))\n\n# Plot the image\nax.imshow(datafusion_results[0])\n\n# Plot configuration\nfor axs in [ax, ax1]:\n    axs.set_xticks([])\n    axs.set_yticks([])\n    \npatches = [mpatches.Patch(color=\"orange\", label=\"2018-01-01 - 2018-01-02\"),\n           mpatches.Patch(facecolor=\"white\", edgecolor=\"black\", label=\"2018-01-02 - 2018-01-13\") ,\n           mpatches.Patch(color=\"blue\", label=\"2018-01-13 - 2018-01-14\"),\n           mpatches.Patch(color=\"lime\", label=\"2018-01-14 - 2018-01-25\"),\n           mpatches.Patch(color=\"red\", label=\"2018-01-25 - 2018-01-26\")]\n\nplt.legend(handles=patches, bbox_to_anchor=(1.05, 1), title=\"Deforestation timing:\", loc=2, borderaxespad=0. )\n\nax.set_title(\"Deforestation detection with Sentinel-1\")\nplt.show()\n\nThanks to the use of datafusion, we have managed to narrow down the date of deforestation, despite the large gap in optical satellite images (cloudless scenes) during January.\n\nThis approach is useful for a visual analysis of images, but is difficultly scalable. In the next section, we will touch upon the automation of the workflow for deforestation event detection.\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-resulting-image","position":59},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Thoughts about automated detection of deforestation events","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#thoughts-about-automated-detection-of-deforestation-events","position":60},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Thoughts about automated detection of deforestation events","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nAs we have seen previously, the manual delineation of deforested parcels using optical images presents several challenges. Furthermore, the method requires significant efforts and time to be scaled up to larger areas. To investigate the potential of automated detection of deforestation, we will make use of the FIS (Feature Info Service) to extract Sentinel-2 derived variables over a given period.\n\nIn the following steps, we will query NDVI values over the entire time-series of available Sentinel-2 data to investigate trends.\n\nFirst, we select a test field from our dataset. We choose a field that was fully forested in December 2017 and fully cleared in February 2018.\n\n# Select a test field\nfield = gran_chaco_subset_2018[gran_chaco_subset_2018[\"field_id\"] == 88025]\n\n# Plot the field\nIPython.display.GeoJSON(field.__geo_interface__)\n\nThe Sentinel Hub Python package also allows to use FIS. In the following steps we will build several requests in order to investigate the data in logical steps.\n\nIn the first request we will query NDVI for the period 2015-01-01 to 2018-02-14. The request looks a lot like the SentinelHubRequest previously used.\n\n# Request NDVI until February 2018\nfis_request = FisRequest(layer='NDVI',\n                         data_collection=DataCollection.SENTINEL2_L1C,\n                         geometry_list=[Geometry(field.geometry.values[0], crs=CRS.WGS84)],\n                         time=('2015-01-01', '2018-02-14'),\n                         resolution='10m',\n                         data_folder='./data',\n                         maxcc=0.1,\n                         config=config\n                         )\nndvi = fis_request.get_data(save_data=False)\n\nLet’s look at the results of our first request.\n\nFIS request returns a list of dictionaries and is difficult to read. To make the results more readable, we created a small function to convert the results to a Pandas Dataframe.\n\ndef fis_data_to_dataframe(fis_data):\n    \"\"\" Creates a DataFrame from list of FIS responses\n    \"\"\"\n    COLUMNS = ['date', 'min', 'max', 'mean', 'stDev']\n    data = []\n    for fd in fis_data:\n        for channel, channel_stats in fd.items():\n            if channel == 'C0':                \n                for stat in channel_stats:\n                    row = [dt.strptime(stat['date'], \"%Y-%m-%d\")]\n                    for column in COLUMNS[1:]:\n                        row.append(stat['basicStats'][column])\n                        data.append(row)\n        \n    # Save to pandas dataframe and reset index\n    df = pd.DataFrame(data, columns=COLUMNS).sort_values(['date']).drop_duplicates()\n    df.reset_index(drop=True, inplace=True)\n    \n    return df\n\n# Convert the FIS results to a dataframe\nndvi_df = fis_data_to_dataframe(ndvi)\n\n# Drop a date (visually identified as hazy)\nndvi_df.drop(ndvi_df.loc[ndvi_df['date']==\"2016-12-01\"].index, inplace=True)\n\nIn the next cell, we plot the results of the first request, nicely formatted in a Pandas Dataframe.\n\nndvi_df\n\nNext, we build a second request that runs from February 2018 to today, to see how NDVI evolves after deforestation has happened.\n\n# Build the request after deforestation\nfis_request = FisRequest(layer='NDVI',\n                         data_collection=DataCollection.SENTINEL2_L1C,\n                         geometry_list=[Geometry(field.geometry.values[0], crs=CRS.WGS84)],\n                         time=('2018-02-14', dt.today()),\n                         resolution='10m',\n                         data_folder='./data',\n                         maxcc=0.05,\n                         config=config\n                         )\n\n# Run the request\nndvi_updated = fis_request.get_data(save_data=False)\n\n# Convert the results to a dataframe\nndvi_df_updated = fis_data_to_dataframe(ndvi_updated)\n\nFinally, we are interested in comparing the temporal evolution of NDVI to that of a parcel that was not deforested. To do so, we selected an area that was still forested in September 2020>\n\n# We select a parcel of forest of approximately the same size of our field for comparison purposes\nforest = [ -60.19555112, -21.23150358, -60.18345680, -21.22224216]\naoi_forest = BBox(bbox=forest, crs=CRS.WGS84)\n\n# Build the request\nfis_request = FisRequest(layer='NDVI',\n                         data_collection=DataCollection.SENTINEL2_L1C,\n                         geometry_list=[aoi_forest],\n                         time=('2015-01-01', dt.today()),\n                         resolution='10m',\n                         maxcc=0.05,\n                         config=config\n                         )\n# Run the request\nforest_patch = fis_request.get_data(save_data=False)\n\n# Convert the results to a dataframe\nforest_df = fis_data_to_dataframe(forest_patch)\n\n# Drop a date (visually identified as hazy)\nforest_df.drop(forest_df.loc[forest_df['date']==\"2018-09-12\"].index, inplace=True)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#thoughts-about-automated-detection-of-deforestation-events","position":61},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the mean NDVI of the selected field over the date range","lvl3":"Thoughts about automated detection of deforestation events","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-mean-ndvi-of-the-selected-field-over-the-date-range","position":62},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the mean NDVI of the selected field over the date range","lvl3":"Thoughts about automated detection of deforestation events","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Now our data is ready, we can plot it in steps.\n\ndef plot_timeline(step=1):\n    \"\"\"Plot timeline.\"\"\"\n    \n    # Check step value\n    if (step < 1 or step >4):\n        raise ValueError(\"Step out of range 1-4\")\n        \n    # Setup subplots\n    fig = plt.figure(figsize=(18,14))\n    gs = fig.add_gridspec(2, 2)\n    ax = fig.add_subplot(gs[1, :])\n    ax2 = fig.add_subplot(gs[0, 0])\n    ax2.set_title('gs[1, :-1]')\n    ax3 = fig.add_subplot(gs[0, 1])\n    ax3.set_title('gs[1, :-1]')\n\n    ###########\n    # 1. Plot the rasters of the field as a reminder\n    show(raster_before, ax=ax2)\n    ax2.set_title(dt.strftime(available_datetimes[before_ind], \"%Y-%m-%d\"))\n    show(raster_after, ax=ax3)\n    ax3.set_title(dt.strftime(available_datetimes[after_ind], \"%Y-%m-%d\"))\n\n    # 2. Plot the mean NDVI until the deforestation\n    ndvi_df.plot(x='date', y='mean', ax=ax, linestyle='-', marker='.', label=r\"Mean NDVI of the field $\\pm 1\\sigma$\" )\n\n    # Plot the standard deviation as a shaded area\n    ax.fill_between(ndvi_df.date,\n                    (ndvi_df[\"mean\"] - ndvi_df[\"stDev\"]),\n                    (ndvi_df[\"mean\"] + ndvi_df[\"stDev\"]),\n                    alpha=0.3)\n\n    # Highlight before and after dates\n    ax.scatter([\"2017-12-31\", \"2018-02-04\"], [ndvi_df[ndvi_df[\"date\"]==\"2017-12-31\"][\"mean\"], ndvi_df[ndvi_df[\"date\"]==\"2018-02-04\"][\"mean\"]], marker=\"o\", s=65, color=\"red\")\n\n    ###########\n    if step >= 2:\n        # 2. Plot period after the identified deforestation event\n        ndvi_df_updated.plot(x='date', y='mean', ax=ax, linestyle='-', marker='.',\n                             color=\"indianred\", label=\"Period after deforestation\" )\n        ax.fill_between(ndvi_df_updated.date, ndvi_df_updated[\"mean\"] - ndvi_df_updated[\"stDev\"],\n                        ndvi_df_updated[\"mean\"] + ndvi_df_updated[\"stDev\"],\n                        alpha=0.3, color=\"indianred\")\n\n    ###########\n    if step >= 3:\n        # 3. Plot dry season months\n        ax.fill_between((\"2015-08-01\", \"2015-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n        ax.fill_between((\"2016-08-01\", \"2016-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n        ax.fill_between((\"2017-08-01\", \"2017-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n        ax.fill_between((\"2018-08-01\", \"2018-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n        ax.fill_between((\"2019-08-01\", \"2019-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n        ax.fill_between((\"2020-08-01\", \"2020-10-30\"), (0,0), (1,1), color=\"lightgrey\", alpha=0.7)\n\n    ###########\n    if step == 4:\n        # 4. Plot forest patch NDVI\n        forest_df.plot(x='date', y='mean', ax=ax, linestyle='-', marker='.', color=\"forestgreen\", label=\"Patch of forest close to AOI\" )\n    \n    # Plot configuration\n    ax.legend()\n    ax.set_ylabel(\"NDVI\")\n    ax.set_xlabel(\"Date\")\n    ax.set_ylim(0, 1)\n\n    ax.tick_params(axis='both', direction='inout', )\n    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n    ax.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n    ax.yaxis.set_ticks_position(\"both\")\n\n    for axs in [ax2, ax3]:\n        field.plot(ax=axs, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n        axs.set_xticks([])\n        axs.set_yticks([])\n\n    plt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-mean-ndvi-of-the-selected-field-over-the-date-range","position":63},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the data","lvl3":"Thoughts about automated detection of deforestation events","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-data","position":64},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the data","lvl3":"Thoughts about automated detection of deforestation events","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Plot the time series by changing the step parameter incresingly from 1 to 4, and observe the graph at each step>\n\nplot_timeline(step=4)\n\nExploring time-series of satellite imagery with FIS is an easy way to understand the data without having to query dozens of images.\n\nWhat does the time series of data tell us?\n\nStep 1:\n\nThe NDVI values have small variations over the years, but we notice a very sharp decrease at the time of the identified deforestation event (before and after deforestation are highlighted in red). Can this drop in NDVI be used to detect deforestation?\n\nStep 2:\n\nWhen looking at the entire time-series of our field until today, we notice large variations in NDVI, with high values followed by large drops. These trends represent cultivated fields that are harvested and cannot be differentiated from deforestation events.\n\nStep 3:\n\nIf we shade the dry season each year, we can see that there is a drop in NDVI for forested areas. Furthermore, the harvesting period also corresponds to the dry season. We also notice more variation in the data outside of the dry season.\n\nStep 4:\n\nBy plotting the entire time-series of available Sentinel-2 data for a forested patch close the to the selected field, we can compare trends between forested areas and areas after deforestation then cultivation. We can also see that the drop in NDVI for the forest isn’t as pronounced during the dry season than for cultivated fields.\n\nThis graph, along with the previous plots, can provide hints on how to implement an automated workflow to detect a deforestation event, without confusing deforestation with harvesting. Maybe you have some ideas? If you want to explore the subject in more detail, you can run through the following “bonus” section...\n\n\n\nEND OF GUIDED TUTORIAL\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-data","position":65},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#bonus-example-testing-the-implementation-of-an-automated-deforestation-detection-method-using-sentinel-2-images","position":66},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"If you want to continue exploring test cases of Sentinel Hub services in the Euro Data Cube, the following cells show an example workflow that automatically detects deforestation events from Sentinel-2 images.\n\nThis empirical method was designed to showcase Sentinel hub features and probably only works locally. If you think of a better solution, don’t hesitate to implement it and share it with the World through the EDC Marketplace!\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#bonus-example-testing-the-implementation-of-an-automated-deforestation-detection-method-using-sentinel-2-images","position":67},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"NDVI comparison before / after a deforestation event","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#ndvi-comparison-before-after-a-deforestation-event","position":68},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"NDVI comparison before / after a deforestation event","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nIn the previous graph, we have seen that even after a deforestation event, there are periods where the NDVI peaks, and is followed by a sharp drop.\n\nFirst, let’s inspect the difference between the maximum NDVI before the know deforestation date, and an other peak later on.\n\nLooking at the graph we will compare the True Color and NDVI images of the selected field on 2017-12-31 and 2018-11-11. We start by requesting a True Color RGB and NDVI band in the Evalscript.\n\nevalscript_multi_response = \"\"\"\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"B08\"],\n    output: [{\n        id: \"truecolor\",\n        bands: 3\n        },\n        {\n        id: \"ndvi\",\n        bands: 1,\n        sampleType: SampleType.UINT16\n        }\n    ]\n  };\n}\n\nfunction evaluatePixel(sample) {\n  let ndvi = index(sample.B08, sample.B04);\n  \n  let gain = 3.5;\n  return {\"truecolor\": [gain * sample.B04, gain * sample.B03, gain * sample.B02],\n         \"ndvi\": [10000 * ndvi + 10000]};\n}\n\"\"\"\n\nNote that we returned ndvi as UINT16 with the following operation: [10000 * ndvi + 10000]\n\nThis trick reduces the size of the returned image, as well as the number of Processing Units used with Sentinel Hub’s process API. You can then convert the returned product back to floats by doing: ndvi_float = (ndvi - 10000.)/10000.\n\nOf course, you can request the NDVI band as FLOAT32 directly if you wish.\n\n# Set AOI bounding box for our example field and image size according to desired resolution\nresolution = 10\naoi_field = BBox(bbox=field.geometry.bounds.values.tolist()[0], crs=CRS.WGS84)\naoi_field_size = bbox_to_dimensions(aoi, resolution=resolution)\n\nIn the next cell we create the request body in a loop for both dates and append the SentinelHubRequest to a list.\n\ndate_list = [\"2017-12-31\", \"2018-11-11\"]\nrequests = []\n\nfor date in date_list:\n    requests.append(SentinelHubRequest(evalscript=evalscript_multi_response,\n                                       input_data=[SentinelHubRequest.input_data(data_collection=DataCollection.SENTINEL2_L2A,\n                                                                                 time_interval=(date,\n                                                                                                date))],\n                                responses=[SentinelHubRequest.output_response('truecolor', MimeType.TIFF),\n                                           SentinelHubRequest.output_response('ndvi', MimeType.TIFF)],\n                                bbox=aoi_field,  \n                                size=aoi_field_size,\n                                config=config))\n\n# Fetch the data for both requests\nt1 = requests[0].get_data()\nt2 = requests[1].get_data()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#ndvi-comparison-before-after-a-deforestation-event","position":69},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl5":"Plot the True Color image and NDVI for the two selected dates","lvl4":"NDVI comparison before / after a deforestation event","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-true-color-image-and-ndvi-for-the-two-selected-dates","position":70},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl5":"Plot the True Color image and NDVI for the two selected dates","lvl4":"NDVI comparison before / after a deforestation event","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nfig = plt.figure(figsize=(16,14))\ngs = fig.add_gridspec(2, 2, width_ratios=(20, 20),wspace=0.1, hspace=0.1)\n\n# Setup subplots\nax = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax3 = fig.add_subplot(gs[1, 0])\nax4 = fig.add_subplot(gs[1, 1])\n\n# Plot True Color images\nax.imshow(t1[0]['truecolor.tif'])\nax1.imshow(t2[0]['truecolor.tif'])\n\n# Plot NDVI (converting to floats)\nndvi_pl = ax3.imshow((t1[0]['ndvi.tif'] - 10000.)/10000., cmap=\"Greens\", vmin=0, vmax=1)\nax4.imshow((t2[0]['ndvi.tif'] - 10000.)/10000., cmap=\"Greens\", vmin=0, vmax=1)\n\n# Plot configuration\nfor axs in [ax, ax1, ax3, ax4]:\n    axs.set_xticks([])\n    axs.set_yticks([])\n    \nax.set_ylabel(\"True Color RGB\")\nax3.set_ylabel(\"NDVI\")\nax.set_title(\"2017-12-11\")\nax1.set_title(\"2018-11-11\")\n\n# Setup colorbar\naxins = inset_axes(ax4, \n               width=\"5%\",  \n               height=\"100%\",  \n               loc='lower left',\n               bbox_to_anchor=(1.05, 0.0, 1, 1),\n               bbox_transform=ax4.transAxes,\n               borderpad=0,\n               )\n\ncb = fig.colorbar(ndvi_pl, cax=axins)\n\nplt.show()\n\nThe above image shows that it is difficult to differenciate between forest and cultures. The NDVI values are also similar between crops and forest, even though a pattern in the cultivated field is visible. Nevertheless, the values are similar if averaged over the field.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-true-color-image-and-ndvi-for-the-two-selected-dates","position":71},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Implementation of an empirical automated approach","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#implementation-of-an-empirical-automated-approach","position":72},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Implementation of an empirical automated approach","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Based on the graph of NDVI values over time, we saw that a drop in NDVI doesn’t always signify a deforestation event, and can also be linked to harvesting fields. We also saw in the plot above, that it is very difficult to differentiate the NDVi of forest and cultivated deforested parcels. However, the graph showed that the minimum NDVI observed during the dry season is higher for forested areas than for cultivated areas.\n\nBased on these observations we will design an algorithm that accounts for the following points:\n\nWe will loop through each available image (with less than 5% cloud cover) in a given period.\n\nFor each image, if the NDVI of the dry season preceding the date is higher than an arbitrary threshold, we consider that the pixel was forested the previous year.\n\nIf the pixel is considered as forested the previous year, we compare the difference in NDVI with the previous date in the time-series, looking for a large drop in NDVI. If we observe a drop (more than an arbitrary threshold), then we assume a deforestation event. However, a pixel can only be deforested once: only the first event in the time series is recorded.\n\nFirst we will set a time period (three months for this example), then use the Catalog API to fetch the valid images over our area of interest (here the overall area defined at the beginning of the Jupyter Notebook.)\n\n# Set start and end date of each period\nSTART_DATE = '2018-01-01'\nEND_DATE = '2018-03-31'\n\n# Query the period using Catalog API (if you get a token error, don't forget to request a new token higher up)\ncollections = \"sentinel-2-l1c\"\ndatetime= f\"{START_DATE}T00:00:00Z/{END_DATE}T23:59:59Z\"\n\n# Run the catalog request\nresponse = oauth.request(\"GET\", f\"https://services.sentinel-hub.com/api/v1/catalog/collections/{collections}/items?bbox={aoi_bbox[0]},{aoi_bbox[1]},{aoi_bbox[2]},{aoi_bbox[3]}&datetime={datetime}&limit=20\", headers=headers)\ncatalog_results = response.json()\n\n# Fetch the dates and cloud cover values\navailable_data = []\nfor entry in catalog_results[\"features\"]:\n    available_data.append((entry[\"properties\"][\"datetime\"], entry[\"properties\"][\"eo:cloud_cover\"]))\n\n# Make a list of dates for cloud_cover less than 5%\ncloud_free_dates = [x[0] for x in available_data if x[1] <= 5]\n\n# Reverse to match Evalscript output\ncloud_free_dates.reverse()\n\nIn the following Evalscript, we will request 4 data outputs for each available image in 2018:\n\nB02 (Blue)\n\nB03 (Green)\n\nB04 (Red)\n\nA binary product containing the “deforested” pixels (value = 1) for further processing.\n\ndeforestation_basic_evalscript = \"\"\"\n//VERSION=3\n\n// number of days with a valid image\nconst n_days = {number_days};\n\n\nfunction setup (){{\n  // Sentinel Hub's function that prepares inputs/outputs\n  return {{\n    input: [\n      // We need 2 datasources for S2L2A, because we are \n      // querying 2 different time ranges\n      {{datasource: \"l2a_winter\", bands:[\"B04\", \"B08\"]}},\n      {{datasource: \"l2a\", bands:[\"B02\", \"B03\", \"B04\", \"B08\"]}}],\n    output: [\n      {{id: \"deforestation_band\", bands: n_days , sampleType: \"UINT8\"}},\n      {{id: \"B02\", bands: n_days , sampleType: \"UINT16\"}},\n      {{id: \"B03\", bands: n_days , sampleType: \"UINT16\"}},\n      {{id: \"B04\", bands: n_days , sampleType: \"UINT16\"}}\n  ],\n  mosaicking: \"ORBIT\"\n  }};\n}}\n\n\nfunction evaluatePixel(samples, scenes) {{\n  // Sentinel Hub's function that processes the data\n  \n  var S2L2A_scenes = scenes.l2a.scenes;\n  var L2AW = samples.l2a_winter;\n  var S2L2A = samples.l2a;\n\n  // 1. Calculate the average NDVI in the winter of the previous year\n  var ndvi = 0;\n\n  for (var i = 0; i < L2AW.length; i++) {{\n    ndvi += index(L2AW[i].B08, L2AW[i].B04);\n  }}\n\n  var avg_ndvi = ndvi / L2AW.length;\n    \n  // 2. Run through all the dates in 2018 and detect deforestation events\n\n  //  Initialise data\n  var cloudless_bands = {{'B02':new Array(n_days).fill(0),\n                         'B03':new Array(n_days).fill(0),\n                         'B04':new Array(n_days).fill(0),\n                         'representation':new Array(n_days).fill(0)}};\n                         \n  var count = 0;\n  var deforestation_sum = 0;\n  var deforestation = [];\n\n  for (var j = S2L2A.length-2; j >= 0; j--){{\n    if (index(S2L2A[j+1].B08, S2L2A[j+1].B04) - index(S2L2A[j].B08, S2L2A[j].B04) > 0.2){{\n      if (avg_ndvi >= 0.35 && deforestation_sum == 0 && index(S2L2A[j].B08, S2L2A[j].B04) < 0.4){{\n        deforestation.push(1);\n        deforestation_sum += 1;\n      }} else {{\n        deforestation.push(0);\n      }}\n    }} else{{\n      deforestation.push(0);\n    }}\n    // Fill bands with data\n    cloudless_bands['B02'][count] = S2L2A[j].B02 * 65535;\n    cloudless_bands['B03'][count] = S2L2A[j].B03 * 65535;\n    cloudless_bands['B04'][count] = S2L2A[j].B04 * 65535;\n    \n    count += 1;\n  }}\n  \n\n  return {{\"deforestation_band\": deforestation,\n          \"B02\": cloudless_bands.B02,\n          \"B03\": cloudless_bands.B03,\n          \"B04\": cloudless_bands.B04}};\n}}\n\"\"\"\n\nIn the follwing cell we build the request, and run it, saving the results to a file, since we want to open the files with rasterio to vectorise the results.\n\nrequest = SentinelHubRequest(\n  evalscript=deforestation_basic_evalscript.format(number_days=len(cloud_free_dates)-1),\n  input_data=[\n    SentinelHubRequest.input_data(\n      data_collection=DataCollection.SENTINEL2_L2A,\n      time_interval=(START_DATE, END_DATE),        \n      other_args = {\"dataFilter\":{\"maxCloudCoverage\":\"5\"},\"id\":\"l2a\"}\n    ),\n    SentinelHubRequest.input_data(\n      data_collection=DataCollection.SENTINEL2_L2A,\n      time_interval=('2017-08-01', '2017-10-01'),        \n      other_args = {\"dataFilter\":{\"maxCloudCoverage\":\"5\"},\"id\":\"l2a_winter\"}\n    ),\n    \n  ],\n  responses=[\n    SentinelHubRequest.output_response('deforestation_band', MimeType.TIFF),\n    SentinelHubRequest.output_response('B02', MimeType.TIFF),\n    SentinelHubRequest.output_response('B03', MimeType.TIFF),\n    SentinelHubRequest.output_response('B04', MimeType.TIFF),\n    \n  ],\n  bbox=aoi_overview,  \n  size=aoi_overview_size,\n  data_folder='./results/deforestation',\n\n  config=config\n)\nresponse = request.get_data(save_data=True) \n\nThe response is stored as a tar, so we need to decompress it.\n\n# Fetch folder created in the destination directory\nfld_d = [f for f in Path(\"./results/deforestation/\").iterdir() if f.is_dir()][0]\n\n# Extract the tar file\nwith tarfile.open(fld_d.joinpath(\"response.tar\") , 'r') as tar:\n    tar.extractall(path=fld_d)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#implementation-of-an-empirical-automated-approach","position":73},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the automatically detected deforested areas on the RGB image","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-automatically-detected-deforested-areas-on-the-rgb-image","position":74},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Plot the automatically detected deforested areas on the RGB image","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"\n\nFor easier plotting we will define a function.\n\ndef plot_fields_RGB(r, g, b, fields, t=0, gain=2, alpha=0.5, title=None):\n    \n    rgb_stack = np.stack((r[:,:,t], g[:,:,t], b[:,:,t]), axis=2)\n    deforested_plots = np.ma.masked_where(fields[:,:,t] == 0, fields[:,:,t])\n\n\n    # make a color map of fixed colors\n    cmap = colors.ListedColormap(['red'])\n    bounds=[0,1]\n    norm = colors.BoundaryNorm(bounds, cmap.N)\n\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,20))\n    ax.imshow(rgb_stack * gain)\n    ax.imshow(deforested_plots, cmap=cmap, norm=norm, interpolation='none', alpha=alpha)\n    \n    # Plot configuration\n    ax.set_xticks([])\n    ax.set_yticks([])\n    \n    patches = [mpatches.Patch(color=\"red\", label=\"Deforested area\", alpha=0.9)]\n    plt.legend(handles=patches, loc=2)\n\n    ax.set_title(title)\n    plt.show()\n\nSince we are running a per-pixel analysis in the Evalscript, noise may appear in the results. We have defined a function in the cell below that allows us to remove spurious pixels and return a “cleaner” result.\n\n# Clean deforestation band\ndef erode_dilate(array, size, dim=0):\n    \n    if dim >= 1:\n        er = morphology.grey_erosion(array, size=(size, size, dim))\n        dil = morphology.grey_dilation(er, size=(size, size, dim))\n    else:\n        er = morphology.grey_erosion(array, size=(size, size))\n        dil = morphology.grey_dilation(er, size=(size, size))\n    \n    \n    return dil\n\n# Fetch the responses from the returned variable and assign them to individual variables\n# The division by 65535 converts the UINT16 DN back to Reflectance\nB02 = response[0]['B02.tif'] / 65535\nB03 = response[0]['B03.tif'] / 65535\nB04 = response[0]['B04.tif'] / 65535\n\n# Clean the deforested array \ndeforest_raster = erode_dilate(response[0][\"deforestation_band.tif\"], 3, dim=1)\n\n# Free the returned variavle from our SentinelHub request\nresponse = None\n\nFinally we can plot the data in the next cell. In the function below, t corresponds to the time slice, gain to the multiplication factor of the RGB image for visualisation, and we fetch the time step from the catalog API (the date corresponds to t + 1, since we skip the first timestep in the Evalscript)\n\n# Plot the RGB image for a date with the raster\nplot_fields_RGB(B04, B03, B02, deforest_raster, t = 0, gain=3, title=cloud_free_dates[1])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#plot-the-automatically-detected-deforested-areas-on-the-rgb-image","position":75},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Convert results to polygons","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#convert-results-to-polygons","position":76},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"Convert results to polygons","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Now that we have saved the binary deforestation raster locally, we can use rasterio to convert the raster to polygons, in order to update the database that we queried at the start of this notebook.\n\n# Open the deforestation band\ndeforestation_raw = []\ndeforestation_cleaned = []\n\nwith rasterio.open(fld_d.joinpath(\"deforestation_band.tif\")) as dataset:\n    # Loop over bands\n    for bnd in range(dataset.count):\n        dataset_band = dataset.read(bnd+1)\n       \n        # Clean the polygons with an erosion / dilation step\n        clean_defor = erode_dilate(dataset_band, 3)\n        \n        # Calculate polygons from both cleaned and raw rasters\n        raw_shapes = list(rasterio.features.shapes(dataset_band,\n                                                   transform=dataset.transform))\n        clean_shapes = list(rasterio.features.shapes(clean_defor,\n                                                     transform=dataset.transform))\n\n        raw_polygons = [shape(geom) for geom, value in raw_shapes if value == 1]\n        clean_polygons = [shape(geom) for geom, value in clean_shapes if value == 1]\n\n        # Make a multipolygon and conver to GeoSeries\n        deforestation_raw.append(geopandas.GeoSeries(unary_union(raw_polygons)))\n        deforestation_cleaned.append(geopandas.GeoSeries(unary_union(clean_polygons)))\n\nLet’s compare the polyons from the first time step to see how the cleaning step performs.\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(18,12))\n\nraw = deforestation_raw[0].plot(ax=ax, color=\"red\", label=\"Raw deforestation detection band\")\nclean = deforestation_cleaned[0].plot(ax=ax, color=\"black\", label=\"Cleaned deforestation detection band\")\n\n# Plot configuration\nax.set_xlim(-60.20, -60.26)\nax.set_xticks([])\nax.set_yticks([])\nplt.show()\n\nIn the plot above, the raw deforestation polygons are plotted in red and the cleaned polygons in black. The erosion dilation step removes a lot of individual scattered pixels, but is a little too “agressive” in some of the plots. Nevertheless, most fields are correctly represented and noise is removed.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#convert-results-to-polygons","position":77},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"“Looping the loop”: adding the polygons back into a dataframe","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#looping-the-loop-adding-the-polygons-back-into-a-dataframe","position":78},{"hierarchy":{"lvl1":"ESA EO \\phi- week 2020","lvl4":"“Looping the loop”: adding the polygons back into a dataframe","lvl3":"Bonus example: testing the implementation of an automated deforestation detection method using Sentinel-2 images","lvl2":"Side Event 2: Euro Data Cube - Hands-on Tutorial and Training Session"},"content":"Now we have a set of polygons representing deforestation, we can add them into our existing dataset.\n\n# Create a geopandas with our polygons\nrdf = geopandas.GeoDataFrame(pd.concat(deforestation_cleaned, ignore_index=True) )\n\n# Add metadata\nrdf[\"pais\"] = \"Paraguay\"\nrdf[\"prov_dep\"] = \"Boquerón\"\nrdf[\"date\"] = [x.split(\"T\")[0] for x in cloud_free_dates[1:]]\n\n# Rename the geometry column\nrdf.rename(columns={0: 'geometry'}, inplace=True)\n\n# Show the created geopandas\nrdf\n\nNow we have a correctly formatted geopandas Dataframe, we can append it to the database that we queried at the start of this tutorial.\n\ngran_chaco_updated = gran_chaco.append(rdf)\n\n# Let's look at the updated dataframe\ngran_chaco_updated\n\nIn this example we only filled out basic information, in the previous steps, you can calculate more of the parameters listed in the table. For now, let’s compare the polygons in the original dataset, with those in the updated dataset.\n\nfig, (ax, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18,12))\n\n# Plot  datasets\ngran_chaco.plot(ax=ax)\ngran_chaco_updated.plot(ax=ax2)\n\nplt.show()\n\nWe can see that we have detected more deforestation events in February and March 2018, a promising result. To share the dataset using geoDB, please refer to the free tutorial Jupyter Notebooks in the Marketplace.\n\nAs mentioned earlier, this basic approach is empirical and may not be robust for different areas/time of year. The goal was to get you started in creating your own scripts, and we hope to see new exciting algorithms in EDC...","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/gran-chaco-phiweek#looping-the-loop-adding-the-polygons-back-into-a-dataframe","position":79},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621","position":0},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API"},"content":"This notebook is based on the \n\nLand-User-Land-Cover Prediction example described in the \n\nEOLearn documentation. The example workflow uses EOLearn to construct a machine learning pipeline for predicting the land use / land cover for the region of the Republic of Slovenia. The import of satellite images to train a model which is then used for the predictions is performed using an \n\nEOTask based on Sentinel Hub’s \n\nprocess API. While this approach is efficient for most applications, querying large volumes of data and performing the processing steps locally can complicate scaling to larger areas (country or continent-wide analysis for example).\n\nIn this notebook, we present an alternative workflow, where the acquisition of the satellite data, processing of derived products and resampling over a fixed timestep is performed with Sentinel Hub services. The process allows for much faster processing times over large areas, reduced costs and the user needs less computational resources to process the data.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621","position":1},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"Before you start"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#before-you-start","position":2},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"Before you start"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#before-you-start","position":3},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Requirements","lvl3":"Before you start"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#requirements","position":4},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Requirements","lvl3":"Before you start"},"content":"In order to run the example you will need an EDC Sentinel Hub API access (Enterprise plan) to access satellite data and an \n\nAmazon Bucket to save the outputs to.\n\nTo configure the notebook to work with your Sentinel Hub account you can use the edc configurator as shown below. You will also need to specify your Amazon Bucket access credentials (user id and secret for \n\nprogrammatic access).\n\nNote: You may need to update the eolearn and sentinelhub package to the latest version.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#requirements","position":5},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Input data","lvl3":"Before you start"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#input-data","position":6},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Input data","lvl3":"Before you start"},"content":"You can access the example input data from the \n\nGithub repository\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#input-data","position":7},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"Overview"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#overview","position":8},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"Overview"},"content":"This notebook is organised in 2 main sections:\n\nPart 1 is dedicated to creating and running the Batch Process with \n\nSentinel Hub Python package.\n\nPart 2 focusses on converting the results obtained in Part 1 to \n\nEOPatches, the format used in \n\nEOLearn.\n\nPart 3 shows how to integrate the workflow into the \n\nLULC pipeline to predict LULC using machine learning algorithms.\n\nLet’s start!\n\n# Basics of Python data handling and visualization\nimport numpy as np\nimport geopandas as gpd\nfrom shapely.geometry import Polygon\nfrom shapely.wkt import loads\nimport rasterio\n\n# Sentinel Hub\nfrom sentinelhub import (SentinelHubBatch, SentinelHubRequest, Geometry, CRS, BBox, DataCollection, MimeType, SHConfig,\n                         BatchSplitter)\n\n# EOLearn\nfrom eolearn.core import (EOPatch, EONode, EOWorkflow, EOExecutor, OverwritePermission, FeatureType, SaveTask, LoadTask,\n                          linearly_connect_tasks)\nfrom eolearn.geometry import VectorToRasterTask, ErosionTask\nfrom eolearn.ml_tools import FractionSamplingTask\n\n# Amazon\nimport boto3\n\n# Utilities\nfrom pathlib import Path, PosixPath\nimport datetime\nfrom tqdm.auto import tqdm\nfrom fs_s3fs import S3FS\nfrom fs import open_fs\nfrom aenum import MultiValueEnum\nfrom time import sleep\n\n# Visualisation\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap, BoundaryNorm\nfrom matplotlib.patches import Patch\n\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#overview","position":9},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl2":"Part 1: create and run the Batch process"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#part-1-create-and-run-the-batch-process","position":10},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl2":"Part 1: create and run the Batch process"},"content":"Run Sentinel Hub Batch Processing to request data for an area of interest, and download the satellite products (bands and derived products) to an Amazon S3 Bucket.\n\nFirst specify Amazon S3 bucket client ID and secret (See Requirements above)\n\nAWS_ID = \"aws-client-id\"\nAWS_SECRET = \"aws-client-secret\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#part-1-create-and-run-the-batch-process","position":11},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"Sentinel Hub authentification","lvl2":"Part 1: create and run the Batch process"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#sentinel-hub-authentification","position":12},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"Sentinel Hub authentification","lvl2":"Part 1: create and run the Batch process"},"content":"In the following cell, we will create an instance of sentinelhub.SHConfig for the Sentinel Hub services. The token is only valid for 1 hour. If you get an message of type  accessToken signature expired later in the workflow, just re-run the next cell. See more \n\ninformation here\n\n# Set up credentials for use with batch\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\nif config.sh_client_id == '' or config.sh_client_secret == '':\n    print(\"Warning! To use Sentinel Hub services, please provide the credentials (client ID and client secret).\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#sentinel-hub-authentification","position":13},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"1.1 Define the Area-of-Interest (AOI):","lvl2":"Part 1: create and run the Batch process"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-1-define-the-area-of-interest-aoi","position":14},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"1.1 Define the Area-of-Interest (AOI):","lvl2":"Part 1: create and run the Batch process"},"content":"Although the Sentinel Hub Batch processing is designed for large areas, running this example Notebook for the entire Republic of Slovenia would be costly (in terms of storage and processing units used). To make the example reproducible, we will run the example for a smaller region: the administrative boundaries of the capital, Ljubljana.\n\nA geographical shape of Slovenia was taken from \n\nthis webpage. The region of Ljubljana was extracted using QGIS and saved as a new geojson. In the following cell the geojson is imported and a buffer of 500 m is applied to it (to make sure to cover the entire extent). The shape svn_border.geojson is available \n\nhere.\n\nBecause the Batch Processing API can’t process shapes with too many coordinates (up to 1500 points are supported), a simplified polygon covering the extent of the geographical shape is created (using simplify), and the coordinates extracted. In the current example, this step is optional, but was included for demonstration purposes.\n\nThe shape is split into smaller tiles by the batch process (see further down).\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-1-define-the-area-of-interest-aoi","position":15},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"1.1.1 Import data, plot AOI, and check the points count","lvl3":"1.1 Define the Area-of-Interest (AOI):","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-1-1-import-data-plot-aoi-and-check-the-points-count","position":16},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"1.1.1 Import data, plot AOI, and check the points count","lvl3":"1.1 Define the Area-of-Interest (AOI):","lvl2":"Part 1: create and run the Batch process"},"content":"\n\nljubljana_data = {\n    \"adm1_code\": \"SVN-962\",\n    \"Shape_Leng\": 1.01284310866,\n    \"Shape_Area\": 0.0321361298149,\n    \"diss_me\": 962,\n    \"adm1_code_\": \"SVN-962\",\n    \"iso_3166_2\": \"SI-\",\n    \"wikipedia\": None,\n    \"sr_sov_a3\": \"SVN\",\n    \"sr_adm0_a3\": \"SVN\",\n    \"iso_a2\": \"SI\",\n    \"adm0_sr\": 1,\n    \"admin0_lab\": 2,\n    \"name\": \"Osrednjeslovenska\",\n    \"name_alt\": \"Ljubljana\",\n    \"name_local\": None,\n    \"type\": \"Statisticna Regije\",\n    \"type_en\": \"Statistical Region\",\n    \"code_local\": None,\n    \"code_hasc\": \"SI.LJ\",\n    \"note\": None,\n    \"hasc_maybe\": None,\n    \"region\": None,\n    \"region_cod\": None,\n    \"region_big\": None,\n    \"big_code\": None,\n    \"provnum_ne\": 111,\n    \"gadm_level\": 2,\n    \"check_me\": 0,\n    \"scalerank\": 10,\n    \"datarank\": 8,\n    \"abbrev\": None,\n    \"postal\": \"LJ\",\n    \"area_sqkm\": 0.0,\n    \"sameascity\": -99,\n    \"labelrank\": 10,\n    \"featurecla\": \"Admin-1 scale rank\",\n    \"admin\": \"Slovenia\",\n    \"name_len\": 17,\n    \"mapcolor9\": 2,\n    \"mapcolor13\": 12,\n    \"geometry\": loads(\"POLYGON ((926425.6431983189 5123589.170469966, 928023.7898916167 5121898.015502713, 930381.3263176056 5121120.044066284, 932172.4018085758 5120986.554265775, 932397.4164062712 5120015.896563099, 932581.6593906969 5119111.593260468, 934172.9482895343 5118295.244651059, 935552.5077836656 5118035.394490954, 937426.0230920448 5118284.182013701, 938974.6457346278 5118919.953589984, 939436.4214525614 5118863.607289625, 940115.1034137213 5118470.883597136, 941661.5894687981 5118743.682363604, 942560.1680774961 5118144.887344502, 942735.089611518 5117724.728520735, 943609.3171581865 5117355.118745014, 943441.7280510126 5116506.263347512, 943476.1717744432 5116029.795751704, 943357.5915462442 5115669.221437243, 943883.7408222458 5115060.955142928, 944401.2580603813 5114573.278955945, 944833.0906094413 5113938.04334936, 945085.8948330702 5113278.305480363, 944854.481928225 5112644.071482883, 945156.6899264865 5110470.215581522, 944463.2053827948 5109883.358539728, 943213.6218703112 5110424.993391757, 942450.1435025067 5110975.866591577, 942002.8597709246 5111157.176478082, 941344.5252792852 5111086.772156567, 940250.6079617536 5110362.048641361, 939987.9768291702 5109818.169601077, 939577.3549704123 5109318.540062902, 938375.9969106899 5108514.419667248, 936051.6183637844 5108285.692598732, 934876.7259672079 5109033.28003256, 932469.7213315063 5110954.777737652, 930583.1400775139 5111205.907107501, 928967.0312091864 5110810.191967965, 928500.3034628865 5110414.20558999, 928620.5574546311 5109381.365577888, 928509.1394418445 5107865.126862759, 926900.3871498384 5108624.263870159, 926099.3870347773 5108522.555558871, 924410.7564367288 5107768.401844963, 923998.0565383206 5106756.500797831, 921805.3913033886 5105602.201608885, 921016.5103012786 5106199.915835703, 921000.6721904315 5106960.150802306, 921510.2298354742 5107796.748059389, 922130.4894534599 5108482.394295073, 922543.3747806235 5109142.328402843, 922331.4077197406 5109594.952222921, 921330.1897642646 5110247.196747772, 920127.357732374 5111618.263417895, 920919.0829407133 5112200.206929425, 920960.7590644892 5112471.259680815, 920960.1393605953 5113007.610408505, 920817.7315732187 5114030.260011839, 920568.43797675 5114679.336590691, 920342.5783931809 5115162.761556501, 920144.6578527923 5115414.51555307, 919381.6598506232 5117060.85083882, 919108.5832219544 5117356.510004638, 918652.2145139208 5117515.658383243, 918148.0906285422 5117492.790082054, 919763.7540312987 5118866.304184149, 920148.1329041517 5119054.139046485, 920302.0922611563 5119266.565990494, 920048.0836169412 5119635.582898952, 919720.6514727444 5120022.646377376, 919448.8270490387 5120476.973462088, 919145.8071278529 5121211.784814458, 918820.2671607826 5121397.144247358, 918838.9195219886 5121652.192733762, 918920.7809071594 5122038.452927704, 919230.1471832383 5122440.292463314, 919706.9407822394 5122680.600692804, 920717.1690435053 5122744.185280813, 921763.7085836534 5123444.913719906, 922373.4495737455 5124545.402263708, 922960.0301947873 5124063.914497981, 923791.9073106179 5124210.8840452, 925808.8960918575 5125017.186416848, 926425.6431983189 5123589.170469966))\")\n}\n\n# Folder where data for running the notebook is stored\nINPUT_DATA = Path(\"./data/\") \n\n# Load geojson file\n# country = gpd.read_file(INPUT_DATA.joinpath('ljubljana.geojson'))\ncountry = gpd.GeoDataFrame(ljubljana_data, crs=\"EPSG:32632\", index=[0])\n\n# Apply a 500m buffer to the shape (indicate a specific feature with [i])\ncountry_buffer = country[country.geometry.name][0].buffer(500)\n\n# Get the country's shape in polygon format\ncountry_shape = country.geometry.values[-1]\n\n# Plot country\ncountry.plot()\nplt.axis('off')\n\n# Print size and points count\nprint('Dimension of the area is {0:.0f} x {1:.0f} m2'.format(country_shape.bounds[2] - country_shape.bounds[0],\n                                                             country_shape.bounds[3] - country_shape.bounds[1]))\nprint('Points count after buffer: ', len(list(country_buffer.exterior.coords)))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-1-1-import-data-plot-aoi-and-check-the-points-count","position":17},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"1.1.2 Get simplified bands and plot geographical extent  that will be used in requests","lvl3":"1.1 Define the Area-of-Interest (AOI):","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-1-2-get-simplified-bands-and-plot-geographical-extent-that-will-be-used-in-requests","position":18},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"1.1.2 Get simplified bands and plot geographical extent  that will be used in requests","lvl3":"1.1 Define the Area-of-Interest (AOI):","lvl2":"Part 1: create and run the Batch process"},"content":"Note: Make sure the points count does not exceed 1500 points after simplification.\n\n# Get the simplified shape of the country\ncountry_sim = country_buffer.simplify(100) #unit in meter\n\n# Check the amount of points forming the polygon\nprint('Points count: ',len(list(country_sim.exterior.coords)))\n\n# Plot shape\nplt.figure()\nplt.axis('off')\nplt.plot(*country_sim.exterior.xy)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-1-2-get-simplified-bands-and-plot-geographical-extent-that-will-be-used-in-requests","position":19},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-2-use-batch-to-fetch-sentinel-2-data-and-resample-to-even-timesteps","position":20},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"Now that the area of interest is defined, we will set up the parameters necessary to run the Batch process, and go through the different steps to acquire the data.\n\nWe will collect Sentinel-2 data and retrieve the following products:\n\nL1C custom list of bands [B02, B03, B04, B08, B11, B12], which corresponds to [B, G, R, NIR, SWIR1, SWIR2] wavelengths.\n\nCalculated NDVI, NDWI, and NDBI information\n\nA mask of validity, based on acquired data from Sentinel and cloud coverage. Valid pixel is if:\n\nIS_DATA == True\n\nCLOUD_MASK == 0 (1 indicates cloudy pixels and 255 indicates NO_DATA)\n\nAll returned products will be returned for specific time intervals between 2 dates. If no data is present on the interval date, the service returns a linear interpolation between the previous and following valid data. The Batch request merges the \n\nEOLearn data download step and \n\ntraining data preparation step into one.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-2-use-batch-to-fetch-sentinel-2-data-and-resample-to-even-timesteps","position":21},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"1.2.1 Prepare Batch input parameters","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-2-1-prepare-batch-input-parameters","position":22},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"1.2.1 Prepare Batch input parameters","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"Here we set the start and end date of the time interval that we want to query, as well as a time step in days for which data will be returned.\n\nWe also specify the name of the Amazon S3 Bucket that was created and parameterised as shown earlier.\n\n# Date parameters: for this example, we will get data from early April to late October.\nSTART = datetime.date(2019, 4, 1)\nEND = datetime.date(2019, 10, 31)\n\nINTERVAL = 15  # Interval for date resampling in days\n\n# Calculate list of dates for the resampling\ndate_iterator = START\ntimestamps = []\nwhile date_iterator < END:\n    timestamps.append(date_iterator)\n    date_iterator = date_iterator + datetime.timedelta(days=INTERVAL)\n    \n# Amazon bucket name\naws_bucket_name = \"my-amazon-bucket\"\n\nBelow, we define the evalscript that will perform all the work on Sentinel Hub servers. The script fetches the images, calculates the indices (NDVI, NDWI, and NDBI), and resamples the data to the defined interval.\n\nevalscript = \"\"\"\n//VERSION=3\n\n// Calculate number of bands needed for all intervals\n// Initialise dates and interval\n// Beware: in JS months are 0 indexed\nvar start_date = new Date(2019, 3, 1, 0, 0, 0);\nvar end_date = new Date(2019, 9, 31, 0, 0, 0);\nvar sampled_dates = sample_timestamps(start_date, end_date, 15, 'day').map(d => withoutTime(d));\nvar nb_bands = sampled_dates.length;\nvar n_valid = 0;\nvar n_all = 0;\n\nfunction interval_search(x, arr) {\n  let start_idx = 0,  end_idx = arr.length - 2;\n\n  // Iterate while start not meets end\n  while (start_idx <= end_idx) {\n    // Find the mid index\n    let mid_idx = (start_idx + end_idx) >> 1;\n\n    // If element is present at mid, return True\n    if (arr[mid_idx] <= x && x < arr[mid_idx + 1]) {\n      return mid_idx;\n    }\n    // Else look in left or right half accordingly\n    else if (arr[mid_idx + 1] <= x) start_idx = mid_idx + 1;\n    else end_idx = mid_idx - 1;\n  }\n  if (x == arr[arr.length-1]){\n    return arr.length-2;\n  }\n\n  return undefined;\n}\n\nfunction linearInterpolation(x, x0, y0, x1, y1, no_data_value=NaN) {\n  if (x < x0 || x > x1) {\n    return no_data_value;\n  }\n  var a = (y1 - y0) / (x1 - x0);\n  var b = -a * x0 + y0;\n  return a * x + b;\n}\n\nfunction lininterp(x_arr, xp_arr, fp_arr, no_data_value=NaN) {\n  results = [];\n  data_mask = [];\n  xp_arr_idx = 0;\n  for(var i=0; i<x_arr.length; i++){\n    var x = x_arr[i];\n    n_all+=1;\n    interval = interval_search(x, xp_arr);\n    if (interval === undefined) {\n      data_mask.push(0);\n      results.push(no_data_value);\n      continue;\n    }\n    data_mask.push(1);\n    n_valid+=1;\n    results.push(\n      linearInterpolation(\n        x,\n        xp_arr[interval],\n        fp_arr[interval],\n        xp_arr[interval+1],\n        fp_arr[interval+1], \n        no_data_value\n      )\n    );\n  }\n\n  return [results, data_mask];\n}\n\n\nfunction interpolated_index(index_a, index_b){\n  // Calculates the index for all bands in array\n  var index_data = [];\n  for (var i = 0; i < index_a.length; i++){\n     // UINT index returned\n     let ind = (index_a[i] - index_b[i]) / (index_a[i] + index_b[i]);\n     index_data.push(ind * 10000 + 10000);\n  }\n  \n  return index_data\n}\n\n\nfunction increase(original_date, period, period_unit){\n    date = new Date(original_date)\n    switch(period_unit){\n        case 'millisecond':\n            return new Date(date.setMilliseconds(date.getMilliseconds()+period));\n        case 'second':\n            return new Date(date.setSeconds(date.getSeconds()+period));\n        case 'minute':\n            return new Date(date.setMinutes(date.getMinutes()+period));\n        case 'hour':\n            return new Date(date.setHours(date.getHours()+period));\n        case 'day':\n            return new Date(date.setDate(date.getDate()+period));\n        case 'month':\n            return new Date(date.setMonth(date.getMonth()+period));\n        default:\n            return undefined\n    }\n}\n\nfunction sample_timestamps(start, end, period, period_unit) {\n    var cDate = new Date(start);\n    var sampled_dates = []\n    while (cDate < end) {\n        sampled_dates.push(cDate);\n        cDate = increase(cDate, period, period_unit);\n    }\n    return sampled_dates;\n}\n\nfunction is_valid(smp){\n  // Check if the sample is valid (i.e. contains no clouds or snow)\n  let clm = smp.CLM;\n  let dm = smp.dataMask;\n\n  if (clm === 1 || clm === 255) {\n        return false;\n  } else if (dm !=1 ) {\n        return false;\n  } else {\n  return true;\n  }\n}\n\nfunction withoutTime(intime){\n  // Return date without time\n  intime.setHours(0, 0, 0, 0);\n  return intime;\n}\n\n\n// Sentinel Hub functions\nfunction setup() {\n  // Setup input/output parameters\n    return {\n        input: [{\n            bands: [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"B12\", \"CLM\", \"dataMask\"],\n            units: \"DN\"\n        }],\n      output: [\n          {id: \"B02\", bands: nb_bands, sampleType: SampleType.UINT16},\n          {id: \"B03\", bands: nb_bands, sampleType: SampleType.UINT16},\n          {id: \"B04\", bands: nb_bands, sampleType: SampleType.UINT16},\n          {id: \"B08\", bands: nb_bands, sampleType: SampleType.UINT16},\n          {id: \"B11\", bands: nb_bands, sampleType: SampleType.UINT16},\n          {id: \"B12\", bands: nb_bands, sampleType: SampleType.UINT16},\n          {id: \"NDVI\", bands: nb_bands, sampleType: SampleType.UINT16},\n          {id: \"NDWI\", bands: nb_bands, sampleType: SampleType.UINT16},\n          {id: \"NDBI\", bands: nb_bands, sampleType: SampleType.UINT16},\n          {id: \"data_mask\", bands: nb_bands, sampleType: SampleType.UINT8}\n      ],\n    mosaicking: \"ORBIT\"\n    }\n}\n\n\n// Evaluate pixels in the bands\nfunction evaluatePixel(samples, scenes) {\n  \n  // Initialise arrays\n  var valid_samples = {'B02':[], 'B03':[], 'B04':[], 'B08':[], 'B11':[], 'B12':[]}; \n  \n  var valid_dates = []\n  // Loop over samples. \n  for (var i = samples.length-1; i >= 0; i--){\n      if (is_valid(samples[i])) {\n        valid_dates.push(withoutTime(new Date(scenes[i].date)));\n        valid_samples['B02'].push(samples[i].B02);\n        valid_samples['B03'].push(samples[i].B03);\n        valid_samples['B04'].push(samples[i].B04);\n        valid_samples['B08'].push(samples[i].B08);\n        valid_samples['B11'].push(samples[i].B11);\n        valid_samples['B12'].push(samples[i].B12);\n      }\n  }\n  \n  var [b02_interpolated, b02_dm] = lininterp(sampled_dates, valid_dates, valid_samples['B02'], 0);\n  var [b03_interpolated, b03_dm] = lininterp(sampled_dates, valid_dates, valid_samples['B03'], 0);\n  var [b04_interpolated, b04_dm] = lininterp(sampled_dates, valid_dates, valid_samples['B04'], 0);\n  var [b08_interpolated, b08_dm] = lininterp(sampled_dates, valid_dates, valid_samples['B08'], 0);\n  var [b11_interpolated, b11_dm] = lininterp(sampled_dates, valid_dates, valid_samples['B11'], 0);\n  var [b12_interpolated, b12_dm] = lininterp(sampled_dates, valid_dates, valid_samples['B12'], 0);\n\n  // Calculate indices and return optimised for UINT16 format (will need unpacking)\n  var ndvi = interpolated_index(b08_interpolated, b04_interpolated);\n  var ndwi = interpolated_index(b03_interpolated, b08_interpolated);\n  var ndbi = interpolated_index(b11_interpolated, b08_interpolated);\n  \n  // Return all arrays\n  return {\n            B02: b02_interpolated,\n            B03: b03_interpolated,\n            B04: b04_interpolated,\n            B08: b08_interpolated,\n            B11: b11_interpolated,\n            B12: b12_interpolated,\n            NDVI: ndvi,\n            NDWI: ndwi,\n            NDBI: ndbi,\n            data_mask: b02_dm\n  }\n}\n\"\"\"\n\nNext, we set the parameters passed to the SentinelHubRequest() and the SentinelHubBatch() to run the batch processing request.\n\nThe following parameters are specified:\n\nevalscript: the evalscript that was written above.\n\ngeometry: the geometry parameters representing the area of interest.\n\nThe input type should be class 'shapely.geometry.polygon.Polygon' returned from \n\nthe “geometry” column (gdf[gdf.geometry.name][i]).\n\ncrs: the code corresponding to the projection parameters of the input data.\n\nSee the \n\ninput format of the CRS helper for constant or enter in the following format: \"EPSG: 3035\".\n\ndatasource: the parameters for the data to query.\n\nSee the most commonly used \n\npredefined datacollections or \n\ndefine a new data collection\n\ntime_interval: the start and end dates set the time period over which to fetch the data.\n\nmosaickingOrder: Choose from \"mostRecent\", \"leastRecent\", and \"leastCC\" (more \n\ninfo).\n\nupsampling/downsampling: Choose from \"NEAREST\", \"BILINEAR\", and \"BICUBIC\" (\n\nexamples for Sentinel-2).\n\noutput_type: Use MimeType to select a data type of the output response returned by the evalscript (more \n\ninfo).\n\ntilingGridId and resolution: these parameters parameters allow to set the grid and resolution of the images returned. To know which paramters to set, refer to the \n\ndedicated documentation. Here we return:\n\ntilingGridId = 1, since less computation power is required for 10km grid. Larger tiling grids require more computational ressources.\n\nresolution = 10, which means our images will have a 10m resolution\n\nbuffer: (Optional) A \n\nbuffer around each tile can be defined.\n\nSet in the following format: (int,int) or None.\n\nbucketName: the \n\nconfigured Amazon S3 Bucket\n\ndescription: A personalised description for the request.\n\nEvalscript = evalscript\ngeometry = country_sim\ncrs = CRS.UTM_32N\ndatasource = DataCollection.SENTINEL2_L1C\ntime_interval = (START, END)\nmosaickingOrder = \"mostRecent\"\nmaxCloudCoverage = 1.0\nupsampling = \"NEAREST\"\ndownsampling = \"NEAREST\"\noutput_type = MimeType.TIFF \ntilingGridId = 1 \nresolution = 10 \nbuffer = (0, 0)\nbucketName = aws_bucket_name \ndescription = \"Slovenia LULC data example\" \n\nrequest_shp = SentinelHubRequest(\n    evalscript=Evalscript,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=datasource,\n            time_interval=time_interval,\n            mosaicking_order=mosaickingOrder,\n            maxcc=maxCloudCoverage,\n            upsampling=upsampling,\n            downsampling=downsampling,\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response(\"B02\", output_type),\n        SentinelHubRequest.output_response(\"B03\", output_type),\n        SentinelHubRequest.output_response(\"B04\", output_type),\n        SentinelHubRequest.output_response(\"B08\", output_type),\n        SentinelHubRequest.output_response(\"B11\", output_type),\n        SentinelHubRequest.output_response(\"B12\", output_type),\n        SentinelHubRequest.output_response(\"NDVI\", output_type),\n        SentinelHubRequest.output_response(\"NDWI\", output_type),\n        SentinelHubRequest.output_response(\"NDBI\", output_type),\n        SentinelHubRequest.output_response(\"data_mask\", output_type)\n    ],\n    geometry=Geometry(geometry, crs=crs),\n    config=config\n)\n\nbatch = SentinelHubBatch(config=config)\n\nbatch_request = batch.create(\n    request_shp,\n    tiling_grid=SentinelHubBatch.tiling_grid(\n        grid_id=tilingGridId,\n        resolution=resolution,\n        buffer=buffer\n    ),\n    bucket_name=bucketName,\n    description=description\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-2-1-prepare-batch-input-parameters","position":23},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"1.2.2 Run the Batch request","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-2-2-run-the-batch-request","position":24},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"1.2.2 Run the Batch request","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"Once all the parameters are set we are ready to run the Batch process. The batch processing API comes with the set of REST APIs which support the execution of various workflows. A diagram of the statuses of a batch processing request is located \n\nhere.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-1-2-2-run-the-batch-request","position":25},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Start the request and return status","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#start-the-request-and-return-status","position":26},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Start the request and return status","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"\n\nbatch_request.to_dict()\n\nExtract request id\n\nrequest_id = batch_request.to_dict()['id']\n\nRe-initialize the request with its request id (Optional)\n\n# batch = SentinelHubBatch(config=config)\n\n# reinit_request = batch.get_request(request_id)\n\n# reinit_request.to_dict()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#start-the-request-and-return-status","position":27},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Show request status","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#show-request-status","position":28},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Show request status","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"In the cell below, we will check the status of the batch processing request. Because Batch Processing API is an asynchronous REST service, we can execute this cell all along the process to verify the progress of the request.\n\nbatch_request = batch.get_request(batch_request)\n\nbatch_request.status\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#show-request-status","position":29},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Additional analysis","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#additional-analysis","position":30},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Additional analysis","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"When executing the following cell:\n\nthe status of the request changes to ANALYSING,\n\nthe evalscript is validated,\n\na list of required tiles is created, and\n\nthe request’s cost is estimated (i.e. the estimated number of processing units (PU) needed for the requested processing).\n\nAfter the analysis is finished the status of the request changes to ANALYSIS_DONE.\n\nbatch.start_analysis(batch_request)\n\nNote: At this point you can run the Show request status cell again to check the status of the request.\n\nwhile batch_request.status.value != 'ANALYSIS_DONE':\n    batch_request = batch.get_request(batch_request)\n    sleep(10)\n    \nbatch_request.status\n\nEstimate number of processing units\n\nOnce analysis is completed the valueEstimate tells us an estimated number of processing units the batch job will cost.\n\nprint(f'Running this batch job will require approximately {batch_request.value_estimate:.4f} processing units')\n\nCheck tile definitions\n\nwe can check information about all tiles.\n\nfor tile_info in batch.iter_tiles(batch_request):\n    print(tile_info)\n\nOptionally, we can request information about a single tile.\n\n# Specify a tile ID\nTILE_ID = '2558718'\n\nbatch.get_tile(batch_request, TILE_ID)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#additional-analysis","position":31},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"START","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#start","position":32},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"START","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"Once you happy with the request parameters and have noted the number of PU consumed (by checking the Show request status), you can launch the processing.\n\nNote: The processing time for this step could be up to an hour or more depending on the amount of data.\n\nbatch.start_job(batch_request)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#start","position":33},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Cancel the request","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#cancel-the-request","position":34},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Cancel the request","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"When the job is running we can decide at any time to cancel it. Results that have already been produced will remain on the bucket.\n\n#batch.cancel_job()\n\nNote: At this point you can run the Show request status cell again to check the status of the request.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#cancel-the-request","position":35},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Show request status","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#show-request-status-1","position":36},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Show request status","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"In the cell below, we will check the status of the batch processing request. Because Batch Processing API is an asynchronous REST service, we can execute this cell all along the process to verify the progress of the request.\n\nwhile batch_request.status.value != 'DONE':\n    batch_request = batch.get_request(batch_request)\n    sleep(10)\n\nbatch_request.status\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#show-request-status-1","position":37},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Visual tracking of the Batch request","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#visual-tracking-of-the-batch-request","position":38},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Visual tracking of the Batch request","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"The following cells allow us to track the progress of the Batch request by plotting the status of the tiles. To visually track the progress of the Batch request, we can keep executing the Plotting command.\n\ndef plot_batch_splitter(splitter):\n    \"\"\" Plots tiles and area geometry from a splitter class\n    \"\"\"\n    tile_geometries = [Geometry(bbox.geometry, bbox.crs) for bbox in splitter.get_bbox_list()]\n    tile_geometries = [geometry.transform(splitter.crs) for geometry in tile_geometries]\n\n    gdf = gpd.GeoDataFrame(\n        {'status': [info['status'] for info in splitter.get_info_list()]},\n        geometry=[geometry.geometry for geometry in tile_geometries],\n        crs=splitter.crs.pyproj_crs()\n    )\n    ax = gdf.plot(column='status', legend=True, figsize=(10, 10))\n\n    area_series = gpd.GeoSeries(\n        [splitter.get_area_shape()],\n        crs=splitter.crs.pyproj_crs()\n    )\n    area_series.plot(ax=ax, facecolor='none', edgecolor='black')\n\n\nsplitter = BatchSplitter(batch_request=batch_request, config=config)\nplot_batch_splitter(splitter)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#visual-tracking-of-the-batch-request","position":39},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"What if some of my tiles fail?","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#what-if-some-of-my-tiles-fail","position":40},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"What if some of my tiles fail?","lvl3":"1.2 Use Batch to fetch Sentinel-2 data and resample to even timesteps","lvl2":"Part 1: create and run the Batch process"},"content":"It can happen that some of the tiles are not processed, and appear with the status FAILED in the plot above. We can use the function defined below to restart the processing for those specific tiles.\n\n# #Re-run the processing for all the tiles that failed\n# batch.restart_job(batch_request)\n\nAlternatively, we can re-run processing only for a single tile.\n\n# # Specify an ID of a tile that failed\n# FAILED_TILE_ID = ''\n\n# batch.reprocess_tile(batch_request, FAILED_TILE_ID)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#what-if-some-of-my-tiles-fail","position":41},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#part-2-convert-batch-process-outputs-to-eopatches","position":42},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"When the Batch request in Part 1 has finished running, we should now have the data located in the specified Bucket. In Part 2 we will focus on converting the results to EoPatches and download the data.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#part-2-convert-batch-process-outputs-to-eopatches","position":43},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"2.1 Set parameters for conversion","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-2-1-set-parameters-for-conversion","position":44},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"2.1 Set parameters for conversion","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"First we specify a few parameters for converting the Batch results to EOLearn Patches.\n\nIf you want to pick up the Notebook after having run the Batch request in an other session, you will need to specify a few parameters that were already defined in Part 1: for that uncomment and run the next cell. If you have just executed the cells in Part 1, you can skip the next cell.\n\n# # Date parameters\n# START = datetime.date(2019, 4, 1)\n# END = datetime.date(2019, 10, 31)\n\n# INTERVAL = 15  # Interval for date resampling in days\n\n# # Calculate list of dates for the resampling\n# date_iterator = START\n# timestamps = []\n# while date_iterator < END:\n#     timestamps.append(date_iterator)\n#     date_iterator = date_iterator + datetime.timedelta(days=INTERVAL)\n    \n# #Amazon client ID and secret\n# AWS_ID = \"aws-client-id\"\n# AWS_SECRET = \"aws-client-secret\"\n    \n# # Amazon bucket name\n# aws_bucket_name = \"your-bucket-name\"\n\n# # Request ID (from the Batch processing)\n# request_id = \"\"\n\n# #Configuration\n# config = SHConfig()\n\nNext, we will set the bands that we want to import into the EOPatches.\n\nIn this example we use:\n\nB02, B03, B04, B08, B11, B12 bands from Sentinel-2\n\nNDVI, NDWI, NDBI indices\n\nValid data band\n\nband_names = ['B02.tif', 'B03.tif', 'B04.tif', 'B08.tif', 'B11.tif','B12.tif',\n              'NDVI.tif', 'NDWI.tif', 'NDBI.tif']\nis_data_band = 'data_mask.tif'\n\nFinally, let’s specify the folder to which we will save the data.\n\n# Output path\nsave_folder = \"./results\"\n\nWe have defined a class to convert the Batch Request to EOPatches for ease of use below.\n\nclass ImportFromAWS:\n    \"\"\"Import EoPatches from a Batch request.\n    \n    This class regroups all the methods to transform the saved results of a batch request\n    located in an Amazon Bucket to EOPatches locally.\n    \n    :param aws_key: Amazon client ID\n    :type aws_key: str\n    :param aws_secret: Amazon secret\n    :type aws_secret: str\n    :param aws_bucket: Amazon bucket name where the batch results were written\n    :type aws_bucket: str\n    :param request_id: Batch request id\n    :type request_id: str \n    param bands: List of bands that should be considered in the import\n    :type bands: list \n    param timestamps: List of timestamps for resampled data\n    :type timestamps: list\n    param is_data: Name of the IS_DATA band from Batch\n    :type is_data: str, optional\n    :param out_path: Path to folder where EOPatches will be saved\n    :type out_path: str, optional \n    \"\"\"\n    \n    def __init__(self, aws_key, aws_secret, aws_bucket, request_id, bands, timestamps,\n                 is_data=None, out_path=\"./\"):\n        \"\"\"Constructor method.        \n        \"\"\"\n        # Path to save the EoPatches\n        self.out_path = Path(out_path)\n            \n        # Make directory\n        self.out_path.mkdir(parents=True, exist_ok=True)\n\n        # AWS credentials\n        if (aws_key == None or aws_secret == None):\n            raise ValueError(\"No Amazon credential provided!\")\n            \n        # Create Amazon session and settings\n        self.session = boto3.Session(aws_access_key_id=aws_key, \n                                     aws_secret_access_key=aws_secret,\n                                    ) \n        self.s3_resource = self.session.resource('s3')\n        self.s3_client = self.session.client('s3')\n        self.bucket_name = aws_bucket\n        self.bucket = self.s3_resource.Bucket(aws_bucket)\n        \n        # Set up filesytem for Amazon Bucket\n        self.s3fs = S3FS(aws_bucket,\n                         dir_path=request_id,\n                         aws_access_key_id=aws_key,\n                         aws_secret_access_key=aws_secret)\n           \n        # Request id\n        self.request_id = request_id\n        \n        # Information about data and metadata\n        self.is_data = is_data\n        self.bands = bands\n        self.timestamps = [x.isoformat() for x in timestamps]\n\n\n    @staticmethod   \n    def _open_band(AWS_session, bucket, request_id, folder, bandname):\n        \"\"\"Open Band.\n        \n        Using Rasterio, open a band in an Amazon S3 Bucket, and return bbox and data.\n        \n        :param session: Amazon boto session\n        :type session: boto3.Session \n        :param bucket: Amazon bucket name\n        :type bucket: str\n        :param request_id: Name of the Batch request ID\n        :type request_id: str\n        :param folder: Name of the folder in which to query data\n        :type folder: str\n        :param bandname: Filename\n        :type bandname: str \n        \"\"\"\n        # Open with Rasterio\n        with rasterio.Env(rasterio.session.AWSSession(AWS_session)) as env:\n            s3_url = f's3://{bucket}/{request_id}/{folder}/{bandname}'\n            with rasterio.open(s3_url) as source:\n\n                    bbox = BBox(source.bounds, CRS(source.crs.to_epsg()))\n                    data = source.read()\n        return data, bbox\n    \n    \n    @staticmethod   \n    def _open_local_band(band_path):\n        \"\"\"Open Local Band.\n        \n        Using Rasterio, open a band in an Amazon S3 Bucket, and return bbox and data.\n        \n        :param session: Amazon boto session\n        :type session: boto3.Session \n        :param bucket: Amazon bucket name\n        :type bucket: str\n        :param request_id: Name of the Batch request ID\n        :type request_id: str\n        :param folder: Name of the folder in which to query data\n        :type folder: str\n        :param bandname: Filename\n        :type bandname: str \n        \"\"\"\n        # Open with Rasterio\n        with rasterio.open(band_path) as source:\n            bbox = BBox(source.bounds, CRS(source.crs.to_epsg()))\n            data = source.read()\n\n        return (data, bbox)\n\n    \n    @staticmethod\n    def _convert_DN(band, in_band):\n        \"\"\"Convert DN to values.\n        \n        It is cheaper to return INT data from SH Hub. In the evalscript a coefficient is applied\n        to the data to return it as INT, and here it needs to be unpacked. This function (for now)\n        considers only 2 ways of saving data: bands starting with B or indices not starting with B.\n        \n        :param band: Band name to convert\n        :type band: str \n        :param in_band: Numpy array to convert\n        :type in_band: np.array \n        :return: The input numpy array converted depending on band name\n        :rtype: np.array\n        \"\"\"\n        if band.startswith(\"B\"):\n            outband = in_band / 10000.\n        else:\n            outband = (in_band - 10000.) / 10000.\n\n        return outband\n\n\n    @staticmethod\n    def _eopatch_import(folder_system, folders, bucket, bands, timestamps, out_path, local=False,\n                        save_local=True, is_data=None, request_id=None, bucket_name=None, session=None):\n        \"\"\"Import EOPatches from local data.\n        \n        After having downloaded the bucket contents to a local folder, extract the EOPatches.\n        \n        :param folder_system: a fs sytem object containing base directory (S3 or local)\n        :type folder_system: s3fs.S3FS or s3fs.core.S3FileSystem\n        :param folders: List of folders to search through\n        :type folders: list \n        :param bucket: boto3 resource Bucket bucket, see :class:`ImportFromAWS`\n        :type bucket: boto3.S3.Bucket(name)\n        :param bands: List of bands to process\n        :type bands: list\n        :param timestamps: List of timestamps corresponding to the bands\n        :type timestamps: list\n        :param out_path: Output folder where the EOPatches are saved\n        :type out_path: str\n        :param local: Set whether the folders are local or on Amazon S3\n        :type local: bool, optional\n        :param save_local: Set whether the EOPatches are saved to local or on Amazon S3\n        :type save_local: bool, optional\n        :param is_data: Name of band containing information of validity of data\n        :type is_data: str, optional\n        :param request_id: When importing from a Amazon bucket, folder name (from Batch)\n        :type request_id: str, optional\n        :param bucket_name: When importing from a Amazon bucket, bucket name\n        :type bucket_name: str, optional\n        :param session: When importing from a Amazon bucket, boto3 S3 session\n        :type session: boto3.S3.session, optional\n\n        \"\"\"\n        # Initialise counter\n        nb_patch = 0\n        \n        # Ignore json file\n        folders = [x for x in folders if not x.endswith(\"json\")]\n        \n        # Loop over the folders which will become patches\n        for fold in tqdm(folders):\n          \n            # Export switch (in case the bands are missing in a patch)\n            export = True\n\n            # Empty EOPatch to be filled\n            eo_patch = EOPatch()\n\n            # List bands in folder\n            current_bands = folder_system.listdir(fold)\n            \n            # Check if the bands in the folder correspond to the bands wanted\n            if any(elem in current_bands for elem in bands):\n                all_bands = {}\n                # Loop through bands\n                for band in bands:\n                    # Different opening method depending on local or not\n                    if local:\n                        band_data, data_bbox = ImportFromAWS._open_local_band(Path(\n                            folder_system.getsyspath(\"\")).joinpath(fold, band))\n                    else:\n                        band_data, data_bbox = ImportFromAWS._open_band(session, \n                                                                        bucket_name, \n                                                                        request_id,\n                                                                        fold, band)\n                    # Convert band to reflectance or index and save\n                    all_bands[band] = ImportFromAWS._convert_DN(band, band_data)\n\n                     # Get IS_DATA\n                if is_data != None and is_data in current_bands:\n                    # Different opening method depending on local or not\n                    if local:\n                        is_data_array, _ = ImportFromAWS._open_local_band(Path(\n                                folder_system.getsyspath(\"\")).joinpath(fold, is_data))\n                    else:\n                        is_data_array, _ = ImportFromAWS._open_band(session, \n                                                                    bucket_name, \n                                                                    request_id,\n                                                                    fold, is_data)\n            # If the bands don't match, skip the patch\n            else:\n                print(f\"Bands don't match for Patch {fold}... skipping...\")\n                export = False\n\n            # if not flag to skip the band, continue\n            if export:\n                # Add bbox to patch\n                eo_patch.bbox = data_bbox\n\n                # Add bands to patch\n                eo_patch.data['FEATURES'] = np.stack([all_bands[x] for x in all_bands.keys()], axis=-1)\n                \n                # Add is data mask to patch\n                eo_patch.mask[\"IS_DATA\"] = np.expand_dims(is_data_array, axis=-1)\n\n                # Add metadata\n                eo_patch.meta_info[\"time_interval\"] = (START.isoformat(), END.isoformat())\n                eo_patch.meta_info[\"band_list\"] = [x.split('.')[0] for x in bands]\n\n                # Add timestamps\n                eo_patch.timestamp = timestamps\n\n                # Save EOPatch (either on local or on Bucket)\n                if save_local:\n                    save_path = str(Path(out_path).joinpath(\"EOPatches\"))\n                else:\n                    save_path = f\"s3://{bucket_name}/EOPatches\"\n\n                eo_patch.save(f\"{save_path}/eopatch_{nb_patch}\",\n                              overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n\n                # Increase counter\n                nb_patch += 1\n\n\n    def convert_to_EOPatches(self, local_bucket=None, save_locally=True):\n        \"\"\"Import of EOPatches.\n        \n        This function converts the contents of an Amazon bucket that is\n        stored locally (after download using e.g. `download_S3_bucket`) or \n        stored on Amazon S3 to EOPatches.\n        \n        :param local_bucket: A local folder containing contents of a Bucket\n        :type local_bucket: str, optional\n        \"\"\"\n        \n        if local_bucket is None:\n            # Open Bucket as folder system\n            folder_sys = self.s3fs\n            # Set local flag to False\n            local = False\n        else:\n            # Open local folder system\n            folder_sys = open_fs(local_bucket)\n            #Set local flag to True\n            local = True\n\n        # Get subfolders in the local folder\n        folders = folder_sys.listdir(\"/\")\n        \n        # Run the import\n        self._eopatch_import(folder_sys, folders, self.bucket, self.bands, self.timestamps,\n                             self.out_path, local=local, save_local=save_locally, is_data=self.is_data,\n                             request_id=self.request_id, bucket_name=self.bucket_name, session=self.session)\n\n\n    def download_from_bucket(self, obj_id=\"S3\"):\n        \"\"\"Download S3 Bucket.\n        \n        Downloads the results of a batch request stored in an Amazon\n        bucket, based on the request ID of the class.\n\n        \"\"\"\n        # Check type\n        if obj_id not in [\"S3\", \"EO\"]:\n            raise ValueError(\"Not a correct object ID to download: choose S3 or EO\")\n\n        # Check if a folder named after the reques ID already exists in the output folder\n        if obj_id == \"S3\":\n            path = self.request_id\n        else:\n            path = \"EOPatches\"\n\n        if self.out_path.joinpath(path).is_dir():\n                raise ValueError(\"Bucket folder already exists on local path! Delete and try again.\")\n        \n        # Download S3/EO bucket\n        print(\"Downloading bucket contents\")\n        \n        keys = []\n        dirs = []\n        next_token = ''\n        base_kwargs = {\n            'Bucket':self.bucket_name,\n            'Prefix':path,\n        }\n        while next_token is not None:\n            kwargs = base_kwargs.copy()\n            if next_token != '':\n                kwargs.update({'ContinuationToken': next_token})\n            results = self.s3_client.list_objects_v2(**kwargs)\n            contents = results.get('Contents')\n            for i in contents:\n                k = i.get('Key')\n                if k[-1] != '/':\n                    keys.append(k)\n                else:\n                    dirs.append(k)\n                \n            next_token = results.get('NextContinuationToken')\n\n        for d in dirs:\n            dest_pathname = self.out_path.joinpath(d)\n            dest_pathname.mkdir(parents=True, exist_ok=True)\n\n        for k in tqdm(keys):\n            dest_pathname = self.out_path.joinpath(k)\n            dest_pathname.parent.mkdir(parents=True, exist_ok=True)\n            self.s3_client.download_file(self.bucket_name, k, str(dest_pathname))   \n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-2-1-set-parameters-for-conversion","position":45},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"2.2 Run conversion from Batch results to EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-2-2-run-conversion-from-batch-results-to-eopatches","position":46},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"2.2 Run conversion from Batch results to EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"Now all the parameters are set, we can run the conversion. For this step there are 2 available options:\n\nDownload the contents of the Amazon S3 Bucket to a local file and convert locally to EOPatches\n\nConvert the data from the Amazon S3 Bucket and download the EOPatches\n\nFirst, we make an object, initialising it with the necessary parameters to perform the conversion.\n\n# Make class to convert Batch to EOPatches\nbatch2eolearn = ImportFromAWS(AWS_ID, AWS_SECRET, aws_bucket_name,\n                              request_id, band_names, timestamps, is_data=is_data_band, \n                              out_path=save_folder)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-2-2-run-conversion-from-batch-results-to-eopatches","position":47},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Option 1: Dowload Bucket and convert locally","lvl4":"2.2 Run conversion from Batch results to EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#option-1-dowload-bucket-and-convert-locally","position":48},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Option 1: Dowload Bucket and convert locally","lvl4":"2.2 Run conversion from Batch results to EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"You can use the in-build function below to download your Amazon Bucket contents, or skip the cell and sync the Bucket using the aws cli tool.\n\n# Download Batch results from Bucket\nbatch2eolearn.download_from_bucket(obj_id=\"S3\")\n\nIf you specify the folder name containing the Batch request data in the convert_to_EOPatches function, the conversion will be performed locally.\n\n# Convert local data to EOPatches\nbatch2eolearn.convert_to_EOPatches(local_bucket=f\"{save_folder}/{request_id}\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#option-1-dowload-bucket-and-convert-locally","position":49},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Option 2: Convert in Bucket and download EOPatches","lvl4":"2.2 Run conversion from Batch results to EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#option-2-convert-in-bucket-and-download-eopatches","position":50},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"Option 2: Convert in Bucket and download EOPatches","lvl4":"2.2 Run conversion from Batch results to EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"The following cell allows you to convert the data that is stored on the Amazon S3 Bucket. Using the save_locally True/False flag you can either directly save the EOPatches on your computer or store them on the Amazon S3 Bucket.\n\n# Convert Batch results in the Amazon Bucket to EoPatches\n# batch2eolearn.convert_to_EOPatches(save_locally=False)\nbatch2eolearn.convert_to_EOPatches(save_locally=False)\n\nIf you save the EOPatches to your Amazon Bucket, you can either download them by using the inbuilt command below or using an other method of your choice (e.g. aws cli).\n\n# Rename the folder created in option 1\nos.rename(\"./results/EOPatches\", \"./results/EOPatches_opt1\")\n\n# Download EOPatches from Bucket\nbatch2eolearn.download_from_bucket(obj_id=\"EO\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#option-2-convert-in-bucket-and-download-eopatches","position":51},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#step-3-continue-processing-data-using-eopatches","position":52},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"Now we have the EOPatches saved locally, we can continue the process as shown in the \n\nexample EOLearn Notebook.\n\nBefore continuing with Model construction and training (see \n\nhere) we will need to import the reference data for Slovenia first. Since we are querying data over Slovenia, we need to fetch the reference data for the whole country \n\nhere.\n\nFor this example, the reference data prepared for Ljubljana can be downloaded \n\nhere.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#step-3-continue-processing-data-using-eopatches","position":53},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"3.1 Prepare the data to train the LULC prediction model","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-1-prepare-the-data-to-train-the-lulc-prediction-model","position":54},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"3.1 Prepare the data to train the LULC prediction model","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-1-prepare-the-data-to-train-the-lulc-prediction-model","position":55},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"3.1.1 Setup reference data","lvl4":"3.1 Prepare the data to train the LULC prediction model","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-1-1-setup-reference-data","position":56},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"3.1.1 Setup reference data","lvl4":"3.1 Prepare the data to train the LULC prediction model","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"For this example, a subset of the country-wide reference for land-use-land-cover is provided. It is available in the form of a geopackage, which contains polygons and their corresponding labels. The labels represent the following 10 classes:\n\nlulcid = 0, name = no data\n\nlulcid = 1, name = cultivated land\n\nlulcid = 2, name = forest\n\nlulcid = 3, name = grassland\n\nlulcid = 4, name = shrubland\n\nlulcid = 5, name = water\n\nlulcid = 6, name = wetlands\n\nlulcid = 7, name = tundra\n\nlulcid = 8, name = artificial surface\n\nlulcid = 9, name = bareland\n\nlulcid = 10, name = snow and ice\n\nclass LULC(MultiValueEnum):\n    \"\"\" Enum class containing basic LULC types\n    \"\"\"\n    NO_DATA            = 'No Data',            0,  '#ffffff'\n    CULTIVATED_LAND    = 'Cultivated Land',    1,  '#ffff00'\n    FOREST             = 'Forest',             2,  '#054907'\n    GRASSLAND          = 'Grassland',          3,  '#ffa500'\n    SHRUBLAND          = 'Shrubland',          4,  '#806000'\n    WATER              = 'Water',              5,  '#069af3'\n    WETLAND            = 'Wetlands',           6,  '#95d0fc'\n    TUNDRA             = 'Tundra',             7,  '#967bb6'\n    ARTIFICIAL_SURFACE = 'Artificial Surface', 8,  '#dc143c'\n    BARELAND           = 'Bareland',           9,  '#a6a6a6'\n    SNOW_AND_ICE       = 'Snow and Ice',       10, '#000000'\n\n    @property\n    def id(self):\n        \"\"\" Returns an ID of an enum type\n\n        :return: An ID\n        :rtype: int\n        \"\"\"\n        return self.values[1]\n\n    @property\n    def color(self):\n        \"\"\" Returns class color\n\n        :return: A color in hexadecimal representation\n        :rtype: str\n        \"\"\"\n        return self.values[2]\n\n\ndef get_bounds_from_ids(ids):\n    bounds = []\n    for i in range(len(ids)):\n        if i < len(ids) - 1:\n            if i == 0:\n                diff = (ids[i + 1] - ids[i]) / 2\n                bounds.append(ids[i] - diff)\n            diff = (ids[i + 1] - ids[i]) / 2\n            bounds.append(ids[i] + diff)\n        else:\n            diff = (ids[i] - ids[i - 1]) / 2\n            bounds.append(ids[i] + diff)\n    return bounds\n\n\n# Reference colormap things\nlulc_bounds = get_bounds_from_ids([x.id for x in LULC])\nlulc_cmap = ListedColormap([x.color for x in LULC], name=\"lulc_cmap\")\nlulc_norm = BoundaryNorm(lulc_bounds, lulc_cmap.N)\n\nThe main point of this task is to create a raster mask from the vector polygons and add it to the eopatch. With this procedure, any kind of a labeled shapefile can be transformed into a raster reference map. This result is achieved with the existing task VectorToRaster from the eolearn.geometry package. All polygons belonging to the each of the classes are separately burned to the raster mask.\n\n# This step takes some time due to the large size of the reference data (https://github.com/sentinel-hub/eo-learn/blob/master/examples/batch-processing/data/ljubljana_ref.gpkg)\nland_use_ref_path = INPUT_DATA.joinpath('ljubljana_ref.gpkg')\n\nland_use_ref = gpd.read_file(land_use_ref_path)\n\nrasterization_task = VectorToRasterTask(land_use_ref, (FeatureType.MASK_TIMELESS, 'LULC'),\n                                    values_column='lulcid', raster_shape=(FeatureType.MASK, 'IS_DATA'),\n                                    raster_dtype=np.uint8)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-1-1-setup-reference-data","position":57},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"3.1.2 Define the workflow","lvl4":"3.1 Prepare the data to train the LULC prediction model","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-1-2-define-the-workflow","position":58},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"3.1.2 Define the workflow","lvl4":"3.1 Prepare the data to train the LULC prediction model","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"Now we want to incorporate the reference data to the EOPatches, we need to load and update the existing patches with the reference data (see \n\nhere). We also want to perform the erosion step shown in the \n\nEOLearn LULC example in order to “clean” the data, as described in this \n\nblog post.\n\nWe will also prepare the model training data (see \n\nhere) by performing random spatial sampling of the EOPatches, and finally split patches for training/validation.\n\nThe following workflow is created and executed:\n\nLoad the existing EOPatches containing satellite data\n\nAdd rasterised reference data\n\nPerform erosion task on reference data\n\nRandom spatial sampling of the EOPatches\n\nSplit patches for training/validation\n\nSave updated EOPatches\n\nFirst we set up the tasks:\n\n# Task for LOAD\nload = LoadTask(f\"{save_folder}/EOPatches\")\n\n# TASK FOR EROSION\n# erode each class of the reference map\nerosion = ErosionTask(mask_feature=(FeatureType.MASK_TIMELESS,'LULC','LULC_ERODED'), disk_radius=1)\n\n# TASK FOR SPATIAL SAMPLING\n# Uniformly sample about pixels from patches\nn_samples = 500000 # half of pixels (1000*1000 patches here)\nref_labels = list(range(11)) # reference labels to take into account when sampling\nspatial_sampling = FractionSamplingTask(\n    features_to_sample=[  # tag fields to sample\n        (FeatureType.DATA, 'FEATURES', 'FEATURES_SAMPLED'),\n        (FeatureType.MASK_TIMELESS, 'LULC_ERODED', 'LULC_ERODED_SAMPLED')],\n    sampling_feature=(FeatureType.MASK_TIMELESS, 'LULC_ERODED'),\n    fraction=0.5\n)\n\n# TASK FOR SAVING\nsave = SaveTask(f\"{save_folder}/EOPatches\", overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n\nThen we wrap tasks into nodes:\n\n# load_node = EONode(load, inputs=[], name=\"Load Task\")\n# erosion_node = EONode(erosion, inputs=[load_node], name=\"Erode Task\")\n# sampling_node = EONode(spatial_sampling, inputs=[erosion_node], name=\"Spatial Sampling Task\")\n# save_node = EONode(save, inputs=[sampling_node], name=\"Save Task\")\nlinked_nodes = linearly_connect_tasks(\n    (load, \"Load Task\"),\n    (rasterization_task, \"Rasterize Task\"),\n    (erosion, \"Erode Task\"), \n    (spatial_sampling, \"Spatial Sampling Task\"),\n    (save, \"Save Task\")\n)\n\n# Define the workflow\nworkflow = EOWorkflow(linked_nodes)\n\n# Let's visualize it\nworkflow.dependency_graph()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-1-2-define-the-workflow","position":59},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"3.1.3 Run the EOWorkflow over all EOPatches","lvl4":"3.1 Prepare the data to train the LULC prediction model","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-1-3-run-the-eoworkflow-over-all-eopatches","position":60},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl5":"3.1.3 Run the EOWorkflow over all EOPatches","lvl4":"3.1 Prepare the data to train the LULC prediction model","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"\n\n%%time\n   \nexecution_args = []\nfor patch in Path(save_folder).joinpath(\"EOPatches\").iterdir():\n     execution_args.append({\n         linked_nodes[0]: {'eopatch_folder': patch.name},\n         linked_nodes[3]: {'seed': 42},\n         linked_nodes[-1]: {'eopatch_folder': patch.name}\n    })\n\nexecutor = EOExecutor(workflow, execution_args, save_logs=True)\nexecutor.run(workers=1, multiprocess=False)\n\nexecutor.make_report()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-1-3-run-the-eoworkflow-over-all-eopatches","position":61},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"3.2 Visualize the patches","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-2-visualize-the-patches","position":62},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl4":"3.2 Visualize the patches","lvl3":"Step 3: continue processing data using EOPatches","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"Now we have EOPatches ready for analysis, we can visualise them before continuing.\n\n# Load a random patch\npatch_ID = 5\n\nRGB True Color of a Patch\n\nfig, ax = plt.subplots(1,figsize=(12,12))\neopatch = EOPatch.load(f'{save_folder}/EOPatches/eopatch_{patch_ID}', lazy_loading=True)\neopatch\nax.imshow(np.clip(eopatch.data['FEATURES'][1][..., [2, 1, 0]] * 3.5, 0, 1))\nax.set_xticks([])\nax.set_yticks([])\nax.set_aspect(1)\nplt.show()\neopatch = None\n\nTemporal mean of NDVI of a patch\n\nfig, ax = plt.subplots(figsize=(12,12))\neopatch = EOPatch.load(f'{save_folder}/EOPatches/eopatch_{patch_ID}', lazy_loading=True)\nndvi = eopatch.data['FEATURES'][:, :, :, 6]\nmask = eopatch.mask['IS_DATA'].squeeze()\nndvi[mask==0] = np.nan\nndvi_mean = np.nanmean(ndvi, axis=0).squeeze()\nim = ax.imshow(ndvi_mean, vmin=0, vmax=0.8, cmap=plt.get_cmap('YlGn'))\nax.set_xticks([])\nax.set_yticks([])\nax.set_aspect(1)\neopatch = None\n\ncb = fig.colorbar(im, ax=ax, orientation='horizontal', pad=0.01, aspect=100)\ncb.ax.tick_params(labelsize=20) \nplt.show()\n\nReference data example of a Patch\n\nfig, ax = plt.subplots(figsize=(12,12))\neopatch = EOPatch.load(f'{save_folder}/EOPatches/eopatch_{patch_ID}', lazy_loading=True)\n\nax.imshow(eopatch.mask_timeless['LULC'].squeeze(), cmap=lulc_cmap, norm=lulc_norm)\nax.set_xticks([])\nax.set_yticks([])\nax.set_aspect(1)\neopatch = None\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#id-3-2-visualize-the-patches","position":63},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"Note:","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#note","position":64},{"hierarchy":{"lvl1":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","lvl3":"Note:","lvl2":"Part 2: convert Batch process outputs to EOPatches"},"content":"At this point, we have a setup similar to what we would have at \n\nSection 6 of the eo-learn LULC tutorial. If you are familiar with the process you can stop here, or you can continue the steps described in the \n\nthe eo-learn example Notebook from here on.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/howtolulc-batch-updated-210621#note","position":65},{"hierarchy":{"lvl1":"Australian Bushfires"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires","position":0},{"hierarchy":{"lvl1":"Australian Bushfires"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires","position":1},{"hierarchy":{"lvl1":"Australian Bushfires"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#australian-bushfires","position":2},{"hierarchy":{"lvl1":"Australian Bushfires"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#australian-bushfires","position":3},{"hierarchy":{"lvl1":"Australian Bushfires","lvl2":"Geo-storytelling with EODASHBOARD and the Euro Data Cube - Notebook #2"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#geo-storytelling-with-eodashboard-and-the-euro-data-cube-notebook-2","position":4},{"hierarchy":{"lvl1":"Australian Bushfires","lvl2":"Geo-storytelling with EODASHBOARD and the Euro Data Cube - Notebook #2"},"content":"In this notebook:\n\nAustralian Bushfires story on EODASHBOARD\n\nSetting an Area of Interest from Open Street Map and Displaying it on a map\n\nVisualising Sentinel-2 data during the bushfire season\n\nVisualising Sentinel-2 indices - SWIR\n\nGetting Carbon Monoxide Data from Sentinel-5p\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#geo-storytelling-with-eodashboard-and-the-euro-data-cube-notebook-2","position":5},{"hierarchy":{"lvl1":"Australian Bushfires","lvl3":"EODASHBOARD Australian Bushfires Story","lvl2":"Geo-storytelling with EODASHBOARD and the Euro Data Cube - Notebook #2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#eodashboard-australian-bushfires-story","position":6},{"hierarchy":{"lvl1":"Australian Bushfires","lvl3":"EODASHBOARD Australian Bushfires Story","lvl2":"Geo-storytelling with EODASHBOARD and the Euro Data Cube - Notebook #2"},"content":"Australian bushfires in 2019-2020 emitted 700 million metric tons of CO2 into the atmosphere.\n\nTo access the full story on the Australian Bushfires that took place in 2019-2020 season visit the \n\nAtmosphere Section on EO Dashboard.\n\nAtmosphere Datasets can be explored on EO Dashboard in the EXPLORE DATASETS mode (\n\nhttps://​eodashboard​.org​/explore), with the Atmosphere Filter Activated.\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#eodashboard-australian-bushfires-story","position":7},{"hierarchy":{"lvl1":"New South Wales AOI"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#new-south-wales-aoi","position":8},{"hierarchy":{"lvl1":"New South Wales AOI"},"content":"Exploring the EO Dashboard we can visually observe that some of the areas most affected by the bushfires in the 2019-2020 season were in the state of Victoria. The bushfires affected a very large area, but we will restrict our analysis to a smaller region, in order to keep the datasets manageable and to have shorter computation times.\n\nNavigating to \n\nPage 3 of the Australian Bushfires Story on EO Dashboard, we can use the time bar in the interactive map to explore the month of December 2019.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#new-south-wales-aoi","position":9},{"hierarchy":{"lvl1":"New South Wales AOI","lvl2":"Using the Overpass Turbo API from Open Street Map to extract the polygon of a region"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#using-the-overpass-turbo-api-from-open-street-map-to-extract-the-polygon-of-a-region","position":10},{"hierarchy":{"lvl1":"New South Wales AOI","lvl2":"Using the Overpass Turbo API from Open Street Map to extract the polygon of a region"},"content":"The \n\nOverpass turbo API is a web-based data filtering tool for \n\nOpenStreetMap.\n\nIn the first step we create a request to fetch the information we are interested in. For further details on how to create the query please look at the manual or have a look at the tutorial mentioned in the introduction.\n\nIn principle a good approach would be to filter by a tag of interest. You can look for possible tags in multiple places, one practical place is \n\ntagfinder.\n\nAs we are looking at the bushfires in 2019-2020 season in Australia we might be interested in looking for data in an area that was affected by the fires, such as New South Wales.\n\nTo reduce the data request we will be focusing only on one city in the region, such as Goald Coast.\n\nSource: \n\nhttps://​overpass​-turbo​.eu​/#\n\nimport requests\nimport json\noverpass_url = \"http://overpass-api.de/api/interpreter\"\n#area[name=\"Sydney\"][admin_level=6];\n# define the query \n\noverpass_query = \"\"\"\n[out:json];\narea[name=\"Gold Coast City\"][admin_level=6];\n(\n  relation[\"type\"=\"boundary\"][\"name\"=\"Gold Coast City\"];\n);\nout geom;\n\"\"\"\n\n# create the request \n\nresponse = requests.get(overpass_url, params={'data': overpass_query})\n\n# get the response \n\ndata = response.json()\n\n# uncomment below to print the response \n\n#data\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#using-the-overpass-turbo-api-from-open-street-map-to-extract-the-polygon-of-a-region","position":11},{"hierarchy":{"lvl1":"New South Wales AOI","lvl3":"Extract the bounding box","lvl2":"Using the Overpass Turbo API from Open Street Map to extract the polygon of a region"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#extract-the-bounding-box","position":12},{"hierarchy":{"lvl1":"New South Wales AOI","lvl3":"Extract the bounding box","lvl2":"Using the Overpass Turbo API from Open Street Map to extract the polygon of a region"},"content":"The API response indicates the outer contour of the city is composed of many segments. We will retain only the  minlat, minlon, maxlat and maxlon.\n\nRecalling here the relevant information from the Overpass API for Gold Coastal City:\n\n‘bounds’: {‘minlat’: -28.26511,\n‘minlon’: 153.16891,\n‘maxlat’: -27.690395,\n‘maxlon’: 153.5519459}\n\nfor the specific forest area around Newcastle and Gosford: the Wollemi, Blue Mountain and Yengo National Parks\n‘bounds’: {‘minlat’: -33.962,\n‘minlon’: 149.815,\n‘maxlat’: -32.815,\n‘maxlon’: 151.370}\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#extract-the-bounding-box","position":13},{"hierarchy":{"lvl1":"New South Wales AOI","lvl3":"Plot the boundingbox on the map","lvl2":"Using the Overpass Turbo API from Open Street Map to extract the polygon of a region"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#plot-the-boundingbox-on-the-map","position":14},{"hierarchy":{"lvl1":"New South Wales AOI","lvl3":"Plot the boundingbox on the map","lvl2":"Using the Overpass Turbo API from Open Street Map to extract the polygon of a region"},"content":"Now that we have the information we are interested in let’s do a basic plot using matplotlib to inspect the results.\n\nYou can then use the requested data to further explore and combine with other datasets to create higher value results.\n\nimport geojson\nimport shapely.wkt\n\n# use the coordinates above to construct the boundingbox\n\n#Goald Costal City\n#area = shapely.wkt.loads('POLYGON((153.16549 -28.309585,153.16549 -27.737359,153.665323 -27.737359,153.665323 -28.309585,153.16549 -28.309585))')\n\n#National Parks\narea = shapely.wkt.loads('POLYGON((149.815 -33.962,149.815 -32.815,151.370 -32.810,151.370 -33.962,149.815 -33.962))')\n\ngj_feat = geojson.Feature(geometry=area, properties={})\n\ngj_feat\n\nimport shapely.geometry\nimport IPython.display \nfrom IPython.display import GeoJSON\nIPython.display.GeoJSON(gj_feat)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#plot-the-boundingbox-on-the-map","position":15},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#visualising-sentinel-2-data-during-the-bushfire-season","position":16},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season"},"content":"\n\nIn the following cells we will access Sentinel-2 imagery from \n\nSentinel Hub. Sentinel Hub is a multi-spectral and multi-temporal big data satellite imagery service, capable of fully automated archiving, real-time processing and distribution of remote sensing data and related EO products. Users can use APIs to retrieve satellite data over their AOI and specific time range from full archives in a matter of seconds.\n\nThe cells below are based on the example notebook available in the \n\nEuro Data Cube Marketplace. You can access the complete Notebook, including several other examples on how to get started with Sentinel-Hub here: \n\nUsing Sentinel Hub Python package in EDC: a starter’s guide.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#visualising-sentinel-2-data-during-the-bushfire-season","position":17},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season","lvl2":"Prerequisites"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#prerequisites","position":18},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season","lvl2":"Prerequisites"},"content":"Before acccessing the data, we will start by importing the necessary Python libraries (already configured in your EDC workspace), generate credentials automatically to access the services and define the plot_image function that can be found in the utils.py \n\nfile located in Sentinel Hub’s \n\nGitHub repository.\n\n# EDC libraries\nfrom edc import setup_environment_variables\n\n# Utilities\nimport os\nimport datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Image\n\n# Sentinel Hub\nfrom sentinelhub import (MimeType, CRS, BBox, SentinelHubRequest, SentinelHubDownloadClient, \n                         DataCollection, bbox_to_dimensions, DownloadRequest, SHConfig)\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#prerequisites","position":19},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season","lvl4":"Credentials","lvl2":"Prerequisites"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#credentials","position":20},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season","lvl4":"Credentials","lvl2":"Prerequisites"},"content":"Credentials for Sentinel Hub services are automatically injected as environement variables. It is therefore easy to populate Sentinel Hub’s credential manager with the values.\n\n# Pass Sentinel Hub credentials to SHConfig\n\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#credentials","position":21},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season","lvl4":"Utility function for plotting images","lvl2":"Prerequisites"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#utility-function-for-plotting-images","position":22},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season","lvl4":"Utility function for plotting images","lvl2":"Prerequisites"},"content":"In the following cell, we define the plot_image function which will be used to display the requested images for all examples demonstrated in this notebook.\n\n# Define the plot_image function\n\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    \"\"\"\n    Utility function for plotting RGB images.\n    \"\"\"\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n# Configure plots for inline use in Jupyter Notebook\n\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#utility-function-for-plotting-images","position":23},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season","lvl2":"Preview the Sentinel-2 imagery"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#preview-the-sentinel-2-imagery","position":24},{"hierarchy":{"lvl1":"Visualising Sentinel-2 data during the bushfire season","lvl2":"Preview the Sentinel-2 imagery"},"content":"For verification, we downloaded a preview from the \n\nEO Browser over the region (not exatly the same boundingbox) and stored it in the Images directory. The Sentinel-2 imagery of \n\nNew South Wales that we will request from Sentinel Hub will be similar to the preview shown below (Sentinel-2 on 2019-12-21):\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#preview-the-sentinel-2-imagery","position":25},{"hierarchy":{"lvl1":"Retrieving Sentinel-2 imagery over the area of interest"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#retrieving-sentinel-2-imagery-over-the-area-of-interest","position":26},{"hierarchy":{"lvl1":"Retrieving Sentinel-2 imagery over the area of interest"},"content":"From the interactive map on EO Dashboard we can select relevant dates when the firest were impacting the Area of Interest. Starting from November 2019 we can observe the Carbon Monoxide plume advancing from the south and extending over the Gold Coast City.\n\nWe will retrieve Sentinel-2 data from the Sentinel Hub.\n\nAll requests require bounding box to be given as an instance of sentinelhub.geometry.BBox with corresponding Coordinate Reference System (sentinelhub.constants.CRS).\n\nIn our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from sentinelhub.constants.CRS.\n\n'bounds': {'minlat': -28.26511, 'minlon': 153.16891, 'maxlat': -27.690395, 'maxlon': 153.5519459}\n\nThe boundingbox will have the format: [minlon,mminlat,maxlon,maxlat]\n\n# Define bbox of the form [minlon,mminlat,maxlon,maxlat]\nminlat=-33.920\nminlon=149.815\nmaxlat=-32.814\nmaxlon=151.348\n\n\n#minlat=-28.26511\n#minlon=153.16891\n#maxlat=-27.690395\n#maxlon=153.5519459\n\n\nGoldCoast_coords_wgs84 = [minlon,minlat,maxlon,maxlat]\n\nWhen the bounding box bounds have been defined, you can initialize the BBox of the area of interest. Using the bbox_to_dimensions utility function, you can provide the desired resolution parameter of the image in meters and obtain the output image shape.\n\nresolution = 60\nGoldCoast_bbox = BBox(bbox=GoldCoast_coords_wgs84, crs=CRS.WGS84)\nGoldCoast_size = bbox_to_dimensions(GoldCoast_bbox, resolution=resolution)\n\nprint(f'Image shape at {resolution} m resolution: {GoldCoast_size} pixels')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#retrieving-sentinel-2-imagery-over-the-area-of-interest","position":27},{"hierarchy":{"lvl1":"Retrieving Sentinel-2 imagery over the area of interest","lvl2":"Retireve the true color (PNG) Sentinel-2 image on a specific date"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#retireve-the-true-color-png-sentinel-2-image-on-a-specific-date","position":28},{"hierarchy":{"lvl1":"Retrieving Sentinel-2 imagery over the area of interest","lvl2":"Retireve the true color (PNG) Sentinel-2 image on a specific date"},"content":"We build the request according to the \n\nAPI Reference, using the SentinelHubRequest class. Each Process API request also needs an \n\nevalscript.\n\nThe information that we specify in the SentinelHubRequest object is:\n\nan evalscript,\n\na list of input data collections with time interval,\n\na format of the response,\n\na bounding box and it’s size (size or resolution).\n\nThe evalscript in the example is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L1C bands.\n\nThe image from November 22nd 2019 is downloaded. Without any additional parameters in the evalscript, the downloaded data will correspond to reflectance values in UINT8 format (values in 0-255 range).\n\n# define the evalscript \n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\n# we nned to specify the collection and the time interval\n# for a list of collections available in the Sentinel Hub visit https://docs.sentinel-hub.com/api/latest/data/ \n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C, \n            time_interval=('2019-12-21', '2019-12-21'),\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=GoldCoast_bbox,\n    size=GoldCoast_size,\n    config=config\n)\n\n# send the request to Sentinel Hub\n\ntrue_color_imgs = request_true_color.get_data()\n\nThe method get_data() will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays.\n\nprint(f'Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.')\nprint(f'Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}')\n\nimage = true_color_imgs[0]\nprint(f'Image type: {image.dtype}')\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\nplot_image(image, factor=3.5/255, clip_range=(0,1))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#retireve-the-true-color-png-sentinel-2-image-on-a-specific-date","position":29},{"hierarchy":{"lvl1":"Visualising Sentinel-2 indices - SWIR"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#visualising-sentinel-2-indices-swir","position":30},{"hierarchy":{"lvl1":"Visualising Sentinel-2 indices - SWIR"},"content":"Sentinel-2 images have \n\n13 bands. To learn more about Sentinel-2 MSI instrument and available products visit the \n\nSentinel-2 webpage.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#visualising-sentinel-2-indices-swir","position":31},{"hierarchy":{"lvl1":"Visualising Sentinel-2 indices - SWIR","lvl3":"Optimising the request"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#optimising-the-request","position":32},{"hierarchy":{"lvl1":"Visualising Sentinel-2 indices - SWIR","lvl3":"Optimising the request"},"content":"We will retrieve the data from Sentinel Hub.\n\nTo get more details about how Sentinel Hub returns the values of the requested data visit: \n\nHow Are The Values Calculated Within Sentinel Hub And How Are They Returned As An Output?\n\nWhen we are downloading big chunks of data, it is important to consider ways to optimize the request. One way to reduce the amount of data downloaded is to get raw digital numbers as INT16 instead of getting reflectances which are FLOAT32. Less data means a faster download and a smaller usage of Sentinel Hub processing units.\n\nIn order to achieve this, we set the input units to DN (digital numbers) and the output sampleType argument to INT16.\n\nGiven that Sentinel-2 has 13 bands, we have to set the output image type to the TIFF format via MimeType.TIFF in the request if we want to retrieve all the bands. In the cell below we are asking only for 3 bands but will use this procedure for exemplification.\n\nThe dynamic range of the digital numbers is 0-10000, so for visualisation we have to scale the downloaded data appropriately.\n\nThe following cell will return the bands B12, B8A and B04 necessary to compute the SWIR index of the Sentinel-2 Level 2A product. More information here: \n\nhttps://​custom​-scripts​.sentinel​-hub​.com​/sentinel​-2​/swir​-rgb/\n\n#define an evalscript with the function to get all 13 bands of the Sentinel-2 image\nevalscript_SWIR = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B12\", \"B8A\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B12, sample.B8A, sample.B04];\n    }\n\"\"\"\n\n\n#call the function\n\nrequest_SWIR = SentinelHubRequest(\n    evalscript=evalscript_SWIR,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A,\n            time_interval=('2019-12-16', '2019-12-16'),\n            mosaicking_order='leastCC'\n    )],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.TIFF)\n    ],\n    bbox=GoldCoast_bbox,\n    size=GoldCoast_size,\n    config=config\n)\n\nSWIR_response = request_SWIR.get_data()\n\n# Image showing the SWIR band B12\n# Factor 1/1e4 due to the DN band values in the range 0-10000\n# Factor 3.5 to increase the brightness\nplot_image(SWIR_response[0], factor=2.5/255, clip_range=(0,1))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#optimising-the-request","position":33},{"hierarchy":{"lvl1":"Getting Carbon Monoxide Data from Sentinel-5p"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#getting-carbon-monoxide-data-from-sentinel-5p","position":34},{"hierarchy":{"lvl1":"Getting Carbon Monoxide Data from Sentinel-5p"},"content":"In the following sections we will see how to access Sentinel-5p Level 2 data from Sentinel Hub using the xcube service, as well as the reprocessed Sentinel-5p Level 3 products which are displayed on EO Dashboard.\nOn the reprocessed data, we will use the Sentinel Hub Statistical API to extract time series over the area of interest defined before.\n\nFor more informaiton about the Sentinel-5p Level 2 products please refer to the Algorithm Theoretical Basis Document (ATBD) available on \n\nthis page.\n\n# xcube_sh imports\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.observers import Observers\nfrom xcube_sh.viewer import ViewerServer\nfrom xcube_sh.sentinelhub import SentinelHub\n\n# xcube imports\nfrom xcube.core.maskset import MaskSet\nfrom xcube.core.geom import mask_dataset_by_geometry\nfrom xcube.core.geom import clip_dataset_by_geometry\n\n# Various utilities\nimport json\nimport xarray as xr\nimport shapely.geometry\nimport IPython.display\nimport zarr\n\n%matplotlib inline\n\nx1 = minlon # degree\ny1 = minlat  # degree\nx2 = maxlon  # degree\ny2 = maxlat  # degree\n\nbbox = x1, y1, x2, y2\n\nVisualize the bounding box. If you don’t see anything, please refer to EDC Setup example \n\nhere.\n\nIPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)\n\nspatial_res = 0.035   # = 3.5 km in degree>\n\ncube_config = CubeConfig(dataset_name='sentinel-5p-l2',\n                         band_names=['CO'],\n                         tile_size=[1835, 2338],\n                         bbox=bbox,\n                         spatial_res=spatial_res,\n                         time_range=['2019-10-01', '2019-12-31'],\n                         time_period='2D')\n\nWe define a request_collector as an observer for SH requests made, so we can show SH usage stats. This is a developer tool, useful for demonstration purposes too. Otherwise, this is not needed.\n\nrequest_collector = Observers.request_collector()\n\nOpen a data cube:\n\nSH = SentinelHub()\nSH.api_url = (\"https://creodias.sentinel-hub.com\")\n\ncube = open_cube(cube_config, observer=request_collector, sentinel_hub=SH)\n\ncube\n\nNo requests have been made yet. Requests are made only if data is actually required.\n\nrequest_collector.stats\n\nNote, the cube’s time coordinates are monotonically increasing and the distance between two time steps is varying:\n\ncube.time.diff(dim='time').plot.line()\n\n#cube.CO\ns5p_co = cube.CO\ns5p_co\n\nTo set the visualisation limits, get the maximum value in the dataset\n\nimport pandas as pd\n\nco_values = list() \ntimestamp = list()\n\nfor i in range(cube.time.shape[0]):\n    co_values.append(np.nanmean(cube.CO.isel(time=i).values[0]))\n    timestamp.append(cube.CO.isel(time=i).time.values)\n        \nassert len(co_values) == len(timestamp)\n    \npd.DataFrame({'DateTime': timestamp, 'Mean CO': co_values})\n\ns5p_co_1712 = cube.CO.sel(time='2019-12-17', method='nearest')\n\n#cube.CO.sel(time='2019-12-16 10:00:00', method='nearest').plot.imshow(vmin=0, vmax=0.08, cmap='rainbow', figsize=(10,9))\n\ns5p_co_1712.plot.pcolormesh(cmap='viridis',figsize=(10,9))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#getting-carbon-monoxide-data-from-sentinel-5p","position":35},{"hierarchy":{"lvl1":"Getting Carbon Monoxide Data from Sentinel-5p","lvl2":"Accessing TROPOMI CO data with Statistical API"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#accessing-tropomi-co-data-with-statistical-api","position":36},{"hierarchy":{"lvl1":"Getting Carbon Monoxide Data from Sentinel-5p","lvl2":"Accessing TROPOMI CO data with Statistical API"},"content":"\n\n#!/usr/bin/python\n\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\nimport json\n\n# Your client credentials\nclient_id = config.sh_client_id\nclient_secret = config.sh_client_secret\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_secret=client_secret)\n\nheader = {\"content-type\": \"application/json\"}\n\njson_body = {\n    \"input\": {\n        \"bounds\": {\n            \"geometry\": {\n                \"type\": \"Polygon\",\n                \"coordinates\": [\n                    [\n                        [\n                            minlon,\n                            minlat\n                        ],\n                        [\n                            minlon,\n                            maxlat\n                        ],\n                        [\n                            maxlon,\n                            maxlat\n                        ],\n                        [\n                            maxlon,\n                            minlat\n                        ],\n                        [\n                            minlon,\n                            minlat\n                        ]\n                    ]\n                ]\n            }\n        },\n        \"data\": [\n            {\n                \"dataFilter\": {\n\n                },\n                \"type\": \"byoc-57a07405-8ec2-4b9c-a273-23e287c173f8\"\n            }\n        ]\n    },\n    \"aggregation\": {\n        \"timeRange\": {\n            \"from\": \"2019-11-01T00:00:00Z\",\n            \"to\": \"2020-01-31T00:00:00Z\"\n        },\n        \"aggregationInterval\": {\n            \"of\": \"P3D\"\n        },\n        \"width\": 100,\n        \"height\": 100,\n        \"evalscript\": '''\n            //VERSION=3\\n\n            function setup() {\\n\n            return {\\n\n                input: [{\\n\n                bands: [\\n\n                    \\\"co\\\",\\n\n                    \\\"dataMask\\\"\\n\n                ]\\n\n                }],\\n\n                output: [\\n\n                {\\n\n                    id: \\\"data\\\",\\n\n                    bands: 1,\\n\n                    sampleType: \\\"FLOAT32\\\"\\n\n                },\\n\n                {\\n\n                    id: \\\"dataMask\\\",\\n\n                    bands: 1\\n\n                }\\n\n                ]\\n\n            }\\n\n            }\\n\n            function evaluatePixel(samples) {\\n\n            let validValue = 1\\n\n            if (samples.co >= 1e20 ){\\n\n                validValue = 0\\n\n            }\\n\n            let index = samples.co;\\n\n            return {\\n\n                data:  [index],\\n\n                dataMask: [samples.dataMask * validValue]\\n\n            }\\n\n            }'''\n        },\n        \"calculations\": {\n            \"default\": {\n\n            }\n        }\n}\n\nurl = \"https://services.sentinel-hub.com/api/v1/statistics\"\nresp = oauth.post(\n    url, data =json.dumps(json_body), headers=header\n)\n\nif resp.status_code == 200:\n    try:\n        respjson = resp.json()\n        response_status = respjson[\"status\"]\n    except Exception:\n        print(\"Issue parsing response\")\n\nprint(respjson)\nrespjson\n\nfrom datetime import datetime\n\n\ntime_axis = [datetime.strptime(entry[\"interval\"][\"from\"], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y/%m/%d\") for entry in respjson[\"data\"]]\nmeans = [entry['outputs']['data']['bands']['B0']['stats']['mean'] for entry in respjson[\"data\"]]\nmins = [entry['outputs']['data']['bands']['B0']['stats']['min'] for entry in respjson[\"data\"]]\nmaxs = [entry['outputs']['data']['bands']['B0']['stats']['max'] for entry in respjson[\"data\"]]\nstd_devs = [entry['outputs']['data']['bands']['B0']['stats']['stDev'] for entry in respjson[\"data\"]]\nstd_upper = [m+s for (m,s) in zip(means, std_devs)]\nstd_lower = [m-s for (m,s) in zip(means, std_devs)]\n\nfig = plt.figure(figsize=(20,10))\n# plot mean values \nplt.plot_date(time_axis, means, linestyle='solid', linewidth=2, color=\"black\", label=\"Mean CO values\")\n\n# plot standard deviation error bars\nplt.errorbar(time_axis, means, yerr=std_devs, linestyle=\"-\")\n\n# plot min/max lines\nplt.plot(time_axis, mins, linestyle=\"--\", linewidth=0.5, color=\"blue\", label=\"Min CO values\")\nplt.plot(time_axis, maxs, linestyle=\"--\", linewidth=0.5, color=\"blue\", label=\"Max CO values\")\n\nplt.title('NO2 Values (Nov 2019 - Jan 2021)')\nplt.legend()\nfig.autofmt_xdate()\nplt.show()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-australian-bushfires#accessing-tropomi-co-data-with-statistical-api","position":37},{"hierarchy":{"lvl1":"Data Access"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access","position":0},{"hierarchy":{"lvl1":"Data Access"},"content":"from eoxhub import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"GEODB\", \"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access","position":1},{"hierarchy":{"lvl1":"Data Access"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#data-access","position":2},{"hierarchy":{"lvl1":"Data Access"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#data-access","position":3},{"hierarchy":{"lvl1":"Data Access","lvl2":"Geo-storytelling with EODASHBOARD and the Euro Data Cube - Notebook #1"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#geo-storytelling-with-eodashboard-and-the-euro-data-cube-notebook-1","position":4},{"hierarchy":{"lvl1":"Data Access","lvl2":"Geo-storytelling with EODASHBOARD and the Euro Data Cube - Notebook #1"},"content":"\n\nThis notebook provides information on how to discover and access the data provided by NASA, ESA and JAXA in the frame of the EO Dashboard cooperation.\n\nThe data provided by the European Space Agency (ESA) can be access through the \n\nEuro Data Cube in both raster and vector format. The raster data is typically available via the \n\nSentinel Hub services whie the vector data is stored in a geodatabase and accessible via the GeoDB service. Data in the Euro Data Cube is typically presented as Collections. To browse all collections available, visit \n\nhttps://​collections​.eurodatacube​.com\n\nNASA make their datasets discoverable as STAC items and available via an open \n\nAPI.\n\nThe Japanse Aerospace Exploration Agency (JAXA) provide some of the data via the Euro Dat Cube (using the same mechanisms as ESA) and others via web services.\n\nIn this notebook we will show you how to access the different datasets.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#geo-storytelling-with-eodashboard-and-the-euro-data-cube-notebook-1","position":5},{"hierarchy":{"lvl1":"Data Access","lvl2":"List of Datasets"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#list-of-datasets","position":6},{"hierarchy":{"lvl1":"Data Access","lvl2":"List of Datasets"},"content":"In EO Dashboard datasets are typically grouped by their primary domain (e.g. Agriculture, or Economy). However, the richness and diversity of the observations make the resources much more valuable when combined.\nFor simplicity, below we list all the datasets grouped by their primary domain.\n\nThe datasets marked with (EU) are available in the Euro Data Cube but they are not exposed via the EO Dashboard. Instead, they are exposed via the \n\nRapid Action on Covid-19 and EO (RACE) Platform, which uses the same technology as \n\nEO Dashboard but is focused only on Europe.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#list-of-datasets","position":7},{"hierarchy":{"lvl1":"Data Access","lvl3":"Economic Datasets","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#economic-datasets","position":8},{"hierarchy":{"lvl1":"Data Access","lvl3":"Economic Datasets","lvl2":"List of Datasets"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#economic-datasets","position":9},{"hierarchy":{"lvl1":"Data Access","lvl4":"Raster","lvl3":"Economic Datasets","lvl2":"List of Datasets"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#raster","position":10},{"hierarchy":{"lvl1":"Data Access","lvl4":"Raster","lvl3":"Economic Datasets","lvl2":"List of Datasets"},"content":"\n\nNightlights \n\nvisualise on EO Dashboard\n\nPopulation Density (Meta) \n\nvisualise on EO Dashboard\n\nPopulation Density (SEDAC) \n\nvisualise on EO Dashboard\n\nRecovery Proxy Maps \n\nvisualise on EO Dashboard\n\nSlowdown Proxy Maps \n\nvisualise on EO Dashboard\n\nGlobal Gridded Relative Deprivation Index (GRDI) Subnational Human Development Index (SHDI) Constituent raster \n\nVisualise on EO Dashboard\n\nGlobal Gridded Relative Deprivation Index (GRDI) VIIRS Night Lights (VNL) Slope Constituent raster\n\nVisualise on EO Dashboard\n\nGlobal Gridded Relative Deprivation Index (GRDI) VIIRS Night Lights (VNL) Constituent raster \n\nVisualise on EO Dashboard\n\nGlobal Gridded Relative Deprivation Index (GRDI) raster showing count of constituent inputs that were filled in per cell using the Fill Missing Values tool \n\nVisualise on EO Dashboard\n\nGlobal Gridded Relative Deprivation Index (GRDI) built-up area (BUILT) Constituent raster \n\nVisualise on EO Dashboard\n\nGlobal Gridded Relative Deprivation Index (GRDI), V1 raster \n\nVisualise on EO Dashboard\n\nGlobal Gridded Relative Deprivation Index (GRDI) Infant Mortality Rate (IMR) Constituent raster \n\nVisualise on EO Dashboard\n\nGlobal Gridded Relative Deprivation Index (GRDI) Child Dependency Ratio (CDR) Constituent raster \n\nVisualise on EO Dashboard\n\nWorld Settlement Footprint \n\nvisualise on EO Dashboard\n\nVolume of activity at parking lot (EU) \n\nvisualise on RACE\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#raster","position":11},{"hierarchy":{"lvl1":"Data Access","lvl4":"Vector / Tabular","lvl3":"Economic Datasets","lvl2":"List of Datasets"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#vector-tabular","position":12},{"hierarchy":{"lvl1":"Data Access","lvl4":"Vector / Tabular","lvl3":"Economic Datasets","lvl2":"List of Datasets"},"content":"\n\nAirports: Throughput \n\nvisualise on EO Dashboard\n\nActivity (cars/containers) \n\nvisualise on EO Dashboard\n\nAirpports: airplanes traffic (EU) \n\nvisualise on RACE\n\nMobilility Data \n\nvisualise on EO Dashboard\n\nPorts and Shipping - Major Harbours \n\nvisualise on EO Dashboard\n\nPorts and Shipping - impact on air quality (EU) \n\nvisualise on RACE\n\nPorts and Shipping - impact on cruises (EU) \n\nvisualise on RACE\n\nPorts and Shipping - traffic AIS (EU) \n\nvisualise on RACE\n\nPorts and Shipping - traffic AIS, Sentinel-1, mobile (EU) \n\nvisualise on RACE\n\nBorder crossing points: volume of activity(EU) \n\nvisualise on RACE\n\nCommercial centres: volume of activity (EU) \n\nvisualise on RACE\n\neurope: Crude Oil Storage Index (EU) \n\nvisualise on RACE\n\neuropean sites: Crude Oil Storage Index (EU) \n\nvisualise on RACE\n\nOil Storage Volume (EU) \n\nvisualise on RACE\n\nFinished Goods Production: output inventory level (EU) \n\nvisualise on RACE\n\nNumber of Trucks Timeseries (EU) \n\nvisualise on RACE\n\nVessel Density Timeseries (EU) \n\nvisualise on RACE\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#vector-tabular","position":13},{"hierarchy":{"lvl1":"Data Access","lvl3":"Agriculture","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#agriculture","position":14},{"hierarchy":{"lvl1":"Data Access","lvl3":"Agriculture","lvl2":"List of Datasets"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#agriculture","position":15},{"hierarchy":{"lvl1":"Data Access","lvl4":"Raster","lvl3":"Agriculture","lvl2":"List of Datasets"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#raster-1","position":16},{"hierarchy":{"lvl1":"Data Access","lvl4":"Raster","lvl3":"Agriculture","lvl2":"List of Datasets"},"content":"\n\nglobal: Aboveground Biomass \n\nvisualise on EO Dashboard\n\nglobal: GEOGLAM Crop Conditions \n\nvisualise on EO Dashboard\n\nglobal: Global NDVI \n\nvisualise on EO Dashboard\n\nglobal: Soil Moisture \n\nvisualise on EO Dashboard\n\nglobal: Solar Induced Chlorophyll Fluorescense \n\nvisualise on EO Dashboard\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#raster-1","position":17},{"hierarchy":{"lvl1":"Data Access","lvl4":"Vector / Tabular","lvl3":"Agriculture","lvl2":"List of Datasets"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#vector-tabular-1","position":18},{"hierarchy":{"lvl1":"Data Access","lvl4":"Vector / Tabular","lvl3":"Agriculture","lvl2":"List of Datasets"},"content":"\n\nActivity Indicator \n\nvisualise on EO Dashboard\n\nHarvesting Activity: cummulative harvested area \n\nvisualise on EO Dashboard\n\nHarvesting Evolution over time \n\nvisualise on EO Dashboard\n\nPlanting Activity \n\nvisualise on EO Dashboard\n\nProductive Area \n\nvisualise on EO Dashboard\n\nProductive Area Change \n\nvisualise on EO Dashboard\n\nRegional Cropland \n\nvisualise on EO Dashboard\n\nAgricultural Workers (EU) \n\nvisualise on RACE\n\nNational Harvesting Evolution (EU) \n\nvisualise on RACE\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#vector-tabular-1","position":19},{"hierarchy":{"lvl1":"Data Access","lvl3":"Health","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#health","position":20},{"hierarchy":{"lvl1":"Data Access","lvl3":"Health","lvl2":"List of Datasets"},"content":"Covid-19 Cases \n\nvisualise on EO Dashboard\n\nCovid-19 Vaccinations \n\nvisualise on EO Dashboard\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#health","position":21},{"hierarchy":{"lvl1":"Data Access","lvl3":"Atmosphere","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#atmosphere","position":22},{"hierarchy":{"lvl1":"Data Access","lvl3":"Atmosphere","lvl2":"List of Datasets"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#atmosphere","position":23},{"hierarchy":{"lvl1":"Data Access","lvl4":"Raster","lvl3":"Atmosphere","lvl2":"List of Datasets"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#raster-2","position":24},{"hierarchy":{"lvl1":"Data Access","lvl4":"Raster","lvl3":"Atmosphere","lvl2":"List of Datasets"},"content":"\n\nglobal: Carbon Monoxide (TROPOMI) \n\nvisualise on EO Dashboard\n\nglobal: Methane (weekly - TROPOMI) \n\nvisualise on EO Dashboard\n\nglobal: Nitrogen Dioxide (weekly - TROPOMI)\n\nvisualise on EO Dashboard\n\nglobal: Nitrogen Dioxide (monthly - OMI/Aura)\n\nvisualise on EO Dashboard\n\nglobal: Nitrogen Dioxide Difference (monthly compared to baseline - OMI/Aura)\n\nvisualise on EO Dashboard\n\nglobal: Nitrogen Dioxide (yearly - OMI/Aura) \n\nvisualise on EO Dashboard\n\nglobal: Sulfur Dioxide (OMI/Aura) \n\nvisualise on EO Dashboard\n\nglobal: Sulfur Dioxide (TROPOMI) \n\nvisualise on EO Dashboard\n\nglobal: Carbon Dioxide mean \n\nvisualise on EO Dashboard\n\nglobal: Carbon Dioxide Difference  (monthly compared to baseline) \n\nvisualise on EO Dashboard\n\neurope: C3S Data - Temperature (EU) \n\nvisualise on RACE\n\neurope: C3S Data - Relative humidity (EU) \n\nvisualise on RACE\n\neurope: C3S Data - Wind U (EU) \n\nvisualise on RACE\n\neurope: C3S Data - Wind V (EU) \n\nvisualise on RACE\n\neurope: CAMS Air Quality - NO2 (EU) \n\nvisualise on RACE\n\neurope: CAMS Air Quality - PM2.5 (EU) \n\nvisualise on RACE\n\neurope: CAMS Air Quality - PM10 (EU)\n\nvisualise on RACE\n\neurope: CAMS Air Quality - O3 (EU) \n\nvisualise on RACE\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#raster-2","position":25},{"hierarchy":{"lvl1":"Data Access","lvl4":"Vector / Tabular","lvl3":"Atmosphere","lvl2":"List of Datasets"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#vector-tabular-2","position":26},{"hierarchy":{"lvl1":"Data Access","lvl4":"Vector / Tabular","lvl3":"Atmosphere","lvl2":"List of Datasets"},"content":"\n\nglobal cities: Air Quality (NO2) at city level \n\nvisualise on EO Dashboard\n\neuropean cities: CAMS Air Quality - NO2 (EU) \n\nvisualise on RACE\n\neuropean cities: CAMS Air Quality - PM2.5 (EU) \n\nvisualise on RACE\n\neuropean cities: CAMS Air Quality - PM10 (EU) \n\nvisualise on RACE\n\neuropean cities: CAMS Air Quality - O3 (EU) \n\nvisualise on RACE\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#vector-tabular-2","position":27},{"hierarchy":{"lvl1":"Data Access","lvl3":"Water & Ocean","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#water-ocean","position":28},{"hierarchy":{"lvl1":"Data Access","lvl3":"Water & Ocean","lvl2":"List of Datasets"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#water-ocean","position":29},{"hierarchy":{"lvl1":"Data Access","lvl4":"Raster","lvl3":"Water & Ocean","lvl2":"List of Datasets"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#raster-3","position":30},{"hierarchy":{"lvl1":"Data Access","lvl4":"Raster","lvl3":"Water & Ocean","lvl2":"List of Datasets"},"content":"\n\nglobal: Ocean Primary Productivity \n\nvisualise on EO Dashboard\n\nglobal: Precipitation Anomaly \n\nvisualise on EO Dashboard\n\nglobal: Soil Moisture \n\nvisualise on EO Dashboard\n\nglobal: Sea Ice Concentration \n\nvisualise on EO Dashboard\n\nglobal: Sea Ice Thickness \n\nvisualise on EO Dashboard\n\nregional: Water Quality Regional Maps (EU)\n\nvisualise on RACE\n\nregional: Water Quality Regional Maps \n\nvisualise on EO Dashboard\n\neurope: CMEMS Water Quality (EU) \n\nvisualise on RACE\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#raster-3","position":31},{"hierarchy":{"lvl1":"Data Access","lvl4":"Vector / Tabular","lvl3":"Water & Ocean","lvl2":"List of Datasets"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#vector-tabular-3","position":32},{"hierarchy":{"lvl1":"Data Access","lvl4":"Vector / Tabular","lvl3":"Water & Ocean","lvl2":"List of Datasets"},"content":"\n\nregional: Water Quality Time Series \n\nvisualise on EO Dashboard\n\nAll the avaialable raster data can be explored in the \n\nEuroDataCube collection archive where you can easily search for data. The vector data, stored in the GeoDB is listed below.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#vector-tabular-3","position":33},{"hierarchy":{"lvl1":"Data Access","lvl3":"How do I access the data?","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#how-do-i-access-the-data","position":34},{"hierarchy":{"lvl1":"Data Access","lvl3":"How do I access the data?","lvl2":"List of Datasets"},"content":"\n\nThe vector data is stored in the GeoDB, you can access it using the following steps:\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#how-do-i-access-the-data","position":35},{"hierarchy":{"lvl1":"Data Access","lvl3":"1. Accessing vector data with GeoDB","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#id-1-accessing-vector-data-with-geodb","position":36},{"hierarchy":{"lvl1":"Data Access","lvl3":"1. Accessing vector data with GeoDB","lvl2":"List of Datasets"},"content":"\n\nThis first cell is just checking the appropriate permissions are in place\n\nfrom edc import check_compatibility\nfrom xcube_geodb.core.geodb import GeoDBClient\ngeodb = GeoDBClient()\ngeodb.whoami\n\nEach indicator has a code which can be used to query the data, we need to define the indicator of interest and the database we are going to query. A full list of the indicators available through the GeoDB is shown bellow. JSON files describing each indicator are available \n\nhere.\n\nName\n\nCollection Code\n\nAvailable Locations\n\nImport/production sites: status of metallic ores\n\nE1\n\nPort of Genoa, Gdynia, Gdansk, Gijon, Genova, Hamburg, Dunkirk, Dunkirque, Ghent\n\nProductive area\n\nE10a1_tri\n\nBrandenburg\n\nActivity Indicator\n\nE10a2_tri\n\nBrandenburg\n\nProductive area change\n\nE10a3_tri\n\nBrandenburg\n\nNumber of berry trucks in 2018-2019\n\nE10a5\n\nLaguna de las Madres\n\nRegional Harvesting Evolution\n\nE10a6\n\nRegions of Spain\n\nHarvesting activity: cumulative harvested area\n\nE10a8\n\nRegions of Spain\n\nNational Harvesting Evolution\n\nE10a10\n\nEurope\n\nCommercial centres: volume of activity\n\nE11\n\nWarsaw, Brussels, Athens, Milan, Rome, Bucharest\n\nBorder crossing points: volume of activity\n\nE12b\n\nGB Border\n\nAirports: throughput\n\nE13b, E13b_tri\n\nEuropean Airports\n\nAirports: airplane traffic\n\nE13d\n\nEuropean Airports\n\nPorts and Shipping - Major Harbours\n\nE13c_tri\n\nHamburg, Ghent, Gdynia, Dunkirk, Genoa, Suez\n\nMaritime Traffic\n\nE13e,f,g,h,i,l,m,n\n\nGioia Tauro, Genoa\n\nChanges in commertial fluxes\n\nE13n\n\nGijon\n\nPorts and Shipping - Major Harbours\n\nE200\n\nHamburg, Ghent, Gdynia, Dunkirk, Genoa, Suez\n\nFinished goods production: output inventory level\n\nE8\n\nSwindon, Cassino, Ghent, Mioveni, Russelsheim, Leipzig, Craiova, Nosovice, Martorell, Barcelona, Emden, Ingolstadt, Kvasiny\n\nActivity (cars/containers)\n\nE9_tri\n\nBeijing, Singapore, Palm Springs, Los Angeles, Arcadia, Nagoya\n\nAir Quality (tropomi NO2)\n\nN1, N1_tri\n\nEuropean Cities & Major World Cities\n\nCAMS Air Quality (PM 2.5)\n\nN1a\n\nEuropean Cities\n\nCAMS Air Quality (NO2)\n\nN1b\n\nEuropean Cities\n\nCAMS Air Quality (PM10)\n\nN1c\n\nEuropean Cities\n\nCAMS Air Quality (O3)\n\nN1d\n\nEuropean Cities\n\nGreenhouse Gas\n\nN2_tri\n\nMajor World Cities\n\nWater Quality Time Series\n\nN3, N3b_tri\n\nBarcelona, Marseilles, Venice Lagoon & Major World Ports\n\nPlease feel free to change the value of geodb_collection and use other indicators.\n\ngeodb_database = \"eodash\"\ngeodb_collection = \"E13c_tri\"\n\nTo get an overview over the data we can get the first rows of the dataset.\n\nThe data contains measured values during a measurement period categorised as “low”, “medium”, “high” under “indicator_value” heading.\n\ndata = geodb.get_collection(collection=geodb_collection, database=geodb_database)\ndata.head()\n\nA valid header line for a CSV uses the strings in bold and looks like this:\n\nAOI,Country,Region,City,Site Name,Description,Method,EO Sensor,Input Data,Indicator code,Time,Measurement Value,Reference Description,Reference time,Reference value,Rule,Indicator Value,Sub-AOI,Y axis,Indicator Name,Color code,Data Provider,AOI_ID,Update Frequency\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#id-1-accessing-vector-data-with-geodb","position":37},{"hierarchy":{"lvl1":"Data Access","lvl3":"2. Accessing Raster Data (SentinelHub)","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#id-2-accessing-raster-data-sentinelhub","position":38},{"hierarchy":{"lvl1":"Data Access","lvl3":"2. Accessing Raster Data (SentinelHub)","lvl2":"List of Datasets"},"content":"\n\nAll the datasets stored \n\nhere are requested using the SentinelHub Processing API, this uncludes satellite data and BYOC datasets.\n\nThese datasets are requested using an evalscript and a request. In the evalscript you must define the collection ID and the band name, along with the visualisation parameters.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#id-2-accessing-raster-data-sentinelhub","position":39},{"hierarchy":{"lvl1":"Data Access","lvl3":"BYOC Datasets","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#byoc-datasets","position":40},{"hierarchy":{"lvl1":"Data Access","lvl3":"BYOC Datasets","lvl2":"List of Datasets"},"content":"\n\nThese datasets have a custom ID which is used to request the data. Below is a list of the data which is stored in this way:\n\nPublic Collection\n\ncollection ID\n\nBandName\n\nDescription\n\nCHL​_water​_quality​_Saturday\n\n82560c29-0b55-44c8-a01c-43b95c359518\n\nchl\n\nChlorophyll anomaly maps for 3 sites: Lagoon Venice, Marseille and Barcelona regions\n\nTSMN​_water​_quality​_Saturday\n\n358448a1-23c1-4d58-924d-22249ab09048\n\ntsmnn\n\nTotal suspended matter maps for 3 sites: Lagoon Venice, Marseille and Barcelona regions\n\nE12C_Motorway\n\nefb2b070-39d6-4cfc-842f-57f8f54f22a0\n\nMotorwayActivity\n\nDetection of moving trucks on motorways in the EU using Sentinel-2\n\nE12D​_Primary​_corrected\n\n06e51c55-a10c-43ba-ad93-ddd6258d5e9a\n\nPrimaryRoadsActivity\n\nDetection of moving trucks on motorways in the EU using Sentinel-2\n\nICEYE_E3\n\nc47fa011-e9cd-4076-9b2f-68a93d757e58\n\nGRD\n\nOil storages filling up as demand for oil decreases when people are not travelling\n\nICEYE_E11\n\n0771d000-92ca-4f7d-9788-b56ca0411cf7\n\nGRD\n\nActivity for leisure industry reduced\n\nICEYE_E11a\n\na9ae7d6a-70c8-4575-854a-1a8f0cb33317\n\nGRD\n\nActivity at leisure facility (Stadium) affected by COVID\n\nICEYE_E13b\n\n4a537983-1c61-4c6e-9c85-7b3972b7b596\n\nGRD\n\nICEYE image and detection of parked airplanes\n\nJAXA​_wq​_chla​_anomaly\n\n198aa13a-b0c0-4b78-8f69-e08fc58551a7\n\nchla\n\nWater quality Chlorophyll-a weekly anomaly\n\nJAXA_wq_tsm_anomaly\n\n925b4bf6-ca1b-45df-a523-88f30823ab07\n\ntsm\n\nTotal suspended matter weekly anomoly\n\n2mT​_2020​_Monthly​_Average​_from​_CDS\n\n0b3eebec-30de-4fa6-9cd3-4b252d45d847\n\nAIR2MT\n\nGridded ERA5 is the fifth generation ECMWF reanalysis for the global climate and weather for the past 4 to 7 decades - 2 meter temperature\n\nWind_10m_u\n\n067fbb53-b1c3-4a57-9c81-adf2488a47ee\n\nwindu10m\n\nGridded ERA5 is the fifth generation ECMWF reanalysis for the global climate and weather for the past 4 to 7 decades - Easterly Winds\n\nWind_10m_v\n\n3043d07f-3c20-410c-9a87-7da720942ab8\n\nwindv10m\n\nGridded ERA5 is the fifth generation ECMWF reanalysis for the global climate and weather for the past 4 to 7 decades - Northern Winds\n\nPopulation_density\n\nb468089b-2627-4787-b984-89c10434f6c6\n\npopulationDensity\n\nGridded Population of the World v4 for year 2020\n\nS5P​-NO2​-tropno​-daily​-check\n\n972e67a7-2ca8-4bf6-964a-11fe772e3ac2\n\ntropno2\n\nThe data comes from the Copernicus Sentinel-5P satellite and shows the averaged nitrogen dioxide concentrations across the globe\n\nS5P-SO2-daily\n\n4ad9663f-d173-411d-8d28-3081d4d9e3aa\n\nso2\n\nThe data comes from the Copernicus Sentinel-5P satellite and shows the average solfure dioxide concentrations\n\nS5P-CO-3daily\n\n57a07405-8ec2-4b9c-a273-23e287c173f8\n\nco\n\nThe data comes from the Copernicus Sentinel-5P satellite and shows the average carbon monoxide concentrations\n\nS5P-CH4-weekly\n\n0ecb4a55-5ce2-4525-bdcb-a333d37d46ef\n\nch4\n\nThe data comes from the Copernicus Sentinel-5P satellite and shows the average methane concentrations\n\nOcean-Net-Primary-Production (BICEP)\n\na216afca-8a65-4072-87a5-8ed7aa21e08a\n\npp\n\nThis dataset is produced in the frame of project Biological Pump and Carbon Exchange Processes (BICEP)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#byoc-datasets","position":41},{"hierarchy":{"lvl1":"Data Access","lvl3":"Requesting Data","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#requesting-data","position":42},{"hierarchy":{"lvl1":"Data Access","lvl3":"Requesting Data","lvl2":"List of Datasets"},"content":"\n\nFirst the permissions:\n\nimport os\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# Your client credentials\nclient_id = os.environ['SH_CLIENT_ID']\nclient_secret = os.environ['SH_CLIENT_SECRET']\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_id=client_id, client_secret=client_secret)\n\n# All requests using this session will have an access token automatically added\nresp = oauth.get(\"https://services.sentinel-hub.com/oauth/tokeninfo\")\n\nAs an example, here we access the population density information for a specific country (Austria).\nWe use the \n\nNUTS Tool to help.\n\nimport requests\n# First let us get the area information of the country from the administratives zones\n# You can find all the different NUTS levels, resolution here: https://gisco-services.ec.europa.eu/distribution/v2/nuts/nuts-2021-files.html\n\nresponse = requests.get(\n    \"https://gisco-services.ec.europa.eu/distribution/v2/nuts/geojson/NUTS_RG_10M_2021_4326_LEVL_0.geojson\"\n)\n\ndata = response.json()\n\n# Now lets find the geometry information for one country\nmatch = [x for x in data[\"features\"] if x[\"properties\"][\"CNTR_CODE\"] == 'AT'][0]\n\nHere we see how to access specifically loaded datasets, for learning how to access default datasets look further down in this tutorial notebook. You have access to a number of \n\ndatasets. We display the syntax using population data:\n\nresponse = requests.post('https://shservices.mundiwebservices.com/api/v1/process',\n  headers={\"Authorization\" : \"Bearer %s\"%(token['access_token'])},\n  json={\n    \"input\": {\n        \"bounds\": {\n            \"geometry\": match[\"geometry\"]\n        },\n        \"data\": [{\n            \"type\": \"byoc-collectionID\"\n        }]\n    },\n    \"output\": {\n        \"width\": 800,\n        \"height\": 400,\n    },\n    \"evalscript\": \"\"\"\n    //VERSION=3\n    function setup() {\n      return {\n        input: [{\n          bands: [\"band_name\", \"dataMask\"], // this sets which bands to use\n        }],\n        output: { // this defines the output image type\n          bands: 4,\n          sampleType: \"UINT8\"\n        }\n      };\n    }\n\n    function evaluatePixel(sample) {\n      var arr = colorBlend(\n          sample.band_name,\n          [1, 5, 25, 250, 1000, 10000],\n          [[255,242,209],[255,218,166],[250,184,85],[253,141,60],[240,59,32],[189,0,38]]\n      ); \n      if (sample.dataMask==1)  arr.push(255);\n      else arr.push(0);\n      return arr;\n    }\n    \"\"\"\n})\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#requesting-data","position":43},{"hierarchy":{"lvl1":"Data Access","lvl4":"Satellite Imagery","lvl3":"Requesting Data","lvl2":"List of Datasets"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#satellite-imagery","position":44},{"hierarchy":{"lvl1":"Data Access","lvl4":"Satellite Imagery","lvl3":"Requesting Data","lvl2":"List of Datasets"},"content":"Now that we have the necessary token we can access the data through the processing API.As described in the documentation we can access multiple datasets, but for this challenge we consider the following the most relevant:\n\nS1GRD\n\nS2L1C\n\nS2L2A\n\nS3OLCI\n\nS3SLSTR\n\nS5PL2\n\nHave also a look at the linked references of the list as they also show available bands for the datasets.\nThis identifier can then be used in the data type definition of the request.The example that follows is taken from the API documentation, we are selecting a bounding box, which bands will be used and a function of how the pixel will be evaluated.\n\nimport requests\n\navailable_datasets = ['S2L1C', 'S2L2A']\nresponses = {}\n\nfor ds in available_datasets:\n    responses[ds] = requests.post('https://services.sentinel-hub.com/api/v1/process',\n      headers={\"Authorization\" : \"Bearer %s\"%(token['access_token'])},\n      json={\n        \"input\": {\n            \"bounds\": {\n                \"bbox\": [ 13.45, 45.4, 13.55,45.5 ]\n            },\n            \"data\": [{\n                \"type\": ds\n            }]\n        },\n        \"evalscript\": \"\"\"\n        //VERSION=3\n\n        function setup() {\n          return {\n            input: [\"B02\", \"B03\", \"B04\"],\n            output: {\n              bands: 3\n            }\n          };\n        }\n\n        function evaluatePixel(\n          sample,\n          scenes,\n          inputMetadata,\n          customData,\n          outputMetadata\n        ) {\n          return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02];\n        }\n        \"\"\"\n    })\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#satellite-imagery","position":45},{"hierarchy":{"lvl1":"Data Access","lvl3":"Requesting Data with SentinelHub Function","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#requesting-data-with-sentinelhub-function","position":46},{"hierarchy":{"lvl1":"Data Access","lvl3":"Requesting Data with SentinelHub Function","lvl2":"List of Datasets"},"content":"You can also request the data using the \n\nSentinelHub Request Function which you may find more intuitive.\n\nfrom sentinelhub import (\n    CRS,\n    BBox,\n    DataCollection,\n    DownloadRequest,\n    MimeType,\n    SentinelHubDownloadClient,\n    SentinelHubRequest,\n    bbox_to_dimensions,\n)\n\nfrom sentinelhub import SHConfig\n\nconfig = SHConfig()\n\nif not config.sh_client_id or not config.sh_client_secret:\n    print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\nBelow we define our area using a bbox, which we use to define a \n\nsentinelhub bbox object. When requesting data with the bbox object you must also define the size of the area. Be aware the maximum number of pixels is (2500, 2500).\n\nThe area can also be defined as a \n\nsentinelhub geometry object from any of the following geometry representations:\n- shapely.geometry.Polygon or shapely.geometry.MultiPolygon\n- A GeoJSON dictionary with (multi)polygon coordinates\n- A WKT string with (multi)polygon coordinates\n\n# define bbox\nbetsiboka_coords_wgs84 = [46.16, -16.15, 46.51, -15.58]\n\n# creating SH bbox object\nresolution = 60\nbetsiboka_bbox = BBox(bbox=betsiboka_coords_wgs84, crs=CRS.WGS84)\nbetsiboka_size = bbox_to_dimensions(betsiboka_bbox, resolution=resolution)\n\nprint(f\"Image shape at {resolution} m resolution: {betsiboka_size} pixels\")\n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=(\"2020-06-12\", \"2020-06-13\"),\n        )\n    ],\n    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n    bbox=betsiboka_bbox, # geometry = geometry\n    size=betsiboka_size, # not needed for geometry object\n    config=config,\n)\n\ntrue_color_imgs = request_true_color.get_data()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#requesting-data-with-sentinelhub-function","position":47},{"hierarchy":{"lvl1":"Data Access","lvl3":"2. Accessing Raster Data (NASA API)","lvl2":"List of Datasets"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#id-2-accessing-raster-data-nasa-api","position":48},{"hierarchy":{"lvl1":"Data Access","lvl3":"2. Accessing Raster Data (NASA API)","lvl2":"List of Datasets"},"content":"\n\nThe data is accessed using a \n\nSTAC endpoint.\n\nimport sys\n!{sys.executable} -m pip install pystac\n\nfrom pystac import Catalog\nimport concurrent.futures\nimport datetime as dt\nfrom ipyleaflet import basemaps, Map, GeoJSON\nimport json\nimport requests as re\nimport matplotlib.pyplot as plt\nimport pprint\nimport time\n\nSTAC_ENDPOINT_URL = \"https://staging-stac.delta-backend.com\"\n\nstac_api_url = 'https://staging-stac.delta-backend.com/'\ncatalog = Catalog.from_file(stac_api_url)\n\nBelow we list the availabe datasets.\n\nfor root, subcatalogs, items in catalog.walk():\n    # subcats represents any catalogs or collections owned by root\n    for cat in subcatalogs:\n        print(cat.id)\n\nSelect an indicator of interesting and load as a json.\n\nre.get(f\"{STAC_ENDPOINT_URL}/collections/no2-monthly\").json()\n\nFind the periodicy of the data.\n\npprint.pprint({\n    k:v for k,v in re.get(f\"{STAC_ENDPOINT_URL}/collections/no2-monthly\").json().items()\n    if k in [\"dashboard:is_periodic\", \"dashboard:time_density\", \"summaries\"]\n})\n\nInspect one of the monthly measurments.\n\nitems = re.get(f\"{STAC_ENDPOINT_URL}/collections/no2-monthly/items?limit=100\").json()[\"features\"]\nitems[0]","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-data-access#id-2-accessing-raster-data-nasa-api","position":49},{"hierarchy":{"lvl1":"Truck Detection Exercise"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2","position":0},{"hierarchy":{"lvl1":"Truck Detection Exercise"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2022.10-14\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2","position":1},{"hierarchy":{"lvl1":"Truck Detection Exercise"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#truck-detection-exercise","position":2},{"hierarchy":{"lvl1":"Truck Detection Exercise"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#truck-detection-exercise","position":3},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#detect-trucks-using-sentinel-2-data-user-guide","position":4},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#detect-trucks-using-sentinel-2-data-user-guide","position":5},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Parallax-based truck detection"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#parallax-based-truck-detection","position":6},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Parallax-based truck detection"},"content":"\n\nThis notebook is a comprehensive script for detecting trucks with Sentinel-2 data. In order to run the detection in your area of interest you will have to modify two cells:\n\nArea of Interest (specify the aoi as bounding box)\n\nDate (specify an acquisition date)\n\nAfterwards, you may simply run all cells and check the result at the end of the script where you can also write the detections as points.\n\nEnsure that you have access to the Sentinel Hub resources for retrieving Sentinel-2 data through its API (via xcube_sh).\n\nAuthor: Henrik Fisser, 2020Explanations on the truck detection on GitHub: \n\nhttps://​github​.com​/hfisser​/Truck​_Detection​_Sentinel2​_COVID19\n\nimport os\nimport subprocess\nimport sys\n\n# installations\ndef install_package(pkg):\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\ninstall_package(\"OSMPythonTools\")\ninstall_package(\"geocube\")\n\n# OSM API\nfrom OSMPythonTools.overpass import overpassQueryBuilder, Overpass\n\nimport numpy as np\nimport xarray as xr\nimport geocube\nimport geopandas as gpd\nimport pandas as pd\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\nfrom xcube.core.maskset import MaskSet\nfrom rasterio import features\nfrom affine import Affine\nfrom shapely import geometry, coords\nfrom shapely.geometry import Polygon, Point, box\nfrom numba import jit\n\nimport IPython.display\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#parallax-based-truck-detection","position":7},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Area of Interest"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#area-of-interest","position":8},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Area of Interest"},"content":"Specify an area of interest as bounding box in format:xmin, ymin, ymax, ymax\n\nbbox = 101.607,3.0500, 101.7507, 3.20, # Kuala Lumpur\nkualalumpur_bbox = [101.607,3.0500, 101.7507, 3.20]\nIPython.display.GeoJSON(box(*bbox).__geo_interface__)\n\nOther AOIs can be generated here, just remeber toc change bbox in the code accrodingly\n\n# bbox = -3.85, 40.3, -3.55, 40.5 # Madrid\n# Madrid_bbox = [-3.85, 40.3, -3.55, 40.5]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#area-of-interest","position":9},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Date"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#date","position":10},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Date"},"content":"Select a cloud-free acquisition and provide the date as “YYYY-MM-DD”.\nYou may select data e.g. here:Copernicus Open Access Hub\n\n\nhttps://​scihub​.copernicus​.eu​/dhus​/​#​/home EO Browser\n\n\nhttps://​apps​.sentinel​-hub​.com​/eo​-browser​/​?zoom​=​10​&​lat​=​41​.9​&​lng​=​12​.5​&​themeId​=​DEFAULT​-THEME\n\nthe identified date below is an almost cloud free image of Sentinel 2 over the area of Kuala Lumpur. In case of other AOI you need to identify a proper date as explained above and set here the updated one\n\n# Start and end date for Kuala Lumpur use case\ndate_start = \"2020-05-18\"\ndate_end = \"2020-05-18\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#date","position":11},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Open Street Maps (OSM)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#open-street-maps-osm","position":12},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Open Street Maps (OSM)"},"content":"Trucks are only detected on roads obtained from OSM.\nYou may specify road types to include. Their descriptions can be found here:\n\nhttps://​wiki​.openstreetmap​.org​/wiki​/Key:highway\n\nosm_values = [\"motorway\", \"trunk\", \"primary\"] # all of key \"highway\"\nroads_buffer = 0.00022 # degree, OSM road vectors are buffered, for motorway, the others lower\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#open-street-maps-osm","position":13},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Processing methods"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#processing-methods","position":14},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Processing methods"},"content":"In the following cells all needed methods are defined. They will be invoked further below.\n\n# re-order bbox from W,S,E,N to S,W,N,E, starting from the bbox defined at the beginning\n\ndef convert_bbox_osm(bbox):\n    offset = 0.05 # add a buffer to bbox in order to be sure cube is entirely covered, pay attention to the signs before the adding the offset\n    bbox_osm = [bbox[1], bbox[0], bbox[3], bbox[2]]\n    bbox_osm[0] -= offset # min lat\n    bbox_osm[1] -= offset # min lon\n    bbox_osm[2] += offset # max lat\n    bbox_osm[3] += offset # max lon\n    return bbox_osm\n\n# bbox List of four coords\n# osm_value String OSM value\n# osm_key String OSM key\n# element_type List of String\n# returns GeoDataFrame\ndef get_osm(bbox, \n            osm_value,\n            element_type = [\"way\", \"relation\"]):\n    osm_key = \"highway\"\n    bbox_osm = convert_bbox_osm(bbox)\n    quot = '\"'\n    select = quot+osm_key+quot + '=' + quot+osm_value+quot\n    select_link = select.replace(osm_value, osm_value + \"_link\") # also get road links\n    select_junction = select.replace(osm_value, osm_value + \"_junction\")\n    geoms = []\n    for selector in [select, select_link, select_junction]:  \n        try:\n            query = overpassQueryBuilder(bbox=bbox_osm, \n                                         elementType=element_type, \n                                         selector=selector, \n                                         out='body',\n                                         includeGeometry=True)\n            elements = Overpass().query(query, timeout=60).elements()\n            # create multiline of all elements\n            if len(elements) > 0:\n                for i in range(len(elements)):\n                    elem = elements[i]\n                    geoms.append(elem.geometry())\n        except:\n            Warning(\"Could not retrieve \" + select)\n    try:\n        lines = gpd.GeoDataFrame(crs = \"EPSG:4326\", geometry = geoms)\n        n = len(geoms)\n        lines[\"osm_value\"] = [osm_value]*n # add road type\n        return lines\n    except:\n        Warning(\"Could not merge \" + osm_value)\n        \n# buffer Float road buffer distance [m]\n# bbox List of four coords\n# bbox_id Integer processing id of bbox\n# osm_values List of String OSM values\n# osm_key String OSM key\n# roads_buffer Float buffer width\n# returns GeoDataFrame\ndef get_roads(bbox, osm_values, roads_buffer):\n    osm_key = \"highway\"\n    roads = []\n    has_error = []\n    offset = 0.00002\n    buffer_dist = \"buffer_distance\"\n    # buffer according to road type\n    m,t,p,s,ter = \"motorway\", \"trunk\", \"primary\", \"secondary\", \"tertiary\"\n    buffers = {m:roads_buffer, t:roads_buffer-offset, p:roads_buffer-(2*offset), s:roads_buffer-(3*offset), ter:roads_buffer-(4*offset)}\n    osm_values_int = {m:1, t:2, p:3, s:4, ter:5}\n    for osm_value in osm_values:\n        roads_osm = get_osm(bbox, osm_value)\n        try:\n            roads_osm = get_osm(bbox, osm_value)\n            roads_osm[buffer_dist] = [buffers[osm_value]] * len(roads_osm)\n            roads_osm[\"osm_value_int\"] = osm_values_int[osm_value]\n            roads.append(roads_osm)\n        except:\n            has_error.append(1)\n            print(\"'get_osm'\" + \"failed for bbox_id osm_value \" + osm_value + \"osm_key\" + osm_key)\n    if len(roads) > len(has_error):\n        roads_merge = gpd.GeoDataFrame(pd.concat(roads, ignore_index=True), crs=roads[0].crs)\n        buffered = roads_merge.buffer(distance=roads_merge[buffer_dist])\n        roads_merge.geometry = buffered\n        return roads_merge\n\n# osm geodataframe of polygons\n# reference_raster xarray with lat and lon\n# returns numpy array\ndef rasterize_osm(osm, reference_raster):\n    osm_values = list(set(osm[\"osm_value\"]))\n    nan_placeholder = 100\n    road_rasters = []\n    for osm_value in osm_values:\n        osm_subset = osm[osm[\"osm_value\"] == osm_value]\n        raster = rasterize(osm_subset, reference_raster.lat, reference_raster.lon)\n        cond = np.isfinite(raster)\n        raster_osm = np.where(cond, list(osm_subset.osm_value_int)[0], nan_placeholder) # use placeholder instead of nan first\n        raster_osm = raster_osm.astype(np.float)\n        road_rasters.append(raster_osm)        \n    # merge road types in one layer\n    road_raster_np = np.array(road_rasters).min(axis=0) # now use the lowest value (highest road level) because some intersect\n    road_raster_np[road_raster_np == nan_placeholder] = 0\n    return road_raster_np # 0=no_road 1=motorway, 2=trunk, ...\n\ndef transform_lat_lon(lat, lon):\n    lat = np.asarray(lat)\n    lon = np.asarray(lon)\n    trans = Affine.translation(lon[0], lat[0])\n    scale = Affine.scale(lon[1] - lon[0], lat[1] - lat[0])\n    return trans * scale\n\ndef rasterize(polygons, lat, lon, fill=np.nan):\n    transform = transform_lat_lon(lat, lon)\n    out_shape = (len(lat), len(lon))\n    raster = features.rasterize(polygons.geometry, out_shape=out_shape,\n                                fill=fill, transform=transform,\n                                dtype=float)\n    return xr.DataArray(raster, coords={\"lat\":lat, \"lon\":lon}, dims=(\"lat\", \"lon\"))\n\n# TruckDetector detects trucks at acquisition-level\nclass TruckDetector():   \n    def __init__(self, band_stack):\n        is_none = band_stack is None\n        self.band_stack = band_stack.chunk(band_stack.dims[\"lat\"], band_stack.dims[\"lon\"]) if not is_none else None\n        self.no_truck_mask = None\n        self.trucks = None\n    \n    def detect(self):\n        B02 = self.band_stack.B02.persist().values\n        B03 = self.band_stack.B03.persist().values\n        B04 = self.band_stack.B04.persist().values\n        B08 = self.band_stack.B08.persist().values\n        B11 = self.band_stack.B11.persist().values\n        no_truck_mask = calc_no_trucks(B02, B03, B04, B08, B11)\n        trucks = detect_trucks(B02, B03, B04, no_truck_mask)\n        lon_lat = {\"lat\":self.band_stack.lat, \"lon\":self.band_stack.lon}\n        self.no_truck_mask = xr.DataArray(no_truck_mask, coords=lon_lat, dims=(\"lat\", \"lon\"))\n        self.trucks = xr.DataArray(trucks, coords=lon_lat, dims=(\"lat\", \"lon\")).astype(np.int)\n        self.filter_trucks()\n                            \n    def filter_trucks(self):\n        self.trucks = filter_spatial_3x3_extended(self.trucks)\n        \n# take xarray and ensure each value with 1 in data has no neighbor with 1 in an extended 3x3 block. Extended means: horizontally and vertically\n# it is also checked for the second-next pixel\n# Method checks only surrounding of values equal 1\n# arr xarray DataArray with values and lat lon\ndef filter_spatial_3x3_extended(arr):\n    values = arr.values\n    lon = arr.lon\n    lat = arr.lat\n    valid = np.where(arr == 1)\n    for y,x in zip(valid[0], valid[1]):\n        y_above = y - 1\n        y_above_next = y - 2\n        x_left = x - 1\n        x_right = x + 1\n        x_left_next = x - 2\n        space_left = x_left >= 0\n        space_right = x_right >= 0 and x_right < len(lon)\n        space_above = y_above >= 0\n        val_left_above = values[y_above, x_left] if space_left and space_above else 0\n        val_right_above = values[y_above, x_right] if space_right and space_above else 0\n        val_left = values[y, x_left] if space_left else 0\n        val_above = values[y_above, x] if space_above else 0\n        val_left_next = values[y, x_left_next] if x_left_next >= 0 else 0\n        val_above_next = values[y_above_next, x] if y_above_next >= 0 else 0\n        # if any of the values left, above and left above has 1 set current value 0\n        if (val_left_above + val_right_above + val_left + val_above + val_left_next + val_above_next) >= 1:\n            values[y,x] = 0\n    arr.values = values\n    return arr\n\n# extracts coordinates at value in np array and returns points as GeoDataFrame\n# data 2d np array\n# match_value Float value in data where point coordinates are extracted\n# lon_lat dict of:\n### \"lon\": np array longitude values\"\n### \"lat\": np array latitude values\"\n# crs String EPSG:XXXX\ndef points_from_np(data, match_value, lon_lat, crs):\n    indices = np.argwhere(data == match_value)\n    if len(indices) > 0:\n        lat_indices = indices[:,[0]]\n        lon_indices = indices[:,[1]]\n        lat_coords = lon_lat[\"lat\"][lat_indices]\n        lon_coords = lon_lat[\"lon\"][lon_indices]\n        points = gpd.GeoDataFrame(geometry = gpd.points_from_xy(lon_coords, lat_coords))\n        points.crs = crs\n        return points\n    \ndef raster_to_points(raster, lon_lat, field_name, crs):\n    points_list = []\n    match_values = np.unique(raster[(raster != 0) * ~np.isnan(raster)]) # by pixel value\n    for x in match_values:\n        points = points_from_np(raster, x, lon_lat, crs=crs)\n        points[field_name] = [x] * len(points)\n        points_list.append(points)\n    return gpd.GeoDataFrame(pd.concat(points_list, ignore_index=True))\n        \n# Calculate a binary mask where pixels that are definitely no trucks are represented as 0. A dictionary with a set of trheshold values is required to reduce or avoid false detection on specific land cover types\n# thresholds Dict with at least:\n### max_ndvi Float above this val: no trucks. For Vegetation\n### max_ndwi Float above this val: no trucks. For Water\n### max_ndsi Float above this val: no_trucks. For Snow\n### min_rgb Float above this val: no_trucks. For dark surfaces, e.g. shadows\n### max_blue Float above this val: no_trucks\n### max_green Float above this val: no trucks\n### max_red Float above this val: no trucks\n### min_b11 Float below this val: no trucks. For dark surfaces, e.g. shadows\n### max_b11 Float below this val: no trucks. For bright (sealed) surfaces, e.g. buildings\n@jit(nopython=True, parallel=True)\ndef calc_no_trucks(B02, B03, B04, B08, B11):\n    th = {\"min_blue\":0.06, \n          \"min_green\":0.04, \n          \"min_red\":0.04,\n          \"max_red\":0.15,\n          \"max_green\":0.15,\n          \"max_blue\":0.2,\n          \"max_ndvi\":0.5,\n          \"max_ndwi\":0.0001,\n          \"max_ndsi\":0.0001,\n          \"min_blue_green_ratio\":0.03,\n          \"min_blue_red_ratio\":0.05, \n          \"max_blue_green_ratio\":0.17, \n          \"max_blue_red_ratio\":0.2}\n    ndvi_mask = ratio(B08, B04) < th[\"max_ndvi\"]\n    ndwi_mask = ratio(B02, B11) < th[\"max_ndwi\"]\n    ndsi_mask = ratio(B03, B11) < th[\"max_ndsi\"]\n    low_rgb_mask = (B02 > th[\"min_blue\"]) * (B03 > th[\"min_green\"]) * (B04 > th[\"min_red\"])\n    high_rgb_mask = (B02 < th[\"max_blue\"]) * (B03 < th[\"max_green\"]) * (B04 < th[\"max_red\"])\n    no_truck_mask = ndvi_mask * ndwi_mask * ndsi_mask * low_rgb_mask * high_rgb_mask\n    return no_truck_mask\n\n# Calculate a binary mask where trucks are represented as 1 and no trucks as 0.\n# thresholds Dict with at least:\n### min_green_ratio Float, minimum value of blue-green ratio\n### min_red_ratio Float, minimum value of blue-red ratio\n@jit(nopython=True, parallel=True)\ndef detect_trucks(B02, B03, B04, no_truck_mask):\n    th = {\"min_blue\":0.06, \n          \"min_green\":0.04, \n          \"min_red\":0.04,\n          \"max_red\":0.15,\n          \"max_green\":0.15,\n          \"max_blue\":0.2,\n          \"max_ndvi\":0.5,\n          \"max_ndwi\":0.0001,\n          \"max_ndsi\":0.0001,\n          \"min_blue_green_ratio\":0.03,\n          \"min_blue_red_ratio\":0.05, \n          \"max_blue_green_ratio\":0.17, \n          \"max_blue_red_ratio\":0.2}\n    bg_ratio = ratio(B02, B03)\n    br_ratio = ratio(B02, B04)\n    bg = bg_ratio > th[\"min_blue_green_ratio\"]\n    br = br_ratio > th[\"min_blue_red_ratio\"]\n    bg_max = bg_ratio < th[\"max_blue_green_ratio\"]\n    br_max = br_ratio < th[\"max_blue_red_ratio\"]\n    trucks = (bg * br * bg_max * br_max) * no_truck_mask\n    return trucks\n\n@jit(nopython=True, parallel=True)\ndef ratio(a, b):\n    return (a-b)/(a+b)\n\n# AcquisitionProcessor processes all valid pixels of a single acquisition in cube\nclass AcquisitionProcessor():\n    def __init__(self, date_np64, cube):\n        self.date_np64 = date_np64\n        self.cube = cube\n        self.band_stack = cube.sel(time = date_np64)\n        self.detector = None\n        self.no_clouds = None\n        self.osm_mask = None\n           \n    def mask_clouds(self):\n        cloud_masking_thresholds = {\"rgb\":0.25,\"blue_green\":0.2,\"blue_red\":0.2}\n        scl = MaskSet(self.band_stack.SCL)\n        high_prob = scl.clouds_high_probability\n        med_prob = scl.clouds_medium_probability\n        cirrus = scl.cirrus\n        no_data = scl.no_data\n        rgb_cloud_mask = calc_rgb_cloud_mask(self.band_stack, cloud_masking_thresholds)\n        self.no_clouds = (high_prob + med_prob + cirrus + no_data + rgb_cloud_mask) == 0\n        self.band_stack = self.band_stack.where(self.no_clouds)\n    \n    def mask_with_osm(self, osm_mask):\n        self.osm_mask = osm_mask\n        self.band_stack = self.band_stack.where(self.osm_mask != 0)\n                \n    def do_detection(self):\n        self.detector = TruckDetector(self.band_stack)\n        self.detector.detect()\n        \ndef calc_rgb_cloud_mask(band_stack, cloud_masking_thresholds):\n    B02, B03, B04 = band_stack.B02, band_stack.B03, band_stack.B04\n    c = cloud_masking_thresholds[\"rgb\"]\n    clouds_rgb = ((B02 > c) + (B03 > c) + (B04 > c)) >= 1\n    # attempt to mask haze without masking out truck pixels (similar! higher blue than red and green)\n    blue_green_ratio = (B02-B03) / (B02+B03)\n    blue_red_ratio = (B02-B04) / (B02+B04)\n    clouds_blue_green = blue_green_ratio > cloud_masking_thresholds[\"blue_green\"]\n    clouds_blue_red = blue_red_ratio > cloud_masking_thresholds[\"blue_red\"]\n    clouds = (clouds_rgb + clouds_blue_green + clouds_blue_red) >= 1\n    return clouds\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#processing-methods","position":15},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Get Sentinel-2 L2A xcube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#get-sentinel-2-l2a-xcube","position":16},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Get Sentinel-2 L2A xcube"},"content":"\n\nIn the following cell you need to configure the cube and the interested bbox of the AOI, so please be careful in aligning the below bbox variable and the time range start and end dates with the one desidere at the beginning of the notebook\n\nconfig = CubeConfig(dataset_name = \"S2L2A\",\n                    band_names = [\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"SCL\"],\n                    tile_size = [512, 512],\n                    bbox = bbox,\n                    spatial_res = 0.00009,\n                    time_range = [date_start, date_end],\n                    time_period='2D')\ncube = open_cube(config)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#get-sentinel-2-l2a-xcube","position":17},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"Acquisition","lvl2":"Get Sentinel-2 L2A xcube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#acquisition","position":18},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"Acquisition","lvl2":"Get Sentinel-2 L2A xcube"},"content":"\n\nacquisition = AcquisitionProcessor(cube.time.values[0], cube)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#acquisition","position":19},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"Plot RGB","lvl2":"Get Sentinel-2 L2A xcube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#plot-rgb","position":20},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"Plot RGB","lvl2":"Get Sentinel-2 L2A xcube"},"content":"\n\nrgb_bands = [\"B04\", \"B03\", \"B02\"]\ncoords, dims = [rgb_bands, cube.lat, cube.lon], [\"bands\", \"lat\", \"lon\"]\nrgb = np.vstack([cube.B04.persist().values, cube.B03.persist().values, cube.B02.persist().values])\nrgb_xr = xr.DataArray(rgb, coords=coords, dims=dims)\nrgb_xr.plot.imshow(figsize=[12,10], rgb=\"bands\", vmin=0, vmax=0.4)\nrgb, rgb_xr = None, None\n\nRGB reflectance\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#plot-rgb","position":21},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Get OSM roads"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#get-osm-roads","position":22},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Get OSM roads"},"content":"\n\nosm_roads = get_roads(bbox, osm_values, roads_buffer)\nosm_roads.plot(figsize=[12,10])\n\nThe OSM road vectors are buffered, hence we see polygons here.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#get-osm-roads","position":23},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"Rasterize OSM roads to S2 cube","lvl2":"Get OSM roads"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#rasterize-osm-roads-to-s2-cube","position":24},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"Rasterize OSM roads to S2 cube","lvl2":"Get OSM roads"},"content":"\n\nosm_roads_np = rasterize_osm(osm_roads, cube.B02)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#rasterize-osm-roads-to-s2-cube","position":25},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Mask"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#mask","position":26},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Mask"},"content":"In case there are clouds in the imagery, they are masked out here. Furthermore, the data is constrained to the OSM roads.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#mask","position":27},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"Clouds","lvl2":"Mask"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#clouds","position":28},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"Clouds","lvl2":"Mask"},"content":"\n\nacquisition.mask_clouds()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#clouds","position":29},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"To OSM roads","lvl2":"Mask"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#to-osm-roads","position":30},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl3":"To OSM roads","lvl2":"Mask"},"content":"Only pixels within the buffered OSM roads are considered.\n\nacquisition.mask_with_osm(osm_roads_np)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#to-osm-roads","position":31},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Detect trucks"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#detect-trucks","position":32},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Detect trucks"},"content":"This is the actual detection being invoked in the “do_detection” wrapper. The output is an xarray DataArray, which is afterwards converted to a GeoDataFrame of points.\n\nacquisition.do_detection()\n# raster detections to points\ntruck_points = raster_to_points(acquisition.detector.trucks.values, {\"lon\":cube.lon.values, \"lat\":cube.lat.values}, \"trucks\", \"EPSG:4326\")\ntruck_points.plot(figsize=[12,10])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#detect-trucks","position":33},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Write detections"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#write-detections","position":34},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Write detections"},"content":"If you would like to write the truck points, simply modify the file path here\n\ntruck_points.to_file(\"trucks.gpkg\", driver=\"GPKG\")\n\nimport geopandas\n\nCould be interesting to have a look at the geopackage fields and values, so ise the geopandas read_file to get more information on the file generated.\n\ntrucks_gpkg = geopandas.read_file(\"trucks.gpkg\")\ntrucks_gpkg \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#write-detections","position":35},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Download the Sentinel 2 True color image from Sentinel hub"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#download-the-sentinel-2-true-color-image-from-sentinel-hub","position":36},{"hierarchy":{"lvl1":"Detect Trucks using Sentinel-2 data user guide","lvl2":"Download the Sentinel 2 True color image from Sentinel hub"},"content":"\n\nfrom sentinelhub import SHConfig\n\nconfig = SHConfig()\n\nif not config.sh_client_id or not config.sh_client_secret:\n    print(\"Warning! To use Process API, please provide the credentials (OAuth client ID and client secret).\")\n\nInjection of SH credentials to run the processing\n\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n%reload_ext autoreload\n%autoreload 2\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport rasterio\nfrom rasterio import plot\nfrom rasterio.plot import show\nfrom rasterio.mask import mask\n\nimport datetime\nfrom sentinelhub import (\n    CRS,\n    BBox,\n    DataCollection,\n    DownloadRequest,\n    MimeType,\n    #MosaickingOrder,\n    SentinelHubDownloadClient,\n    SentinelHubRequest,\n    bbox_to_dimensions,\n)\n\nIn the following  cell we need to set resolution of the image, the bbox and the CRS of reference. Please be careful in using the same CRS or EPSG used for the detection in order to execute the last cell properly. Currently the detections CRS has been set as:\n“EPSG:4326” or “CRS:WGS84”\n\nresolution = 10\nkualalumpur_bbox = BBox(bbox=bbox, crs=CRS.WGS84)\nkualalumpur_size = bbox_to_dimensions(kualalumpur_bbox, resolution=resolution)\n\nprint(f\"Image shape at {resolution} m resolution: {kualalumpur_size} pixels\")\n\nevalscript = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"],\n               \n            }],\n            output: {\n                bands: 3,\n                sampleType: \"AUTO\"\n                \n            }\n        };\n    }\n\n    \n    function evaluatePixel(sample) {\n        return [sample.B04*2, sample.B03*2, sample.B02*2];\n    }\n\"\"\"\n\nrequest_true_colour = SentinelHubRequest(\n    data_folder= \"./Outputs\",\n    evalscript=evalscript,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L2A,\n            time_interval=(date_start, date_end)\n            \n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response(\"default\", MimeType.TIFF)\n        \n    ],\n    bbox=kualalumpur_bbox,\n    size=kualalumpur_size,\n    config=config,\n)\n\ntiff_image = request_true_colour.get_data(save_data=True)\n\nIn order to plot the image downloaded we need first to define the plot_image function as follow. In case of mage too dark or too bright yuo could play with the\n\n“”“function evaluatePixel(sample) {\nreturn [sample.B042, sample.B032, sample.B02*2];”“”\n\nyou can find in the evalscript above\n\n# Define the plot_image function\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    \"\"\"\n    Utility function for plotting RGB images.\n    \"\"\"\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    \n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplot_image(tiff_image[0], factor=1/255, clip_range=(0,1))\n\nIn order to set the location of the tiff requesteed via SentinelHub, you need to identify the folder and set it in the input image path.\n\n#input_image = \"Downloaded_S2_TCI/2020-05-18-00_00_2020-05-18-23_59_Sentinel-2_L2A_True_color (1).tiff\"\ninput_image = \"./Outputs/a308013e4b1539348e30b3393836e689/response.tiff\"\n\ninput_image_png = rasterio.open(input_image) \n\nplt.figure(figsize=(15, 15))\nshow(input_image_png.read(), transform=input_image_png.transform)\nplt.show()\n\ntrucks_gpkg.plot()\n\nprint('vector data projection is:', trucks_gpkg.crs)\nprint('raster data projection is:', input_image_png.crs)\n\n%matplotlib inline\n\nfig, ax = plt.subplots(figsize=(100, 50))\nshow(input_image_png.read(), transform=input_image_png.transform, ax=ax)\ntrucks_gpkg.plot(ax=ax, color='yellow', alpha=.30) ## alpha is the transparency setting\nplt.show()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-detect-trucks-sentinel2#download-the-sentinel-2-true-color-image-from-sentinel-hub","position":37},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice","position":0},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020"},"content":"from eoxhub import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"SH\", \"GEODB\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice","position":1},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#environmental-impacts-of-lockdown-in-venice-italy-during-2020","position":2},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#environmental-impacts-of-lockdown-in-venice-italy-during-2020","position":3},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Geo-storytelling with EODASHBOARD and the Euro Data Cube - Notebook #2"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#geo-storytelling-with-eodashboard-and-the-euro-data-cube-notebook-2","position":4},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Geo-storytelling with EODASHBOARD and the Euro Data Cube - Notebook #2"},"content":"\n\nThis notebook looks at the impact of the mobility restrictions imposed in the Italian region Veneto during the Covid-19 pandemic to restrict the spread of the virus.\n\nIt uses Earth Observation data from ESA, NASA and JAXA from the \n\nEO Dashboard, together with other geospatial data as well as non-EO information.\n\nTo read more about the tri-agency collaboration visit \n\nhttps://​eodashboard​.org.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#geo-storytelling-with-eodashboard-and-the-euro-data-cube-notebook-2","position":5},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"In this Notebook:"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#in-this-notebook","position":6},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"In this Notebook:"},"content":"We download and plot open data about mobility over the region of Veneto and determine extreme values associated with the lockdown\n\nWe then access vessel density data in the venice Lagoon and evaluate the reduction in vessel traffic during the lockdown\n\nUsing the extreme value’s date as a proxy for the period of reduced activity, we request NASA nightlight data and visually inspect if changes are visible\n\nWe inspect whether an environmental impact of the activity reduciton is visible in the water quality in the lagoon by visually inspecting Copernicus Sentinel-2 imagery\n\nWe proceed to access and visualise Chlorophyll-a concentration maps in the Venice lagoon\n\nWe access water quality time series and inspect the Chlorophyll-a variation compared to the climatology\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#in-this-notebook","position":7},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Permissions and Package Download","lvl2":"In this Notebook:"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#permissions-and-package-download","position":8},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Permissions and Package Download","lvl2":"In this Notebook:"},"content":"\n\n#Import necessary packages\n\nimport concurrent.futures\nimport datetime as dt\nfrom ipyleaflet import basemaps, Map, GeoJSON\nimport json\nimport requests as re\nimport matplotlib.pyplot as plt\nimport pprint\nimport time\nimport datetime\nimport csv\nimport requests\nimport numpy as np\nimport sys\nimport pandas as pd\nimport geojson\nimport requests as re\nfrom ipyleaflet import Map, basemaps, basemap_to_tiles, TileLayer, SplitMapControl\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom bokeh.plotting import figure, show, output_notebook\nfrom bokeh.models import ColumnDataSource\nfrom bokeh.palettes import Spectral3\nfrom bokeh.palettes import Spectral6\nfrom bokeh.transform import factor_cmap\nfrom __future__ import print_function\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\nimport matplotlib.patches as mpatches\n\n\n# Configure plots for inline use in Jupyter Notebook\n%matplotlib inline\n\n# Time Series data in Step 6. are store in the geodatabase, so we check if the xcube_geodb service is active\n\nfrom edc import check_compatibility\nfrom xcube_geodb.core.geodb import GeoDBClient\ngeodb = GeoDBClient()\ngeodb.whoami\n\n# Sentinel-2 imagery and the water quality maps that we use in Steps 4. and 5. will be accessed from the Sentinel Hub. \n# Here we make sure that the data needed for the authentication to use the Sentinel Hub services is available, and we establish a session \n\nimport os\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n# Your client credentials\nclient_id = os.environ['SH_CLIENT_ID']\nclient_secret = os.environ['SH_CLIENT_SECRET']\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n# Get token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_id=client_id, client_secret=client_secret)\n# All requests using this session will have an access token automatically added\nresp = oauth.get(\"https://services.sentinel-hub.com/oauth/tokeninfo\")\n# Sentinel Hub\nfrom sentinelhub import (MimeType, CRS, BBox, SentinelHubRequest, SentinelHubDownloadClient, \n                         DataCollection, bbox_to_dimensions, DownloadRequest, SHConfig)\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#permissions-and-package-download","position":9},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Covid Mobility Data from Google"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#covid-mobility-data-from-google","position":10},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Covid Mobility Data from Google"},"content":"Google provides open data on mobility, called “Google COVID-19 Community Mobility Reports”. To access the original data source, visit: \n\nhttps://​www​.google​.com​/covid19​/mobility/\n\nIn EO Dashboard this indicator is called “Mobility Data” and provides country-level aggregated charts. On EO Dashboard it can be accessed at: \n\nhttps://​eodashboard​.org​/explore​?indicator​=GG.\n\nAll charts and maps on EO Dashboard provide an “embed link” and we will use this together with the IFrame library to inspect the mobility trends at country level for Italy.\n\nTip: try interacting with the chart, zoom in/out, activate/deactivate categories by clicking on the legend items, hover over the chart to get more details\n\n# How Mobility data is presented in EO Dashboard\n\nfrom IPython.display import IFrame\nIFrame('https://eodashboard.org/iframe?poi=IT-GG', width=800, height=500)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#covid-mobility-data-from-google","position":11},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Mobility in Veneto","lvl2":"Covid Mobility Data from Google"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#mobility-in-veneto","position":12},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Mobility in Veneto","lvl2":"Covid Mobility Data from Google"},"content":"We want to focus only on the region of Veneto, not the entire country, as we will use the COVID Mobility data to relate lockdowns to changing behaviour in the region and especially in the Venice lagoon.\n\nWe use this data to estimate the times where the lockdown restrictions were at their highest and inturn relate this to activity and finaly water quality.\n\nThe Covid Mobility data covers the larger area of Veneto, which includes the region of Venice. Below we display the region using NUTS data:\n\nimport requests\n# First let us get the area information of the country from the administratives zones\n# You can find all the different NUTS levels, resolution here: https://gisco-services.ec.europa.eu/distribution/v2/nuts/nuts-2021-files.html\n\nresponse = requests.get(\n    \"https://gisco-services.ec.europa.eu/distribution/v2/nuts/geojson/NUTS_RG_10M_2021_4326_LEVL_2.geojson\"\n)\n\ndata = response.json()\n\n# Now lets find the geometry information for one country\nmatch = [x for x in data[\"features\"] if x[\"properties\"][\"NUTS_ID\"] == 'ITH3'][0]\n\nimport shapely.geometry\nimport IPython.display\nIPython.display.GeoJSON(match)\n\n# Download google mobilty dataset\n\nurl = 'https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv'\n\ngfile = requests.get(url, allow_redirects=True)\nopen('gmobility_data.csv', 'wb').write(gfile.content)\n\n# open dataset and retrieve the data\nwith open('gmobility_data.csv') as csvfile:\n    reader = csv.DictReader(csvfile, delimiter=\",\", quotechar='\"')\n    country_data = {}\n    # Le us say we interested in retail_and_recreation_percent_change_from_baseline in 3 countries, France, Italy and Austria\n    countries = [\"IT\"]\n    for key in countries:\n        country_data[key] = []\n    # We iterate through the csv rows and extract the wanted data\n    for row in reader:\n        # For now we skip subregional data and only look at overall country data\n        # this is the case for countries that have no information on the following 3 parameters\n        if row[\"sub_region_1\"] == 'Veneto' and row[\"sub_region_2\"] == '' and row[\"metro_area\"] == '' :\n            location_key = row[\"country_region_code\"]\n\n            if location_key in countries:\n                country_data[location_key].append((\n                    datetime.datetime.strptime(row[\"date\"], \"%Y-%m-%d\"), # convert to date object\n                    float(row[\"retail_and_recreation_percent_change_from_baseline\"]) #convert to float\n                ))\n\n# creating a pandas dataframe to store the data\nveneto = pd.DataFrame(country_data[key], columns=['date','retail_and_recreation_percent_change_from_baseline'])\nveneto['date'] =  pd.to_datetime(veneto['date'], infer_datetime_format=True)\nveneto_ts = veneto.set_index('date') \n\n# resampling the data\nweekly_veneto = veneto_ts.resample('W').mean()\n\n# plotting the data\nweekly_veneto.plot(y='retail_and_recreation_percent_change_from_baseline', figsize=(15,8))\n\n# We output the date of the lowest value\nweekly_veneto.retail_and_recreation_percent_change_from_baseline.idxmin()\n\nWe can see from the figure the drop in the activity from the baseline within the region and use this to help understand the impacts of this change.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#mobility-in-veneto","position":13},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Requesting Vessel Density Data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#requesting-vessel-density-data","position":14},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Requesting Vessel Density Data"},"content":"\n\nWe retrieve vessel data from the Euro Data Cube for Venice lagoon.\n\nThis data layer is covering only the European region and can be visualised on the EO Dashboard instance focused only on Europe. This instance is branded “Rapid Action on Covid 19 and EO (RACE)” and includes some of the datasets from the ESA-NASA-JAXA instance as well as other Europe-centric datasets.\nThis dashboard instance is accessble at \n\nhttps://​race​.esa​.int.\n\nThe vessel density data visualisation in the RACE Dashboard can be inspected here: \n\nhttps://​race​.esa​.int​/​?poi​=​World​-E13o\n\n# let's use the IFrame to embed the vesel density map\n# for a better experience, access this indicator direclty on the RACE Dashboard, at: https://race.esa.int/?poi=World-E13o \n# there you will be able to use the Draw AOI feature to generate times sereis of vessel density on your custom area.\n\n# the view below is offering limitted functionalities.\n# the 4 tabs: ALL, CARGO, TANKER, OTHERS\n\nIFrame('https://race.esa.int/iframe?poi=World-E13o', width=800, height=500)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#requesting-vessel-density-data","position":15},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Getting the actual vessel density map data","lvl2":"Requesting Vessel Density Data"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#getting-the-actual-vessel-density-map-data","position":16},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Getting the actual vessel density map data","lvl2":"Requesting Vessel Density Data"},"content":"The vessel data is accessible using the Sentinel Hub service, and can be retrieve using the byoc (bring your own COG) code availble in the \n\nEurodatacube Collections.\n\n# define the area\n\ndef bbox(coord_list):\n     box = []\n     for i in (0,1):\n         res = sorted(coord_list, key=lambda x:x[i])\n         box.append((res[0][i],res[-1][i]))\n     ret = f\"({box[0][0]} {box[1][0]}, {box[0][1]} {box[1][1]})\"\n     return ret\n\n# Parse the json here\n\nimport geojson\nimport shapely.wkt\n\n# We have the POLYGON pre-defined for the Venice Lagoon. It is the same one that is used in EO Dashboard to display the Venice Water Quality Maps.\n\narea = shapely.wkt.loads('POLYGON((12.174395 44.778037,12.196361 44.816998,12.085149 45.405263,12.426024 45.583514,13.153667 45.779148,13.603981 45.811687,13.804426 45.675662,13.823647 45.596962,13.626039 45.443008,13.549156 45.433376,13.626039 45.323461,13.713905 45.095238,13.78383 44.980605,13.830519 44.892158,13.8 44.5,12.234821 44.481556,12.06659 44.581469,12.174395 44.778037))')\ngj_feat = geojson.Feature(geometry=area, properties={})\n\nIPython.display.GeoJSON(gj_feat)\n\n# we create a bounding box for the geojson \n\nline = bbox(list(geojson.utils.coords(gj_feat)))\nprint(line)\n\n# use the coordinates to define the boundinbox for the Venice Laggon in the Adriatic \nadriatic = [\n  12.06659,\n  44.481556,\n  13.830519,\n  45.811687\n]\n\n# set the resolution and create a Sentinel Hub bbox and size object\n\nresolution = 100\nadriatic_bbox = BBox(bbox=adriatic, crs=CRS.WGS84)\nadriatic_size = bbox_to_dimensions(adriatic_bbox, resolution=resolution)\n\nprint(f'Image shape at {resolution} m resolution: {adriatic_bbox} pixels')\n\n# Define the plot_image function\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    \"\"\"\n    Utility function for plotting RGB images.\n    \"\"\"\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    \n    ax.set_xticks([])\n    ax.set_yticks([])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#getting-the-actual-vessel-density-map-data","position":17},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request vessel density data from the Sentinel Hub","lvl3":"Getting the actual vessel density map data","lvl2":"Requesting Vessel Density Data"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-vessel-density-data-from-the-sentinel-hub","position":18},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request vessel density data from the Sentinel Hub","lvl3":"Getting the actual vessel density map data","lvl2":"Requesting Vessel Density Data"},"content":"First we build the evalscript to request the data\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-vessel-density-data-from-the-sentinel-hub","position":19},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"variables to be inicted in the script for retrieving the SH images  and bands","lvl2":"Requesting Vessel Density Data"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#variables-to-be-inicted-in-the-script-for-retrieving-the-sh-images-and-bands","position":20},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"variables to be inicted in the script for retrieving the SH images  and bands","lvl2":"Requesting Vessel Density Data"},"content":"\n\n### Parameters for the scripts for retrieving images from SH\nband = \"All\"\ncollectionID = \"beee9b47-b1ab-4044-baa5-0958d3465f12\"\nstart_date_cov = \"2020-03-15\"\nend_date_cov= \"2020-04-15\" \nstart_date_pre = \"2020-01-15\"\nend_date_pre= \"2020-02-15\" \n\nevalscript_vessels = \"\"\"\n    //VERSION=3\n    function setup() {\n    return {\n        input: [{\n          bands: [\"%s\", \"dataMask\"], // this sets which bands to use\n        }],\n        output: { // this defines the output image type\n          bands: 4,\n          sampleType: \"UINT8\"\n        }\n    };\n}\n\nfunction evaluatePixel(sample) {\n\n  var arr = colorBlend(sample.%s,    [0.5, 2, 5 , 10, 20 , 100],    \n  [[0,155,143],[0,219,0],[255,252,0],[244,154,0],[208,19,0], [161,0,0] ]); \n  if (sample.dataMask==1)  arr.push(255);\n  else arr.push(0);\n  return arr;\n}\n\n    \"\"\"%(band,band)\nprint(evalscript_vessels)\n\nNow we request data over the lockdown period, remember we detected a low point in activity of 2020-04-05.\n\nrequest_vessels_covid = SentinelHubRequest(\n    evalscript=evalscript_vessels,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc(collectionID),\n            time_interval=(start_date_cov, end_date_cov),\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=adriatic_bbox,\n    size=adriatic_size,\n    config=config\n)\n\nWe set the pre-covid period one month before.\n\nrequest_vessels_pre = SentinelHubRequest(\n    evalscript=evalscript_vessels,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc('beee9b47-b1ab-4044-baa5-0958d3465f12'),\n            time_interval=(start_date_pre, end_date_pre),\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=adriatic_bbox,\n    size=adriatic_size,\n    config=config\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#variables-to-be-inicted-in-the-script-for-retrieving-the-sh-images-and-bands","position":21},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request vessel density map data during lockdown","lvl3":"variables to be inicted in the script for retrieving the SH images  and bands","lvl2":"Requesting Vessel Density Data"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-vessel-density-map-data-during-lockdown","position":22},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request vessel density map data during lockdown","lvl3":"variables to be inicted in the script for retrieving the SH images  and bands","lvl2":"Requesting Vessel Density Data"},"content":"\n\nvessel_covid = request_vessels_covid.get_data()\n\nimage = vessel_covid[0]\nprint(f'Image type: {image.dtype}')\n\n# plot function\ncovid_data = request_vessels_covid.get_data()\nplot_image(covid_data[0], factor=1 / 255)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-vessel-density-map-data-during-lockdown","position":23},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request vessel density map data before lockdown","lvl3":"variables to be inicted in the script for retrieving the SH images  and bands","lvl2":"Requesting Vessel Density Data"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-vessel-density-map-data-before-lockdown","position":24},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request vessel density map data before lockdown","lvl3":"variables to be inicted in the script for retrieving the SH images  and bands","lvl2":"Requesting Vessel Density Data"},"content":"\n\nvessel_pre = request_vessels_pre.get_data()\n\nimage = vessel_pre[0]\nprint(f'Image type: {image.dtype}')\n\n# plot function\npre_data = request_vessels_pre.get_data()\nplot_image(pre_data[0], factor=1 / 255)\n\n# get the range of values for the vessel density maps\n\nimport numpy as np\nmin_pre = np.amin(pre_data[0])\nmax_pre = np.amax(pre_data[0])\n\nmin_post = np.amin(covid_data[0])\nmax_post = np.amax(covid_data[0])\n\nprint (\"min value pre-lockdown:\", min_pre, \"max value pre-lockdown:\", max_pre)\nprint (\"min value lockdown:\", min_post, \"max value lockdown:\", max_post)\n\nThe red areas indicate areas with high vessel density and the dark green areas with low density.\nFrom the two images we can see a clear reduction in vessel density with the data corresponding to reduced acrivity in the Veneto region.\n\nFrom the \n\ndataset documentation we know that the units of density in the published maps are total ship time in hours spent in a cell over the whole month. As the cells are 1 km , this is immediately per square km.\n\nSo every pixel in the original data has a value of N = nr_hours x nr_ships x nr_days_in_month\n\nIn order to obtain the density as the average number of instantaneous ships per square km, the values of the published monthly maps must be divided by the total number of hours in the month, which is 28, 30 or 31 times 24 hours depending on the month. For the published yearly average maps, the values must be multiplied by 12 and divided by 365 times 24 hours (for 2017).\n\nTo convert to ship density per square degree instead of per square km, the published numbers can be multiplied by the factor ( 60 * 1.852 )2 cos( latitude ).\n\nNote that in the plotted images above, the pixel values range between [0, 255]. This is due to the fact that all values above 100 hours have been capped at 255.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-vessel-density-map-data-before-lockdown","position":25},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Exercise 1: Use EO Dashboard/ RACE Dashboard to extract vessel density time series","lvl2":"Requesting Vessel Density Data"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#exercise-1-use-eo-dashboard-race-dashboard-to-extract-vessel-density-time-series","position":26},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Exercise 1: Use EO Dashboard/ RACE Dashboard to extract vessel density time series","lvl2":"Requesting Vessel Density Data"},"content":"\n\nVessel data can be accessed on the RACE Dashboard at \n\nhttps://​race​.esa​.int​/​?poi​=​World​-E13o\n\nUsing the Draw AOI feature, generate a time series chart. Note that the polygon information is included in the URL.\nUse the information from the previously defined bounding box to customise the AOI, then regenerate the graph.\nDownload the CSV and import it into your workspace.\n\nRead the CSV and plot the graph.\nCan you determine significant changes in the vessel traffic from the plot?\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#exercise-1-use-eo-dashboard-race-dashboard-to-extract-vessel-density-time-series","position":27},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Using the NASA API to retrieve nightlights data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#using-the-nasa-api-to-retrieve-nightlights-data","position":28},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Using the NASA API to retrieve nightlights data"},"content":"Let’s inspect the Nightlights data over Venice. To inspect other locations and learn more about these datasets access this \n\nNightlights Story on EO Dashboard\n\nIFrame('https://eodashboard.org/explore?indicator=N5&poi=IT01-N5', width=800, height=500)\n\nNow we retrieve nightlights data from the NASA API to check if there is a reduction in activity in the island of Venice over the covid period. The High Definition Nightlights dataset is processed to eliminate light sources like moonlight reflectance and other interferences. The darker shades are places with less light while the lighter shades of yellow are areas with more light.\n\nThe endpoints include a STAC API, which is a catalog endpoint to retrieve metadata on available datasets: \n\nhttps://​staging​-stac​.delta​-backend​.com​/docs/\n\nThe other is to render the data for which we find information in the STAC API: \n\nhttps://​staging​-raster​.delta​-backend​.com​/docs/\n\n# endpoints for nasa api\nSTAC_ENDPOINT_URL = \"https://staging-stac.delta-backend.com\"\nRASTER_ENDPOINT_URL = \"https://staging-raster.delta-backend.com\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#using-the-nasa-api-to-retrieve-nightlights-data","position":29},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request metadata for the nightlights data","lvl2":"Using the NASA API to retrieve nightlights data"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-metadata-for-the-nightlights-data","position":30},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request metadata for the nightlights data","lvl2":"Using the NASA API to retrieve nightlights data"},"content":"\n\n# summary of the metadata for the indicator of interest\nnightlights_collection_summary = re.get(f\"{STAC_ENDPOINT_URL}/collections/nightlights-hd-monthly\").json()\nnightlights_collection_summary\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-metadata-for-the-nightlights-data","position":31},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request nightlights data before lockdown","lvl2":"Using the NASA API to retrieve nightlights data"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-nightlights-data-before-lockdown","position":32},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request nightlights data before lockdown","lvl2":"Using the NASA API to retrieve nightlights data"},"content":"\n\n# retrieving a pre-covid image from the STAC API\n\nresponse_pre = re.post(\n    f\"{STAC_ENDPOINT_URL}/search\", \n    json={\n        \"collections\": [\"nightlights-hd-monthly\"],\n        \"query\": {\"datetime\": {\"eq\":\"2019-04-01T00:00:00\"}},\n        \"limit\": 100\n    }\n).json()\nitem_pre = response_pre[\"features\"][0]\n\nIn order to render the image correctly you must define the visualisation parameters, which will differ between datasets. Here in the \n\ndocumentation you can input the correct visualisation parameters and generate an output, this will help you to form the request within the notebook.\n\n# rendering the image with the RASTER API\ntiles_pre_covid = re.get(\n    f\"{RASTER_ENDPOINT_URL}/stac/tilejson.json?collection={item_pre['collection']}&item={item_pre['id']}&assets=cog_default&bidx=1&unscale=false&resampling=nearest&max_size=1024&rescale=0%2C255&colormap_name=plasma\", \n).json()\ntiles_pre_covid\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-nightlights-data-before-lockdown","position":33},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request nightlights data during lockdown","lvl2":"Using the NASA API to retrieve nightlights data"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-nightlights-data-during-lockdown","position":34},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl4":"Request nightlights data during lockdown","lvl2":"Using the NASA API to retrieve nightlights data"},"content":"\n\n# retrieving a covid image from the STAC API\n\nresponse_nasa_covid = re.post(\n    f\"{STAC_ENDPOINT_URL}/search\", \n    json={\n        \"collections\": [\"nightlights-hd-monthly\"],\n        \"query\": {\"datetime\": {\"eq\":\"2020-04-01T00:00:00\"}},\n        \"limit\": 100\n    }\n).json()\nitem_covid = response_nasa_covid[\"features\"][0]\n\ntiles_covid = re.get(\n    f\"{RASTER_ENDPOINT_URL}/stac/tilejson.json?collection={item_covid['collection']}&item={item_covid['id']}&assets=cog_default&bidx=1&unscale=false&resampling=nearest&max_size=1024&rescale=0%2C255&colormap_name=plasma\", \n).json()\ntiles_covid\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#request-nightlights-data-during-lockdown","position":35},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Directly compare the two images","lvl2":"Using the NASA API to retrieve nightlights data"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#directly-compare-the-two-images","position":36},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Directly compare the two images","lvl2":"Using the NASA API to retrieve nightlights data"},"content":"\n\n# set map parameters\ncenter = [45.438558, 12.333421]\nzoom = 13\n\n# display interactive map\nm = Map(center=center, zoom=zoom)\nm\n\nleft = TileLayer(url=tiles_pre_covid[\"tiles\"][0])\nright = TileLayer(url=tiles_covid[\"tiles\"][0])\n\ncontrol = SplitMapControl(left_layer=left, right_layer=right)\nm.add_control(control)\n\nThe darker areas indicate a reduction in luminosity and the yellow areas higher luminosity, when comparing the two images we can see a reduction in activity over the covid period.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#directly-compare-the-two-images","position":37},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Retrieving Sentinel 2 imagery over the Island of Venice","lvl2":"Using the NASA API to retrieve nightlights data"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#retrieving-sentinel-2-imagery-over-the-island-of-venice","position":38},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Retrieving Sentinel 2 imagery over the Island of Venice","lvl2":"Using the NASA API to retrieve nightlights data"},"content":"Now we have identified the drop in activity due to the lockdown conditions we can retrieve the satellite images to see if there is a corresponding impact visable.\n\nSentinel-2 is a multispectral satellite with 13 spectral bands, launched in 2016. We use the Red, Green and Blue bands to contruct a true colour image over the island of Vencie from August 2019 to August 2020.\n\nThis data is stored in the Sentinel Hub, for more infomation on the dataset and parameters visit the \n\ndocumentation.\n\nFirst we define a bounding box for our area of intrest. An easy way to do this is using the \n\nSH Request Builder.\n\n# defining our bbox over the island of Venice\n\nvenice = [\n  12.296613,\n  45.411707,\n  12.393469,\n  45.469281\n]\n\n#Set the resolution and create a sentinel hub bbox and size object\n\nresolution = 10\nvenice_bbox = BBox(bbox=venice, crs=CRS.WGS84)\nvenice_size = bbox_to_dimensions(venice_bbox, resolution=resolution)\n\nprint(f'Image shape at {resolution} m resolution: {venice_bbox} pixels')\n\nBelow we use the \n\nEvalscript to define the metadata and preprocessing for RGB Sentinel-2 imagery from the Sentinelhub.\n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02];\n    }\n\"\"\"\n\n# We create a list of dates for retreiving multiple images\n\nstart = datetime.datetime(2019,8,1)\nend = datetime.datetime(2020,8,1)\nn_chunks =13\ntdelta = (end - start) / n_chunks\nedges = [(start + i*tdelta).date().isoformat() for i in range(n_chunks)]\nslots = [(edges[i], edges[i+1]) for i in range(len(edges)-1)]\n\nprint('Monthly time windows:\\n')\nfor slot in slots:\n    print(slot)\n\n# define the function to retreive the image\ndef get_true_color_request(time_interval):\n    return SentinelHubRequest(\n        evalscript=evalscript_true_color,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.SENTINEL2_L1C,\n                time_interval=time_interval,\n                mosaicking_order='leastCC'\n            )\n        ],\n        responses=[\n            SentinelHubRequest.output_response('default', MimeType.PNG)\n        ],\n        bbox=venice_bbox,\n        size=venice_size,\n        config=config\n    )\n\n# create a list of requests\nlist_of_requests = [get_true_color_request(slot) for slot in slots]\nlist_of_requests = [request.download_list[0] for request in list_of_requests]\n\n# download data with multiple threads\ndata = SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=5)\n# some stuff for pretty plots\nncols = 3\nnrows = 4\naspect_ratio = venice_size[0] / venice_size[1]\nsubplot_kw = {'xticks': [], 'yticks': [], 'frame_on': False}\n\nfig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(5 * ncols * aspect_ratio, 5 * nrows),\n                        subplot_kw=subplot_kw)\n\nfor idx, image in enumerate(data):\n    ax = axs[idx // ncols][idx % ncols]\n    ax.imshow(np.clip(image * 2.5/255, 0, 1))\n    ax.set_title(f'{slots[idx][0]}  -  {slots[idx][1]}', fontsize=10)\n\nplt.tight_layout()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#retrieving-sentinel-2-imagery-over-the-island-of-venice","position":39},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"EXERCISE"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#exercise","position":40},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"EXERCISE"},"content":"Are you aware of the atmospheric correction effect on the image? To understand the impact on the true color images use SENTINEL2_L2A instead of SENTINEL2_L1C in the get true color request function\n\nFrom the images we can see a sharp reduction in the amount of boats which are travelling around the Island of Venice, and a corresponding impovement in the water quality.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#exercise","position":41},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Requesting Water Quality Data from JAXA"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#requesting-water-quality-data-from-jaxa","position":42},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Requesting Water Quality Data from JAXA"},"content":"\n\nIn order to test our theory about the improved water quality we use JAXA water quality data, specifically \n\nwater quality Chlorophyll-a weekly anomaly.\n\nAs data is stored in the Sentinel Hub we use a similar syntax as above to retrieve the data but instead define the byoc code, stated in the documentation.\n\nWe will request this data using the Adriatic boundinbox.\n\nThe following cell is reccomended to set the reference collection and the band to be used.\n\n### Parameters for the scripts for retrieving images from SH\nband = \"chla\"\ncollectionID = \"198aa13a-b0c0-4b78-8f69-e08fc58551a7\"\nstart_date = \"2020-03-15\"\nend_date= \"2020-04-15\" \n\nevalscript_jaxa = \"\"\"\n    //VERSION=3\n    function setup() {\n      return {\n        input: [\"%s\"],\n        output: { bands: 1,\n          sampleType: \"UINT8\" }\n      };\n    }\n    function evaluatePixel(sample) {\n        return [sample.%s];\n    }\n    \"\"\"%(band,band)\nprint(evalscript_jaxa)\n\n#defining the request\nrequest_jaxa = SentinelHubRequest(\n    evalscript=evalscript_jaxa,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.define_byoc(collectionID),  #('4f5f67f1-5715-4f2b-8c98-ae57948ee2f5'),\n            time_interval=(start_date, end_date),\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=adriatic_bbox,\n    size=adriatic_size,\n    config=config\n)\n\njaxa = request_jaxa.get_data()\n\n# retreiving a single image\nimage = jaxa[0]\nprint(f'Image type: {image.dtype}')\n\n# plot function\nplot_image(jaxa[0], factor=1 / 255)\n\ndef get_water_quality_request(time_interval):\n    return SentinelHubRequest(\n        evalscript=evalscript_jaxa,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.define_byoc(collectionID),\n                time_interval=time_interval\n            )\n        ],\n        responses=[\n            SentinelHubRequest.output_response('default', MimeType.PNG)\n        ],\n        bbox=adriatic_bbox,\n        size=adriatic_size,\n        config=config\n    )\n\n# create a list of requests\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.cm import coolwarm \n\nlist_of_requests = [get_water_quality_request(slot) for slot in slots]\nlist_of_requests = [request.download_list[0] for request in list_of_requests]\n\n# download data with multiple threads\ndata = SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=5)\n# some stuff for pretty plots\nncols = 3\nnrows = 4\naspect_ratio = venice_size[0] / venice_size[1]\nsubplot_kw = {'xticks': [], 'yticks': [], 'frame_on': False}\n\nfig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(5 * ncols * aspect_ratio, 5 * nrows),\n                        subplot_kw=subplot_kw)\n\nfor idx, image in enumerate(data):\n    ax = axs[idx // ncols][idx % ncols]\n    ax.imshow(np.clip(image * 1/255, 0, 1))\n    ax.set_title(f'{slots[idx][0]}  -  {slots[idx][1]}', fontsize=10)\nplt.tight_layout()\n\nThe range lies from 0-1 (blue to yellow), 0 being no anomaly in chlorophyll-a and the 1 being high anomaly. From a first look at the images it is hard to make robust conclusions on the water quality. However the image retrieved over the period of the first lockdown does seem to have the lowest anomalies.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#requesting-water-quality-data-from-jaxa","position":43},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Exercise 2: Retrieving Water Quality Datasets from the SentinelHub","lvl2":"Requesting Water Quality Data from JAXA"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#exercise-2-retrieving-water-quality-datasets-from-the-sentinelhub","position":44},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Exercise 2: Retrieving Water Quality Datasets from the SentinelHub","lvl2":"Requesting Water Quality Data from JAXA"},"content":"Search the edc collections and retrieve a different \n\nwater quality product.\n\nCopy the above structure to access another water quality dataset, you will need to change some parameters.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#exercise-2-retrieving-water-quality-datasets-from-the-sentinelhub","position":45},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Retrieving water quality time series from GeoDB"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#retrieving-water-quality-time-series-from-geodb","position":46},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl2":"Retrieving water quality time series from GeoDB"},"content":"\n\nOn EO Dahboard we also have access to Chlorophyll a and Total Suspended Sediments time sereis data on a number of locations, including Venice.\nYou can inspect these time series on the dashboard at: \n\nhttps://​eodashboard​.org​/explore​?indicator​=​N3b\n\nFor Venice, the time series is available here: \n\nhttps://​eodashboard​.org​/explore​?indicator​=​N3b​&​poi​=​IT6​-N3b\n\nThe displayed time series show weekly Chl concentration anomalies (%) as calculated from Sentinel-3 (purple), MODIS (blue) and GCOM-C(light blue) around the Alta Aqua Oceanographic Tower (AAOT at 45.30 N, 12.50 E) in the North Adriatic Sea, the Mediterranean sub-basin most influenced by river runoff, in particular by the Po River, which is the largest river in Italy and which runs along many different industrialized areas.\n\nOn EO Dashboard we can see that the measurements from the three sensors on Sentinel3, MODIS and GCOM-C are in agreement.\n\nWe could go a bit deeper in the analysis if we only focus on the Sentinel3 data, where we have access to the same time series but compared to the climatology. This graph is not available on EO Dashboard, but we can visualise it on The RACE platform.\nThis data is stored in the EuroDataCube GeoDB.\n\n(For a complete overview of where the data is available please use the DataAccess.jpynb).\n\nhttps://​race​.esa​.int​/​?indicator​=​N3​&​poi​=​IT6​-N3\n\ngeodb_database = \"eodash\"\ngeodb_collection = \"N3\"\n\ndata = geodb.get_collection(collection=geodb_collection, database=geodb_database)\ndata.head()\n\n# display the locations of the data\ncities = geodb.get_collection_pg(geodb_collection, database=geodb_database, group='city, geometry', select='city, geometry')\n\nfeatures = json.loads(cities.to_json())\n\nIPython.display.GeoJSON(features)\n    \n\ndef plot_city(city=cities.city[0]):\n    #A bit hidden in this function lies the query against the RACE collection of interest.\n    gdf = geodb.get_collection(geodb_collection, database=geodb_database, query=f\"city=eq.{city}\")\n    \n    # A bit if data cleaning to get this working as None values are given as '/'\n    gdf = gdf.drop(gdf[gdf.indicator_value == \"/\"].index)\n    \n    indicator_values = geodb.get_collection_pg(geodb_collection, database=geodb_database, group='indicator_value', select='indicator_value')\n    \n    # A bit if data cleaning to get this working as None values are given as '/'\n    indicator_values = indicator_values.drop(indicator_values[indicator_values.indicator_value == \"/\"].index)\n    \n    gdf['time'] = pd.to_datetime(gdf.time)\n    gdf['measurement_value']  = gdf.measurement_value.astype(float)\n    source = ColumnDataSource(data=dict(time=gdf.time, measurement_value=gdf.measurement_value, indicator_value=gdf.indicator_value))\n    \n    p = figure(x_axis_type='datetime', width=800)\n    p.title.text = geodb_collection + \" in \" +  city\n    p.title.align = \"center\"\n    p.title.text_font_size = \"25px\"\n\n    p.vbar(x='time', top='measurement_value', legend_field=\"indicator_value\", line_width=2, fill_color=factor_cmap('indicator_value', palette=Spectral3, factors=indicator_values.indicator_value), line_color=factor_cmap('indicator_value', palette=Spectral3, factors=indicator_values.indicator_value), source=source)\n\n    show(p)\n\nNow we plot the cities with insitu water quality timeseries for the Venice lagoon.\n\n# Generate a unique list of cities\noutput_notebook()\ncities = geodb.get_collection_pg(geodb_collection, database=geodb_database, group='city', select='city')\n\ninteract(plot_city, city=cities.city[0]);\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#retrieving-water-quality-time-series-from-geodb","position":47},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Exercise 3","lvl2":"Retrieving water quality time series from GeoDB"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#exercise-3","position":48},{"hierarchy":{"lvl1":"Environmental Impacts of Lockdown in Venice, Italy during 2020","lvl3":"Exercise 3","lvl2":"Retrieving water quality time series from GeoDB"},"content":"Can you make some conclusions from the time series? This event has been studied at length in the literature, this \n\npaper can be a starting point for some ideas on how to improve the method.\n\nThere could be another reason for the change in water quality in the region, the largest river in Italy is located just below Venice. Can you preform some anaylsis to investigate this further?","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-lockdown-in-venice#exercise-3","position":49},{"hierarchy":{"lvl1":"Lockdown in Venice"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-nasa-api-lockdown-in-venice","position":0},{"hierarchy":{"lvl1":"Lockdown in Venice"},"content":"from eoxhub import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-nasa-api-lockdown-in-venice","position":1},{"hierarchy":{"lvl1":"Lockdown in Venice"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-nasa-api-lockdown-in-venice#lockdown-in-venice","position":2},{"hierarchy":{"lvl1":"Lockdown in Venice"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-nasa-api-lockdown-in-venice#lockdown-in-venice","position":3},{"hierarchy":{"lvl1":"Lockdown in Venice","lvl2":"Mapping the effects of mobility restriction in Venice on nightlight intensity using the NASA API"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-nasa-api-lockdown-in-venice#mapping-the-effects-of-mobility-restriction-in-venice-on-nightlight-intensity-using-the-nasa-api","position":4},{"hierarchy":{"lvl1":"Lockdown in Venice","lvl2":"Mapping the effects of mobility restriction in Venice on nightlight intensity using the NASA API"},"content":"In this notebook:\n\nWe use the NASA STAC API to discover available data for the Nightlights data set and plot mean nightlight intensity before and after covid lockdowns\n\nWe use the STAC items to access raster tiles for the Nightlights dataset, mosaic them together to create a single raster at a higher zoom level and then calculate pixel-by-pixel variance across the the timesteps to visualize which areas of Venice had the largest change in nightlight intensity throughout the lockdown period\n\n# endpoints for nasa api\nSTAC_ENDPOINT_URL = \"https://staging-stac.delta-backend.com\"\nRASTER_ENDPOINT_URL = \"https://staging-raster.delta-backend.com\"\n\nimport requests as re\n\n# Summary of the metadata for the nightlights intensity indicator\nnightlights_collection_summary = re.get(f\"{STAC_ENDPOINT_URL}/collections/nightlights-hd-monthly\").json()\nnightlights_collection_summary\n\nimport sys\n!{sys.executable} -m pip install ipyleaflet geojson\n\nfrom ipyleaflet import basemaps, Map, GeoJSON\nimport geojson\n\n# Define a bounding box for Venice: \nbbox_venice = [11.7631744, 45.06062636, 12.79039608, 45.79310055]\n[e,s,w,n] = bbox_venice\n\nm = Map(\n    basemap=basemaps.OpenStreetMap.Mapnik,\n    center=(45,14),\n    zoom=6,\n    scroll_wheel_zoom=True\n)\n\ngeo = GeoJSON(\n    data=geojson.Feature(geometry=geojson.Polygon([[(e,s), (e,n), (w,n), (w,s), (e,s)]]), properties={}),\n    style={\"color\": \"red\", \"fillOpacity\": 0}\n)\nm.add_layer(geo)\nm\n\n# retrieve all items from the STAC API within that collection, within the Venice bounding box\nresponse_pre = re.post(\n    f\"{STAC_ENDPOINT_URL}/search\", \n    json={\n        \"collections\": [\"nightlights-hd-monthly\"],\n        \"bbox\": bbox_venice,\n        \"limit\": 100\n    }\n).json()\nfeatures = response_pre[\"features\"]\nprint(\"Number of results: \", len(features))\nprint(\"First and last dates: \", features[0][\"properties\"][\"start_datetime\"], features[-1][\"properties\"][\"start_datetime\"])\n\nfrom datetime import datetime\n\n# filter the features to only include those from Jan 1st 2020 onwards\ncovid_features = list(filter( \n    lambda f: (\n        datetime.strptime(f[\"properties\"][\"start_datetime\"], \"%Y-%m-%dT%H:%M:%S\") >= datetime(2020, 1, 1)\n    ), \n    features\n))\nfeatures = list(sorted(features, key= lambda f: f[\"properties\"][\"start_datetime\"]))\nprint(\"First and last dates: \", covid_features[0][\"properties\"][\"start_datetime\"], features[-1][\"properties\"][\"start_datetime\"])\n\n# Format dates for plot and extract corresponding mean value from statistics for each STAC Item\ndates = [datetime.strptime(f[\"properties\"][\"start_datetime\"], \"%Y-%m-%dT%H:%M:%S\") for f in covid_features]\nmeans = [f[\"assets\"][\"cog_default\"][\"raster:bands\"][0][\"statistics\"][\"mean\"] for f in covid_features]\n\n# Plot mean nightlights intensity values \nfrom matplotlib import pyplot as plt\n\nfig = plt.figure(figsize=(20,10))\nplt.plot(dates, means, label=\"Mean nightlights intensity (dimensionless)\")\nplt.axvline(datetime(2020,3,8).timestamp()/60/60/24, color=\"r\", label=\"First lockdown started\")\nplt.title(\"Mean Nightlight intensity in Venice\")\nplt.legend()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-nasa-api-lockdown-in-venice#mapping-the-effects-of-mobility-restriction-in-venice-on-nightlight-intensity-using-the-nasa-api","position":5},{"hierarchy":{"lvl1":"Lockdown in Venice","lvl3":"In the next section we wil use the raster tiles themselves to perform a pixel-by-pixel variance calculation","lvl2":"Mapping the effects of mobility restriction in Venice on nightlight intensity using the NASA API"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-nasa-api-lockdown-in-venice#in-the-next-section-we-wil-use-the-raster-tiles-themselves-to-perform-a-pixel-by-pixel-variance-calculation","position":6},{"hierarchy":{"lvl1":"Lockdown in Venice","lvl3":"In the next section we wil use the raster tiles themselves to perform a pixel-by-pixel variance calculation","lvl2":"Mapping the effects of mobility restriction in Venice on nightlight intensity using the NASA API"},"content":"\n\n# View Tilejson for a single feature,  which includes a preformatted URL we can use to request the tiles from \n# the raster API\ntilejson = re.get(\n        f\"{RASTER_ENDPOINT_URL}/stac/tilejson.json?collection={features[0]['collection']}&item={features[0]['id']}&assets=cog_default&bidx=1&unscale=false&resampling=nearest&max_size=1024&rescale=0%2C255&colormap_name=inferno\", \n    ).json()\ntilejson\n\n\nfrom ipyleaflet import TileLayer\n\nm = Map(\n    basemap=basemaps.OpenStreetMap.Mapnik,\n    center=(45,14),\n    zoom=6,\n    scroll_wheel_zoom=True\n)\n\ntile_layer = TileLayer(url=tilejson[\"tiles\"][0], min_zoom=tilejson[\"minzoom\"], max_zoom=tilejson[\"maxzoom\"])\nm.add_layer(tile_layer)\nm\n\n\n# Use morecantile to calculate the Web mercator (row/x, column/y, zoom/z) tiles we want to query, \n# given the lat/lon bounding box\n\n!{sys.executable} -m pip install morecantile\nimport morecantile\n\nzoom_level = 5\ntms = morecantile.tms.get(\"WebMercatorQuad\")\ncorner_tiles = [tms._tile(*tms.xy(*pair),zoom_level) for pair in [(e,s), (e,n), (w,n), (w,s)]]\nmin_x, max_x = min(t.x for t in corner_tiles), max(t.x for t in corner_tiles)\nmin_y, max_y = min(t.y for t in corner_tiles), max(t.y for t in corner_tiles)\ntiles = [morecantile.Tile(x,y,zoom_level) for x in range(min_x, max_x+1) for y in range(min_y, max_y+1)]\ntiles\n\n\nZoom level 5 is the lowest zoom level at which the Venice bounding box is entirely contained within a single Web-mercator tile\n\n[tile] = tiles\nr = re.get(\n       tilejson[\"tiles\"][0].replace(\"{z}/{x}/{y}\", f\"{tile.z}/{tile.x}/{tile.y}\")\n   )\nr.status_code\n\nimport io\nfrom PIL import Image\n\nim = Image.open(io.BytesIO(r.content))\nim\n\nObviously this zoom level is too low, so we will need to request tiles for higher zoom levels and mosaic them together\n\nzoom_level = 10\ntms = morecantile.tms.get(\"WebMercatorQuad\")\ncorner_tiles = [tms._tile(*tms.xy(*pair),zoom_level) for pair in [(e,s), (e,n), (w,n), (w,s)]]\nmin_x, max_x = min(t.x for t in corner_tiles), max(t.x for t in corner_tiles)\nmin_y, max_y = min(t.y for t in corner_tiles), max(t.y for t in corner_tiles)\ntiles = [morecantile.Tile(x,y,zoom_level) for x in range(min_x, max_x+1) for y in range(min_y, max_y+1)]\ntiles\n\nAt zoom level 10 the Venice bounding box is contained within 16 Web-mercator tiles\n\n#!{sys.executable} -m pip install numpy==1.21\nimport numpy as np\n\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef _get_raster(tilejson_url, tile):\n    r = re.get(tilejson_url.replace(\"{z}/{x}/{y}\", f\"{tile.z}/{tile.x}/{tile.y}\"))\n    if not r.status_code == 200: \n        raise Exception(r.content)\n    a = np.array(Image.open(io.BytesIO(r.content)))\n    return a, (tile.y-min_y)*256, (tile.y-min_y+1)*256, (tile.x-min_x)*256, (tile.x-min_x+1)*256\n    \n    \n    \n# Define a function which will request each of the 16 web-mercator tiles and insert it into a \n# single mosaic'ed image\ndef mosaic_image(feature, tiles):\n    canvas = np.zeros(((max_x - min_x+1)*256, (max_y-min_y+1)*256))\n    \n    tilejson_url = re.get(\n            f\"{RASTER_ENDPOINT_URL}/stac/tilejson.json?collection={feature['collection']}&item={feature['id']}&assets=cog_default&bidx=1&unscale=false&resampling=nearest&max_size=1024&rescale=0%2C255\", \n    ).json()[\"tiles\"][0]\n        \n   \n    \n    with ThreadPoolExecutor(max_workers=10) as executor: \n        result = executor.map(_get_raster, [tilejson_url for _ in tiles], tiles)\n\n    for a, ymin, ymax, xmin, xmax in result: \n        canvas[ymin:ymax,xmin:xmax] = a[:,:,0]\n    return canvas\n    \n\n\n# define a 3D array that will hold all of the composite (mosaic) images we generate\ndatacube = np.zeros(((max_x - min_x+1)*256, (max_y-min_y+1)*256, len(features)))\n\nfor i, feature in enumerate(features): \n    print(f\"Feature {i} out of {len(features)}\")\n\n    image = mosaic_image(\n        feature = feature,\n        tiles=tiles\n    )\n    datacube[:,:,i] = image\n\n\n# Calculate the variance of the 3D array along the 3rd axis (time)\n# ignoring 0/nan values \nvar_array = np.var(datacube, axis=2, where=datacube > 0)\n\nim = Image.fromarray(var_array).convert(\"RGB\")\nim\n\nLooking at the variance map above, we can see that while the city centers did not experience much change in nightlight intensity throughout the lockdown, re-opening and re-lockdown periods of 2020-2021, the areas around the city centers display the greatest variance\n\n# For reference here is a image of the nightlights itensity before the lockdown\nim = Image.fromarray(datacube[:,:,0]).convert(\"RGB\")\nim","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-nasa-api-lockdown-in-venice#in-the-next-section-we-wil-use-the-raster-tiles-themselves-to-perform-a-pixel-by-pixel-variance-calculation","position":7},{"hierarchy":{"lvl1":"NO2 timeseries analysis"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis","position":0},{"hierarchy":{"lvl1":"NO2 timeseries analysis"},"content":"NO2 time series analysis on EO Dashboard: \n\nhttps://​www​.eodashboard​.org​/story​?id​=​air​-pollution​-us​-india​-china\n\nIntroduction\nThe air quality analysis focuses on monitoring tropospheric nitrogen dioxide (NO2) measured by the Tropospheric Monitoring Instrument (TROPOMI) aboard Copernicus Sentinel-5P.\nEarth-observing satellites equipped with TROPOMI instrument are being used to map air pollution worldwide and have revealed a significant drop in nitrogen dioxide (NO2) concentrations – coinciding with the strict quarantine measures which cause less emissions of the air pollutant nitrogen dioxide due to reduced traffic and industrial activities.\nThe nitrogen dioxide concentrations vary from day to day due to changes in the weather (such as wind speed, cloudiness, etc) and conclusions cannot be drawn based on just one day of data alone. By combining data for a specific period of time (e.g. averaging over 14 days) the meteorological variability partially averages out and impact of changes due to human activity become more clearly visible.\n\nNotebook Description\nThis notebook allows the user to compute and extract NO2 timeseries statistics over predefined AOIs.\nThe nomeclature of the files you see in the notebook are the one used to generate the indicator on the dashbaord. So they can be customized as desired. Nevertheless to produce a Dashboard compliant indicator the format of columns and other parameters need to be formatted as represented in the workflow.\n\nTo collect information about TROPOMI NO2 and data provided please visit the \n\nfollowing link\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis","position":1},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl3":"Important Note"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#important-note","position":2},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl3":"Important Note"},"content":"In order to run this notebook specific libraries are necessary. These libraries are preinstalled as custom Conda Environments for the IGARSS-22 workshop. If you want to follow this tutorial in your private (local or EOxHub) workspace environment please follow the instructions \n\nhere. The yaml file with all dependencies and libraries to create the custom environment is provided below:name: no2ts_full\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - _libgcc_mutex=0.1=main\n  - affine=2.3.0=py_0\n  - attrs=19.3.0=py_0\n  - backcall=0.2.0=pyh9f0ad1d_0\n  - backports=1.0=py_2\n  - backports.functools_lru_cache=1.6.4=pyhd8ed1ab_0\n  - blas=1.0=mkl\n  - bzip2=1.0.8=h7b6447c_0\n  - ca-certificates=2020.6.24=0\n  - cairo=1.14.12=h8948797_3\n  - certifi=2020.6.20=py37_0\n  - cfitsio=3.470=hb7c8383_2\n  - click=7.1.2=py_0\n  - click-plugins=1.1.1=py_0\n  - cligj=0.5.0=py37_0\n  - curl=7.67.0=hbc83047_0\n  - decorator=5.1.1=pyhd8ed1ab_0\n  - entrypoints=0.4=pyhd8ed1ab_0\n  - expat=2.2.9=he6710b0_2\n  - fontconfig=2.13.0=h9420a91_0\n  - freetype=2.10.2=h5ab3b9f_0\n  - freexl=1.0.5=h14c3975_0\n  - geos=3.8.0=he6710b0_0\n  - geotiff=1.5.1=h21e8280_1\n  - giflib=5.1.4=h14c3975_1\n  - glib=2.63.1=h5a9c865_0\n  - hdf4=4.2.13=h3ca952b_2\n  - hdf5=1.10.4=hb1b8bf9_0\n  - icu=58.2=he6710b0_3\n  - intel-openmp=2020.1=217\n  - ipykernel=5.3.4=py37h888b3d9_1\n  - ipython=7.18.1=py37hc6149b9_1\n  - ipython_genutils=0.2.0=py_1\n  - jedi=0.17.2=py37h89c1867_2\n  - jpeg=9b=h024ee3a_2\n  - json-c=0.13.1=h1bed415_0\n  - jupyter_client=7.1.2=pyhd8ed1ab_0\n  - jupyter_core=4.9.2=py37h89c1867_0\n  - kealib=1.4.7=hd0c454d_6\n  - krb5=1.16.4=h173b8e3_0\n  - ld_impl_linux-64=2.33.1=h53a641e_7\n  - libboost=1.67.0=h46d08c1_4\n  - libcurl=7.67.0=h20c2e04_0\n  - libdap4=3.19.1=h6ec2957_0\n  - libedit=3.1.20191231=h14c3975_1\n  - libffi=3.2.1=hd88cf55_4\n  - libgcc-ng=9.1.0=hdf63c60_0\n  - libgdal=3.0.2=h27ab9cc_0\n  - libgfortran-ng=7.3.0=hdf63c60_0\n  - libkml=1.3.0=h590aaf7_4\n  - libnetcdf=4.6.1=h11d0813_2\n  - libpng=1.6.37=hbc83047_0\n  - libpq=11.2=h20c2e04_0\n  - libsodium=1.0.18=h36c2ea0_1\n  - libspatialite=4.3.0a=h793db0d_0\n  - libssh2=1.9.0=h1ba5d50_1\n  - libstdcxx-ng=9.1.0=hdf63c60_0\n  - libtiff=4.1.0=h2733197_0\n  - libuuid=1.0.3=h1bed415_2\n  - libxcb=1.14=h7b6447c_0\n  - libxml2=2.9.10=he19cac6_1\n  - lz4-c=1.8.1.2=h14c3975_0\n  - mkl=2020.1=217\n  - mkl-service=2.3.0=py37he904b0f_0\n  - mkl_fft=1.1.0=py37h23d657b_0\n  - mkl_random=1.1.1=py37h0573a6f_0\n  - ncurses=6.2=he6710b0_1\n  - nest-asyncio=1.5.5=pyhd8ed1ab_0\n  - numpy=1.19.1=py37hbc911f0_0\n  - numpy-base=1.19.1=py37hfa32c7d_0\n  - openjpeg=2.3.0=h05c96fa_1\n  - openssl=1.1.1g=h7b6447c_0\n  - parso=0.7.1=pyh9f0ad1d_0\n  - pcre=8.44=he6710b0_0\n  - pexpect=4.8.0=pyh9f0ad1d_2\n  - pickleshare=0.7.5=py_1003\n  - pip=20.1.1=py37_1\n  - pixman=0.40.0=h7b6447c_0\n  - poppler=0.65.0=h581218d_1\n  - poppler-data=0.4.9=0\n  - postgresql=11.2=h20c2e04_0\n  - proj=6.2.1=haa6030c_0\n  - prompt-toolkit=3.0.29=pyha770c72_0\n  - ptyprocess=0.7.0=pyhd3deb0d_0\n  - pygments=2.11.2=pyhd8ed1ab_0\n  - pyparsing=2.4.7=py_0\n  - python=3.7.7=h191fe78_0_cpython\n  - python_abi=3.7=2_cp37m\n  - pyzmq=20.0.0=py37h5a562af_1\n  - rasterio=1.1.0=py37h41e4f33_0\n  - readline=7.0=h7b6447c_5\n  - setuptools=49.2.0=py37_0\n  - shapely=1.7.0=py37h98ec03d_0\n  - six=1.15.0=py_0\n  - snuggs=1.4.7=py_0\n  - sqlite=3.32.3=h62c20be_0\n  - tbb=2018.0.5=h6bb024c_0\n  - tiledb=1.6.3=h1fb8f14_0\n  - tk=8.6.10=hbc83047_0\n  - tornado=6.1=py37h4abf009_0\n  - traitlets=5.1.1=pyhd8ed1ab_0\n  - wcwidth=0.2.5=pyh9f0ad1d_2\n  - wheel=0.34.2=py37_0\n  - xerces-c=3.2.2=h780794e_0\n  - xz=5.2.5=h7b6447c_0\n  - zeromq=4.3.3=h58526e2_3\n  - zlib=1.2.11=h7b6447c_3\n  - zstd=1.3.7=h0b5b093_0\n  - pip:\n    - aenum==2.2.4\n    - boto3==1.14.36\n    - botocore==1.17.36\n    - chardet==3.0.4\n    - docutils==0.15.2\n    - idna==2.10\n    - jmespath==0.10.0\n    - oauthlib==3.1.0\n    - pandas==1.1.0\n    - pathlib==1.0.1\n    - pillow==7.2.0\n    - pyproj==2.6.1.post1\n    - python-dateutil==2.8.1\n    - pytz==2020.1\n    - requests==2.24.0\n    - requests-oauthlib==1.3.0\n    - s3transfer==0.3.3\n    - sentinelhub==3.0.5\n    - tifffile==2020.7.24\n    - urllib3==1.25.10\n    - utm==0.5.0\n    - wget==3.2\n    - xlrd==1.2.0\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#important-note","position":3},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Concept of analysis"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#concept-of-analysis","position":4},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Concept of analysis"},"content":"As input data source a Bring Your Own COG - BYOC data collection (S5P-NO2-tropno-daily-check) is used that is composed by Tropospheric Nitrogen dioxide (NO2) global coverage maps, each of which is a spatial average of NO2 bi-weekly concentration value.\n\nSOURCE: \n\nhttps://​browser​.eurodatacube​.com​/​?zoom​=​10​&​lat​=​41​.9​&​lng​=​12​.5​&​collectionId​=​s5p​-no2​-tropno​-daily​-check​&​layerId​=​NO2​&​type​=​sentinel​-hub​-edc​&​fromTime​=​2021​-05​-19T08​%3A45​%3A36​.153Z​&​toTime​=​2022​-05​-19T08​%3A45​%3A36​.153Z\n\nThe core of the notebook is then to compute median, std, max, min statistics on specific areas (AoI) and time range, and output this information on a csv that can be directly ingested in the geoDB and the related timeseries visualized on the EO Dashboard.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#concept-of-analysis","position":5},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Notebook step by step guide"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#notebook-step-by-step-guide","position":6},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Notebook step by step guide"},"content":"As you can see the different cells execute different commands to allow the generation of the required files.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#notebook-step-by-step-guide","position":7},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Import Libraries"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#import-libraries","position":8},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Import Libraries"},"content":"this cell aim at importing the necessary libraries to run the notebook.\n\n# Import packages\nimport itertools\nimport os\nimport numpy\nimport wget\nimport shapely\nimport rasterio\nimport datetime\nimport csv\nimport shutil\n\nfrom shapely import wkt\nfrom rasterio.merge import merge\nfrom rasterio.mask import mask\nfrom pathlib import Path\nfrom sentinelhub import MimeType, CRS, BBox, BBoxSplitter\nfrom sentinelhub.geometry import Geometry\nfrom sentinelhub.geo_utils import bbox_to_dimensions\nfrom shapely.geometry import shape, Polygon\n\nimport sys\nimport getopt\n\nimport time as tm\nimport urllib\nfrom urllib.error import HTTPError\n\n#!pip install matplotlib\nimport sys\n!{sys.executable} -m pip install matplotlib\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#import-libraries","position":9},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Input Parameters"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#input-parameters","position":10},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Input Parameters"},"content":"in this cell the user shall enter the location of the input parameters and the files themselves:\n\nInput-Output files\n\ninputfile: indicate where the file is and which file to use as input\n\nOutput location:\n\nfilename: is the standar file name used to be ingested into the dashboard. It shall be a csv file with specific  columns and formats\n\ncities_info: os.path.basename() method is used to get the base name in the specified path (inputfile)\n\nINPUT_DIR_NAME: os.path.dirname()  method used to get the directory name from the specified path (inputfile)\n\nOUTPUT_FOLDER: to generate a dedicated folder where tos tore the outputs in case it doesn’t exist.\n\n# Input-Output files\ninputfile = \"./Inputs/No2TestCase.xls\"\nmode='full'\n\nnow = datetime.datetime.now()\ncurrent_proctime = now.strftime(\"%Y%m%dT%H%M%S\")\n\n# Output location\nfilename= 'N1_trilateral_' + current_proctime + '.csv'\ncities_info=os.path.basename(inputfile)\nINPUT_DIR_NAME = os.path.dirname(inputfile)\n\nOUTPUT_FOLDER = f\"./Outputs/N1_tri/{current_proctime}/\"\nif not os.path.exists(OUTPUT_FOLDER):\n    os.makedirs(OUTPUT_FOLDER)\nPARENT_DATASET_DIR = OUTPUT_FOLDER\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#input-parameters","position":11},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Server instance"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#server-instance","position":12},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Server instance"},"content":"The server and the instances needed to use the proper files. The collections is avaialbe in the SH.\n\n# Server instance\nWMS_SERVER_URL = \"https://services.sentinel-hub.com/ogc/wms/\"\nINSTANCE_ID = \"c1f84418-3731-4b42-b92b-737c47d327a6\"\nLAYER_NAME = \"S5P-TW-WEEKLY-NEW\"\n\n# Parameters\nRES_X = 1627.315\nRES_Y = RES_X\nprint(RES_X)\n\nCRS_TARGET = \"WGS84\"\nIMAGE_DEPTH = \"32f\" # 8, 16, 32f (8bit uint, 16bit uint or 32bit float)\nIMAGE_FORMAT = \"tif\" # Only tif image is supported right now\n\n# Defining text info to be printed in the output file\nregion=''\nsite=''\ndescription='Tropospheric Nitrogen dioxide (NO2) column accumulated in last 14 days'\ndescription='Air Quality'\nmethod='Spatial average of NO2 bi-weekly concentration value on the city area'\neosensor='TROPOMI'\ninput_data='Sentinel-5p Level-3 NO2'\nindicator_code='N1'\nref_description='Spatial statistics [median,std,max,min,percentage valid pixels] of the current date within the city area'\nref_time=''\nref_value=''\nrule=''\nindicator_value=''\nyaxis='Tropospheric NO2 (μmol/m2)'\n#yaxis='Tropospheric NO2 (\\N{GREEK SMALL LETTER MU}mol/m2)'\ncolor=''\nindicator_name='TROPOMI: Spatial average over the city area of bi-weekly tropospheric nitrogen dioxide (NO2) concentrations'\nprovider='EMSS'\n#AOI_ID=''\nupdate_freq='Bi-weekly'\n\nfieldnames = ['AOI','Country','Region','City','Site Name','Description','Method','EO Sensor','Input Data','Indicator code','Time','Measurement Value','Reference Description','Reference time','Reference value','Rule','Indicator Value','Sub-AOI','Y axis','Indicator Name','Color code','Data Provider','AOI_ID','Update Frequency']\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#server-instance","position":13},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Defining WMS downloader"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#defining-wms-downloader","position":14},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Defining WMS downloader"},"content":"In order to execute the statistics the tiles shall be accessed and further processed. In order to do that through SH, you have to consider some of the limitations the WMS has set up. In particular:\n\nWMS_MAXIMUM_DATA_SIZE: the Maximum data size in pixel that can be requested from server (= 2500 Pixels). The following script allow to access to the needed patches (2500x2500) and to merge them into one image afterwards.\n\n# Defining WMS downloader\n\"\"\"## Downloader function definition\"\"\"\n\nWMS_MAXIMUM_DATA_SIZE = 2500 # Maximum data size in pixel that can be requested from server\nWMS_VERSION = \"1.1.1\"\n\ndef mergeImageFiles(filesList, outFileName):\n\n    images = list(map(lambda x: rasterio.open(x, 'r'), filesList))\n    merged, transform = merge(images)\n\n    with rasterio.open(outFileName,\n                       \"w\",\n                       driver='Gtiff',\n                       count=images[0].count,\n                       height=merged.shape[1],\n                       width=merged.shape[2],\n                       transform=transform,\n                       crs=images[0].crs,\n                       dtype=images[0].dtypes[0]) as dest:\n        dest.write(merged)\n\ndef crs_string_to_object(crs_string):\n    if crs_string == \"WGS84\":\n        return CRS.WGS84\n    else:\n        raise Exception(\"Unsupported CRS\")\n        \ndef image_format_string_to_object(image_ext_string, depth_string=None):\n    if image_ext_string == \"tif\":\n        if depth_string == \"8\":\n            return MimeType.TIFF_d8\n        elif depth_string == \"16\":\n            return MimeType.TIFF_d16\n        elif depth_string == \"32f\":\n            return MimeType.TIFF_d32f\n        else:\n            raise Exception(\"Unsupported image format\")\n    else:\n        raise Exception(\"Unsupported image format\")\n        \n\ndef wmsRequestData(wms_server_url, instanceID, aoi, layer_name, crs, image_format, resolution, start_date, end_date, output_folder, filename):\n    \n    # Only supports GeoTiff format\n    if not image_format.is_tiff_format:\n        raise Exception(\"Unsopported image format\")\n        \n    # Create output folder\n    os.makedirs(output_folder, exist_ok=True)\n    \n    image_name, image_ext = os.path.splitext(filename)\n    # Calculate bbox wrapper around geometry\n    geometry = Geometry(aoi, crs)\n    bbox_wrapper = geometry.bbox\n    \n    bbox_wrapper_dims = bbox_to_dimensions(bbox_wrapper, resolution)\n    # Calculate optimum grid to split area if area to download is greater than server size limit\n    x_grid = (bbox_wrapper_dims[0] // WMS_MAXIMUM_DATA_SIZE) + 1\n    y_grid = (bbox_wrapper_dims[1] // WMS_MAXIMUM_DATA_SIZE) + 1\n    \n    bbox_partition = bbox_wrapper.get_partition(num_x=x_grid, num_y=y_grid)\n\n    downloaded_file_list = []\n    for i, j in itertools.product(range(x_grid), range(y_grid)):\n        # Get bbox in the grid\n        bbox = bbox_partition[i][j]\n        # Assemble WMS request\n        wms_query = wms_server_url + instanceID + \"?\" + \"version=\" + WMS_VERSION + \"&service=WMS\" + \"&request=GetMap\" + \"&format=\" + image_format.get_string() + \"&crs=\" + crs.ogc_string() + \"&layers=\" + layer_name + \"&RESX=\" + str(resolution[0]) + \"m\" + \"&RESY=\" + str(resolution[1])+ \"m\" + \"&BBOX=\" + str(bbox) + \"&TIME=\" + start_date + \"/\" + end_date\n        #wms_query = wms_server_url + instanceID + \"?\" + \"version=\" + WMS_VERSION + \"&service=WMS\" + \"&request=GetMap\" + \"&format=\" + image_format.get_string() + \"&crs=\" + crs.ogc_string() + \"&layers=\" + layer_name + \"&WIDTH=\" + str(resolution[0]) + \"&HEIGHT=\" + str(resolution[1])+ \"&BBOX=\" + str(bbox) + \"&TIME=\" + start_date + \"/\" + end_date\n        patch_filename = image_name + \"_\" + str(i) + \"_\" + str(j) + image_ext\n        \n        print(wms_query)\n        # Download image patch\n        print(\"Downloading patch (%d, %d) ...\" %(i, j))\n        wget.download(wms_query, out=os.path.join(output_folder, patch_filename))\n        downloaded_file_list.append(os.path.join(output_folder, patch_filename))\n            \n    # Merge images\n    print(\"Merging patches ...\")\n    mergeImageFiles(downloaded_file_list, os.path.join(output_folder, filename))\n    print(\"Done!!!\")\n    \n    # Remove image patches\n    for file in downloaded_file_list:\n        os.remove(file)\n        \ndef mask_raster(raster_file, aoi, output_file):\n    with rasterio.open(raster_file) as src:\n        if isinstance(aoi, shapely.geometry.MultiPolygon):\n            polygons = [polygon for polygon in aoi]\n        else:\n            polygons = [aoi]\n        out_image, out_transform = mask(src, polygons, crop=False)\n        out_meta = src.meta\n        \n        out_meta.update({\"driver\": \"GTiff\",\n                     \"height\": out_image.shape[1],\n                     \"width\": out_image.shape[2],\n                     \"transform\": out_transform})\n\n        with rasterio.open(output_file, \"w\", **out_meta) as dest:\n            dest.write(out_image)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#defining-wms-downloader","position":15},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Location parameters reading function"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#location-parameters-reading-function","position":16},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Location parameters reading function"},"content":"the following cells aim at providing the functions to locate and re-call the parameters needed to run the core of the script for extracting the NO2 timeseries\n\n# Reading function for reading location parameters\n\ndef read_input_pandas(filename):\n    import pandas as pd\n#    df = pd.read_csv(filename, header=1)\n    df = pd.read_excel(filename,'cities')\n    print(df.head(5))\n    city=numpy.array(df.loc[:, 'City'])\n    country=numpy.array(df.loc[:,'Country'])\n    POINTS=numpy.array(df.loc[:,'Point Coordinates [LAT,LON]'])\n    DELTAS_X=numpy.array(df.loc[:,'DELTA_X'])\n    DELTAS_Y=numpy.array(df.loc[:,'DELTA_Y'])\n    AOI_ID=numpy.array(df.loc[:,'AOI_ID'])\n    POLYGONS=numpy.array(df.loc[:,'POLYGON'])\n    print(city)\n    print(POINTS)\n    print(DELTAS_X)\n    print(AOI_ID)\n    print(POLYGONS)\n    return city, country, DELTAS_X, DELTAS_X, AOI_ID, POINTS, POLYGONS\n\n# Resampling raster needed only when EDC does not allow to get data in full resolution\nimport os\nimport rasterio\n\nfrom rasterio.enums import Resampling\n\ndef resample_raster(raster_file, scale_factor, output_folder, output_filename):\n    os.makedirs(output_folder, exist_ok=True)\n    \n    input_raster_name, input_raster_ext = os.path.splitext(os.path.basename(raster_file))\n    \n    with rasterio.open(raster_file) as src:\n                \n        # resample data to target shape\n        data = src.read(\n            out_shape=(\n                src.count,\n                int(src.height * scale_factor),\n                int(src.width * scale_factor)\n            ),\n            resampling=Resampling.nearest\n        )\n\n        # scale image transform\n        out_transform = src.transform * src.transform.scale(\n            (src.width / data.shape[-1]),\n            (src.height / data.shape[-2])\n        )\n        \n        out_meta = src.meta.copy()\n        out_meta.update({\"height\": data.shape[1],\n                         \"width\": data.shape[2],\n                         \"transform\": out_transform})\n        with rasterio.open(os.path.join(output_folder, output_filename), \"w\", **out_meta) as dest:\n            dest.write(data)\n\n# Utility functions\n\n# Creating empty file with header\ndef creating_output_csv(filename):\n    with open(filename,'w') as csv_file:\n        fieldnames = ['AOI','Country','Region','City','Site Name','Description','Method','EO Sensor','Input Data','Indicator code','Time','Measurement Value','Reference Description','Reference time','Reference value','Rule','Indicator Value','Sub-AOI','Y axis','Indicator Name','Color Code','Data Provider','AOI_ID','Update Frequency']\n        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n        writer.writeheader()\n        csv_file.close()\n        \n# Removing rows with dates compressing last 30 days\ndef removing_lines_csv(filename):\n    from datetime import date\n    import pandas as pd\n    fieldnames = ['AOI','Country','Region','City','Site Name','Description','Method','EO Sensor','Input Data','Indicator code','Time','Measurement Value','Reference Description','Reference time','Reference value','Rule','Indicator Value','Sub-AOI','Y axis','Indicator Name','Color Code','Data Provider','AOI_ID','Update Frequency']\n    #with open(filename,'a') as csv_file:\n    no2_df = pd.read_csv(filename)\n    print('Full N1 indicator file')\n    print(no2_df)\n    print(no2_df.Time.unique())\n    print(no2_df.Time.unique()[-1])\n    print(no2_df.Time.unique()[-2]) \n    start_date=no2_df.Time.unique()[-2]\n    no2_df.loc[(no2_df['Time'] == no2_df.Time.unique()[-2]) & (no2_df['Time'] == no2_df.Time.unique()[-1])]\n    print('Lines to overwrite')\n    print(no2_df.loc[(no2_df['Time'] == no2_df.Time.unique()[-2]) & (no2_df['Time'] == no2_df.Time.unique()[-1])])\n    print('Remaining lines')\n    print(no2_df.loc[(no2_df['Time'] != no2_df.Time.unique()[-2]) & (no2_df['Time'] != no2_df.Time.unique()[-1])]) \n    #no2_df.drop(no2_df.loc[(no2_df['Time'] >= no2_df.Time.unique()[-2]) & (no2_df['Time'] <= no2_df.Time.unique()[-1])])\n        #csv_file.close()\n    updated_df=no2_df.loc[(no2_df['Time'] != no2_df.Time.unique()[-2]) & (no2_df['Time'] != no2_df.Time.unique()[-1])]\n    updated_df['Measurement Value']=numpy.round(updated_df['Measurement Value'],6)\n    updated_df.to_csv(filename,columns=fieldnames, index = False)\n    updated_df.to_csv(filename+'.2',columns=fieldnames,index = False)\n    start=start_date.split('T')[0]\n    #start_date = datetime.strptime(start,'%Y-%m-%d')\n    start_date = date.fromisoformat(start)\n    #datetime.date(2019, 12, 4)\n    return start_date\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#location-parameters-reading-function","position":17},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Core of the script"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#core-of-the-script","position":18},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl2":"Core of the script"},"content":"The core then allow to run the script and and compute the statistics needed (min, max, median, std) .\nIn particular there are two modes you can used based on the purpose of the run. At the beginning of the project there was the need to update only records that changed over time, also on already executed period, because the source (S5P Pal) could provided nrt data and consolidated data). Then in order to be always updated with the consolidated data, it has been decided to run the script for the entire period and not only on updated values. For this reason the two modes represents exactly one of the two situations described:\n\nfull: execute the script for the entire period NO2 maps are avaialbe as it was done from scratch\n\nupdate: execute the scripts and update only the records that have been updated.\n\nIt is recommended to use the “full” mode.\nIn order to have clear how the output csv shall be formatted in terms of column, you can refer to the:\n\nfieldnames parameter\n\n## Core of the script\n\nimport os\nimport shapely\nfrom shapely import wkt\nimport datetime\nimport csv\nimport requests\n\n##############################################################\n# Download input file\nif not os.path.exists(os.path.join(INPUT_DIR_NAME,cities_info)):\n    url = 'https://github.com/eurodatacube/notebooks/blob/master/notebooks/contributions/IGARSS2022/No2TestCase.xls?raw=true'\n    r = requests.get(url, allow_redirects=True)\n    os.makedirs(INPUT_DIR_NAME, exist_ok=True)\n    open(os.path.join(INPUT_DIR_NAME,cities_info), 'wb').write(r.content)\n\n# Getting location parameters \ncity, country, DELTAS_X, DELTAS_Y, AOI_ID, POINTS, POLYGONS = read_input_pandas(os.path.join(INPUT_DIR_NAME,cities_info))\n\n# Defining time variables for looping\ndelta = datetime.timedelta(days=14) \ntoday = datetime.date.today()  \nend_date = today.strftime(\"%Y-%m-%d\")\n\n# Creating back up file\nif  os.path.isfile(os.path.join(PARENT_DATASET_DIR,filename)) and os.path.exists(os.path.join(PARENT_DATASET_DIR,filename)):\n    shutil.copy(os.path.join(PARENT_DATASET_DIR,filename),os.path.join(PARENT_DATASET_DIR,filename+'.bkp-'+end_date))\n\nif mode == 'full':\n    creating_output_csv(os.path.join(PARENT_DATASET_DIR,filename))\n    start = datetime.date(2022,1,10)\n    start = datetime.date(2021,1,4)\nelif mode == 'update':  \n    #delta1 = datetime.timedelta(days=30)\n    #start_date =today-delta1\n    start=removing_lines_csv(os.path.join(PARENT_DATASET_DIR,filename))\n    print(start)\n\n#end_date = today.strftime(\"%Y-%m-%d\")\nprint(end_date)\nend_date = today \n\n#initiating no2 average value to empty\nmean_value=[]\ndates=[]\nprint(len(city))\n#start=datetime.date(2020,6,8)\n#end_date=datetime.date(2020,6,23)\nfor k in range(0,len(city)):\n  print('###############################')\n  print('City:'+city[k])\n  start_date=start\n  DELTA_X=DELTAS_X[k]\n  DELTA_Y=DELTAS_Y[k]\n  LON=float(POINTS[k].split(',')[0])\n  LAT=float(POINTS[k].split(',')[1])\n  POINT=[LON, LAT]\n  print(str(POINT[0])+','+str(POINT[1]))\n  AOI = \"POLYGON((\"+str(POINT[1]-DELTA_X)+\" \"+str(POINT[0]-DELTA_Y)+\",\"+str(POINT[1]+DELTA_X)+\" \"+str(POINT[0]-DELTA_Y)+\",\"+str(POINT[1]+DELTA_X)+\" \"+str(POINT[0]+DELTA_Y)+\",\"+str(POINT[1]-DELTA_X)+\" \"+str(POINT[0]+DELTA_Y)+\",\"+str(POINT[1]-DELTA_X)+\" \"+str(POINT[0]-DELTA_Y)+\"))\"\n  print(AOI)\n  AOI=POLYGONS[k]\n  print(AOI)\n  cityname = city[k]\n  cityname=cityname.replace(\" \", \"\")\n  print(cityname)\n  IMAGE_REF_NAME=cityname+\"_S5p_L3_NO2\"\n  \n  # Read AOI and convert to shapely format\n  aoi = shapely.wkt.loads(AOI)\n  AOIstr=str(POINT[0])+'_'+str(POINT[1])\n  mean_value=[]\n  #end_date = datetime.date(2020, 6, 9)\n  #start_date = datetime.date(2020, 6, 8) \n  print('start',start_date)\n  print('stop',end_date)\n  while start_date +delta  <= end_date:\n    print(start_date)\n    START_DATE = start_date.strftime(\"%Y-%m-%d\")\n    #END_DATE=START_DATE\n    #date2= start_date+delta\n    #END_DATE= date2.strtime(\"%Y-%m-%d\")\n    END_DATE=START_DATE\n    \n    #dates=numpy.append(dates,START_DATE)\n\n    IMAGE_NAME = IMAGE_REF_NAME + \"_\" + START_DATE.translate({ord(i): None for i in '-:'}) + \"_\" + END_DATE.translate({ord(i): None for i in '-:'})\n    IMAGE_NAME_TIF = IMAGE_NAME + '.tif'\n    IMAGE_TIF = os.path.join(OUTPUT_FOLDER, IMAGE_NAME_TIF)\n    IMAGE_CLIPPED_NAME = IMAGE_NAME + \"_clipped\"\n    IMAGE_CLIPPED_NAME_TIF = IMAGE_NAME + \"_clipped\" + \".tif\"\n    IMAGE_CLIPPED_TIF = os.path.join(OUTPUT_FOLDER, IMAGE_CLIPPED_NAME_TIF)\n    try:\n        wmsRequestData(WMS_SERVER_URL, INSTANCE_ID, aoi, LAYER_NAME, crs_string_to_object(CRS_TARGET), image_format_string_to_object(IMAGE_FORMAT, IMAGE_DEPTH), (RES_X, RES_Y), START_DATE, END_DATE, OUTPUT_FOLDER, IMAGE_NAME_TIF)\n    except HTTPError as err:\n        print('Server sent error code {}.'.format(err.code))\n        print('\\nRetrying...')\n        tm.sleep(10)\n        continue\n\n    ## there is no need to resample as sinergise updated the WMS server to admit our request\n    # Downsampling of the WMS images downloaded at 1000m to 5500m original resolution\n    # resample_raster(OUTPUT_FOLDER+'/'+IMAGE_NAME_TIF, 1000/1627.315, OUTPUT_FOLDER, IMAGE_NAME_TIF)\n\n    with rasterio.open(OUTPUT_FOLDER+'/'+IMAGE_NAME_TIF) as no2:\n      band=no2.read(1)\n      #weight=no2.read(3)\n      band = numpy.where(band > 2000, numpy.NaN, band)\n      print('Mininum')\n      print(numpy.nanmin(band))\n      band = numpy.where(band < 0,numpy.NaN, band)\n      print('Mininum2')\n      print(numpy.nanmin(band))\n      nonnans = numpy.count_nonzero(~numpy.isnan(band))\n      perc = numpy.count_nonzero(~numpy.isnan(band))/numpy.shape(band)[0]/numpy.shape(band)[1]*100\n      #perc = numpy.where(perc>100.0,100.0,perc)\n      print('Nonperc:'+str(perc))\n\n      ## weighting band with normalised weigth band (outside pols max=14)\n      #band=numpy.multiply(band,weight/14.0)\n\n      new_value=numpy.nanmean(numpy.nanmean(band))\n      max=numpy.nanmax(numpy.nanmax(band))\n      min=numpy.nanmin(numpy.nanmin(band))\n      std=numpy.nanstd(band)\n      median=numpy.nanmedian(numpy.nanmedian(band))\n     # weightmean=numpy.mean(numpy.mean(weight))#/14\n      print('Values are')\n      value, count = numpy.unique(band.flatten(), return_counts = True, axis = 0)\n      print('max: '+str(max)+' min: '+str(min)+' median: '+str(median)+' mean:'+str(new_value)+' std:'+str(std)+' count: '+str(count[0]))#+' weigth_average:'+str(weightmean))\n      mean_value=numpy.append(mean_value,new_value)\n    measurement=str(numpy.round(new_value,6))\n    ref_value=[median,std,max,min,perc]#,weightmean]\n    \n    # Removing downloaded tif (no need to keep them)\n    os.remove(IMAGE_TIF)    \n    time=START_DATE+'T00:00:00'\n    subAOI=AOI\n #   ref_value=[median,std,max,min]\n#    ref_value.append(perc)\n    ref_time=time\n    line=str(POINT[0])+' '+str(POINT[1])+','+country[k]+','+region+','+city[k]+','+site+','+description+','+method+','+eosensor+','+input_data+','+indicator_code+','+time+','+str(measurement)+','+ref_description+','+ref_time+','+str(ref_value)+','+rule+','+indicator_value+','+subAOI+','+yaxis+','+indicator_name+','+color+','+provider+','+AOI_ID[k]+','+update_freq+'\\n'\n    \n    fieldnames = ['AOI','Country','Region','City','Site Name','Description','Method','EO Sensor','Input Data','Indicator code','Time','Measurement Value','Reference Description','Reference time','Reference value','Rule','Indicator Value','Sub-AOI','Y axis','Indicator Name','Color Code','Data Provider','AOI_ID','Update Frequency']\n    with open(os.path.join(PARENT_DATASET_DIR,filename), mode='a') as csv_file:\n      writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n      #if numpy.array_equal(ref_value,numpy.asarray([numpy.NaN,numpy.NaN,numpy.NaN,numpy.NaN,0.0])):\n      if str(ref_value) == '[nan, nan, nan, nan, 0.0]':#, 0.0]':\n        ref_value = 'NaN'\n        measurement = 'NaN'\n        print('NaN conditions verified')\n      if time == '2019-03-18T00:00:00' and city[k] == 'Paris':\n        ref_value = [179.6195, 49.52065, 286.7863, 90.32629, 100.0]#, 13.375]\n        measurement = 180.275910\n        print('Paris 20190318 condition verified')\n      writer.writerow({'AOI':str(POINT[0])+','+str(POINT[1]),'Country':country[k],'Region':region,'City':city[k],'Site Name':site,'Description':description,'Method':method,'EO Sensor':eosensor,'Input Data':input_data,'Indicator code':indicator_code,'Time':time,'Measurement Value':str(measurement),'Reference Description':ref_description,'Reference time':ref_time,'Reference value':str(ref_value),'Rule':rule,'Indicator Value':indicator_value,'Sub-AOI':AOI,'Y axis':yaxis,'Indicator Name':indicator_name,'Color Code':color,'Data Provider':provider,'AOI_ID':AOI_ID[k],'Update Frequency':update_freq})\n      csv_file.close()\n \n    #go to next iteration\n    start_date += delta\n \n  # Sorting the final file by time and city\n  with open(os.path.join(PARENT_DATASET_DIR,filename),newline='') as csvfile:\n    spamreader = csv.DictReader(csvfile, delimiter=\",\")\n#    sortedlist = sorted(spamreader, key=lambda row:(row['Time'],row['City']), reverse=False)\n    sortedlist = sorted(spamreader, key=lambda row:(row['Time'],row['City']), reverse=False)\n  with open(os.path.join(PARENT_DATASET_DIR,filename), 'w') as f:\n    writer = csv.DictWriter(f, fieldnames=fieldnames)\n    writer.writeheader()\n    for row in sortedlist:\n        writer.writerow(row)    \n  #print(mean_value)\n  #numpy.savetxt(PARENT_DATASET_DIR+'/'+IMAGE_REF_NAME+\".csv\", mean_value, delimiter=\",\")\n \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#core-of-the-script","position":19},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl3":"Now is time to play with results","lvl2":"Core of the script"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#now-is-time-to-play-with-results","position":20},{"hierarchy":{"lvl1":"NO2 timeseries analysis","lvl3":"Now is time to play with results","lvl2":"Core of the script"},"content":"first try to figure out how the generated output is structured using the panda dataframe\n\n#df = pd.read_csv(\"Outputs/N1_tri/20220708T032639/N1_trilateral_20220708T032639.csv\")\ndf = pd.read_csv(os.path.join(PARENT_DATASET_DIR,filename))\ndf\n\nAnd now that we understand how the data is structured we can print the time series for selected fields and cities\n\n#df = pd.read_csv(\"Outputs/N1_tri/20220708T032639/N1_trilateral_20220708T032639.csv\", usecols=(3,10,11))\ndf = pd.read_csv(os.path.join(PARENT_DATASET_DIR,filename), usecols=(3,10,11))\ndf\n\n#plt.rcParams[\"figure.figsize\"] = [7.00, 3.50]\n#plt.rcParams[\"figure.autolayout\"] = True\ndf_filtered = df.loc[df['City'] == 'Kuala Lumpur ']\ndf_filtered\n\nfig = plt.figure(figsize=(20,10))\nplt.title('Mean of NO2 timeseries data')\nfig.autofmt_xdate()\nplt.plot(df_filtered[\"Time\"], df_filtered[\"Measurement Value\"])\nplt.show()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-no2-timeseries-analysis#now-is-time-to-play-with-results","position":21},{"hierarchy":{"lvl1":"Time series using STAC API statistics endpoints"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi","position":0},{"hierarchy":{"lvl1":"Time series using STAC API statistics endpoints"},"content":"from eoxhub import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi","position":1},{"hierarchy":{"lvl1":"Time series using STAC API statistics endpoints"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#time-series-using-stac-api-statistics-endpoints","position":2},{"hierarchy":{"lvl1":"Time series using STAC API statistics endpoints"},"content":"This notebook demonstrates how to generate a timeseries using STAC API statistics endpoints.\n\nAuthor: Leo Thomas\n\nLasted Updated Date: July 13, 2022\n\nimport datetime as dt\nfrom ipyleaflet import basemaps, Map, GeoJSON\nimport json\nimport requests as re\nimport matplotlib.pyplot as plt\nimport pprint\nimport time\n\nSTAC_API_URL = \"https://staging-stac.delta-backend.com\"\nRASTER_API_URL = \"https://staging-raster.delta-backend.com\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#time-series-using-stac-api-statistics-endpoints","position":3},{"hierarchy":{"lvl1":"Declare your collection of interest"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#declare-your-collection-of-interest","position":4},{"hierarchy":{"lvl1":"Declare your collection of interest"},"content":"You can discover available collections the following ways:\n\nUse the {STAC_ENDPOINT_URL}/collections API endpoint (JSON response)\n\nProgrammatically using pystac (see example in the list-collections.ipynb notebook\n\nIn the STAC Browser: \n\nhttp://​delta​-staging​-stac​-browser​.s3​-website​-us​-east​-1​.amazonaws​.com/\n\ncollection = 'no2-monthly'\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#declare-your-collection-of-interest","position":5},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Discover data using the STAC endpoint"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#discover-data-using-the-stac-endpoint","position":6},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Discover data using the STAC endpoint"},"content":"\n\nre.get(f\"{STAC_API_URL}/collections/{collection}\").json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#discover-data-using-the-stac-endpoint","position":7},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Describe the periodic nature of the data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#describe-the-periodic-nature-of-the-data","position":8},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Describe the periodic nature of the data"},"content":"\n\npprint.pprint({\n    k:v for k,v in re.get(f\"{STAC_API_URL}/collections/no2-monthly\").json().items()\n    if k in [\"dashboard:is_periodic\", \"dashboard:time_density\", \"summaries\"]\n})\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#describe-the-periodic-nature-of-the-data","position":9},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Load and inspect one of the STAC items"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#load-and-inspect-one-of-the-stac-items","position":10},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Load and inspect one of the STAC items"},"content":"This step is just for demonstration, to inspect what an item looks like.\n\nitems = re.get(f\"{STAC_API_URL}/collections/{collection}/items?limit=100\").json()[\"features\"]\nitems[0]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#load-and-inspect-one-of-the-stac-items","position":11},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Define a bounding box"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#define-a-bounding-box","position":12},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Define a bounding box"},"content":"We’ve defined a bounding box for France in this case.\n\nbounding_box_france = { \n    \"type\": \"Feature\",\n    \"properties\": {},\n    \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [[\n            [\n              -5.4534286,\n              41.2632185\n            ],\n            [\n              9.8678344,\n              41.2632185\n            ],\n            [\n              9.8678344,\n              51.268318\n            ],\n            [\n              -5.4534286,\n              51.268318\n            ],\n            [\n              -5.4534286,\n              41.2632185\n            ]\n        ]]\n    }\n}\n\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#define-a-bounding-box","position":13},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Map the bounding box"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#map-the-bounding-box","position":14},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Map the bounding box"},"content":"This step is for visual inspection of the bounding box.\n\nm = Map(\n    basemap=basemaps.OpenStreetMap.Mapnik,\n    center=(47,4),\n    zoom=3\n)\ngeo = GeoJSON(\n    data=bounding_box_france,\n    style={\"color\": \"red\", \"fillOpacity\": 0}\n)\nm.add_layer(geo)\nm\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#map-the-bounding-box","position":15},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Use /cog/statistics to get data for the bounding box"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#use-cog-statistics-to-get-data-for-the-bounding-box","position":16},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Use /cog/statistics to get data for the bounding box"},"content":"First, we create a generate_stats function and then we call it with the bounding box defined for France.\n\ndef generate_stats(item, bounding_box):\n    result = re.post(\n        f\"{RASTER_API_URL}/cog/statistics\", \n        params={\n            \"url\":item[\"assets\"][\"cog_default\"][\"href\"]\n        },\n        json=bounding_box\n    ).json()    \n    return {\n        **result[\"properties\"], \"start_datetime\":item[\"properties\"][\"start_datetime\"]\n    }\n   \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#use-cog-statistics-to-get-data-for-the-bounding-box","position":17},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Generate and estimate time to generate statistics"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#generate-and-estimate-time-to-generate-statistics","position":18},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Generate and estimate time to generate statistics"},"content":"This may take a minute, depending on the network.\n\nstart = time.time()\nstats = [generate_stats(item, bounding_box_france) for item in items]\nend = time.time()\nprint(f\"Elapsed time for small bounding box (france): {round(end-start,2)} seconds. Items queried: {len(items)}\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#generate-and-estimate-time-to-generate-statistics","position":19},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Inspect one result"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#inspect-one-result","position":20},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl2":"Inspect one result"},"content":"\n\nstats[1]\n\ndates = [dt.datetime.strptime(stat[\"start_datetime\"], \"%Y-%m-%dT%H:%M:%S\") for stat in stats]\nmeans = [stat[\"statistics\"][\"1\"][\"mean\"] for stat in stats]\nstd_devs = [stat[\"statistics\"][\"1\"][\"std\"] for stat in stats]\nupper_bounds = [m+s for (m,s) in zip(means, std_devs)]\nlower_bounds = [m-s for (m,s) in zip(means, std_devs)]\n\nfig = plt.figure(figsize=(20,10))\nplt.plot(dates, means, 'black', label=\"Mean monthly NO2 values\")\n\nplt.fill_between(dates, upper_bounds, lower_bounds, facecolor=\"lightgray\", interpolate=False, label=\"+/- one standard devation\")\nplt.legend()\nplt.title(\"NO2 Values in France (2016-2022)\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#inspect-one-result","position":21},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl3":"Comparison: multi vs single threaded approach","lvl2":"Inspect one result"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#comparison-multi-vs-single-threaded-approach","position":22},{"hierarchy":{"lvl1":"Declare your collection of interest","lvl3":"Comparison: multi vs single threaded approach","lvl2":"Inspect one result"},"content":"Earlier we requested the statistics from the NASA API for each timestep individually. The API is powered by \n\nAWS Lambda, which is highly scalable. Since each statistics request is for a single timestamp, we can request statistics for multiple timesteps concurrently. We will do this by using the concurrent.futures library:\n\nfrom concurrent.futures import ThreadPoolExecutor \n\ndef _generate_stats(item):\n    return generate_stats(item, bounding_box_france)\n\nstart = time.time()\nwith ThreadPoolExecutor(max_workers=10) as executor: \n    stats = list(executor.map(_generate_stats, items))\nend = time.time()\nprint(f\"Elapsed time for small bounding box (france) with multi-threading: {round(end-start,2)} seconds. Items queried: {len(items)}\")","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi#comparison-multi-vs-single-threaded-approach","position":23},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo","position":0},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification"},"content":"from edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo","position":1},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#lpis-use-case-for-land-use-land-cover-classification","position":2},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification"},"content":"This notebook demonstrates how Euro Data Cube (EDC) tools can be utilized for an exploratory analysis and manipulation of data in Land Parcel Identification System (LPIS). The most important part is the example of using satellite imagery and machine learning algorithms to provide additional information about the area of interest, which should be a valuable support for decisions related with LPIS controls.\n\nA workflow consist of three parts:\n\nPrepare and explore LPIS data, reference land use data and satellite imagery\n\nRun Machine Learning for Land Cover Land Use (LULC) prediction\n\nVisualize results and extract information to support LPIS controls\n\nStep 2. is based on machine learning pipeline developed for LULC prediction in \n\nSlovenia. The workflow in this notebook is simplified and focused less on machine learning algorithm and more on usefulness of the results. It allows the user to change settings such as: area of interest, time range, mapping of classes.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#lpis-use-case-for-land-use-land-cover-classification","position":3},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"AWS: S3 bucket, SentinelHub and database access parameters"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#aws-s3-bucket-sentinelhub-and-database-access-parameters","position":4},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"AWS: S3 bucket, SentinelHub and database access parameters"},"content":"You need to replace the placeholder values with your own database Amazon S3 and SentinelHub parameters:\n\n# S3 parameters\naws_access_key_id = \"<aws_access_key>\"\naws_secret_access_key = \"<aws_secret_key>\"\naws_s3_bucket = \"<aws_s3_bucket_name>\" # Bucket must be configured as described here:\n                                       # https://docs.sentinel-hub.com/api/latest/#/API/byoc?id=configuring-the-bucket\naws_s3_path = \"<aws_s3_path_prediction>\" # path on the bucket for the reference data, example: \"DCFS/{0}/{value_name}.tiff\", where {0} represents patch index\n                                        # where {0} represents patch index.\n\n# SentinelHub\nsentinelhub_prediction_layer = '<sentinelhub_prediction_layer>' # name of the \"Prediction\" layer within the above defined SentinelHub instance ID\nsentinelhub_land_use_layer = '<sentinelhub_prediction_layer>' # name of the \"Land use\" layer within the above defined SentinelHub instance ID\nsentinelhub_prediction_diff_layer = '<sentinelhub_prediction_layer>' # name of the \"Prediction vs. Land use difference\" layer within the above defined SentinelHub instance ID\n \n# BYOC collections\nsentinelhub_collection_name = \"DCFS\"\n\n\n# This notebook uses the EO-Learn ML library which requires configuration passed via the 'sentinel.config' tool\n!sentinelhub.config --sh_base_url 'https://services.sentinel-hub.com'\n!sentinelhub.config --sh_client_id $SH_CLIENT_ID\n!sentinelhub.config --sh_client_secret $SH_CLIENT_SECRET\n!sentinelhub.config --instance_id $SH_INSTANCE_ID\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#aws-s3-bucket-sentinelhub-and-database-access-parameters","position":5},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"User constants"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#user-constants","position":6},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"User constants"},"content":"\n\ncountry_name = \"slovenia\"\ncountry_crs_code = \"EPSG:32633\"\ncountry_border_file = 'svn_buffered.geojson'\n\ndb_srid = 3794\ndb_land_use_table = \"land_use_slo\"\ndb_land_use_class_column = \"raba_id\"\ndb_lpis_table = \"lpis_slo\"\ndb_lpis_class_column = \"raba_id\"\n\nselected_db_records_time = '2019-09-30' # records that are used as a reference to compare with prediction\nselected_patch_center = (16.1977, 46.7299) # 15.1664, 46.2498) # (13.860377, 46.283196) # longitude, latitude\nselected_patch_displayed_time = '2019-09-15' #User's input. Must be a value in cube.time\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#user-constants","position":7},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Import packages"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#import-packages","position":8},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Import packages"},"content":"\n\n# Firstly, some necessary imports\n\n# Jupyter notebook related\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n# Built-in modules\nimport pickle\nimport sys\nimport os\nimport datetime\nimport time\nimport itertools\nimport math\nimport subprocess\nimport json\nimport fiona\nfrom geojson import Polygon as geoJsonPolygon\nfrom enum import Enum\n\n# interactive map\nfrom ipyleaflet import Map as LeafletMap, Marker as LeafletMarker, Polygon as LeafletPolygon\nfrom ipyleaflet import ImageOverlay as LeafletImageOverlay, DrawControl as LeafletDrawControl\nfrom ipyleaflet import LayersControl as LeafletLayersControl, LayerGroup as LeafletLayerGroup\nfrom ipyleaflet import basemaps, basemap_to_tiles\n\n# Basics of Python data handling and visualization\nimport numpy as np\nimport geopandas as gpd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as patches\nfrom matplotlib.transforms import Bbox as plotBbox\nfrom matplotlib import colors\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\nfrom shapely.geometry import Polygon\nfrom tqdm import tqdm_notebook as tqdm\n\n# Machine learning \nimport lightgbm as lgb\nfrom sklearn.externals import joblib\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\n# Imports from eo-learn and sentinelhub-py\nfrom eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, \\\n    LoadTask, SaveTask, EOExecutor\nfrom eolearn.io import S2L1CWCSInput, ExportToTiff\nfrom eolearn.mask import AddCloudMaskTask, get_s2_pixel_cloud_detector, AddValidDataMaskTask\nfrom eolearn.geometry import VectorToRaster, PointSamplingTask, ErosionTask\nfrom eolearn.features import LinearInterpolation, SimpleFilterTask\nfrom sentinelhub import BBoxSplitter, BBox, CRS, CustomUrlParam, UtmGridSplitter\n\n# OAuth2\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# DB and raw geometry\nfrom xcube_geodb.core.geodb import GeoDBClient\nimport psycopg2\nfrom psycopg2._psycopg import AsIs\nfrom psycopg2.extensions import register_adapter\nimport shapely.wkt\nfrom shapely.geometry import Polygon, MultiPolygon\nfrom geopandas import GeoDataFrame\nimport pyproj\n\n# imports for xcube\nimport xarray as xr\nimport shapely.geometry\nfrom shapely.ops import cascaded_union\nimport zarr\n\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.observers import Observers\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.viewer import ViewerServer\nimport xcube.core.geom\nimport xcube.core.chunk\n\n# Amazon S3\nimport boto3\n\nimport logging\nglobalLogger = logging.getLogger()\nglobalLogger.setLevel(logging.CRITICAL)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#import-packages","position":9},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Mappings and colors"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#mappings-and-colors","position":10},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Mappings and colors"},"content":"\n\nlulcMapping = {\n    0: {\"name\": 'No Data', \"color\": [1.00, 1.00, 1.00]},\n    1: {\"name\": 'Cultivated Land', \"color\": [0.75, 1.00, 0.00]},\n    2: {\"name\": 'Forest', \"color\": [0.01, 0.21, 0.00]},\n    3: {\"name\": 'Grassland', \"color\": [0.98, 0.45, 0.02]},\n    4: {\"name\": 'Shrubland', \"color\": [0.82, 0.70, 0.44]},\n    5: {\"name\": 'Water', \"color\": [0.02, 0.60, 0.95]},\n    6: {\"name\": 'Wetlands', \"color\": [0.84, 1.00, 1.00]},\n    7: {\"name\": 'Tundra', \"color\": [0.78, 0.62, 0.94]},\n    8: {\"name\": 'Artificial Surface', \"color\": [0.55, 0.00, 0.06]},\n    9: {\"name\": 'Bareland', \"color\": [0.90, 0.85, 0.65]},\n    10: {\"name\": 'Snow and Ice', \"color\": [0.00, 0.00, 0.00]}\n}\n    \nlulcColorMapping = {id: entry[\"color\"] for id, entry in lulcMapping.items()}\nlulcLegendTexts = {id: str(id) + \" = \" + entry[\"name\"] for id, entry in lulcMapping.items()}\n\n## mapping of land use classes into 10 classes that are to be predicted\nlulcToLandUseMapping = {\n    0: [0, 9999, 1411], # NOTE 1411 doesn't match any class\n    1: [1100, 1150, 1160, 1161, 1170, 1180, 1181, 1190, 1191, 1192, 1211, 1212, 1221, 1222, 1230, 1240, 1610],\n    2: [1420, 2000, 1907],\n    3: [1130, 1131, 1300, 1320, 1321, 1330, 1600, 1906, 1800, 1430],\n    4: [5000, 1500, 1410],\n    5: [7000, 1905],\n    6: [4100, 4210, 4220],\n    7: [],\n    8: [3000, 1902, 1903, 1904],\n    9: [6000],\n    10: []\n}\n\nlandUseToLulcMapping = {landUse: lulc for lulc, landUseList in lulcToLandUseMapping.items() for landUse in landUseList}\n\nlandUseMapping = {\n    1100: {\"name\": 'Arable land', \"color\": [0.60, 0.40, 0.40]},\n    1130: {\"name\": 'Temporary grassland (not in use anymore)', \"color\": [0.11, 0.56, 0.56]},\n    1131: {\"name\": 'Temporary grassland', \"color\": [0.11, 0.56, 0.56]},\n    1150: {\"name\": 'Field for snail farming', \"color\": [0.60, 0.40, 0.40]},\n    1160: {\"name\": 'Hop field', \"color\": [1.00, 0.20, 1.00]},\n    1161: {\"name\": 'Hop field in rotation', \"color\": [1.00, 0.20, 1.00]},\n    1170: {\"name\": 'Strawberry field', \"color\": [0.60, 0.40, 0.40]},\n    1180: {\"name\": 'Permanent crops on arable land', \"color\": [1.00, 0.73, 0.60]},\n    1181: {\"name\": 'Permanent crops on arable land where production is not in soil (not eligible)', \"color\": [1.00, 0.73, 0.60]},\n    1190: {\"name\": 'Greenhouse', \"color\": [0.60, 0.40, 0.40]},\n    1191: {\"name\": 'Greenhouse where production is not in soil (not eligible)', \"color\": [0.60, 0.40, 0.40]},\n    1192: {\"name\": 'Greenhouse with fruit plants', \"color\": [1.00, 0.73, 0.60]},\n    1211: {\"name\": 'Vineyard', \"color\": [1.00, 1.00, 0.20]},\n    1212: {\"name\": 'Nursery', \"color\": [1.00, 0.68, 0.68]},\n    1221: {\"name\": 'Intensive orchard', \"color\": [1.00, 0.73, 0.20]},\n    1222: {\"name\": 'Extensive orchard', \"color\": [1.00, 0.60, 0.20]},\n    1230: {\"name\": 'Olive grove', \"color\": [0.73, 0.73, 0.20]},\n    1240: {\"name\": 'Other permanent crop', \"color\": [1.00, 0.73, 0.60]},\n    1300: {\"name\": 'Permanent grassland', \"color\": [0.20, 1.00, 0.20]},\n    1320: {\"name\": 'Permanent grassland with scattered ineligible features (Pro-rata)', \"color\": [0.20, 0.78, 0.80]},\n    1321: {\"name\": 'Swampy meadows', \"color\": [0.04, 0.96, 0.85]},\n    1330: {\"name\": 'Mountain pasture (not in use anymore)', \"color\": [0.50, 1.00, 0.20]},\n    1410: {\"name\": 'Overgrown agricultural area', \"color\": [1.00, 0.37, 0.37]},\n    1411: {\"name\": 'Area for removing overgrowth', \"color\": [0.21, 0.58, 0.45]},\n    1420: {\"name\": 'Forest plantation', \"color\": [0.20, 0.80, 0.60]},\n    1430: {\"name\": 'Extensive karst pasture', \"color\": [0.58, 0.98, 0.67]},\n    1500: {\"name\": 'Trees and shrubs', \"color\": [0.15, 0.84, 0.24]},\n    1600: {\"name\": 'Uncultivated agricultural land  ', \"color\": [0.50, 0.25, 0.25]},\n    1610: {\"name\": 'Agricultural land being prepared for cultivation', \"color\": [0.20, 0.73, 0.20]},\n    1800: {\"name\": 'Forest trees on agricultural land', \"color\": [0.15, 0.84, 0.24]},\n    1902: {\"name\": 'Hayrack', \"color\": [0.72, 0.52, 0.05]},\n    1903: {\"name\": 'Dirt road', \"color\": [0.85, 0.77, 0.65]},\n    1904: {\"name\": 'Dry stone', \"color\": [0.75, 0.75, 0.75]},\n    1905: {\"name\": 'Trench', \"color\": [0.75, 0.75, 0.75]},\n    1906: {\"name\": 'Grassy border between fields', \"color\": [0.20, 1.00, 0.20]},\n    1907: {\"name\": 'Trees in line', \"color\": [0.15, 0.84, 0.24]},\n    2000: {\"name\": 'Forest', \"color\": [0.15, 0.84, 0.24]},\n    3000: {\"name\": 'Built-up area and related surface', \"color\": [1.00, 0.20, 0.50]},\n    4100: {\"name\": 'Swamp', \"color\": [0.04, 0.96, 0.85]},\n    4210: {\"name\": 'Reed', \"color\": [0.04, 0.96, 0.85]},\n    4220: {\"name\": 'Other marshy areas', \"color\": [0.04, 0.96, 0.85]},\n    5000: {\"name\": 'Dried open area with special vegetation', \"color\": [0.50, 0.50, 1.00]},\n    6000: {\"name\": 'Open area with little or no vegetation', \"color\": [0.84, 1.00, 0.67]},\n    7000: {\"name\": 'Water', \"color\": [0.50, 1.00, 1.00]},\n    9999: {\"name\": 'No data', \"color\": [0.00, 0.00, 0.00]}\n}\n\nlandUseColorMapping = {id: entry[\"color\"] for id, entry in landUseMapping.items()}\nlandUseLegendTexts = {id: str(id) + \" = \" + ((entry[\"name\"][:15] + '..') if len(entry[\"name\"]) > 15 else entry[\"name\"]) for id, entry in landUseMapping.items()}\n\ndiffColorMapping = { # Blue through yellow to red\n    -10: [0.19, 0.21, 0.58], \n    -9: [0.27, 0.29, 0.60], \n    -8: [0.35, 0.37, 0.62], \n    -7: [0.43, 0.45, 0.63], \n    -6: [0.52, 0.53, 0.65],\n    -5: [0.60, 0.61, 0.67], \n    -4: [0.68, 0.68, 0.69], \n    -3: [0.76, 0.76, 0.70], \n    -2: [0.84, 0.84, 0.72], \n    -1: [0.92, 0.92, 0.74],\n    0: [1.00, 1.00, 0.75], \n    1: [0.97, 0.90, 0.69], \n    2: [0.93, 0.80, 0.63], \n    3: [0.90, 0.70, 0.57], \n    4: [0.86, 0.60, 0.51],\n    5: [0.83, 0.50, 0.45], \n    6: [0.80, 0.40, 0.39], \n    7: [0.76, 0.30, 0.33], \n    8: [0.73, 0.20, 0.27], \n    9: [0.69, 0.10, 0.21],\n    10: [0.66, 0.00, 0.15]\n}\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#mappings-and-colors","position":11},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Database loading functionality"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#database-loading-functionality","position":12},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Database loading functionality"},"content":"\n\n# needed for DB mapping\nregister_adapter(np.int64, AsIs)\nregister_adapter(Polygon, AsIs)\nregister_adapter(MultiPolygon, AsIs)\n\ndef loadFromDatabase(geodb, taskName, tableName, landUseColumnName, recordId, bbox, crs, \n    dateFilterMin, dateFilterMax, maxRows = None, logging = True, mappedColumnName = None, mappingLambdaFunc = None):\n    \n    conditions = []\n    if not dateFilterMin is None:\n        conditions.append(\"d_update >= '{}'\".format(dateFilterMin));\n\n    if not dateFilterMax is None:\n        conditions.append(\"d_update <= '{}'\".format(dateFilterMax));\n\n    if not recordId is None:\n        conditions.append(\"id=eq.{}\".format(recordId));\n        \n    if len(conditions) == 0:\n        conditions.append(\"id >= -1\")\n        \n    if not bbox is None:\n        transformer = pyproj.Transformer.from_crs(str(crs), \"EPSG:\" + str(db_srid), always_xy=True)\n        bbox_x1y1 = transformer.transform(bbox.min_x, bbox.min_y)\n        bbox_x2y2 = transformer.transform(bbox.max_x, bbox.max_y)\n        bbox_native = BBox((bbox_x1y1[0], bbox_x1y1[1], bbox_x2y2[0], bbox_x2y2[1]), crs)\n    \n        gdf = geodb.get_collection_by_bbox(collection = tableName, \n            bbox = (bbox_native.min_x, bbox_native.min_y, bbox_native.max_x, bbox_native.max_y), \n            where = \" AND \".join(conditions),\n            comparison_mode = \"intersects\", bbox_crs = db_srid, \n            limit = 0 if maxRows is None else maxRows, offset = 0)\n    else:\n        gdf = geodb.get_collection(collection = tableName, query = \" AND \".join(conditions))\n        \n    gdf.crs = fiona.crs.from_epsg(db_srid)\n    gdf = gdf.to_crs(str(crs))\n    gdf.crs = {\"init\": \"epsg:{}\".format(crs.value)}\n    \n    # Map the specific \"raba_id\" column to the general \"land_use\". Also add a mapped column name if needed.\n    gdf[\"land_use\"] = gdf[\"raba_id\"]\n    if (mappedColumnName and mappingLambdaFunc):\n        gdf[mappedColumnName] = gdf.apply(lambda row: mappingLambdaFunc(row[\"raba_id\"]), axis = 1)\n    \n    if logging and not bbox is None:\n        print(taskName + \": \" + str(len(gdf)) + ' DB records for bbox = ' + str(bbox))\n\n    return gdf\n\n\ndef loadFromDatabaseWithLulcMapping(geodb, taskName, tableName, landUseColumnName, recordId, bbox, crs, \n    dateFilterMin, dateFilterMax, maxRows = None, logging = True):\n    \n    return loadFromDatabase(geodb, taskName, tableName, landUseColumnName, recordId, bbox, crs, \n        dateFilterMin, dateFilterMax, maxRows, logging,\n        \"lulcid\", lambda lulc: landUseToLulcMapping[lulc] if lulc in landUseToLulcMapping else 0)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#database-loading-functionality","position":13},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"SentinelHub client functionality"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#sentinelhub-client-functionality","position":14},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"SentinelHub client functionality"},"content":"\n\nclass SentinelHubClient():\n    def __init__(self, sh_oauth_session, s3_bucket):\n        self.sh_oauth_session = sh_oauth_session\n        self.s3_bucket = s3_bucket\n        \n    def getCollectionByName(self, name):\n        try:\n            url = \"{base_url}/byoc/collections\"\n            url = url.format(base_url = sentinelhub_url)\n            response = self.sh_oauth_session.get(url = url)\n            response.raise_for_status()\n\n            for collection_data in response.json()[\"data\"]:\n                if collection_data[\"name\"] == name:\n                    return collection_data[\"id\"]\n            return None\n        except Exception as e:\n            print(e)\n            raise\n    \n    def createCollection(self, name):\n        try:\n            url = \"{base_url}/byoc/collections\"\n            url = url.format(base_url = sentinelhub_url)\n            response = self.sh_oauth_session.post(url = url, json = {'name': name, 's3Bucket': self.s3_bucket})\n            response.raise_for_status()\n            return response.json()[\"data\"][\"id\"]\n        except Exception as e:\n            print(e)\n            raise\n            \n    def getTileByPath(self, collection_id, s3_file_path):\n        try:\n            url = \"{base_url}/byoc/collections/{collection_id}/tiles\"\n            url = url.format(base_url = sentinelhub_url, collection_id = collection_id)\n            response = self.sh_oauth_session.get(url = url)\n            response.raise_for_status()\n\n            for tile_data in response.json()[\"data\"]:\n                if tile_data[\"path\"] == s3_file_path:\n                    return tile_data[\"id\"]\n            return None\n        except Exception as e:\n            print(e)\n            raise\n            \n    def deleteTile(self, collection_id, tile_id):\n        try:\n            url = \"{base_url}/byoc/collections/{collection_id}/tiles/{tile_id}\"\n            url = url.format(base_url = sentinelhub_url, collection_id = collection_id, tile_id = tile_id)\n            response = self.sh_oauth_session.delete(url = url)\n            response.raise_for_status()\n        except Exception as e:\n            print(e)\n            raise\n            \n    def ingestTile(self, collection_id, s3_file_path, bbox):\n        try:\n            crs = {\"type\": \"name\", \"properties\": {\"name\": \"urn:ogc:def:crs:EPSG::{}\".format(bbox.crs.value)}}\n            cover_geometry = geoJsonPolygon([bbox.get_polygon()], crs = crs)\n            json = json = {\"path\": s3_file_path, \"coverGeometry\": cover_geometry, \"tileGeometry\": cover_geometry}\n            \n            url = \"{base_url}/byoc/collections/{collection_id}/tiles\"\n            url = url.format(base_url = sentinelhub_url, collection_id = collection_id)\n            response = self.sh_oauth_session.post(url = url, json = json)\n            response.raise_for_status()\n            tile_id = response.json()[\"data\"][\"id\"]\n\n            # wait until tile ingested\n            url = \"{base_url}/byoc/collections/{collection_id}/tiles/{tile_id}\"\n            url = url.format(base_url = sentinelhub_url, collection_id = collection_id, tile_id = tile_id)\n            while True:\n                response = self.sh_oauth_session.get(url = url)\n                response.raise_for_status()\n                status = response.json()[\"data\"][\"status\"]\n                if status != 'INGESTING' and status != 'WAITING':\n                    if status == 'FAILED':\n                        print(\"Failed to ingest tile \" + s3_file_path + \": \" + response.json()[\"data\"][\"failedIngestionCause\"])\n                    break\n                time.sleep(1)\n            \n            return tile_id\n        except Exception as e:\n            print(e)\n            raise\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#sentinelhub-client-functionality","position":15},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#part-1-exploratory-analysis","position":16},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Part 1: Exploratory Analysis"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#part-1-exploratory-analysis","position":17},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Define the Area-of-Interest (AOI):","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-the-area-of-interest-aoi","position":18},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Define the Area-of-Interest (AOI):","lvl2":"Part 1: Exploratory Analysis"},"content":"The whole territory of a country is splited into patches which makes the processing more efficient. The process is run on are of 3x3 patches for demonstration purposes.  AOI can be selected as the id of the patch in the middle.\n\nMain steps in this part of the notebook:\n\nA geographical shape of Slovenia was taken from \n\nNatural Earth database and a buffer was applied. The shape is available in repository: example_data/svn_buffered.geojson\n\nConvert it to selected CRS: taken to be the CRS of central UTM tile (UTM_33N)\n\nSplit it into smaller, manageable, non-overlapping rectangular tiles (patches)\n\nSelect a small 3x3 area for classification\n\nBe sure that your choice of CRS is the same as the CRS of your reference data.\n\nIn the case that you are having problems with empty data being downloaded, try changing the CRS to something that suits the location of the AOI better.\n\ncountry_crs = CRS(country_crs_code)\n\n# Folder where data for running the notebook is stored\nDATA_FOLDER = os.path.join('example_data')\n\n# Load geojson file\ncountry = gpd.read_file(os.path.join(DATA_FOLDER, country_border_file))\n\n# Convert CRS\ncountry = country.to_crs(crs={'init': CRS.ogc_string(country_crs)})\n\n# Get the country's shape in polygon format\ncountry_shape = country.geometry.values[-1]\n\n# Create the splitter to obtain a list of bboxes\nuse_smaller_patches = True\nbbox_splitter_large = BBoxSplitter([country_shape], country_crs, (25, 17))\nbbox_splitter_small = BBoxSplitter([country_shape], country_crs, (25 * 3, 17 * 3))\n\nbbox_splitter = bbox_splitter_small if use_smaller_patches else bbox_splitter_large\nbbox_list_aligned = [BBox((10 * math.floor(bbox.min_x / 10), 10 * math.floor(bbox.min_y / 10), \n                           10 * math.floor(bbox.max_x / 10), 10 * math.floor(bbox.max_y / 10)), country_crs) \n                     for bbox in bbox_splitter.get_bbox_list()]\n\nbbox_list = np.array(bbox_list_aligned)\ninfo_list = np.array(bbox_splitter.get_info_list())\n\n\n# For the future examples, we will be using a specific set of patches,\n# Select a central patch\n\nfrom_wgs84_transformer = pyproj.Transformer.from_crs(str(CRS.WGS84), str(country_crs), always_xy=True)\ncenter_x, center_y = from_wgs84_transformer.transform(selected_patch_center[0], selected_patch_center[1])\n\ndef bboxContains(bbox, x, y):\n    return (x >= bbox.min_x) and (x < bbox.max_x) and (y >= bbox.min_y) and (y < bbox.max_y)\n\n# find index of the patch that contains user-defined central coordinate\ncenter_patch_index = next((index for index, bbox in enumerate(bbox_list) if bboxContains(bbox, center_x, center_y)), None)\n\n# Obtain surrounding patches\npatchIDs = []\nfor idx, [bbox, info] in enumerate(zip(bbox_list, info_list)):\n    if (abs(info['index_x'] - info_list[center_patch_index]['index_x']) <= 1 and\n        abs(info['index_y'] - info_list[center_patch_index]['index_y']) <= 1):\n        patchIDs.append(idx)\n\n# Check if final size is 3x3\nif len(patchIDs) < 9:\n    print('Warning! Use a different central patch ID, this one is on the border.')\n    \n# Change the order of the patches (used for plotting later)\npatchIDs = np.transpose(np.fliplr(np.array(patchIDs).reshape(3, 3))).ravel()\n\n# Prepare info of selected EOPatches\ngeometry = [Polygon(bbox.get_polygon()) for bbox in bbox_list[patchIDs]]\nidxs_x = [info['index_x'] for info in info_list[patchIDs]]\nidxs_y = [info['index_y'] for info in info_list[patchIDs]]\n\ngdf = gpd.GeoDataFrame({'index_x': idxs_x, 'index_y': idxs_y}, \n                       crs={'init': CRS.ogc_string(country_crs)}, \n                       geometry=geometry)\n\n## NOTE: save to shapefile, uncomment if needed\n# shapefile_name = './selected_3x3_bboxes_' + country_name + '_small.shp' if use_smaller_patches \\\n#    else './selected_3x3_bboxes_' + country_name + '_large.shp'\n# gdf.to_file(shapefile_name)\n\n# Visualize the selection\npoly = gdf['geometry'][0]\nx1, y1, x2, y2 = poly.bounds\naspect_ratio = (y1 - y2) / (x1 - x2)\n\nfontdict = {'family': 'monospace', 'weight': 'normal', 'size': 11}\n\n# if bboxes have all same size, estimate offset\nxl, yl, xu, yu = gdf.geometry[0].bounds\nxoff, yoff = (xu - xl) / 3, (yu - yl) / 5\n\n# figure\nfig, ax = plt.subplots(figsize=(20, 20));\ngdf.plot(ax=ax,facecolor='w',edgecolor='r',alpha=0.5);\ncountry.plot(ax=ax, facecolor='w',edgecolor='b',alpha=0.5);\nax.set_title('Selected 3x3 patches within the border');\nplt.axis('off');\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-the-area-of-interest-aoi","position":19},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visualization-of-land-use-reference-data-in-selected-aoi","position":20},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"\n\n# Rearange selected EOPatches into bbox, which can be used for xcube definition\npatches_geometries = [Polygon(bbox.transform(CRS.WGS84).get_polygon()) for bbox in bbox_list[patchIDs]]\nbbox_of_patches = gpd.GeoSeries(cascaded_union(patches_geometries))\n\nx1 = bbox_of_patches.bounds['minx'][0].item()\ny1 = bbox_of_patches.bounds['miny'][0].item()\nx2 = bbox_of_patches.bounds['maxx'][0].item()\ny2 = bbox_of_patches.bounds['maxy'][0].item()\ntotal_bbox_wgs84 = x1, y1, x2, y2\n\n# Rearange selected EOPatches into bbox, which can be used for xcube definition\npatches_geometries = [Polygon(bbox.get_polygon()) for bbox in bbox_list[patchIDs]]\nbbox_of_patches = gpd.GeoSeries(cascaded_union(patches_geometries))\n\nx1 = bbox_of_patches.bounds['minx'][0].item()\ny1 = bbox_of_patches.bounds['miny'][0].item()\nx2 = bbox_of_patches.bounds['maxx'][0].item()\ny2 = bbox_of_patches.bounds['maxy'][0].item()\ntotal_bbox = x1, y1, x2, y2\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visualization-of-land-use-reference-data-in-selected-aoi","position":21},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Land use (reference) data for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#land-use-reference-data-for-selected-aoi","position":22},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Land use (reference) data for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"Land use data are public in Slovenia, you can download the full dataset \n\nhere, selecting the Grafični podatki RABA za celo Slovenijo (shape.rar ~ 500 MB) KoordSistem: D96/TM. The dataset is provided in the national D96/TM coordinate system. It was stored ingeo database. Transformation of reference data to UTM_33N is preformed while reading the data from the database.\n\n# Distinct \"d_update\":\ndistinct_d_update = [    \n    \"2019-09-30\",\n    \"2019-06-30\",\n    \"2019-03-31\",\n    \"2019-01-03\",\n    \"2018-09-30\",\n    \"2018-06-30\",\n    \"2018-03-31\",\n    \"2017-12-31\",\n    \"2017-09-30\",\n    \"2017-06-30\",\n    \"2017-03-31\",\n    \"2016-12-31\",\n    \"2016-09-30\",\n    \"2016-06-30\",\n    \"2016-03-31\",\n    \"2015-12-31\",\n    \"2015-09-30\",\n    \"2015-06-30\",\n    \"2015-03-31\",\n    \"2015-01-13\"\n]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#land-use-reference-data-for-selected-aoi","position":23},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot time series of land use and mapped land use for selected bbox","lvl4":"Land use (reference) data for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-time-series-of-land-use-and-mapped-land-use-for-selected-bbox","position":24},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot time series of land use and mapped land use for selected bbox","lvl4":"Land use (reference) data for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"\n\nselected_timeseries_times = [distinct_d_update[0], distinct_d_update[5], distinct_d_update[8]]\nselected_timeseries_center = (15.5250405633, 46.5505120371) # longitude, latitude\nselected_timeseries_size = 900 # meters\n\ndef displayPlot(title, ax, data, dataColumn, bbox, colorMapping, legendMapping):\n    ax.set_xlim([bbox.min_x, bbox.max_x])\n    ax.set_ylim([bbox.min_y, bbox.max_y])\n\n    # since geopandas does its own normalization, we need to find used values,\n    # to properly map the colors and legend texts to the actual values\n    uniqueVals = data[dataColumn].unique()\n    uniqueVals.sort()\n    cmap = colors.ListedColormap([colorMapping[val] for val in uniqueVals])\n    norm = colors.BoundaryNorm(range(cmap.N), cmap.N)\n    \n    data.plot(ax=ax, column=dataColumn, edgecolor='w', alpha=1, categorical=True, legend=True, cmap=cmap, norm=norm)\n    ax.set_title(title);\n    for text, label in zip(ax.get_legend().get_texts(), [legendMapping[val] for val in uniqueVals]):\n        text.set_text(label)\n\ngeodb = GeoDBClient()\nfrom_wgs84_transformer = pyproj.Transformer.from_crs(str(CRS.WGS84), str(country_crs), always_xy=True)\nx, y = from_wgs84_transformer.transform(selected_timeseries_center[0], selected_timeseries_center[1])\nsize = selected_timeseries_size\nbbox = (x - size * 0.5, y - size * 0.5, x + size * 0.5, y + size * 0.5)\nbbox = BBox(bbox=list(bbox), crs=country_crs)\n\nfor d_update in selected_timeseries_times:\n    # Plot time series of land use for selected bbox\n    land_use = loadFromDatabaseWithLulcMapping(geodb, \"Land use\", db_land_use_table, db_land_use_class_column, \n        None, bbox, bbox.crs, d_update, d_update)\n    \n    fig, axes = plt.subplots(1, 2, figsize=(20, 20))\n\n    displayPlot('Land Use ({})'.format(d_update), axes[0], land_use, 'land_use', bbox, landUseColorMapping, landUseLegendTexts)\n    displayPlot('Mapped land use ({})'.format(d_update), axes[1], land_use, 'lulcid', bbox, lulcColorMapping, lulcLegendTexts)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-time-series-of-land-use-and-mapped-land-use-for-selected-bbox","position":25},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#satellite-imagery-for-selected-aoi","position":26},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#satellite-imagery-for-selected-aoi","position":27},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Configure xcube","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#configure-xcube","position":28},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Configure xcube","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"\n\n## Plot time series of satellite images for bbox\nspatial_res_meters = 10\npixx = (total_bbox[2] - total_bbox[0]) / spatial_res_meters; pixy = (total_bbox[3] - total_bbox[1]) / spatial_res_meters;\nspatial_res = float(np.mean([(total_bbox_wgs84[2] - total_bbox_wgs84[0]) / pixx, (total_bbox_wgs84[3] - total_bbox_wgs84[1]) / pixy]))\n\ncube_config = CubeConfig(dataset_name='S2L1C',\n                         band_names=[\"B02\", \"B03\", \"B04\", \"B08\", \"B11\", \"B12\"],\n                         chunk_size=[512, 512],\n                         geometry=total_bbox_wgs84,\n                         spatial_res=spatial_res,\n                         time_range=['2019-02-01', '2019-09-30'],\n                         time_period='4D')  \n\n# So we can print some SentinelHub usage stats\nrequest_collector = Observers.request_collector()\ncube = open_cube(cube_config, request_collector, client_id=sentinelhub_client_id, client_secret=sentinelhub_client_secret)\n\n# Add Indecies\n## NDVI\nb_red = cube.B04\nb_nir = cube.B08\nndvi = (b_nir - b_red) / (b_nir + b_red)\nndvi.attrs['long_name'] = 'Normalized Difference Vegetation Index'\nndvi.attrs['units'] = 'unitless'\ncube[\"ndvi\"] = ndvi\n\n## NDWI\nb_green = cube.B03\nb_nir = cube.B08\nndwi = (b_green - b_nir) / (b_green + b_nir)\nndwi.attrs['long_name'] = 'Normalized Difference Water Index'\nndwi.attrs['units'] = 'unitless'\ncube[\"ndwi\"] = ndwi\n\n# cube.time\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#configure-xcube","position":29},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot True Color image from selected date","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-true-color-image-from-selected-date","position":30},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot True Color image from selected date","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"\n\n# True color image\nfactor = 2.5\nR = cube.B04.sel(time=selected_patch_displayed_time)*factor\nG = cube.B03.sel(time=selected_patch_displayed_time)*factor\nB = cube.B02.sel(time=selected_patch_displayed_time)*factor\nRGB = np.dstack([R, G, B])\nrgb_array = xr.DataArray(RGB, dims=('lat', 'lon', 'b'), coords=dict(lat=cube.B04.lat, lon=cube.B04.lon))\nimg = rgb_array.plot.imshow(rgb='b', figsize=(16, 16))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-true-color-image-from-selected-date","position":31},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot time series of satellite images for selected band","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-time-series-of-satellite-images-for-selected-band","position":32},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot time series of satellite images for selected band","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"\n\n# Plot time series of band B04\nimg = cube.B04.plot.imshow(col='time', col_wrap=4, vmin=0, vmax=0.2, cmap='Greys_r')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-time-series-of-satellite-images-for-selected-band","position":33},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot time series of NDVI","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-time-series-of-ndvi","position":34},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot time series of NDVI","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"\n\n# Plot time series of NDVI\nimg = cube.ndvi.plot.imshow(col='time', col_wrap=4, vmin=-0.2, vmax=0.8, cmap='YlGn')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-time-series-of-ndvi","position":35},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot all bands and data in xcube for given date","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-all-bands-and-data-in-xcube-for-given-date","position":36},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Plot all bands and data in xcube for given date","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"\n\n# Plot all bands and data in xcube for given date\nfor band in cube.data_vars:\n    cube[band].sel(time=selected_patch_displayed_time).plot.imshow(vmin=0, vmax=0.4, cmap='Greys_r', figsize=(16, 14))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-all-bands-and-data-in-xcube-for-given-date","position":37},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Zoom closer to user defined area (mask xcube)","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"type":"lvl5","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#zoom-closer-to-user-defined-area-mask-xcube","position":38},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl5":"Zoom closer to user defined area (mask xcube)","lvl4":"Satellite imagery for selected AOI","lvl3":"Visualization of land use (reference) data in selected AOI","lvl2":"Part 1: Exploratory Analysis"},"content":"\n\n# Mask original cube with smaller bbox\n#zoomed_center = (15.1645, 46.2495) # (13.860377, 46.283196) # longitude, latitude\nzoomed_center = (0.5 * (total_bbox_wgs84[0] + total_bbox_wgs84[2]), 0.5 * (total_bbox_wgs84[1] + total_bbox_wgs84[3]))\nzoomed_size = 0.25 # ratio to the original 3x3 patches cube\n\nzoomed_size_degrees = zoomed_size\nselected_bbox = (\n    zoomed_center[0] - zoomed_size * 0.5 * (total_bbox_wgs84[2] - total_bbox_wgs84[0]), \n    zoomed_center[1] - zoomed_size * 0.5 * (total_bbox_wgs84[3] - total_bbox_wgs84[1]),\n    zoomed_center[0] + zoomed_size * 0.5 * (total_bbox_wgs84[2] - total_bbox_wgs84[0]), \n    zoomed_center[1] + zoomed_size * 0.5 * (total_bbox_wgs84[3] - total_bbox_wgs84[1])\n)\nsmall_cube = xcube.core.geom.mask_dataset_by_geometry(cube, selected_bbox, no_clip=False, save_geometry_wkt=True)\n\n# True color\nfactor = 2.5\nR = small_cube.B04.sel(time=selected_patch_displayed_time)*factor\nG = small_cube.B03.sel(time=selected_patch_displayed_time)*factor\nB = small_cube.B02.sel(time=selected_patch_displayed_time)*factor\nRGB = np.dstack([R, G, B])\nrgb_array = xr.DataArray(RGB, dims=('lat', 'lon', 'b'), coords=dict(lat=small_cube.B04.lat, lon=small_cube.B04.lon))\nimg = rgb_array.plot.imshow(rgb='b', figsize=(16, 16))\n\n# Plot all bands for selected time\nfor band in small_cube.data_vars:\n    small_cube[band].sel(time=selected_patch_displayed_time).plot.imshow(vmin=0, vmax=0.4, cmap='Greys_r', figsize=(16, 14))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#zoom-closer-to-user-defined-area-mask-xcube","position":39},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#part-2-lulc-prediction-with-machine-learning","position":40},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#part-2-lulc-prediction-with-machine-learning","position":41},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Set some of the inputs for prediction with ML","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#set-some-of-the-inputs-for-prediction-with-ml","position":42},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Set some of the inputs for prediction with ML","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\nselected_db_land_use_date = '2019-09-30'\nselected_date_interval_for_satellite_imagery = ['2019-01-01', '2019-09-19']\nselected_max_cc = 0.8\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#set-some-of-the-inputs-for-prediction-with-ml","position":43},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#fill-eopatches-with-data","position":44},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"Now it’s time to create EOPatches and fill them with Sentinel-2 data using Sentinel Hub services. We will add the following data to each EOPatch:\n\nL1C custom list of bands [B02, B03, B04, B08, B11, B12], which corresponds to [B, G, R, NIR, SWIR1, SWIR2] wavelengths.\n\nSentinelHub’s cloud probability map and cloud mask\n\nAdditionally, we will add:\n\nCalculated NDVI, NDWI, euclidean NORM information\n\nA mask of validity, based on acquired data from Sentinel and cloud coverage. Valid pixel is if:\n\nIS_DATA == True\n\nCLOUD_MASK == 0 (1 indicates that pixel was identified to be covered with cloud)\n\nAn EOPatch is created and manipulated using EOTasks, which are chained in an EOWorkflow. In this example the final workflow is executed on all patches, which are saved to the specified directory.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#fill-eopatches-with-data","position":45},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Define some needed custom EOTasks","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-some-needed-custom-eotasks","position":46},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Define some needed custom EOTasks","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\nclass SentinelHubValidData:\n    \"\"\"\n    Combine Sen2Cor's classification map with `IS_DATA` to define a `VALID_DATA_SH` mask\n    The SentinelHub's cloud mask is asumed to be found in eopatch.mask['CLM']\n    \"\"\"\n    def __call__(self, eopatch):        \n        return np.logical_and(eopatch.mask['IS_DATA'].astype(np.bool), \n                              np.logical_not(eopatch.mask['CLM'].astype(np.bool)))\n    \nclass CountValid(EOTask):   \n    \"\"\"\n    The task counts number of valid observations in time-series and stores the results in the timeless mask.\n    \"\"\"\n    def __init__(self, count_what, feature_name):\n        self.what = count_what\n        self.name = feature_name\n        \n    def execute(self, eopatch):\n        eopatch.add_feature(FeatureType.MASK_TIMELESS, self.name, np.count_nonzero(eopatch.mask[self.what],axis=0))\n        \n        return eopatch\n\n\nclass NormalizedDifferenceIndex(EOTask):   \n    \"\"\"\n    The tasks calculates user defined Normalised Difference Index (NDI) between two bands A and B as:\n    NDI = (A-B)/(A+B).\n    \"\"\"\n    def __init__(self, feature_name, band_a, band_b):\n        self.feature_name = feature_name\n        self.band_a_fetaure_name = band_a.split('/')[0]\n        self.band_b_fetaure_name = band_b.split('/')[0]\n        self.band_a_fetaure_idx = int(band_a.split('/')[-1])\n        self.band_b_fetaure_idx = int(band_b.split('/')[-1])\n        \n    def execute(self, eopatch):\n        band_a = eopatch.data[self.band_a_fetaure_name][..., self.band_a_fetaure_idx]\n        band_b = eopatch.data[self.band_b_fetaure_name][..., self.band_b_fetaure_idx]\n        \n        ndi = (band_a - band_b) / (band_a  + band_b)\n        \n        eopatch.add_feature(FeatureType.DATA, self.feature_name, ndi[..., np.newaxis])\n        \n        return eopatch\n\n    \nclass EuclideanNorm(EOTask):   \n    \"\"\"\n    The tasks calculates Euclidian Norm of all bands within an array:\n    norm = sqrt(sum_i Bi**2),\n    where Bi are the individual bands within user-specified feature array.\n    \"\"\"\n    def __init__(self, feature_name, in_feature_name):\n        self.feature_name = feature_name\n        self.in_feature_name = in_feature_name\n    \n    def execute(self, eopatch):\n        arr = eopatch.data[self.in_feature_name]\n        norm = np.sqrt(np.sum(arr**2, axis=-1))\n        \n        eopatch.add_feature(FeatureType.DATA, self.feature_name, norm[..., np.newaxis])\n        return eopatch\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-some-needed-custom-eotasks","position":47},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Define the workflow tasks","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-the-workflow-tasks","position":48},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Define the workflow tasks","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\n# TASK FOR BAND DATA\n# add a request for B(B02), G(B03), R(B04), NIR (B08), SWIR1(B11), SWIR2(B12) \n# from default layer 'ALL_BANDS' at 10m resolution\n# Here we also do a simple filter of cloudy scenes. A detailed cloud cover \n# detection is performed in the next step\ncustom_script = 'return [B02, B03, B04, B08, B11, B12];'\nadd_data = S2L1CWCSInput(\n    layer='BANDS-S2-L1C', \n    feature=(FeatureType.DATA, 'BANDS'), # save under name 'BANDS'\n    custom_url_params={CustomUrlParam.EVALSCRIPT: custom_script}, # custom url for 6 specific bands\n    resx='10m', # resolution x\n    resy='10m', # resolution y\n    maxcc=selected_max_cc # maximum allowed cloud cover of original ESA tiles\n)\n\n# TASK FOR CLOUD INFO\n# cloud detection is performed at 80m resolution \n# and the resulting cloud probability map and mask \n# are scaled to EOPatch's resolution\ncloud_classifier = get_s2_pixel_cloud_detector(average_over=2, dilation_size=1, all_bands=False)\nadd_clm = AddCloudMaskTask(cloud_classifier, 'BANDS-S2CLOUDLESS', cm_size_y='80m', cm_size_x='80m', \n                           cmask_feature='CLM', # cloud mask name\n                           cprobs_feature='CLP' # cloud prob. map name\n                          )\n\n# TASKS FOR CALCULATING NEW FEATURES\n# NDVI: (B08 - B04)/(B08 + B04)\n# NDWI: (B03 - B08)/(B03 + B08)\n# NORM: sqrt(B02^2 + B03^2 + B04^2 + B08^2 + B11^2 + B12^2)\nndvi = NormalizedDifferenceIndex('NDVI', 'BANDS/3', 'BANDS/2')\nndwi = NormalizedDifferenceIndex('NDWI', 'BANDS/1', 'BANDS/3')\nnorm = EuclideanNorm('NORM','BANDS')\n\n# TASK FOR VALID MASK\n# validate pixels using SentinelHub's cloud detection mask and region of acquisition \nadd_sh_valmask = AddValidDataMaskTask(SentinelHubValidData(), \n                                      'IS_VALID' # name of output mask\n                                     )\n\n# TASK FOR COUNTING VALID PIXELS\n# count number of valid observations per pixel using valid data mask \ncount_val_sh = CountValid('IS_VALID', # name of existing mask\n                          'VALID_COUNT' # name of output scalar\n                         )\n\n# TASK FOR SAVING TO OUTPUT (if needed)\npath_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\nif not os.path.isdir(path_out):\n    os.makedirs(path_out)\nsave = SaveTask(path_out, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-the-workflow-tasks","position":49},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Reference map task","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#reference-map-task","position":50},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Reference map task","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"For this example, a subset of the country-wide reference for land-use-land-cover is provided. It is available in the form of a shapefile, which contains polygons and their corresponding labels. The labels represent the 10 classes from the lulcMapping.\n\nThe main point of this task is to create a raster mask from the vector polygons and add it to the eopatch. With this procedure, any kind of a labeled shapefile can be transformed into a raster reference map. This result is achieved with the existing task VectorToRaster from the eolearn.geometry package. All polygons belonging to the each of the classes are separately burned to the raster mask.\n\nclass LoadFromDatabaseTask(EOTask):\n    def __init__(self, feature, taskName, crs, tableName, landUseColumneName, \n        dateFilterMin, dateFilterMax, mappedColumnName = None, mappingLambdaFunc = None):\n        \n        self.feature_type, self.feature_name = next(self._parse_features(feature)())\n        self.taskName = taskName\n        self.crs = crs\n        self.tableName = tableName\n        self.landUseColumneName = landUseColumneName\n        self.dateFilterMin = dateFilterMin\n        self.dateFilterMax = dateFilterMax\n        self.mappedColumnName = mappedColumnName\n        self.mappingLambdaFunc = mappingLambdaFunc\n\n    def execute(self, eopatch, geodb):\n        eopatch[self.feature_type][self.feature_name] = loadFromDatabase(geodb, \n            self.taskName, self.tableName, self.landUseColumneName, None, eopatch.bbox, eopatch.bbox.crs,\n            self.dateFilterMin, self.dateFilterMax, None, True,\n            self.mappedColumnName, self.mappingLambdaFunc)\n        return eopatch\n    \n\n# LPIS\nload_lpis_db_task = LoadFromDatabaseTask((FeatureType.VECTOR_TIMELESS, 'LPIS_GDF'), \n    \"LPIS\", country_crs, db_lpis_table, db_lpis_class_column, selected_db_land_use_date, selected_db_land_use_date)\n\nlpis_rasterization_task = VectorToRaster((FeatureType.VECTOR_TIMELESS, 'LPIS_GDF'), (FeatureType.MASK_TIMELESS, 'LPIS'),\n    values_column='land_use', raster_shape=None, raster_resolution = 10,\n    raster_dtype=np.uint16)\n\nlpis_export_tiff = ExportToTiff((FeatureType.MASK_TIMELESS, 'LPIS'))\n\n\n# Land use\nload_land_use_db_task = LoadFromDatabaseTask((FeatureType.VECTOR_TIMELESS, 'LAND_USE_GDF'), \n    \"Land use\", country_crs, db_land_use_table, db_land_use_class_column, selected_db_land_use_date, selected_db_land_use_date, \n    \"lulcid\", lambda lulc: landUseToLulcMapping[lulc] if lulc in landUseToLulcMapping else 0)\n\nland_use_rasterization_task = VectorToRaster((FeatureType.VECTOR_TIMELESS, 'LAND_USE_GDF'), (FeatureType.MASK_TIMELESS, 'LAND_USE'),\n    values_column='land_use', raster_shape=None, raster_resolution = 10,\n    raster_dtype=np.uint16)\n\nland_use_export_tiff = ExportToTiff((FeatureType.MASK_TIMELESS, 'LAND_USE'))\n\n\n# LULC, uses the previously loaded LAND_USE_GDF\nlulc_rasterization_task = VectorToRaster((FeatureType.VECTOR_TIMELESS, 'LAND_USE_GDF'), (FeatureType.MASK_TIMELESS, 'LULC'),\n    values_column='lulcid', raster_shape=(FeatureType.MASK, 'IS_VALID'),\n    raster_dtype=np.uint8)\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#reference-map-task","position":51},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Define the workflow","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-the-workflow","position":52},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Define the workflow","lvl3":"Fill EOPatches with data:","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"All the tasks that were defined so far create and fill the EOPatches. The tasks need to be put in some order and executed one by one. This can be achieved by manually executing the tasks, or more conveniently, defining an EOWorkflow which does this for you.\n\nThe following workflow is created and executed:\n\nCreate EOPatches with band data\n\nAdd cloud info\n\nCalculate and add NDVI, NDWI, NORM\n\nAdd mask of valid pixels\n\nAdd scalar feature representing the cound of valid pixels\n\nSave eopatches\n\nAn EOWorkflow can be linear or more complex, but it should be acyclic. Here we will use the linear case of the EOWorkflow, available as LinearWorkflow\n\nDefine the workflow\n\n# Define the workflow\nworkflow = LinearWorkflow(\n    add_data,\n    add_clm,\n    ndvi,\n    ndwi,\n    norm,\n    add_sh_valmask,\n    count_val_sh,\n    load_lpis_db_task,\n    lpis_rasterization_task,\n    lpis_export_tiff,\n    load_land_use_db_task,\n    land_use_rasterization_task,\n    land_use_export_tiff,\n    lulc_rasterization_task,\n    save\n)\n\n# Let's visualize it\nworkflow.dependency_graph()\n\nThis may take some time, so go grab a cup of coffee ...\n\n%%time\n\n# Execute the workflow\n\nsource_tiff_location = './source_tiff'\nif not os.path.isdir(source_tiff_location):\n    os.makedirs(source_tiff_location)\n\n# define additional parameters of the workflow\ngeodb = GeoDBClient()\nexecution_args = []\nfor idx, bbox in enumerate(bbox_list[patchIDs]):\n    execution_args.append({\n        add_data: {'bbox': bbox, 'time_interval': selected_date_interval_for_satellite_imagery},\n        load_land_use_db_task: {'geodb': geodb},\n        load_lpis_db_task: {'geodb': geodb},\n        lpis_export_tiff: {'filename': '{}/lpis_eopatch_{}_original.tiff'.format(source_tiff_location, idx)},\n        land_use_export_tiff: {'filename': '{}/land_use_eopatch_{}_original.tiff'.format(source_tiff_location, idx)},\n        save: {'eopatch_folder': 'eopatch_{}'.format(idx)}\n    })\n    \nglobalLogger.setLevel(logging.CRITICAL)\n\nexecutor = EOExecutor(workflow, execution_args, save_logs=True)\nexecutor.run(workers=1, multiprocess=False)\n\nexecutor.make_report()\n\nIn this case, all patches come from a small region, so all of them have the same dates of acquisition for at least a few dates, so we can inspect the area without interpolation at this point.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-the-workflow","position":53},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visualize the true color image","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visualize-the-true-color-image","position":54},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visualize the true color image","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\nselected_timestamp = datetime.datetime.strptime('2019-05-01', \"%Y-%m-%d\") # or None\n\n# Draw the RGB image\npath_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\nfig = plt.figure(figsize=(20, 20 * aspect_ratio))\n\npbar = tqdm(total=9)\nfor i in range(9):\n    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n    timeIndex = next(i for i, time in enumerate(eopatch.timestamp) if time.date() == selected_timestamp.date()) if not selected_timestamp is None else None\n    if timeIndex is None:\n        timeIndex = 0\n        \n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(np.clip(eopatch.data['BANDS'][timeIndex][..., [2, 1, 0]] * 3.5, 0, 1))\n    plt.xticks([])\n    plt.yticks([])\n    ax.set_aspect(\"auto\")\n    pbar.update(1)\n    del eopatch\n\nfig.subplots_adjust(wspace=0, hspace=0)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visualize-the-true-color-image","position":55},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visualize the reference map","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visualize-the-reference-map","position":56},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visualize the reference map","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\npath_out = './eopatches_small/' if use_smaller_patches else './eopatches_large/'\nfig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n\ncmapValues = [color for id, color in lulcColorMapping.items()]\nnormValues = list(lulcColorMapping.keys())\nnormValues.append(20)\ncmap = colors.ListedColormap(cmapValues)\nnorm = colors.BoundaryNorm(normValues, cmap.N + 1)\n    \npbar = tqdm(total=9)\nfor i, ax in enumerate(axes.flat):\n    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out, i), lazy_loading=True)\n    im = ax.imshow(eopatch.mask_timeless['LULC'].squeeze(), cmap=cmap, norm=norm)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_aspect(\"auto\")\n    pbar.update(1)\n    del eopatch\n\nfig.subplots_adjust(wspace=0, hspace=0)\n\ncb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\ncb.ax.tick_params(labelsize=20) \ncb.set_ticks([id for id in lulcMapping.keys()])\ncb.ax.set_xticklabels([entry[\"name\"] for entry in lulcMapping.values()], rotation=45, fontsize=15)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visualize-the-reference-map","position":57},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Prepare the training data","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#prepare-the-training-data","position":58},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Prepare the training data","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"We will create a new workflow that processes the data:\n\nRemove too cloudy scenes\n\nCheck the ratio of the valid data for each patch and for each time frame\n\nKeep only time frames with > 80 % valid coverage (no clouds)\n\nConcatenate BAND, NDVI, NDWI, NORM info into a single feature called FEATURES\n\nPerform temporal interpolation (filling gaps and resampling to the same dates)\n\nCreate a task for linear interpolation in the temporal dimension\n\nProvide the cloud mask to tell the interpolating function which values to update\n\nPerform erosion\n\nThis removes artefacts with a width of 1 px, and also removes the edges between polygons of different classes\n\nRandom spatial sampling of the EOPatches\n\nRandomly take a subset of pixels from a patch to use in the machine learning training\n\nSplit patches for training/validation\n\nSplit the patches into a training and validation set\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#prepare-the-training-data","position":59},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Define EOTasks","lvl3":"Prepare the training data","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-eotasks","position":60},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Define EOTasks","lvl3":"Prepare the training data","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\nclass ConcatenateData(EOTask):\n    \"\"\" Task to concatenate data arrays along the last dimension\n    \"\"\"\n    def __init__(self, feature_name, feature_names_to_concatenate):\n        self.feature_name = feature_name\n        self.feature_names_to_concatenate = feature_names_to_concatenate\n\n    def execute(self, eopatch):\n        arrays = [eopatch.data[name] for name in self.feature_names_to_concatenate]\n\n        eopatch.add_feature(FeatureType.DATA, self.feature_name, np.concatenate(arrays, axis=-1))\n\n        return eopatch\n    \n    \nclass ValidDataFractionPredicate:\n    \"\"\" Predicate that defines if a frame from EOPatch's time-series is valid or not. Frame is valid, if the \n    valid data fraction is above the specified threshold.\n    \"\"\"\n    def __init__(self, threshold):\n        self.threshold = threshold\n        \n    def __call__(self, array):\n        coverage = np.sum(array.astype(np.uint8)) / np.prod(array.shape)\n        return coverage > self.threshold\n    \n# TASK TO LOAD EXISTING EOPATCHES\nload = LoadTask(path_out)\n\n# TASK FOR CONCATENATION\nconcatenate = ConcatenateData('FEATURES', ['BANDS', 'NDVI', 'NDWI', 'NORM'])\n\n# TASK FOR FILTERING OUT TOO CLOUDY SCENES\n# keep frames with > 80 % valid coverage\nvalid_data_predicate = ValidDataFractionPredicate(0.8)\nfilter_task = SimpleFilterTask((FeatureType.MASK, 'IS_VALID'), valid_data_predicate)\n\n# TASK FOR LINEAR INTERPOLATION\n# linear interpolation of full time-series and date resampling\nrangeParams = selected_date_interval_for_satellite_imagery.copy()\nrangeParams.append(16) # step of 16 days between key values\nresampled_range = tuple(rangeParams)\nlinear_interp = LinearInterpolation(\n    'FEATURES', # name of field to interpolate\n    mask_feature=(FeatureType.MASK, 'IS_VALID'), # mask to be used in interpolation\n    copy_features=[(FeatureType.MASK_TIMELESS, 'LULC')], # features to keep\n    resample_range=resampled_range, # set the resampling range\n    bounds_error=False # extrapolate with NaN's\n)\n\n# TASK FOR EROSION\n# erode each class of the reference map\nerosion = ErosionTask(mask_feature=(FeatureType.MASK_TIMELESS,'LULC','LULC_ERODED'), disk_radius=1)\n\n# TASK FOR SPATIAL SAMPLING\n# Uniformly sample about pixels from patches\nn_samples = int(4e4) if use_smaller_patches else int(1e5) # no. of pixels to sample\nref_labels = list(range(11)) # reference labels to take into account when sampling\nspatial_sampling = PointSamplingTask(\n    n_samples=n_samples, \n    ref_mask_feature='LULC_ERODED', \n    ref_labels=ref_labels, \n    sample_features=[  # tag fields to sample\n        (FeatureType.DATA, 'FEATURES'),\n        (FeatureType.MASK_TIMELESS, 'LULC_ERODED')\n    ])\n\npath_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\nif not os.path.isdir(path_out_sampled):\n    os.makedirs(path_out_sampled)\nsave = SaveTask(path_out_sampled, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n\n# Define the workflow\nworkflow = LinearWorkflow(\n    load,\n    concatenate,\n    filter_task,\n    linear_interp,\n    erosion,\n    spatial_sampling,\n    save\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#define-eotasks","position":61},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Run the EOWorkflow over all EOPatches","lvl3":"Prepare the training data","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#run-the-eoworkflow-over-all-eopatches","position":62},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Run the EOWorkflow over all EOPatches","lvl3":"Prepare the training data","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\n%%time\n   \nexecution_args = []\nfor idx in range(len(patchIDs)):\n    execution_args.append({\n        load: {'eopatch_folder': 'eopatch_{}'.format(idx)},\n        save: {'eopatch_folder': 'eopatch_{}'.format(idx)}\n    })\n    \nexecutor = EOExecutor(workflow, execution_args, save_logs=True)\n\nexecutor.run(workers=1, multiprocess=True)\n\nexecutor.make_report()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#run-the-eoworkflow-over-all-eopatches","position":63},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Model construction and training","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#model-construction-and-training","position":64},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Model construction and training","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"The patches are split into a train and test subset, where we take the patch with ID = 1 for testing, since it seems a good representative of the area.\n\nThe test sample is hand picked because of the small set of patches, otherwise with a larged overall set, the training and testing patches should be randomly chosen.\n\nThe sampled features and labels are loaded and reshaped into n \\times m, where n represents the number of training pixels, and m = f \\times t the number of all features (in this example 207), with f the size of bands and band combinations (in this example 9) and t the length of the resampled time-series (in this example 23)\n\nLightGBM is used as a ML model. It is a fast, distributed, high performance gradient boosting framework based on decision tree algorithms, used for many machine learning tasks.\n\nThe default hyper-parameters are used in this example. For more info on parameter tuning, check the \n\nReadTheDocs of the package.\n\n# load sampled eopatches\neopatches = []\npath_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n\nfor i in range(9):\n    eopatches.append(EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True))    \n\neopatches = np.array(eopatches)\n\n# Definition of the train and test patch IDs\ntrain_ID = [0,2,3,4,5,6,7,8] if use_smaller_patches else [0,1,3,4,5,6,7,8]\ntest_ID = [1] if use_smaller_patches else [2]\n\n# Set the features and the labels for train and test sets\nfeatures_train = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[train_ID]])\nlabels_train = np.array([eopatch.mask_timeless['LULC_ERODED_SAMPLED'] for eopatch in eopatches[train_ID]])\nfeatures_test = np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[test_ID]])\nlabels_test = np.array([eopatch.mask_timeless['LULC_ERODED_SAMPLED'] for eopatch in eopatches[test_ID]])\n\n# get shape\np1, t, w, h, f = features_train.shape\np2, t, w, h, f = features_test.shape\np = p1 + p2\n\n# reshape to n x m\nfeatures_train = np.moveaxis(features_train, 1, 3).reshape(p1 * w * h, t * f)\nlabels_train = np.moveaxis(labels_train, 1, 2).reshape(p1 * w * h, 1).squeeze()\nfeatures_test = np.moveaxis(features_test, 1, 3).reshape(p2 * w * h, t * f)\nlabels_test = np.moveaxis(labels_test, 1, 2).reshape(p2 * w * h, 1).squeeze()\n\n# remove points with no reference from training (so we dont train to recognize \"no data\")\nmask_train = labels_train == 0\nfeatures_train = features_train[~mask_train]\nlabels_train = labels_train[~mask_train]\n\n# remove points with no reference from test (so we dont validate on \"no data\", which doesn't make sense)\nmask_test = labels_test == 0\nfeatures_test = features_test[~mask_test]\nlabels_test = labels_test[~mask_test]\n\n%%time\n\n# Set up training classes\nlabels_unique = np.unique(labels_train)\n\n# Set up the model\nmodel = lgb.LGBMClassifier(\n    objective='multiclass', \n    num_class=len(labels_unique), \n    metric='multi_logloss'\n)\n\n# train the model\nmodel.fit(features_train, labels_train)\n\n# uncomment to save the model\nmodel_base_name = 'model_SI_LULC_smaller' if use_smaller_patches else 'model_SI_LULC_larger'\njoblib.dump(model, './{}.pkl'.format(model_base_name))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#model-construction-and-training","position":65},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Validation","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#validation","position":66},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Validation","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\nValidation of the model is a crucial step in data science. All models are wrong, but some are less wrong than others, so model evaluation is important.\n\nIn order to validate the model, we use the training set to predict the classes, and then compare the predicted set of labels to the “ground truth”.\n\nUnfortunately, ground truth in the scope of EO is a term that should be taken lightly. Usually, it is not 100 % reliable due to several reasons:\n\nLabels are determined at specific time, but land use can change (what was once a field, may now be a house)\n\nLabels are overly generalized (a city is an artificial surface, but it also contains parks, forests etc.)\n\nSome classes can have an overlap or similar definitions (part of a continuum, and not discrete distributions)\n\nHuman error (mistakes made when producing the reference map)\n\nThe validation is performed by evaluating various metrics, such as accuracy, precision, recall, F_1 score, some of which are nicely described \n\nin this blog post\n\n# uncomment to load the model and replace with your file, usually just correct the date\nmodel_path = './model_SI_LULC_smaller.pkl' if use_smaller_patches else './model_SI_LULC_larger.pkl'\nmodel = joblib.load(model_path)\n\n# predict the test labels\nplabels_test = model.predict(features_test)\n\nGet the overall accuracy (OA) and the weighted F_1 score\n\nprint('Classification accuracy {:.1f}%'.format(100 * metrics.accuracy_score(labels_test, plabels_test)))\nprint('Classification F1-score {:.1f}%'.format(100 * metrics.f1_score(labels_test, plabels_test, average='weighted')))\n\nF_1 score, precision, and recall for each class separately\n\nclass_labels_test = set(np.unique(labels_test))\nclass_labels_train = set(np.unique(labels_train))\nclass_labels = list(class_labels_test.union(class_labels_train))\nclass_names = [entry[\"name\"] for entry in lulcMapping.values()]\n\nf1_scores = metrics.f1_score(labels_test, plabels_test, labels=class_labels, average=None)\nrecall = metrics.recall_score(labels_test, plabels_test, labels=class_labels, average=None)\nprecision = metrics.precision_score(labels_test, plabels_test, labels=class_labels, average=None) \n\nprint('             Class              =  F1  | Recall | Precision')\nprint('         --------------------------------------------------')\nfor idx, lulctype in enumerate([class_names[idx] for idx in class_labels]):\n    print('         * {0:20s} = {1:2.1f} |  {2:2.1f}  | {3:2.1f}'.format(lulctype, \n                                                                         f1_scores[idx] * 100, \n                                                                         recall[idx] * 100, \n                                                                         precision[idx] * 100))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#validation","position":67},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Plot the standard and transposed Confusion Matrix","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-the-standard-and-transposed-confusion-matrix","position":68},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Plot the standard and transposed Confusion Matrix","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\n# Define the plotting function\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues, ylabel='True label', xlabel='Predicted label', filename=None):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    np.set_printoptions(precision=2, suppress=True)\n    \n    if normalize:\n        cm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + np.finfo(np.float).eps)\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap, vmin=0, vmax=1)\n    plt.title(title, fontsize=20)\n    # plt.colorbar()\n    tick_marks = np.arange(len(classes)+1)-0.5\n    plt.xticks(tick_marks, classes, rotation=45, fontsize=20)\n    plt.yticks(tick_marks, classes, fontsize=20)\n    \n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\",\n                 fontsize=12)\n\n    plt.tight_layout()\n    plt.ylabel(ylabel, fontsize=20)\n    plt.xlabel(xlabel, fontsize=20)\n\nfig = plt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 1)\nconf_matrix_gbm = metrics.confusion_matrix(labels_test, plabels_test)\nplot_confusion_matrix(conf_matrix_gbm, \n                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n                      normalize=True, \n                      ylabel='Truth (LAND COVER)', \n                      xlabel='Predicted (GBM)',\n                      title='Confusion matrix');\n\nplt.subplot(1, 2, 2)\nconf_matrix_gbm = metrics.confusion_matrix(plabels_test, labels_test)\nplot_confusion_matrix(conf_matrix_gbm, \n                      classes=[name for idx, name in enumerate(class_names) if idx in class_labels], \n                      normalize=True, \n                      xlabel='Truth (LAND COVER)', \n                      ylabel='Predicted (GBM)',\n                      title='Transposed Confusion matrix');\n\nplt.tight_layout()\n\nfig = plt.figure(figsize=(20, 5))\n\nlabel_ids, label_counts = np.unique(labels_train, return_counts=True)\n\nplt.bar(range(len(label_ids)), label_counts/100)\nplt.xticks(range(len(label_ids)), [class_names[i] for i in label_ids], rotation=45, fontsize=20);\nplt.yticks(fontsize=20);\nplt.ylabel(\"Area [ha] \", size=18)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#plot-the-standard-and-transposed-confusion-matrix","position":69},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Predict LULC","lvl2":"Part 2: LULC prediction with Machine Learning"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#predict-lulc","position":70},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Predict LULC","lvl2":"Part 2: LULC prediction with Machine Learning"},"content":"\n\nclass PredictPatch(EOTask):\n    \"\"\"\n    Task to make model predictions on a patch. Provide the model and the feature, \n    and the output names of labels and scores (optional)\n    \"\"\"\n    def __init__(self, model, features_feature, predicted_labels_name, predicted_scores_name=None):\n        self.model = model\n        self.features_feature = features_feature\n        self.predicted_labels_name = predicted_labels_name\n        self.predicted_scores_name = predicted_scores_name\n        \n    def execute(self, eopatch):\n        ftrs = eopatch[self.features_feature[0]][self.features_feature[1]]\n        \n        t, w, h, f = ftrs.shape\n        ftrs = np.moveaxis(ftrs, 0, 2).reshape(w * h, t * f)\n        \n        plabels = self.model.predict(ftrs)\n        plabels = plabels.reshape(w, h)\n        plabels = plabels[..., np.newaxis]\n        eopatch.add_feature(FeatureType.MASK_TIMELESS, self.predicted_labels_name, plabels)\n        \n        if self.predicted_scores_name:\n            pscores = self.model.predict_proba(ftrs)\n            _, d = pscores.shape\n            pscores = pscores.reshape(w, h, d)\n            eopatch.add_feature(FeatureType.DATA_TIMELESS, self.predicted_scores_name, pscores)\n        \n        return eopatch\n\nclass ConvertToCOGTiff(EOTask):\n    def execute(self, eopatch, src_filename, dest_filename):\n        subprocess.run(\"gdaladdo -r average --config GDAL_TIFF_OVR_BLOCKSIZE 1024 \" + src_filename + \" 2 4 8 16 32\", shell=True, check=True)\n        subprocess.run(\"gdal_translate -co TILED=YES -co COPY_SRC_OVERVIEWS=YES -co BLOCKXSIZE=1024 -co BLOCKYSIZE=1024 -co COMPRESS=DEFLATE --config GDAL_TIFF_OVR_BLOCKSIZE 1024 \" + src_filename + \" \" + dest_filename, shell=True, check=True)\n        return eopatch\n\n\nclass UploadAmazonS3File(EOTask):\n    def __init__(self, bucket, s3_client = None, aws_access_key_id = None, aws_secret_access_key = None):\n        if not s3_client is None:\n            self.s3_client = s3_client\n        elif not aws_access_key_id is None and not aws_secret_access_key is None:\n            self.s3_client = UploadAmazonS3File.createClient(aws_access_key_id, aws_secret_access_key)\n        else:\n            raise ValueError(\"Either s3_client must be defined, or both aws_access_key_id and aws_secret_access_key\")\n        self.bucket = bucket\n    \n    def execute(self, eopatch, src_filename, dest_filename):\n        with open(src_filename, \"rb\") as f:\n            self.s3_client.upload_fileobj(f, self.bucket, dest_filename)\n        return eopatch\n    \n    def createClient(aws_access_key_id, aws_secret_access_key):\n        return boto3.client('s3',\n            aws_access_key_id = aws_access_key_id, aws_secret_access_key = aws_secret_access_key)\n\nclass CreateSHCollectionFromS3(EOTask):\n    def __init__(self, sh_oauth_session, s3_bucket, collection_id):\n        self.sh_client = SentinelHubClient(sh_oauth_session, s3_bucket)\n        self.s3_bucket = s3_bucket\n        self.collection_id = collection_id\n        \n    def execute(self, eopatch, s3_file_path):\n        tile_id = self.sh_client.getTileByPath(self.collection_id, s3_file_path)\n        if not tile_id is None:\n            self.sh_client.deleteTile(self.collection_id, tile_id)\n        \n        self.sh_client.ingestTile(self.collection_id, s3_file_path, eopatch.bbox)\n        \n        return eopatch\n\n# TASK TO LOAD EXISTING EOPATCHES\nload = LoadTask(path_out_sampled)\n\n# TASK FOR PREDICTION\npredict = PredictPatch(model, (FeatureType.DATA, 'FEATURES'), 'LBL_GBM', 'SCR_GBM')\n\n# TASK FOR SAVING\nsave = SaveTask(str(path_out_sampled), overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n\n# TASK TO EXPORT TIFF\nexport_tiff = ExportToTiff((FeatureType.MASK_TIMELESS, 'LBL_GBM'))\n\n# Convert generated TIFF to COG\nconvert_prediction_to_cog_tiff = ConvertToCOGTiff()\nconvert_land_use_to_cog_tiff = ConvertToCOGTiff()\nconvert_lpis_to_cog_tiff = ConvertToCOGTiff()\n\n# Upload to Amazon S3\ns3_upload_prediction = UploadAmazonS3File(aws_s3_bucket, None, aws_access_key_id, aws_secret_access_key)\ns3_upload_land_use = UploadAmazonS3File(aws_s3_bucket, None, aws_access_key_id, aws_secret_access_key)\ns3_upload_lpis = UploadAmazonS3File(aws_s3_bucket, None, aws_access_key_id, aws_secret_access_key)\n\n\n# Ingest in SentinelHub\nsh_oauth_session = OAuth2Session(client = BackendApplicationClient(client_id = sentinelhub_client_id))\nsh_oauth_token = sh_oauth_session.fetch_token(token_url = sentinelhub_url + '/oauth/token',\n    client_id = sentinelhub_client_id, client_secret = sentinelhub_client_secret)\n\nsh_client = SentinelHubClient(sh_oauth_session, aws_s3_bucket)\n\nsentinelhub_collection_id = sh_client.getCollectionByName(sentinelhub_collection_name)\nif sentinelhub_collection_id is None:\n    sentinelhub_collection_id = sh_client.createCollection(sentinelhub_collection_name)\n\nprint(\"SH collection ID:\", sentinelhub_collection_id)\n\nsh_create_collection = CreateSHCollectionFromS3(sh_oauth_session, aws_s3_bucket, sentinelhub_collection_id)\n\n\nworkflow = LinearWorkflow(\n    load,\n    predict,\n    export_tiff,\n    convert_prediction_to_cog_tiff,\n    convert_land_use_to_cog_tiff,\n    convert_lpis_to_cog_tiff,\n    s3_upload_prediction,\n    s3_upload_land_use,\n    s3_upload_lpis,\n    sh_create_collection,\n    save\n)\n\npredicted_tiff_location = './predicted_tiff'\nif not os.path.isdir(predicted_tiff_location):\n    os.makedirs(predicted_tiff_location)\n    \nsource_tiff_location = './source_tiff'\n\n# create a list of execution arguments for each patch\nexecution_args = []\nfor i in range(len(patchIDs)):\n    bbox = bbox_list[i]\n    eopath_subfolder_name = \"{0:.0f}_{1:.0f}_{2:.0f}_{3:.0f}__epsg{crs}\".format(\n        bbox.min_x, bbox.min_y, bbox.max_x, bbox.max_y, crs = bbox.crs.value)\n    \n    execution_args.append(\n        {\n            load: {'eopatch_folder': 'eopatch_{}'.format(i)},\n            export_tiff: {'filename': '{}/prediction_eopatch_{}_original.tiff'.format(predicted_tiff_location, i)},\n            convert_prediction_to_cog_tiff: {'src_filename': '{}/prediction_eopatch_{}_original.tiff'.format(predicted_tiff_location, i), \n                'dest_filename': '{}/prediction_eopatch_{}.tiff'.format(predicted_tiff_location, i)},\n            convert_land_use_to_cog_tiff: {'src_filename': '{}/land_use_eopatch_{}_original.tiff'.format(source_tiff_location, i),\n                'dest_filename': '{}/land_use_eopatch_{}.tiff'.format(source_tiff_location, i)},\n            convert_lpis_to_cog_tiff: {'src_filename': '{}/lpis_eopatch_{}_original.tiff'.format(source_tiff_location, i),\n                'dest_filename': '{}/lpis_eopatch_{}.tiff'.format(source_tiff_location, i)},\n            s3_upload_prediction: {'src_filename': '{}/prediction_eopatch_{}.tiff'.format(predicted_tiff_location, i), \n                'dest_filename': aws_s3_path.format(eopath_subfolder_name, value_name = \"prediction\")},\n            s3_upload_land_use: {'src_filename': '{}/land_use_eopatch_{}.tiff'.format(source_tiff_location, i), \n                'dest_filename': aws_s3_path.format(eopath_subfolder_name, value_name = \"land_use\")},\n            s3_upload_lpis: {'src_filename': '{}/lpis_eopatch_{}.tiff'.format(source_tiff_location, i), \n                'dest_filename': aws_s3_path.format(eopath_subfolder_name, value_name = \"lpis\")},\n            sh_create_collection: {'s3_file_path': aws_s3_path.format(eopath_subfolder_name, value_name = \"(BAND)\")},\n            save: {'eopatch_folder': 'eopatch_{}'.format(i)}\n        }\n    )\n\n# run the executor on 2 cores\nexecutor = EOExecutor(workflow, execution_args)\n\n# uncomment below save the logs in the current directory and produce a report!\n#executor = EOExecutor(workflow, execution_args, save_logs=True)\n\nexecutor.run(workers=2, multiprocess=False)\nexecutor.make_report()\n\n# %%time\n# merge with gdal_merge.py (with compression) using bash command magic\n#!gdal_merge.py -o predicted_tiff/merged_prediction.tiff -co compress=LZW predicted_tiff/prediction_eopatch_*\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#predict-lulc","position":71},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Part 3: Visualize the prediction"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#part-3-visualize-the-prediction","position":72},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl2":"Part 3: Visualize the prediction"},"content":"\n\npath_out_sampled = './eopatches_sampled_small/' if use_smaller_patches else './eopatches_sampled_large/'\n\nfig, axes = plt.subplots(figsize=(20, 20 * aspect_ratio), nrows=3, ncols=3)\n\ncmapValues = [color for id, color in lulcColorMapping.items()]\nnormValues = list(lulcColorMapping.keys())\nnormValues.append(20)\ncmap = colors.ListedColormap(cmapValues)\nnorm = colors.BoundaryNorm(normValues, cmap.N + 1)\n\npbar = tqdm(total=9)\nfor i, ax in enumerate(axes.flat):\n    eopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, i), lazy_loading=True)\n    im = ax.imshow(eopatch.mask_timeless['LBL_GBM'].squeeze(), cmap=cmap, norm=norm)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_aspect(\"auto\")\n    pbar.update(1)\n\nfig.subplots_adjust(wspace=0, hspace=0)\n\ncb = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='horizontal', pad=0.01, aspect=100)\ncb.ax.tick_params(labelsize=20) \ncb.set_ticks([id for id in lulcMapping.keys()])\ncb.ax.set_xticklabels([entry[\"name\"] for entry in lulcMapping.values()], rotation=45, fontsize=15)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#part-3-visualize-the-prediction","position":73},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visual inspection of patches","lvl2":"Part 3: Visualize the prediction"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visual-inspection-of-patches","position":74},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visual inspection of patches","lvl2":"Part 3: Visualize the prediction"},"content":"Here is just a simple piece of code that allows a closer inspection of the predicted labels.\n\nRandom subsets of patches are chosen, where prediction and ground truth are compared. For visual aid the mask of differences and the true color image are also provided.\n\nIn majority of the cases, differences seem to lie on the border of different structures.\n\n# Draw the Reference map\n\nfig = plt.figure(figsize=(20, 20))\n\nidx = np.random.choice(range(9))\ninspect_size = 100\n\neopatch = EOPatch.load('{}/eopatch_{}'.format(path_out_sampled, idx), lazy_loading=True)\n\nw, h = eopatch.mask_timeless['LULC'].squeeze().shape\n\nw_min = np.random.choice(range(w - inspect_size))\nh_min = np.random.choice(range(h - inspect_size))\n\ncmap = colors.ListedColormap([color for id, color in lulcColorMapping.items()])\nnorm = colors.BoundaryNorm(range(cmap.N), cmap.N)\n\nax = plt.subplot(2, 2, 1)\nplt.imshow(eopatch.mask_timeless['LULC'].squeeze()[w_min: w_min + inspect_size, h_min : h_min + inspect_size], cmap=cmap, norm=norm)\nplt.xticks([])\nplt.yticks([])\nax.set_aspect(\"auto\")\nplt.title('Ground Truth', fontsize=20)\n\nax = plt.subplot(2, 2, 2)\nplt.imshow(eopatch.mask_timeless['LBL_GBM'].squeeze()[w_min: w_min + inspect_size, h_min: h_min + inspect_size], cmap=cmap, norm=norm)\nplt.xticks([])\nplt.yticks([])\nax.set_aspect(\"auto\")\nplt.title('Prediction', fontsize=20)\n\nax = plt.subplot(2, 2, 3)\nmask = eopatch.mask_timeless['LBL_GBM'].squeeze() != eopatch.mask_timeless['LULC'].squeeze()\nplt.imshow(mask[w_min: w_min + inspect_size, h_min: h_min + inspect_size], cmap='gray')\nplt.xticks([])\nplt.yticks([]);\nax.set_aspect(\"auto\")\nplt.title('Difference', fontsize=20)\n\nax = plt.subplot(2, 2, 4)\nimage = np.clip(eopatch.data['FEATURES'][8][..., [2, 1, 0]] * 3.5, 0, 1)\nplt.imshow(image[w_min: w_min + inspect_size, h_min: h_min + inspect_size])\nplt.xticks([])\nplt.yticks([]);\nax.set_aspect(\"auto\")\nplt.title('True Color', fontsize=20)\n\nfig.subplots_adjust(wspace=0.1, hspace=0.1)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visual-inspection-of-patches","position":75},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Land Use vs Prediction","lvl2":"Part 3: Visualize the prediction"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#land-use-vs-prediction","position":76},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Land Use vs Prediction","lvl2":"Part 3: Visualize the prediction"},"content":"\n\n# Get SH collection ID\nsh_oauth_session = OAuth2Session(client = BackendApplicationClient(client_id = sentinelhub_client_id))\nsh_oauth_token = sh_oauth_session.fetch_token(token_url = sentinelhub_url + '/oauth/token',\n    client_id = sentinelhub_client_id, client_secret = sentinelhub_client_secret)\n\nsh_client = SentinelHubClient(sh_oauth_session, aws_s3_bucket)\n\nsentinelhub_collection_id = sh_client.getCollectionByName(sentinelhub_collection_name)\n\nprint(\"SH collection ID:\", sentinelhub_collection_id)\n\n## Plot utility functions\n\ndef createColorMapAndNorm(colorMapping, insertZero: bool, extraVal: int):\n    cmapValues = list(colorMapping.values())\n    normValues = list(colorMapping.keys())\n    \n    if insertZero:\n        normValues.insert(0, 0)\n        cmapValues.insert(0, [1, 1, 1])\n        \n    if not extraVal is None:\n        normValues.append(extraVal) # need to add a value, so the real last value can be used\n    \n    cmap = colors.ListedColormap(cmapValues)\n    norm = colors.BoundaryNorm(normValues, cmap.N)  \n    return cmap, norm\n\ndef plotMap(data, title, colorMapping, legendTexts, insertZero: bool, extraVal: int, \n    cbarHorizontal: bool, cbarPad: float, cbarAspect: float, \n    cbarTextSize: float, cbarTextRotation: float, hasLegend = True): \n    \n    figure, ax = plt.subplots(figsize=(20, 16))\n    ax.set_title(title, fontsize=25)\n    \n    bounds = xcube.core.geom.get_dataset_bounds(data)\n    cmap, norm = createColorMapAndNorm(colorMapping, insertZero, extraVal)\n    img = plt.imshow(data.values, cmap=cmap, norm=norm, extent=(bounds[0], bounds[2], bounds[1], bounds[3]))\n\n    if hasLegend:\n        cb = figure.colorbar(img, ax=ax, orientation='horizontal' if cbarHorizontal else 'vertical', pad=cbarPad, aspect=cbarAspect)\n\n        #cb = figure.colorbar(img)\n        cb.set_ticks(list(colorMapping.keys()))\n        if not legendTexts is None:\n            if cbarHorizontal:\n                cb.ax.set_xticklabels(legendTexts, fontsize=cbarTextSize, rotation=cbarTextRotation)\n            else:\n                cb.ax.set_yticklabels(legendTexts, fontsize=cbarTextSize, rotation=cbarTextRotation)\n\n    return figure, ax, img\n\n# DB parcel loading utility functions\n\ndef addLineStringToPath(pathCoords, pathCommands, lineString, isReverse):\n    isFirst = True\n    for xy in lineString.coords:\n        pathCoords.append(xy)\n        pathCommands.append(patches.Path.MOVETO if isFirst else patches.Path.LINETO)\n        isFirst = False\n    \ndef geometryToPatch(geometry, lineColor, fillColor):\n    pathCoords = []\n    pathCommands = []\n    \n    addLineStringToPath(pathCoords, pathCommands, geometry.exterior, False)\n    for interior in geometry.interiors:\n        addLineStringToPath(pathCoords, pathCommands, interior, True)\n\n    if len(pathCoords) <= 0 or len(pathCommands) <= 0:\n        return None\n    return patches.PathPatch(patches.Path(pathCoords, pathCommands), fc = fillColor, ec = lineColor, lw = 0.5)\n\ndef addPatchToPlot(ax, patch):\n    if not patch is None:\n        ax.add_patch(patch)\n\n# Read prediction form SH BYOC to xcube\n# Rearange selected EOPatches into bbox, which can be used for xcube definition\npatches_geometries = [Polygon(bbox.get_polygon()) for bbox in bbox_list[patchIDs]]\nbbox_of_patches = gpd.GeoSeries(cascaded_union(patches_geometries))\n\nx1 = bbox_of_patches.bounds['minx'][0].item()\ny1 = bbox_of_patches.bounds['miny'][0].item()\nx2 = bbox_of_patches.bounds['maxx'][0].item()\ny2 = bbox_of_patches.bounds['maxy'][0].item()\ncube_bbox = x1, y1, x2, y2\n\nspatial_res_meters = 10\n\ncube_pred_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=[\"prediction\"],                        \n                         chunk_size=[512, 512],\n                         crs=\"http://www.opengis.net/def/crs/EPSG/0/32633\",\n                         geometry=cube_bbox,\n                         time_range=['2019-01-01', '2020-01-01'],\n                         time_period='1y',\n                         spatial_res=spatial_res_meters,\n                         band_sample_types='UINT8',\n                         collection_id=sentinelhub_collection_id)\n\n# So we can print some SentinelHub usage stats\nrequest_collector = Observers.request_collector()\n\ncube_prediction = open_cube(cube_pred_config, request_collector, client_id = sentinelhub_client_id, client_secret = sentinelhub_client_secret)\n# cube_prediction\n\ndata = cube_prediction[\"prediction\"][0,:,:]\nplotMap(data, 'Prediction', lulcColorMapping, lulcLegendTexts.values(), False, 20, \n    True, 0.03, 100, 15, 45)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#land-use-vs-prediction","position":77},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Land use visualization","lvl3":"Land Use vs Prediction","lvl2":"Part 3: Visualize the prediction"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#land-use-visualization","position":78},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Land use visualization","lvl3":"Land Use vs Prediction","lvl2":"Part 3: Visualize the prediction"},"content":"\n\n# Add land use to cube_prediction\n\ncube_pred_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=[\"land_use\"],                        \n                         chunk_size=[512, 512],\n                         crs=\"http://www.opengis.net/def/crs/EPSG/0/32633\",\n                         geometry=cube_bbox,\n                         time_range=['2019-01-01', '2020-01-01'],\n                         time_period='1y',\n                         spatial_res=10,\n                         band_sample_types='UINT16',\n                         collection_id=sentinelhub_collection_id)\n\nrequest_collector = Observers.request_collector()\n\ncube_land_use = open_cube(cube_pred_config, request_collector, client_id = sentinelhub_client_id, client_secret = sentinelhub_client_secret)\ncube_prediction[\"land_use\"] = cube_land_use[\"land_use\"]\n# cube_prediction\n\ndata = cube_prediction[\"land_use\"][0,:,:]\nplotMap(data, 'Land use', landUseColorMapping, landUseLegendTexts.values(), True, 10000, False, 0.03, 50, 12, 0)\nplt.show()\n\n# Add mapped land use data\ndimensions = cube_prediction[\"prediction\"].values[0].shape\nland_use_map = np.zeros((1, dimensions[0], dimensions[1]), 'uint8')\nland_use_map[0, :, :] = np.array([np.array([landUseToLulcMapping[val] for val in val_arr]) for val_arr in cube_prediction[\"land_use\"].values[0]])\nland_use_map_xa = xr.DataArray(land_use_map,\n                  dims=cube_prediction[\"prediction\"].dims,\n                  coords=cube_prediction[\"prediction\"].coords)\nland_use_map_xa_chunk = xcube.core.chunk.chunk_dataset(land_use_map_xa, chunk_sizes=(1, 512, 512))\ncube_prediction[\"land_use_mapped\"] = cube_land_use[\"land_use\"]\ncube_prediction[\"land_use_mapped\"] = land_use_map_xa_chunk\n# cube_prediction\n\n# compute difference between prediction and land use\ncube_prediction[\"diff_prediction_land_use\"] = cube_prediction[\"prediction\"] - cube_prediction.land_use_mapped\n\ndata = cube_prediction.diff_prediction_land_use[0,:,:]\nplotMap(data, 'Prediction vs. land use difference', diffColorMapping, None, False, 100, False, 0.03, 50, 12, 0, hasLegend = False)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#land-use-visualization","position":79},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"LPIS visualization","lvl3":"Land Use vs Prediction","lvl2":"Part 3: Visualize the prediction"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#lpis-visualization","position":80},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"LPIS visualization","lvl3":"Land Use vs Prediction","lvl2":"Part 3: Visualize the prediction"},"content":"\n\n# Add LPIS to cube_prediction\n\ncube_pred_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=[\"lpis\"],                        \n                         chunk_size=[512, 512],\n                         crs=\"http://www.opengis.net/def/crs/EPSG/0/32633\",\n                         geometry=cube_bbox,\n                         time_range=['2019-01-01', '2020-01-01'],\n                         time_period='1y',\n                         spatial_res=10,\n                         band_sample_types='UINT16',\n                         collection_id=sentinelhub_collection_id)\n\nrequest_collector = Observers.request_collector()\n\ncube_lpis = open_cube(cube_pred_config, request_collector, client_id = sentinelhub_client_id, client_secret = sentinelhub_client_secret)\ncube_prediction[\"lpis\"] = cube_lpis[\"lpis\"]\n# cube_prediction\n\ndata = cube_prediction[\"lpis\"][0,:,:]\nplotMap(data, 'LPIS', landUseColorMapping, landUseLegendTexts.values(), True, 10000, False, 0.03, 25, 12, 0)\nplt.show()\n\n# Add mapped land use data\ndimensions = cube_prediction[\"prediction\"].values[0].shape\nlpis_map = np.zeros((1, dimensions[0], dimensions[1]), 'uint8')\n\n# Note! We must offset data, to clearly recognize in the difference, where LPIS has no data\nlpis_map[0, :, :] = np.array([np.array([(50 + landUseToLulcMapping[val] if val > 0 else 25) for val in val_arr]) for val_arr in cube_prediction[\"lpis\"].values[0]])\n\nlpis_map_xa = xr.DataArray(lpis_map,\n                  dims=cube_prediction[\"prediction\"].dims,\n                  coords=cube_prediction[\"prediction\"].coords)\nlpis_map_xa_chunk = xcube.core.chunk.chunk_dataset(lpis_map_xa, chunk_sizes=(1, 512, 512))\ncube_prediction[\"lpis_mapped\"] = lpis_map_xa_chunk\n# cube_prediction\n\ncube_prediction[\"diff_prediction_lpis\"] = cube_prediction.lpis_mapped - cube_prediction[\"prediction\"]\ndata = cube_prediction.diff_prediction_lpis[0,:,:]\n\n# add \"out-of-range\" values as black\ncolorMapping = {50 - len(lulcMapping): [0, 0, 0]} \ncolorMapping.update({(id + 50): color for id, color in diffColorMapping.items()})\nlegendTexts = [str(i) for i in range(-len(lulcMapping) + 1, +len(lulcMapping) + 1)]\nlegendTexts.insert(0, 'No data')\n\nplotMap(data, 'Prediction vs. LPIS difference', colorMapping, legendTexts, False, None, False, 0.03, 50, 12, 0, hasLegend = False)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#lpis-visualization","position":81},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Select smaller AOI (ask BC)","lvl3":"Land Use vs Prediction","lvl2":"Part 3: Visualize the prediction"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#select-smaller-aoi-ask-bc","position":82},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"Select smaller AOI (ask BC)","lvl3":"Land Use vs Prediction","lvl2":"Part 3: Visualize the prediction"},"content":"\n\nsubset_size_ratio = 0.3 # regarding the full extent\n\nbounds = xcube.core.geom.get_dataset_bounds(cube_prediction)\nbounds_center_x = (bounds[0] + bounds[2]) / 2\nbounds_center_y = (bounds[1] + bounds[3]) / 2\nbounds_width = (bounds[2] - bounds[0])\nbounds_height = (bounds[3] - bounds[1])\n\nsubset_bbox = (\n    bounds_center_x - bounds_width * subset_size_ratio / 2,\n    bounds_center_y - bounds_height * subset_size_ratio / 2,\n    bounds_center_x + bounds_width * subset_size_ratio / 2,\n    bounds_center_y + bounds_height * subset_size_ratio / 2\n)\n\nsubset_cube_prediction = xcube.core.geom.clip_dataset_by_geometry(cube_prediction, subset_bbox)\nsubset_cube_prediction_data = subset_cube_prediction[\"prediction\"][0,:,:]\nsubset_cube_land_use_data = subset_cube_prediction[\"land_use\"][0,:,:]\nsubset_cube_diff_data = subset_cube_prediction[\"diff_prediction_land_use\"][0,:,:]\n\nfigurePrediction, axPrediction, imgPrediction = plotMap(subset_cube_prediction_data, 'Prediction', lulcColorMapping, lulcLegendTexts.values(), False, 20, False, 0.03, 50, 12, 0)\nfigureLandUse, axLandUse, imgLandUse = plotMap(subset_cube_land_use_data, 'Land use', landUseColorMapping, landUseLegendTexts.values(), True, 10000, False, 0.03, 50, 12, 0)\nfigureDiff, axDiff, imgDiff = plotMap(subset_cube_diff_data, 'Difference', diffColorMapping, None, False, 100, False, 0.03, 50, 12, 0, hasLegend = False)\n\ngeodb = GeoDBClient()\nland_use = loadFromDatabaseWithLulcMapping(geodb, \"Land use\", db_land_use_table, db_land_use_class_column, None,\n    BBox(subset_bbox, crs = country_crs), country_crs, selected_db_records_time, selected_db_records_time)\n\nfor row in land_use.iterrows():\n    addPatchToPlot(axPrediction, geometryToPatch(row[1]['geometry'], (1, 0, 0, 1), (0, 0, 0, 0)))\n    addPatchToPlot(axLandUse, geometryToPatch(row[1]['geometry'], (1, 0, 0, 1), (0, 0, 0, 0)))\n    addPatchToPlot(axDiff, geometryToPatch(row[1]['geometry'], (0, 1, 0, 1), (0, 0, 0, 0)))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#select-smaller-aoi-ask-bc","position":83},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visualizations per parcel (ask BC)","lvl2":"Part 3: Visualize the prediction"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visualizations-per-parcel-ask-bc","position":84},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl3":"Visualizations per parcel (ask BC)","lvl2":"Part 3: Visualize the prediction"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#visualizations-per-parcel-ask-bc","position":85},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"List of parcels to select from","lvl3":"Visualizations per parcel (ask BC)","lvl2":"Part 3: Visualize the prediction"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#list-of-parcels-to-select-from","position":86},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"List of parcels to select from","lvl3":"Visualizations per parcel (ask BC)","lvl2":"Part 3: Visualize the prediction"},"content":"\n\nx1 = bbox_of_patches.bounds['minx'][0].item()\ny1 = bbox_of_patches.bounds['miny'][0].item()\nx2 = bbox_of_patches.bounds['maxx'][0].item()\ny2 = bbox_of_patches.bounds['maxy'][0].item()\ncubeBBox = BBox((x1, y1, x2, y2), country_crs)\n\nfromWgs84Transform = pyproj.Transformer.from_crs(str(CRS.WGS84), str(country_crs))\ntoWgs84Transform = pyproj.Transformer.from_crs(str(country_crs), str(CRS.WGS84))\n\nselectedParcelId = None\n    \ndef computeLeafletScaleLevel(bbox):\n    return math.floor(1 + math.log(40000000 / max(bbox.max_x - bbox.min_x, bbox.max_y - bbox.min_y), 2))\n\ndef createLeafletMap(bbox):\n    mapCenter = toWgs84Transform.transform((bbox.min_x + bbox.max_x) / 2, (bbox.min_y + bbox.max_y) / 2)\n\n    terrainLayer = basemap_to_tiles(basemaps.Stamen.Terrain) \n    terrainLayer.name = \"Background\"\n    scaleLevel = computeLeafletScaleLevel(bbox)\n    leafletMap = LeafletMap(layers = (terrainLayer, ), center = mapCenter, zoom = scaleLevel)\n    return leafletMap\n\ndef lineStringToLeafletLocations(lineString):\n    return [toWgs84Transform.transform(xy[0], xy[1]) for xy in lineString.coords]\n\ndef addGeometryToLeafletMap(leafletMap, geomId, geometry, lineColor, fillColor, clickFunc):\n    locations = [lineStringToLeafletLocations(geometry.exterior)]\n    for interior in geometry.interiors:\n        locations.extend([lineStringToLeafletLocations(interior)])\n    if len(locations) > 0:\n        layer = LeafletPolygon(locations = locations, \n            color = lineColor, opacity = 0.5, fill_color = fillColor, fill_opacity = 0.6, weight = 1)\n        leafletMap.add_layer(layer)\n        def layerClickFunc(**kwargs):\n            clickFunc(**kwargs, geomId = geomId)\n        layer.on_click(layerClickFunc)\n        \ndef loadParcelsToLeafletMap(leafletMap, bbox, tableName, landUseColumnName, clickFunc):\n    geodb = GeoDBClient()\n    \n    data = loadFromDatabaseWithLulcMapping(geodb, \"\", tableName, landUseColumnName, None, bbox, bbox.crs,  \n        selected_db_records_time, selected_db_records_time, maxRows = None, logging = False)\n\n    for row in data.iterrows():\n        color = lulcColorMapping[row[1]['lulcid']]\n        colorHtml = \"#{:02x}{:02x}{:02x}\".format(int(color[0] * 255), int(color[1] * 255), int(color[2] * 255))\n        addGeometryToLeafletMap(leafletMap, row[1]['id'], row[1]['geometry'], \"#FF0000\", colorHtml, clickFunc)\n\ndef createLeafletMapSentinelWmsLayer(leafletMap, instanceId, name, layer, bbox, resolution, visible, opacity):\n    bboxWgs84 = toWgs84Transform.transform(bbox.min_x, bbox.min_y), toWgs84Transform.transform(bbox.max_x, bbox.max_y)\n    \n    wmsUrl = 'http://services.sentinel-hub.com/ogc/wms/{instanceId}?' \\\n        + 'request=GetMap&layers={layer}&bbox={x1},{y1},{x2},{y2}&crs={crs}&format=image/png&width={w}&height={h}'\n    wmsUrl = wmsUrl.format(instanceId = instanceId, layer = layer, \n        x1 = bbox.min_x, y1 = bbox.min_y, x2 = bbox.max_x, y2 = bbox.max_y, crs = str(country_crs), \n        w = int((bbox.max_x - bbox.min_x) / resolution), h = int((bbox.max_y - bbox.min_y) / resolution))\n\n    return LeafletImageOverlay(url = wmsUrl, name = name, bounds = bboxWgs84, on = visible, opacity = opacity)\n\ndef addLeafletRectangleDrawControl(leafletMap):\n    drawControls = LeafletDrawControl()\n    drawControls.rectangle = {\n        \"shapeOptions\": {\n            \"fillColor\": \"#ff0000\",\n            \"color\": \"#ff0000\",\n            \"fillOpacity\": 0.75\n        }\n    }\n    drawControls.polygon = {}\n    drawControls.polyline =  {}\n    drawControls.circle = {}\n    drawControls.circlemarker = {}\n    leafletMap.add_control(drawControls)\n    return drawControls\n\ndef leafletParcelSelectionClickFunc(**kwargs):  \n    global selectedParcelId\n    selectedParcelId = kwargs['geomId']\n    print(\"Selected parcel \" + str(selectedParcelId))\n\ndef leafletOverviewDrawFunc(self, action, geo_json):  \n    geometry = geo_json['geometry']\n    if (geometry['type'] == 'Polygon') and len(geometry['coordinates']) == 1 and len(geometry['coordinates'][0]) == 5:\n        coords = geometry['coordinates'][0]\n        x1y1 = fromWgs84Transform.transform(coords[0][1], coords[0][0])\n        x2y2 = fromWgs84Transform.transform(coords[2][1], coords[2][0])\n        bbox = BBox((\n            min(cubeBBox.max_x, max(cubeBBox.min_x, x1y1[0])), \n            min(cubeBBox.max_y, max(cubeBBox.min_y, x1y1[1])),\n            min(cubeBBox.max_x, max(cubeBBox.min_x, x2y2[0])), \n            min(cubeBBox.max_y, max(cubeBBox.min_y, x2y2[1]))), country_crs)\n        \n        for layer in leafletMapParcelSelection.layers:\n            if isinstance(layer, LeafletPolygon):\n                leafletMapParcelSelection.remove_layer(layer)\n        \n        leafletMapParcelSelection.center = (coords[0][1] + coords[2][1]) * 0.5, (coords[0][0] + coords[2][0]) * 0.5\n        leafletMapParcelSelection.zoom = computeLeafletScaleLevel(bbox)\n        loadParcelsToLeafletMap(leafletMapParcelSelection, bbox, db_land_use_table, db_land_use_class_column, leafletParcelSelectionClickFunc)\n\n\nleafletMapOverview = createLeafletMap(cubeBBox)\n\nleafletMapOverview.add_layer(createLeafletMapSentinelWmsLayer(leafletMapOverview, sentinelhub_instance_id, \"Difference\", sentinelhub_prediction_diff_layer, cubeBBox, 10, False, 0.85))\nleafletMapOverview.add_layer(createLeafletMapSentinelWmsLayer(leafletMapOverview, sentinelhub_instance_id, \"Land use\", sentinelhub_land_use_layer, cubeBBox, 10, False, 0.85))\nleafletMapOverview.add_layer(createLeafletMapSentinelWmsLayer(leafletMapOverview, sentinelhub_instance_id, \"Prediction\", sentinelhub_prediction_layer, cubeBBox, 10, True, 0.85))\n\ndrawControls = addLeafletRectangleDrawControl(leafletMapOverview)\ndrawControls.on_draw(leafletOverviewDrawFunc)\nleafletMapOverview.add_control(LeafletLayersControl())\nleafletMapOverview.layout.height = '800px'\ndisplay(leafletMapOverview)\n\nleafletMapParcelSelection = createLeafletMap(cubeBBox)\nleafletMapParcelSelection.layout.height = '800px'\ndisplay(leafletMapParcelSelection)\n\ndef loadSingleRecordFromDatabase(recordId):\n    geodb = GeoDBClient()\n    data = loadFromDatabaseWithLulcMapping(geodb, \"Land use\", db_land_use_table, db_land_use_class_column, recordId, None, country_crs, None, None)\n\n    for row in data.iterrows():\n        return row[1]\n    return None\n\ndef addLineStringToPath(pathCoords, pathCommands, lineString, isReverse):\n    isFirst = True\n    for xy in lineString.coords:\n        pathCoords.append(xy)\n        pathCommands.append(patches.Path.MOVETO if isFirst else patches.Path.LINETO)\n        isFirst = False\n    \ndef geometryToPatch(geometry, lineColor, fillColor):\n    pathCoords = []\n    pathCommands = []\n    \n    addLineStringToPath(pathCoords, pathCommands, geometry.exterior, False)\n    for interior in geometry.interiors:\n        addLineStringToPath(pathCoords, pathCommands, interior, True)\n\n    if len(pathCoords) <= 0 or len(pathCommands) <= 0:\n        return None\n    return patches.PathPatch(patches.Path(pathCoords, pathCommands), fc = fillColor, ec = lineColor, lw = 2)\n\nif selectedParcelId is None:\n    print(\"Select first the parcel in the above details map!\")\nelse:\n    selectedParcelData = loadSingleRecordFromDatabase(selectedParcelId)\n\n    selectedParcelCubePrediction = xcube.core.geom.mask_dataset_by_geometry(cube_prediction, selectedParcelData['geometry'])\n    selectedParcelCubePredictionData = selectedParcelCubePrediction[\"prediction\"][0,:,:]\n    selectedParcelCubeLandUseData = selectedParcelCubePrediction[\"land_use\"][0,:,:]\n    selectedParcelCubeDiffData = selectedParcelCubePrediction[\"diff_prediction_land_use\"][0,:,:]\n\n    figurePrediction, axPrediction, imgPrediction = plotMap(selectedParcelCubePredictionData, 'Prediction', lulcColorMapping, lulcLegendTexts.values(), False, 20, False, 0.03, 50, 12, 0)\n    figureLandUse, axLandUse, imgLandUse = plotMap(selectedParcelCubeLandUseData, 'Land use', landUseColorMapping, landUseLegendTexts.values(), True, 10000, False, 0.03, 50, 12, 0)\n    figureDiff, axDiff, imgDiff = plotMap(selectedParcelCubeDiffData, 'Difference', diffColorMapping, None, False, 100, False, 0.03, 50, 12, 0)\n\n    addPatchToPlot(axPrediction, geometryToPatch(selectedParcelData['geometry'], (1, 0, 0, 1), (0, 0, 0, 0)))\n    addPatchToPlot(axLandUse, geometryToPatch(selectedParcelData['geometry'], (1, 0, 0, 1), (0, 0, 0, 0)))\n    addPatchToPlot(axDiff, geometryToPatch(selectedParcelData['geometry'], (0, 1, 0, 1), (0, 0, 0, 0)))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#list-of-parcels-to-select-from","position":87},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"TODO: calculate % of wrongly predicted area for this parcel","lvl3":"Visualizations per parcel (ask BC)","lvl2":"Part 3: Visualize the prediction"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#todo-calculate-of-wrongly-predicted-area-for-this-parcel","position":88},{"hierarchy":{"lvl1":"LPIS Use Case for Land Use / Land Cover Classification","lvl4":"TODO: calculate % of wrongly predicted area for this parcel","lvl3":"Visualizations per parcel (ask BC)","lvl2":"Part 3: Visualize the prediction"},"content":"\n\n    ","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lpis-lulc-slo#todo-calculate-of-wrongly-predicted-area-for-this-parcel","position":89},{"hierarchy":{"lvl1":"Living Planet Symposium 2022 Training Session"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services","position":0},{"hierarchy":{"lvl1":"Living Planet Symposium 2022 Training Session"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services","position":1},{"hierarchy":{"lvl1":"Living Planet Symposium 2022 Training Session","lvl2":"Living Planet Symposium 2022 Training Session"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#living-planet-symposium-2022-training-session","position":2},{"hierarchy":{"lvl1":"Living Planet Symposium 2022 Training Session","lvl2":"Living Planet Symposium 2022 Training Session"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#living-planet-symposium-2022-training-session","position":3},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#leverage-euro-data-cube-services-for-accessing-analysing-and-visualising-eo-data","position":4},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data"},"content":"\n\nOriginal JN: Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube\n\nAuthor original JN: William Ray\n\nEdited and extended by: Alicja Balfanz & Max Kampen","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#leverage-euro-data-cube-services-for-accessing-analysing-and-visualising-eo-data","position":5},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Getting started with EDC"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#getting-started-with-edc","position":6},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Getting started with EDC"},"content":"In this demonstration Jupyter Notebook, we will be visualising and analysing a flooding event using Sentinel data to demonstrate how you can use EDC for your own applications. Much of what we we will focus on can be used for many other applications and use cases.\n\nWe are going to use EDC with its associated libaries and APIs to do this. In this notebook we will learn how to:\n\nBuild a data cube\n\nCreate a new variable\n\nVisualise a variable of your data cube\n\nCreate a new variable using a threshold\n\nVisualise a spatial subset of a variable over time\n\nCreate a new variable based upon space and time\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#getting-started-with-edc","position":7},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Configuration"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#configuration","position":8},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Configuration"},"content":"Before acccessing the data, we will start by importing the necessary Python libraries (already configured in your EDC workspace), and fetch pre-generated credentials as environment variables to access the services.\n\n# Check compatibility and import environment credentials\nfrom edc import check_compatibility\ncheck_compatibility(\"user-2023.03-02\", dependencies=[\"GEODB\", \"SH\"])\n\n# EDC libraries\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.sentinelhub import SentinelHub\nfrom xcube.core.geom import mask_dataset_by_geometry\n\n# Sentinel Hub\nfrom sentinelhub import BBox\n\n# Utilities\nimport IPython.display\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport rioxarray\nimport shapely\n\n# Numerical computation\nimport xarray as xr\nimport numpy as np\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#configuration","position":9},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Define an AOI"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#define-an-aoi","position":10},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Define an AOI"},"content":"Next, we will define our area of interest using a bounding box. For our example we will use WGS84 coordinates to build the data cube. We have chosen an AOI that covers Madagascar’s capital city Antananarivo and surrounding regions. In early 2022, the east coast of Madagascar was impacted by two different tropical weather systems, which caused heavy rainfall and flooding in the country’s capital and Analamanga region (\n\nsource). Across Madagascar, the heavy rainfall persisted throughout January and February, when the moderate tropical storm Ana and the tropical cyclone Batsirai made landfall in January and Februrary respectively (\n\nsource).\n\n# Bbox\nAntananarivo_bbox = [47.221985, -19.129599, 47.671051, -18.659257]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(Antananarivo_bbox,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#define-an-aoi","position":11},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"How to build a data cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#how-to-build-a-data-cube","position":12},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"How to build a data cube"},"content":"Firstly, we will go through the required steps to build a data cube.\n\nWe are going to visualise the flooding events using Sentinel-2 imagery. The Sentinel-2 system (consisting of two twin satellites) is part of the Copernicus programme and collects multispectral data globally with a revisit time of 5 days. The satellite’s multispectral imager acquires data in 13 spectral bands spanning from the visible and near infrared to shortwave infrared.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#how-to-build-a-data-cube","position":13},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Check available Sentinel-2 L2A bands","lvl2":"How to build a data cube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#check-available-sentinel-2-l2a-bands","position":14},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Check available Sentinel-2 L2A bands","lvl2":"How to build a data cube"},"content":"Using EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset to help us build the cube!\n\n# Create a Sentinel Hub class\nSH = SentinelHub()\n\n# List bands for S2-L2A\nSH.band_names('S2L2A')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#check-available-sentinel-2-l2a-bands","position":15},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Build an xcube","lvl2":"How to build a data cube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#build-an-xcube","position":16},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Build an xcube","lvl2":"How to build a data cube"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S2L2A for Sentinel-2 L2A. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call the B02, B03, B04, B08, CLM (Blue, Green, Red & NIR, Cloud Mask) bands.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 30 meters, we set the resolution to 0.00045 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-2 L2A data is available from October 2016 onwards. In this example, we will fetch data for January 2022 through March 2022.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30M corresponds to 30 minutes, thus avoiding duplicate datasets.\n\nNote: the return _coerce_scalar_to_timedelta_type(arg, unit=unit, errors=errors) warning can be safely ignored.\n\n# Setup xcube\ns2_cube_config = CubeConfig(dataset_name='S2L2A',\n                            band_names=['B02', 'B03', 'B04', 'B08', 'CLM'],\n                            bbox=Antananarivo_bbox,\n                            spatial_res=0.00045,\n                            time_range=['2022-01-01', '2022-04-01'],\n                            time_tolerance='30M')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#build-an-xcube","position":17},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Open the xcube","lvl2":"How to build a data cube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#open-the-xcube","position":18},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Open the xcube","lvl2":"How to build a data cube"},"content":"In the following cell we open the cube and display its contents. It’s important to note that at this stage, we’re not processing anything, but generate a cube on the fly with data ready to be called when needed for analysis.\n\nOnce you open the cube, you can visualise the contents. For example, you can view the number of timestamps as a list in the Coordinates tab. You can also visualise the seperate variables, with information on their size and data type.\n\n# Open cube (on the fly)\ns2_cube = open_cube(s2_cube_config)\n\n# Display contents\ns2_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#open-the-xcube","position":19},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Create a new variable","lvl2":"How to build a data cube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#create-a-new-variable","position":20},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Create a new variable","lvl2":"How to build a data cube"},"content":"A great way to visualise the extent of surface water with multispectral data at hand, is to use the Normalised Difference Water Index (NDWI). We can calculate the index with the Green and NIR bands as stated below, and add it to the data cube as a new variable.\n\nNDWI = Green - NIR / Green + NIR\n\nFor this, we are going to create a new variable in the next cell. To create the new variable we are using two existing variables defined as s2.cube.B03 and s2_cube.B08. We then insert these variables into an index formula to calculate our ndwi variable. To integrate the new varibale into our data cube, we first need to define a new empty data cube attribute, provided with a name and associated units, before assigning the calculated ndwi variable to it. Feel free to call s2_cube again to check the newly added variable that can now be called from the data cube.\n\n# Define NDWI in visualisation\nndwi = ((s2_cube.B03-s2_cube.B08)/(s2_cube.B03+s2_cube.B08))\n\nndwi.attrs['long_name'] = 'NDWI'\nndwi.attrs['units'] ='unitless'\n\ns2_cube['NDWI'] = ndwi\ns2_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#create-a-new-variable","position":21},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"How to visualise your datacube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#how-to-visualise-your-datacube","position":22},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"How to visualise your datacube"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#how-to-visualise-your-datacube","position":23},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Visualise variables","lvl2":"How to visualise your datacube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#visualise-variables","position":24},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Visualise variables","lvl2":"How to visualise your datacube"},"content":"We are going to visualise a True Color image and the NDWI image in the same plot. For the True Color image, we select the Blue, Green and RED bands for one timstamp in the data cube in order to create a multiband RGB image stack. For visualisation purposes, we will multiply the reflectance values by 3 to brighten the image a little. We also fetch the NDWI variable for the exact same date for a side-by-side comparison.\n\n# Select timestamp\nt = '2022-01-30 07:00:00'\n\n# Select the bands and stack them.\nRed = s2_cube.B04.sel(time=t, method='nearest')\nGreen = s2_cube.B03.sel(time=t, method='nearest')\nBlue = s2_cube.B02.sel(time=t, method='nearest')\n\nrgb = np.dstack((Red,Green,Blue)) #Stack the three arrays\n\nndwi = s2_cube.NDWI.sel(time=t, method='nearest')\n\n# Plot \nf = plt.figure(figsize=[18, 16])\nf.add_subplot(1, 2, 1)\nplt.title(f\"True Color: {str(s2_cube.time.sel(time=t, method='nearest').data).split('T')[0]}\")\nplt.imshow(3 * rgb)  # We multiply the rgb by 3 to make the image brighter\nf.add_subplot(1, 2, 2)\nplt.title(f\"NDWI: {str(s2_cube.time.sel(time=t, method='nearest').data).split('T')[0]}\")\nplt.imshow(ndwi, vmin=-1, vmax=1, cmap='GnBu')\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#visualise-variables","position":25},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Visualise multiple timestamps","lvl2":"How to visualise your datacube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#visualise-multiple-timestamps","position":26},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Visualise multiple timestamps","lvl2":"How to visualise your datacube"},"content":"We would like to get a better idea of the course of events and examine how the two storm weather systems affected the area. The flooding events we are trying to monitor happened in the middle of the Southwest Indian Ocean cyclone season, which approximately lasts from November until April. In order to check how many suitable Sentinel-2 acquisitions we have at hand, we will take a look at multiple timestamps from the data cube.\n\n# Select timestamps\nndwi1 = s2_cube.NDWI.sel(time='2022-01-05 07:00:00', method='nearest')\nndwi2 = s2_cube.NDWI.sel(time='2022-01-15 07:00:00', method='nearest')\nndwi3 = s2_cube.NDWI.sel(time='2022-01-30 07:00:00', method='nearest')\nndwi4 = s2_cube.NDWI.sel(time='2022-02-09 07:00:00', method='nearest')\nndwi5 = s2_cube.NDWI.sel(time='2022-02-24 07:00:00', method='nearest')\nndwi6 = s2_cube.NDWI.sel(time='2022-03-06 07:00:00', method='nearest')\nndwi7 = s2_cube.NDWI.sel(time='2022-03-16 07:00:00', method='nearest')\nndwi8 = s2_cube.NDWI.sel(time='2022-03-31 07:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[16, 18])\nax1 = f.add_subplot(3, 3, 1)\nax2 = f.add_subplot(3, 3, 2)\nax3 = f.add_subplot(3, 3, 3)\nax4 = f.add_subplot(3, 3, 4)\nax5 = f.add_subplot(3, 3, 5)\nax6 = f.add_subplot(3, 3, 6)\nax7 = f.add_subplot(3, 3, 7)\nax8 = f.add_subplot(3, 3, 8)\n\naxlist = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]\n\nt = ndwi1.plot.imshow(ax=ax1, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi2.plot.imshow(ax=ax2, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi3.plot.imshow(ax=ax3, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi4.plot.imshow(ax=ax4, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi5.plot.imshow(ax=ax5, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi6.plot.imshow(ax=ax6, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi7.plot.imshow(ax=ax7, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi8.plot.imshow(ax=ax8, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"NDWI\")\n\nplt.show()\n\nUnsurprisingly, the weather conditions during storm season are not suitable for Earth monitoring with optical imagery. Of the eight dates we have requested, only one, the acquisition from 30th January, is not completely overcast and the remaining ones are unusable. Fortunately, we can resort to using Sentinel-1 GRD radar data, which is unimpeded by weather conditions and should provide a better picture of the course of events.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#visualise-multiple-timestamps","position":27},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Buildind a Sentinel-1 data cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#buildind-a-sentinel-1-data-cube","position":28},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Buildind a Sentinel-1 data cube"},"content":"The Sentinel-1 satellite system is also part of the Copernicus programme and collects data globally with a revisit time of 5 days when both twin satellites are active. Unfortunately, the recent failure of Sentinel-1B leaves us with longer revisit times (\n\nsource). In contrast to Sentinel-2, Sentinel-1 SAR is an active sensor that sends SAR signals and records the backscatter. Due to the wavelengths used, SAR is not hindered by clouds and can be operated day and night.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#buildind-a-sentinel-1-data-cube","position":29},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Buildind a Sentinel-1 data cube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#check-sentinel-1-grd-available-bands","position":30},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Buildind a Sentinel-1 data cube"},"content":"Using EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset.\n\n# List bands for S1-GRD\nSH.band_names('S1GRD')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#check-sentinel-1-grd-available-bands","position":31},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Build the S-1 GRD xcube","lvl2":"Buildind a Sentinel-1 data cube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#build-the-s-1-grd-xcube","position":32},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Build the S-1 GRD xcube","lvl2":"Buildind a Sentinel-1 data cube"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S1GRD for Sentinel-1 GRD. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call just the VV polarisation band.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 30 meters, we set the resolution to 0.00045 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-1 GRD data is available from February 2015 onwards. In this example, we will fetch data for January 2022 through March 2022.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30M corresponds to 30 minutes, thus avoiding duplicate datasets.\n\nNote: the return _coerce_scalar_to_timedelta_type(arg, unit=unit, errors=errors) warning can be safely ignored.\n\n# Setup xcube\ns1_cube_config = CubeConfig(dataset_name='S1GRD',\n                            band_names=['VV'],\n                            bbox=Antananarivo_bbox,\n                            spatial_res=0.00045,\n                            time_range=['2022-01-01', '2022-04-01'],\n                            time_tolerance='30M')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#build-the-s-1-grd-xcube","position":33},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Open the xcube","lvl2":"Buildind a Sentinel-1 data cube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#open-the-xcube-1","position":34},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Open the xcube","lvl2":"Buildind a Sentinel-1 data cube"},"content":"In the following cell we pass the configurated cube to the open cube command to open the cube and display its contents.\n\n# Open cube (on the fly)\ns1_cube = open_cube(s1_cube_config)\n\n# Display contents\ns1_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#open-the-xcube-1","position":35},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Visualising the flooded areas using SAR","lvl2":"Buildind a Sentinel-1 data cube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#visualising-the-flooded-areas-using-sar","position":36},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Visualising the flooded areas using SAR","lvl2":"Buildind a Sentinel-1 data cube"},"content":"Firstly, we need to generate a new variable. For Sentinel-1 data, the values are returned in linear power. For a more convenient analysis we will convert the values to decibels. This is done by mutiplying the log10 of each pixel value by 10. Secondly, as there will be pixels with a value of -inf after this operation, we need to account for this with the second function that will automatically assign 0 to these pixels.\n\n# Convert VV Digital numbers to Decibels\nvv_dn = s1_cube.VV\nvv_db = 10 * (np.log10(vv_dn))\n\nvv_db = vv_db.where(np.isfinite(vv_db), 0)\n\nvv_db.attrs['long_name'] = 'VV_dB'\nvv_db.attrs['units'] = 'decibels'\n\ns1_cube['VV_dB'] = vv_db\n\nFrom the news and our previous visualisation of Sentinel-2 data, we know that there was significant surface water flooding in January and February 2022. Let’s visualise one of the acquisitions from the end of January, when the tropical storm Ana brought heavy rainfall to the area. Here, we select the closest acquisition to 25th January 2022 and plot the calculated VV_dB variable for our region of interest.\n\n# select and define the timestamp you want to visualise \nVV_dB_timestamp = s1_cube.VV_dB.sel(time='2022-01-25 07:00:00', method='nearest')\n\n# plot the timestamp\nVV_dB_timestamp.plot.imshow(vmin=-40, vmax=0, cmap='winter', figsize=(10, 10))\n\n# save and display the plot\nplt.show()\n\nOn this Sentinel-1 acquisition from 27th January, we can clearly see the extent of flooded areas in darker blue colour. The visualisation already looks fairly well defined, so let’s plot multiple timestamps to confirm that this is a good variable for generating subsequent products like flood masks.\n\n#### Timestamp selection\nvv1 = s1_cube.VV_dB.sel(time='2022-01-03 07:00:00', method='nearest')\nvv2 = s1_cube.VV_dB.sel(time='2022-01-15 07:00:00', method='nearest')\nvv3 = s1_cube.VV_dB.sel(time='2022-01-27 07:00:00', method='nearest')\nvv4 = s1_cube.VV_dB.sel(time='2022-02-08 07:00:00', method='nearest')\nvv5 = s1_cube.VV_dB.sel(time='2022-02-20 07:00:00', method='nearest')\nvv6 = s1_cube.VV_dB.sel(time='2022-03-04 07:00:00', method='nearest')\nvv7 = s1_cube.VV_dB.sel(time='2022-03-16 07:00:00', method='nearest')\nvv8 = s1_cube.VV_dB.sel(time='2022-03-28 07:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[16, 18])\nax1 = f.add_subplot(3, 3, 1)\nax2 = f.add_subplot(3, 3, 2)\nax3 = f.add_subplot(3, 3, 3)\nax4 = f.add_subplot(3, 3, 4)\nax5 = f.add_subplot(3, 3, 5)\nax6 = f.add_subplot(3, 3, 6)\nax7 = f.add_subplot(3, 3, 7)\nax8 = f.add_subplot(3, 3, 8)\n\naxlist = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]\n\nt = vv1.plot.imshow(ax=ax1, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv2.plot.imshow(ax=ax2, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv3.plot.imshow(ax=ax3, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv4.plot.imshow(ax=ax4, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv5.plot.imshow(ax=ax5, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv6.plot.imshow(ax=ax6, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv7.plot.imshow(ax=ax7, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv8.plot.imshow(ax=ax8, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"VV dB\")\n\nplt.show()\n\nThis gives us a much clearer picture of the spatial and temporal extent of the flooding events in the region. We can make out two flooding peaks in the acquisitons from 27th January and 4th March, which are congruent with the reports on the two storms making landfall.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#visualising-the-flooded-areas-using-sar","position":37},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Creating a flood mask","lvl2":"Buildind a Sentinel-1 data cube"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#creating-a-flood-mask","position":38},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Creating a flood mask","lvl2":"Buildind a Sentinel-1 data cube"},"content":"Next, we want to generate a flood mask using a threshold for the VV_dB variable. In VV polarization mode, values below -20 dB are usually surface water. Let’s define different thresholds for a side-by-side comparison in order to find the most suitable value for generating the flood mask.\n\nflood_threshold1_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB >= -15, 1)\nflood_threshold2_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB >= -18, 1)\nflood_threshold3_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB >= -20, 1)\n\nflood_threshold1_step2 = flood_threshold1_step1.where(flood_threshold1_step1 == 1, 0)\nflood_threshold2_step2 = flood_threshold2_step1.where(flood_threshold2_step1 == 1, 0)\nflood_threshold3_step2 = flood_threshold3_step1.where(flood_threshold3_step1 == 1, 0)\n\nflood_threshold1 = flood_threshold1_step2.sel(time='2022-01-27 07:00:00', method='nearest')\nflood_threshold2 = flood_threshold2_step2.sel(time='2022-01-27 07:00:00', method='nearest')\nflood_threshold3 = flood_threshold3_step2.sel(time='2022-01-27 07:00:00', method='nearest')\n\nNext we will plot the new thresholds we want to test:\n\n# Plot \nf = plt.figure(figsize=[20, 16])\nax1 = f.add_subplot(2, 3, 1)\nax2 = f.add_subplot(2, 3, 2)\nax3 = f.add_subplot(2, 3, 3)\n\nflood_threshold1.plot.imshow(ax=ax1, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nflood_threshold2.plot.imshow(ax=ax2, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nflood_threshold3.plot.imshow(ax=ax3, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\n\nplt.show()\n\nChanging the threshold by only 2 or 3 dB makes a large difference. If we set a higher threshold, we pick up a lot more false positives. With a lower threshold, we start to create more false negatives and a more fragmented flood extent. Based on the visualisation above, we will use -18 dB as the threshold.\n\nLet’s add the flood mask variable to our Sentinel-1 data cube. At first glance, the below cell may not make much sense. The definition of variable step1 could be interpreted as assigning a value of 1 to pixels that are equal or more than -18 dB. However, what is actually happening is that the .where method preserves all the pixel values of the variable that are below -18 dB and assigns everything else a value of 1. More detailed information on the method can be found in the \n\nrespective xarray documentation.\n\n# Assign all pixels equal or smaller than -18 a value of 1 and preserve the values of pixels \nstep1 = s1_cube.VV_dB.where(s1_cube.VV_dB >= -18, 1)\n\n# Assign all other pixels a value of 0. \nflooded = step1.where(step1 == 1, 0)\n\nflooded.attrs['long_name'] = 'flood_mask'\nflooded.attrs['units'] = 'nounits'\n\ns1_cube['flood_mask'] = flooded\ns1_cube\n\nLet’s plot the generated flood mask over multiple timestamps again:\n\n#### Timestamp selection\nfm1 = s1_cube.flood_mask.sel(time='2022-01-03 07:00:00', method='nearest')\nfm2 = s1_cube.flood_mask.sel(time='2022-01-15 07:00:00', method='nearest')\nfm3 = s1_cube.flood_mask.sel(time='2022-01-27 07:00:00', method='nearest')\nfm4 = s1_cube.flood_mask.sel(time='2022-02-08 07:00:00', method='nearest')\nfm5 = s1_cube.flood_mask.sel(time='2022-02-20 07:00:00', method='nearest')\nfm6 = s1_cube.flood_mask.sel(time='2022-03-04 07:00:00', method='nearest')\nfm7 = s1_cube.flood_mask.sel(time='2022-03-16 07:00:00', method='nearest')\nfm8 = s1_cube.flood_mask.sel(time='2022-03-28 07:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[16, 18])\nax1 = f.add_subplot(3, 3, 1)\nax2 = f.add_subplot(3, 3, 2)\nax3 = f.add_subplot(3, 3, 3)\nax4 = f.add_subplot(3, 3, 4)\nax5 = f.add_subplot(3, 3, 5)\nax6 = f.add_subplot(3, 3, 6)\nax7 = f.add_subplot(3, 3, 7)\nax8 = f.add_subplot(3, 3, 8)\n\naxlist = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8]\n\nt = fm1.plot.imshow(ax=ax1, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nfm2.plot.imshow(ax=ax2, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nfm3.plot.imshow(ax=ax3, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nfm4.plot.imshow(ax=ax4, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nfm5.plot.imshow(ax=ax5, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nfm6.plot.imshow(ax=ax6, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nfm7.plot.imshow(ax=ax7, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nfm8.plot.imshow(ax=ax8, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\n\nplt.show()\n\nDespite the flood mask containing some noise, the chosen threshold looks adequate across time and space. Let’s move on to visualising the data from the temporal point of view.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#creating-a-flood-mask","position":39},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"How to generate a time series plot for a point"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#how-to-generate-a-time-series-plot-for-a-point","position":40},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"How to generate a time series plot for a point"},"content":"We now have a really good picture of how the flooding evolved over space and time. Following this, we want to monitor a specific point location within the AOI and observe how NDWI and then VV_dB variables in the cubes compare over time. Firstly, we define the point’s coordinates with point_lat and point_lon. These are used as inputs when we select the variables accross all available timestamps with the help of the .to_series() method. It’s at this point too that we use the CLM variable to mask out cloudy areas from the Sentinel 2 acquisitions in the time steps.\n\n# Set latitude and longitude of point to query\npoint_lat = -18.96377\npoint_lon = 47.48737\n\n# Get timeseries\nmasked = s2_cube.NDWI.where(s2_cube.CLM == 0)\ntimeseriesNDWI_masked = masked.sel(lat=point_lat, lon=point_lon, method='nearest').to_series()\ntimeseriesNDWI_masked = timeseriesNDWI_masked.where(timeseriesNDWI_masked !=0).dropna()\n\ntimeseriesNDWI = s2_cube.NDWI.sel(lat=point_lat, lon=point_lon, method='nearest').to_series()\ntimeseriesNDWI = timeseriesNDWI.where(timeseriesNDWI !=0).dropna()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#how-to-generate-a-time-series-plot-for-a-point","position":41},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Plot NDWI time series for a given point location","lvl2":"How to generate a time series plot for a point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#plot-ndwi-time-series-for-a-given-point-location","position":42},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Plot NDWI time series for a given point location","lvl2":"How to generate a time series plot for a point"},"content":"Using matplotlib we can now visualise how NDWI changes over time. In the plot we will plot 2 series, a cloud-masked series in blue, and an unmasked series in grey.\n\n# Plot NDWI timeseries\n_, ax = plt.subplots(1, figsize=(15, 6))\nax.plot(timeseriesNDWI, color=\"Grey\", marker=\"o\", linewidth=0.5, alpha=0.4)\nax.plot(timeseriesNDWI_masked, color=\"blue\", linestyle=\"none\", marker=\"o\", linewidth=0.5)\nax.set_title(f\"NDWI timeseries. Latitude: {point_lat}, Longitude: {point_lon}.\")\nplt.show()\n\nThe NDWI time series for Sentinel-2 doesn’t really show us anything significant. There is no farily consistent NDWI value to go from which makes it difficult to establish a point of reference. There are peaks in NDWI at the end of December and the start of February but as was demonstrated earlier cloud cover is a big issue. There are big gaps between non-cloudy acquisitions of over a month in some cases. Let’s plot the same but for the VV polarisation from Sentinel-1.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#plot-ndwi-time-series-for-a-given-point-location","position":43},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Plot VV dB timeseries for a given point location","lvl2":"How to generate a time series plot for a point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#plot-vv-db-timeseries-for-a-given-point-location","position":44},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Plot VV dB timeseries for a given point location","lvl2":"How to generate a time series plot for a point"},"content":"We can now visualise how VV dB changes over time.\n\n# Get timeseries\ntimeseriesVV_dB = s1_cube.VV_dB.sel(lat=point_lat, lon=point_lon, method='nearest').to_series()\ntimeseriesVV_dB = timeseriesVV_dB.where(timeseriesVV_dB !=0).dropna()\n\n# Plot VV_dB timeseries\nfig, ax = plt.subplots(1, figsize=(12, 6))\nax.plot(timeseriesVV_dB, color=\"blue\", marker=\"o\", linewidth=0.5)\nax.set_title(f\"VV dB timeseries. Latitude: {point_lat}, Longitude: {point_lon}.\")\nplt.show()\n\nThis is much clearer than the Sentinel 2 time series as we have more observations due to no interference from cloud cover. We have a clear point of reference for what the VV polarisation response is during flood and non flooded time periods with a VV response of -8 to 0 dB when dry and < - dB when flooded. The time series really clearly shows the two flood events at the end of January and February.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#plot-vv-db-timeseries-for-a-given-point-location","position":45},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Plot VV dB timeseries for a given AOI polygon","lvl2":"How to generate a time series plot for a point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#plot-vv-db-timeseries-for-a-given-aoi-polygon","position":46},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Plot VV dB timeseries for a given AOI polygon","lvl2":"How to generate a time series plot for a point"},"content":"Let’s take this another step further, and generate the time series using a polygon instead of a point. For this we can use for example the administrative regions of Madagaskar, which are included into the geoDB (\n\nsource).\n\nTo be able to use data from the geoDB, we need to instantiate a geoDB client.\n\nfrom xcube_geodb.core.geodb import GeoDBClient\ngeodb = GeoDBClient()\n\nTo see, what geoDB role we have, we can ask who I am. You will see a different id in your workspace.\n\ngeodb.whoami\n\nDifferent resoulution of administrative boundaries of Madagaskar are in the database called “madagascar_adm_boundaries”. Let’s have a look how many different collections we have:\n\ngeodb.get_my_collections(database=\"madagascar_adm_boundaries\")\n\nLet’s have a look, what is in the adm1 collection:\n\nadm1 = geodb.get_collection_pg(\"adm1\", database=\"madagascar_adm_boundaries\")\n\nWe want to get a brief idea of the data inside the collection, so we print out the first few lines of the data\n\nadm1.head()\n\nSometimes it helps more to see a plot of the data, here we group the regions by the column “old_provin”.\n\nadm1.plot(column=\"old_provin\", figsize=(15,15), cmap = 'jet')\n\n\nThe data inside collection adm1 is a bit too coarse for our area of interest, let’s see what we find in adm2:\n\nadm2 = geodb.get_collection_pg(\"adm2\", database=\"madagascar_adm_boundaries\")\n\nadm2.head()\n\nWe are interested in the administrative region of Antananarivo, which belongs to Analamanga. Here we select only the rows which belong to Analamanga.\n\nadm2_Analamanga = geodb.get_collection(\"adm2\", database=\"madagascar_adm_boundaries\", query='adm1_en=eq.Analamanga')\n\n\nadm2_Analamanga\n\nLet’s take a bief look at a plot of our subset:\n\nadm2_Analamanga.plot(figsize=(15,15), cmap = 'jet')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#plot-vv-db-timeseries-for-a-given-aoi-polygon","position":47},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Select regions to mask the cube","lvl2":"How to generate a time series plot for a point"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#select-regions-to-mask-the-cube","position":48},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Select regions to mask the cube","lvl2":"How to generate a time series plot for a point"},"content":"\n\nsub_Analamanga = adm2_Analamanga.loc[(adm2_Analamanga.adm2_en == \"Antananarivo Atsimondrano\") |\n                                     (adm2_Analamanga.adm2_en == \"Antananarivo Avaradrano\") |\n                                     (adm2_Analamanga.adm2_en == \"Ambohidratrimo\") |\n                                     (adm2_Analamanga.adm2_en == \"1er Arrondissement\") |\n                                     (adm2_Analamanga.adm2_en == \"2e Arrondissement\") |\n                                     (adm2_Analamanga.adm2_en == \"3e Arrondissement\") |\n                                     (adm2_Analamanga.adm2_en == \"4e Arrondissement\") |\n                                     (adm2_Analamanga.adm2_en == \"5e Arrondissement\") |\n                                     (adm2_Analamanga.adm2_en == \"6e Arrondissement\") ]\n\nsub_Analamanga\n\nsub_Analamanga.plot(figsize=(15,15), cmap = 'jet')\n\n\nNow we have selected only the rows which we are interested in. But they are in seperate geometry objects:\n\nsub_Analamanga.geometry\n\nUnify the subareas into one area of interest:\n\nAntananarivo_region = shapely.ops.unary_union(geoms=[sub_Analamanga.geometry.iloc[i] for i in range(len(sub_Analamanga.geometry))])\n\n# Plot the polygon on a map\n\nIPython.display.GeoJSON(shapely.geometry.polygon.Polygon(Antananarivo_region).__geo_interface__)\n\nNext, let’s mask our dataset by the polygon we have just defined and visualise our ‘masked’ datacube.\n\ns1_cube\n\nNow we take a look at the data which is within our desired administrative boundaries. Therefore we mask the s1_cube:\n\nwater_antananarivo = mask_dataset_by_geometry(s1_cube, geometry=Antananarivo_region)\n\nLet’s visualise our masked data cube using the timestep on 27th January and the VV_dB variable:\n\nwater_antananarivo.VV_dB.isel(time=2).plot.imshow(cmap='Greys', vmin=-20, vmax=0, figsize=(10, 10))\nplt.show()\n\nOK, this looks good. Now we are going to calculate the mean VV dB polarisation across the area for each time step. Firstly, we want to calculate the mean VV_dB on axis 1 (lat) and 2 (lon). The second function removes any observations with values of 0 (observations that don’t cover our area of interest).\n\n# calculate the mean VV dB for each time step\ntimeseriesVV_dB = water_antananarivo.VV_dB.mean(axis=(1,2), skipna=True)\n\n# remove any observations with no data\ntimeseriesVV_dB = timeseriesVV_dB.where(timeseriesVV_dB !=0).dropna(\"time\")\n\n# return the new data cube chunk\ntimeseriesVV_dB\n\nNext we can plot this new array we have generated. The result is an excellent time series plot showing the two flood events that occured in the time period. We can see the larger picture as this is the mean value over several pixels rather than just a single point like we previously plotted.\n\n# Plot VV_dB timeseries\nfig, ax = plt.subplots(1, figsize=(12, 6))\nax.plot(timeseriesVV_dB.time, timeseriesVV_dB, color=\"blue\", marker=\"o\", linewidth=0.5)\nax.set_title(\"Mean VV dB returned from AOI over 01-01-2022 to 01-05-2022\")\nax.set_xlabel('Time')\nax.set_ylabel('VV dB')\nplt.show()\n\nIn the time series plot generated from averaged VV_dB values over the selected region, the two separate flooding events appear appear as one longer period with surface flooding that stretches from mid January to early March 2022.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#select-regions-to-mask-the-cube","position":49},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Creating advanced variables"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#creating-advanced-variables","position":50},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Creating advanced variables"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#creating-advanced-variables","position":51},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Mapping flooding frequency across the whole AOI","lvl2":"Creating advanced variables"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#mapping-flooding-frequency-across-the-whole-aoi","position":52},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl3":"Mapping flooding frequency across the whole AOI","lvl2":"Creating advanced variables"},"content":"We can utilise the generated water mask to calculate the flooding frequency proportionate to the overall number of observations. Since the flood mask is a binary layer, we just need to calculate the sum of all flooded observations for each pixel and divide it by the total number (count) of observations.\n\nflood_sum = s1_cube.flood_mask.sum(dim=\"time\")\nflood_count = s1_cube.flood_mask.count(dim=\"time\")\nflood_average = flood_sum / flood_count\n\nflood_average.attrs['long_name'] = 'flood_average'\nflood_average.attrs['units'] = 'nounits'\n\ns1_cube['flood_average'] = flood_average\n\nNow let’s plot the flood_average into a plot:\n\nflood_average.plot.imshow(cmap='GnBu', vmin=0, vmax=0.5, figsize=(10, 10))\nplt.show()\n\nFor our end product, we have visualised the flood plain extent very clearly here and can also identify some areas that are more susceptible to flooding than others. Added value products like this flood average map enable policy makers to make more informed decisions,\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#mapping-flooding-frequency-across-the-whole-aoi","position":53},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Export a variable to GeoTiff"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#export-a-variable-to-geotiff","position":54},{"hierarchy":{"lvl1":"Leverage Euro Data Cube services for accessing, analysing and visualising EO data","lvl2":"Export a variable to GeoTiff"},"content":"Finally we will export some of the variables we have generated in this notebook. This is really easy to do and is shown in the next cell:\n\n# define the timestep you wish to export\ntimestep = flood_threshold2_step2.sel(time='2022-01-27 10:00:00', method='nearest')\n\n# define projection\ntimestep_wgs84 = timestep.rio.write_crs(\"epsg:4326\")\n\n# write to raster\ntimestep_wgs84.rio.to_raster(\"flood_extent_20220127.tif\")\n\nNow let’s export the flood_average variable which is even easier to do as we don’t need to select a single timestamp.\n\n# define projection\nflood_average_wgs84 = flood_average.rio.write_crs(\"epsg:4326\")\n\n# write to raster\nflood_average_wgs84.rio.to_raster(\"flood_average.tif\")","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/lps2022-leverage-euro-data-cube-services#export-a-variable-to-geotiff","position":55},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns","position":0},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-0.24.5\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns","position":1},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#impact-of-covid19-induced-lockdown-on-no2-levels","position":2},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels"},"content":"Countries have initiated lockdown measures to control the spread of the disease\n\nNot all of the measures were successful (Italy)\n\nCountries (Germany) which successful implemented a lockdown showed a marked decrease in NO2 levels\n\nNO2 is produced when fossil fuels are burned, as during transportation (cars, trucks etc. ) or\n\ndue to other economic activities (like factories )\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#impact-of-covid19-induced-lockdown-on-no2-levels","position":3},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Load required dependencies & credentials"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#load-required-dependencies-credentials","position":4},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Load required dependencies & credentials"},"content":"\n\n# Import required packages\n\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.sentinelhub import SentinelHub\nimport xarray as xr\n\nfrom sentinelhub import BBox, WmsRequest, DataSource, SHConfig\nfrom functools import partial\n\nimport numpy as np\nimport pandas as pd\n\nfrom matplotlib import pyplot as plt\n\n\n# Set Sentinel Hub credentials\n\nimport os\nsh_credentials = dict(client_id=os.environ['SH_CLIENT_ID'],\n                      client_secret=os.environ['SH_CLIENT_SECRET']) # This is only provided when the Oauth credentials are created\n\n# Sentinel-3 OLCI, Sentinel-3 SLSTR and Sentinel-5 layers are processed on different infrastructure, \n# which requires to used different end-point\n\nsh_credentials.update(api_url='https://creodias.sentinel-hub.com') \n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#load-required-dependencies-credentials","position":5},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Core function to calculate NO2 values"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#core-function-to-calculate-no2-values","position":6},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Core function to calculate NO2 values"},"content":"NO2 values are calculated over the given period (Jan -May) for 2020 & 2019\n\ndef caculateNO2(geometry, timerange):\n    \"\"\"\n    parameters:\n    geometry: BBox object to be passed. This contains the bounding box for the area of interest (AOI)\n    timerange: list giving the start & end of the time range format: YYYY-mm-dd\n    \n    return:\n    a dataframe with two columns: Mean NO2 and Timestamp\n    NO2 mean values for the time span between given timerange \n    \n    \"\"\"\n    cube_config = CubeConfig(dataset_name='S5PL2',\n                         band_names=['NO2'],\n                         tile_size=[512, 512],\n                         geometry=geometry,\n                         spatial_res=abs(bbox[2]-bbox[0])/512,\n                         time_range= timerange,\n                         time_period='3D') \n    cube = open_cube(cube_config, **sh_credentials)\n\n    no2_values = list() \n    timestamp = list()\n\n    for i in range(cube.time.shape[0]):\n        no2_values.append(np.nanmean(cube.NO2.isel(time=i).values[0]))\n        timestamp.append(cube.NO2.isel(time=i).time.values)\n        \n    assert len(no2_values) == len(timestamp)\n    \n    return pd.DataFrame({'DateTime': timestamp, 'Mean NO2': no2_values})\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#core-function-to-calculate-no2-values","position":7},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Read area of interest as a csv file"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#read-area-of-interest-as-a-csv-file","position":8},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Read area of interest as a csv file"},"content":"Uncomment the next code block if you want to read the AOI from a csv file\n\nFile has the following columns:\n\nCountry: Name of country/territory of interest\n\nx1, y1 : Upper left corner co-ordinates (lat/lon)\n\nx2, y2 : Lower right corner co-ordinates\n\n# aoi = pd.read_csv('AOI.csv')\n# print(aoi.shape)\n# print(aoi.head(8))\n\n# shape = aoi.shape\n# nullCount = sum(aoi.isna().sum())\n# print(f\"Shape of 2020 DF: {shape}, Count of Null values: {nullCount}\".format(shape , nullCount ))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#read-area-of-interest-as-a-csv-file","position":9},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Define AOI as a list"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#define-aoi-as-a-list","position":10},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Define AOI as a list"},"content":"This is a list of dictionaries with the required information\n\nEach dict has the following keys:\n\nCountry: Name of country/territory of interest\n\nx1, y1 : Upper left corner co-ordinates (lat/lon)\n\nx2, y2 : Lower right corner co-ordinates\n\naoi = list()\n\n#Define two dicts\ncountry1 = dict()\ncountry1['Country'] = 'Italy'\ncountry1['x1'] = 46.28 \ncountry1['y1'] = 6.42\ncountry1['x2'] = 37.25\ncountry1['y2'] = 19.73\naoi.append(country1)\n\ncountry2 = dict()\ncountry2['Country'] = 'Germany'\ncountry2['x1'] = 54.77 \ncountry2['y1'] = 4.70\ncountry2['x2'] = 47.63\ncountry2['y2'] = 15.73\naoi.append(country2)\n\n#print(len(aoi))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#define-aoi-as-a-list","position":11},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Main loop"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#main-loop","position":12},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Main loop"},"content":"We iterate over each row in the aoi.csv file\n\nSentinel-5P data for each defined AOI cube is extracted\n\nNO2 values for each tile is then averaged & stored in a list\n\nFor the purpose of this demo we will calculate the NO2 values for one AOI and for one month\n(That will ensure that we don’t exceed the timelimit of 10mins!)\n\nimport time \n\nstart = time.time()\naoi_no2 = list()\n\n# Check length of provided aoi list OR dataframe\nlen_aoi = len(aoi)\n\n# Define how many AOIs you want to process. For the demo we will use only one \ncounter = 1\n\nfor idx in range(counter):\n    aoi_dict = dict()\n    \n    # Check if aoi is passed as a list or a dataframe\n    if isinstance(aoi, list):\n        aoi_dict['Country_BBox'] = aoi[idx]['Country']\n        x1 = int(aoi[idx]['x1'])  # degree \n        y1 = int(aoi[idx]['y1'])  # degree\n        x2 = int(aoi[idx]['x2'])  # degree\n        y2 = int(aoi[idx]['y2'])  # degree\n                \n    else:\n        aoi_dict['Country_BBox'] = aoi.loc[idx]['Country']\n        print(\"Processing: \", aoi_dict['Country_BBox'])\n        x1 = int(aoi.loc[idx]['x1'])  # degree \n        y1 = int(aoi.loc[idx]['y1'])  # degree\n        x2 = int(aoi.loc[idx]['x2'])  # degree\n        y2 = int(aoi.loc[idx]['y2'])  # degree\n\n    bbox = x1, y1, x2, y2\n    timerange = ['2020-01-01', '2020-01-31']\n    aoi_dict['NO2_2020'] = caculateNO2(bbox, timerange)\n    shape = aoi_dict['NO2_2020'].shape\n    nullCount = sum(aoi_dict['NO2_2020'].isna().sum())\n    print(f\"Shape of 2020 DF: {shape}, Count of Null values: {nullCount}\".format(shape , nullCount ))    \n    \n    timerange = ['2019-01-01', '2019-01-31']\n    aoi_dict['NO2_2019'] = caculateNO2(bbox, timerange)\n    shape = aoi_dict['NO2_2019'].shape\n    nullCount = sum(aoi_dict['NO2_2019'].isna().sum())\n    print(f\"Shape of 2019 DF: {shape}, Count of Null values: {nullCount}\".format(shape , nullCount ))\n\n    aoi_no2.append(aoi_dict)\n\nend = time.time()\n#print(len(aoi_no2))\n\n\nprint(\"Total processing time: {:.2} mins\".format((end-start)/60)) \n\nThe list is then pickled so that the information can then be reused in another run\n\nimport pickle \n#print(len(aoi_no2))\nwith open('aoi_list_no2.pkl', 'wb') as f:\n    pickle.dump(aoi_no2, f)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#main-loop","position":13},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Plotting function"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#plotting-function","position":14},{"hierarchy":{"lvl1":"Impact of Covid19 induced lockdown on NO2 levels","lvl2":"Plotting function"},"content":"This plots the NO2 values over time\n\nimport matplotlib.pyplot as plt\n\ndef plot_no2(idx):\n    \"\"\"\n    parameters:\n    idx: Input id for accessing NO2 data \n    \n    return:\n    None\n    line plots for NO2 (2020 vs 2019) are generated\n    \"\"\"\n\n    plt.plot(aoi_no2[idx]['NO2_2020']['DateTime'], aoi_no2[idx]['NO2_2020']['Mean NO2'],  label = 'NO2 levels (2020)')\n    plt.plot(aoi_no2[idx]['NO2_2020']['DateTime'], aoi_no2[idx]['NO2_2019']['Mean NO2'], label = 'NO2 levels (2019)')\n    plt.ylabel('NO2 Levels')\n    plt.xlabel('Month')\n    plt.title('NO2 levels for '+ aoi_no2[idx]['Country_BBox'])\n    plt.legend()\n    plt.savefig(aoi_no2[idx]['Country_BBox']+'.png')\n    plt.show()\n\nfor idx in range(len(aoi_no2)):\n    plot_no2(idx)\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-analysis-covid19-lockdowns#plotting-function","position":15},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator","position":0},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE"},"content":"Indicator E8 is calculated at the logistic areas operated at the production sites such as motor vehicle manufacturing, the large number of metal objects (e.g. machinery, vehicles) produces a strong signature in the radar backscatter signal. The observations are provided by the Synthetic Aperture Radar such as the C-band Copernicus Sentinel-1 satellites (source: \n\nRACE ESA)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator","position":1},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Importing needed modules"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#importing-needed-modules","position":2},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Importing needed modules"},"content":"\n\n#imports\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport datetime as dt\nimport os\n\nfrom matplotlib import mlab\nfrom shapely import geometry, wkt\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nfrom datetime import datetime\n\nfrom sentinelhub import (\n    CRS,\n    BBox,\n    DataCollection,\n    Geometry,\n    SentinelHubStatistical,\n    SentinelHubStatisticalDownloadClient,\n    SHConfig,\n    parse_time,\n    geometry,\n    SentinelHubCatalog,\n    bbox_to_dimensions,\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#importing-needed-modules","position":3},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"SentinelHub account configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#sentinelhub-account-configuration","position":4},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"SentinelHub account configuration"},"content":"\n\nsh_client_id=\"\"\nsh_client_secret=\"\"\n\nif not sh_client_id:\n    sh_client_id = os.environ[\"SH_CLIENT_ID\"]\n\nif not sh_client_secret:\n    sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n\nif not sh_client_id or not sh_client_secret:\n    raise ValueError(\"No valid Sentinel HUB credentials are available. Plese contact system administrator.\")    \n    \nconfig = SHConfig()\n\nconfig.sh_client_id = sh_client_id\nconfig.sh_client_secret = sh_client_secret\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#sentinelhub-account-configuration","position":5},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Input Parameters"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#input-parameters","position":6},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Input Parameters"},"content":"Volvo Cars, Ghent, Belgium\n\naoi = \"POLYGON ((3.754824 51.096633, \\\n              3.753451 51.096242, \\\n              3.755747 51.093102, \\\n              3.755661 51.09511, \\\n              3.755211 51.094989, \\\n              3.754953 51.095393, \\\n              3.755211 51.09608, \\\n              3.755125 51.0967, \\\n              3.755447 51.097953, \\\n              3.755168 51.098048, \\\n              3.755009 51.097886, \\\n              3.754116 51.097697, \\\n              3.754824 51.096633))\"\n\ntime_period= \"2023-01-01/2023-05-31\"\n\nOUTPUT_DIR = \"\" # \"/home/E8/result-data/e8\" # will be copied to the local folder of the user requesting the data\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#input-parameters","position":7},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl4":"Parameter preparation","lvl3":"Input Parameters"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#parameter-preparation","position":8},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl4":"Parameter preparation","lvl3":"Input Parameters"},"content":"\n\nfrom_to = time_period.split(\"/\")\n\ninterval = (f'{from_to[0]}T00:00:00Z', f'{from_to[1]}T23:59:59Z')\nprint(f'interval: {interval}')\n\ngeometry = Geometry(aoi, crs=CRS.WGS84)\nprint(geometry)\n\nsize = bbox_to_dimensions(geometry.bbox, resolution=5)\nprint(f'size: {size}')\n\ncollection = DataCollection.SENTINEL1_IW\nprint(f'collection: {collection}')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#parameter-preparation","position":9},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Evalscript definition"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#evalscript-definition","position":10},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Evalscript definition"},"content":"Evalscript to retreve the VH channel in linear units\n\n#evalscript (linear units)\nevalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\n      bands: [\"VH\", \"dataMask\"]\n    }],\n    output: [\n      {\n        id: \"default\",\n        bands: 1\n      },\n      {\n        id: \"dataMask\",\n        bands: 1\n      }]\n  };\n}\n\nfunction evaluatePixel(samples) {\n    return {\n        default: [samples.VH],\n        dataMask: [samples.dataMask],\n    };\n}\n\n\"\"\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#evalscript-definition","position":11},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"SentinelHub statistical API request (linear units)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#sentinelhub-statistical-api-request-linear-units","position":12},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"SentinelHub statistical API request (linear units)"},"content":"\n\n# Definition of the SentinelHUB statistical API request (linear unit)\nrequest = SentinelHubStatistical(\n    aggregation=SentinelHubStatistical.aggregation(\n        evalscript=evalscript,\n        time_interval=interval,\n        aggregation_interval='P1D', \n        size=size\n    ),\n    input_data=[\n        SentinelHubStatistical.input_data(\n            collection,            \n            other_args={\"dataFilter\": {\"mosaickingOrder\": \"mostRecent\",\"resolution\": \"HIGH\"},\n                        \"processing\": {\"orthorectify\": \"True\",\"backCoeff\": \"GAMMA0_TERRAIN\",\"demInstance\": \"COPERNICUS\"}},            \n      ),\n    ],\n    geometry=geometry,\n    config=config\n)\n\n# helper function\n\ndef stats_to_df(stats_data):\n    \"\"\"Transform Statistical API response into a pandas.DataFrame\"\"\"\n    df_data = []\n\n    for single_data in stats_data[\"data\"]:\n        df_entry = {}\n        is_valid_entry = True\n\n        df_entry[\"interval_from\"] = parse_time(single_data[\"interval\"][\"from\"]).date()\n        df_entry[\"interval_to\"] = parse_time(single_data[\"interval\"][\"to\"]).date()\n\n        for output_name, output_data in single_data[\"outputs\"].items():\n            for band_name, band_values in output_data[\"bands\"].items():\n\n                band_stats = band_values[\"stats\"]\n                if band_stats[\"sampleCount\"] == band_stats[\"noDataCount\"]:\n                    is_valid_entry = False\n                    break\n                band_name='gamma0'\n                for stat_name, value in band_stats.items():\n                    col_name = f\"{output_name}_{band_name}_{stat_name}\"\n                    if stat_name == \"percentiles\":\n                        for perc, perc_val in value.items():\n                            perc_col_name = f\"{col_name}_{perc}\"\n                            df_entry[perc_col_name] = perc_val\n                    else:\n                        df_entry[col_name] = value\n\n        if is_valid_entry:\n            df_data.append(df_entry)\n\n    return pd.DataFrame(df_data)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#sentinelhub-statistical-api-request-linear-units","position":13},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Execute statistical API call"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#execute-statistical-api-call","position":14},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Execute statistical API call"},"content":"\n\n%%time\n\nstats = request.get_data()[0]\n\nstats\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#execute-statistical-api-call","position":15},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl2":"Convert to Dataframe"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#convert-to-dataframe","position":16},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl2":"Convert to Dataframe"},"content":"\n\n#convert statistical data to pandas dataframe\ndf = stats_to_df(stats)\ndf=df[['interval_from','default_gamma0_mean']]\ndf.rename(columns = {'interval_from':'Acquisition date','default_gamma0_mean':'mean_gamma0'}, inplace = True)\ndf.head()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#convert-to-dataframe","position":17},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Removing outliers","lvl2":"Convert to Dataframe"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#removing-outliers","position":18},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Removing outliers","lvl2":"Convert to Dataframe"},"content":"\n\ndef remove_and_interpolate_outliers(df):\n    import pandas as pd\n    import numpy as np\n    # Read stats file\n    \n    # create thresholds\n    min_threshold, max_threshold = df['mean_gamma0'].quantile([0.01,0.99])\n    \n    # create a new dataframe excluding the outlier rows\n    outlier_removed = df[(df['mean_gamma0'] < max_threshold)&(df['mean_gamma0'] > min_threshold)]\n    outliersId = df[(df['mean_gamma0'] >= max_threshold) | (df['mean_gamma0'] <= min_threshold)].index\n    \n    # diplay the shape of new dataset\n    print(outlier_removed.shape)\n    # the orignal shape \n    print(df.shape)\n    \n    df2=df.copy()\n    # fill with nans\n    df2.loc[outliersId,['mean_gamma0']]=np.nan\n    # interpolate nans\n    outlier_rem_interp = df2.interpolate(method='nearest',order=2)\n    return outlier_rem_interp\n\ndf_filt=remove_and_interpolate_outliers(df)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#removing-outliers","position":19},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Exporting results","lvl2":"Convert to Dataframe"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#exporting-results","position":20},{"hierarchy":{"lvl1":"Finished Goods Inventory indicator for RACE","lvl3":"Exporting results","lvl2":"Convert to Dataframe"},"content":"\n\ndf.to_csv(os.path.join(OUTPUT_DIR,'average_gamma0_time_series.csv'),index=False)\n\nimport matplotlib.pyplot as plt\nimport matplotlib\n\nfig = df_filt.plot(x='Acquisition date', figsize=(20, 10), fontsize=10).get_figure()\nplt.title('Time series of normalized radar backscatter [gamma0]')\nplt.ylabel('gamma0')\nfig.savefig(os.path.join(OUTPUT_DIR,'average_gamma0_time_series.pdf'))","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/race-finishedgoodsinventory-inidcator#exporting-results","position":21},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope","position":0},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope"},"content":"This Jupyter Notebook demonstrates how to import PlanetScope data into Sentinel Hub and then access it.\n\nWe will use Simple search and Order products APIs[1].\n\nUseful links:[1] \n\nTPDI API documentation[2] \n\nTPDI API reference (Swagger documentation)[3] \n\nAbout PlanetScope data\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope","position":1},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Imports and credentials"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#imports-and-credentials","position":2},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Imports and credentials"},"content":"\n\nTo run this JN, you will need:\n\nSH crednetinal (client_id and client_secret)\n\nPlanet’s APi key (PLANET_API_KEY)\n\nIf you are running the JN ouside of EDC JupyterHub (e.g., localy) you will have to provide these credentials manually in a cell starting with “# Credentials”.\n\nIf you are running the JN on EDC JupyterHub and have activated an EDC SH subscription, you only need to provide your Planet API key.\n\nfrom edc import setup_environment_variables\nsetup_environment_variables()\n\n# Credentials\nclient_id = %env SH_CLIENT_ID\nclient_secret = %env SH_CLIENT_SECRET\nPLANET_API_KEY = %env MY_PLANET_API_KEY\n\nimport requests \nimport json\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\nimport os\nimport datetime\nimport dateutil.parser\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\n\n# Get token for the session\ntoken = oauth.fetch_token(\n    token_url='https://services.sentinel-hub.com/oauth/token',\n    client_id=client_id, client_secret=client_secret\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#imports-and-credentials","position":3},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Get my quota"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#get-my-quota","position":4},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Get my quota"},"content":"\n\nTo order PlanetScope data one needs to have enough avaliable quota tied to his SH account. To check your quota:\n\n#Get my quota\nurl = f\"https://services.sentinel-hub.com/dataimport/v1/quotas\"\n\nr = oauth.get(url=url)\nr.json()\n\nWe see that the user bought quota for 50 km^2 of PlanetScope data and has already ordered 5 km^2 of data. Here are more details about \n\nPurshasing PlanetSope data.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#get-my-quota","position":5},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Search"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#search","position":6},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Search"},"content":"\n\n# User's defiend search criteria\n# aoi\n#aoi = {'type': 'Polygon',\n#  'coordinates': [[[12.560804463221928, 41.885177999999996],\n#    [12.585804463221926, 41.885177999999996],\n#    [12.585804463221926, 41.910178],\n#    [12.560804463221928, 41.910178],\n#    [12.560804463221928, 41.885177999999996]]]}\n\naoi = {\"type\": \"Polygon\", \n       \"coordinates\": [[[12.567054463221927, 41.891428], \n                        [12.579554463221926, 41.891428], \n                        [12.579554463221926, 41.903928], \n                        [12.567054463221927, 41.903928], \n                        [12.567054463221927, 41.891428]]]}\n# dates\ndate_from = \"2020-04-15T00:00:00.000Z\"\ndate_to = \"2020-04-17T00:00:00.000Z\"\n\n# max cloud coverage\nmaxcc = 30\n\n# Search\nurl = \"https://services.sentinel-hub.com/dataimport/v1/search\"\n\nquery = {\n    \"provider\": \"PLANET\",\n    \"planetApiKey\": PLANET_API_KEY,\n    \"bounds\": {\n        \"geometry\": aoi\n    },\n    \"data\": [\n        {\n            \"itemType\": \"PSScene4Band\",\n            \"dataFilter\": {\n                \"timeRange\": {\n                    \"from\": date_from,\n                    \"to\": date_to\n                },\n                \"maxCloudCoverage\": maxcc\n            }\n        }\n    ]\n}\n\nresponse = oauth.post(url, json=query)\nresponse.raise_for_status()\n\nresults = response.json()\nresults\n\n# Print out the most interesting metadata\nsearch_results = [(feature[\"id\"], feature[\"properties\"]['acquired'], \\\n                   feature[\"properties\"]['cloud_cover']) \\\n                   for feature in results[\"features\"]]\nprint(\"Product id \\t acquisition date & time \\t cloud cover  \")\nfor item in search_results:\n    print(item[0],   item[1],   item[2])\n\n# Additional filtering of search results by cloud coverage\nitem_ids = [feature['id'] for feature in results[\"features\"] \n            if feature[\"properties\"]['cloud_cover'] == 0]\nitem_ids\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#search","position":7},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Order data import"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#order-data-import","position":8},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Order data import"},"content":"\n\nurl = \"https://services.sentinel-hub.com/dataimport/v1/orders\"\n\nquery['data'][0][\"productBundle\"] = \"analytic\"\n\nname = \"EDC demo 1\"\npayload = {\n    \"name\": name,\n    \"input\": query\n}\n\nresponse = oauth.post(url, json=payload)\nresponse.raise_for_status()\n\norder = response.json()\n\norder_id = order['id']\narea = order['sqkm']\nprint(f\"Order {name}, id: {order_id}, area: {area} km^2\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#order-data-import","position":9},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Confirm the order"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#confirm-the-order","position":10},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Confirm the order"},"content":"\n\nurl = f\"https://services.sentinel-hub.com/dataimport/v1/orders/{order_id}/confirm\"\n\nresponse = oauth.post(url)\nresponse.raise_for_status()\n\nresponse.json()[\"status\"]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#confirm-the-order","position":11},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl2":"Check Status"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#check-status","position":12},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl2":"Check Status"},"content":"\n\norder_id = order_id\n\nurl = f\"https://services.sentinel-hub.com/dataimport/v1/orders/{order_id}\"\n\nresponse = oauth.get(url)\nresponse.raise_for_status()\n\norder_status = response.json()\n\norder_status[\"status\"]\n\n# Save the collection id\ncollection_id = order_status[\"collectionId\"]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#check-status","position":13},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"List all orders","lvl2":"Check Status"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#list-all-orders","position":14},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"List all orders","lvl2":"Check Status"},"content":"\n\nurl = \"https://services.sentinel-hub.com/dataimport/v1/orders\"\n\nresponse = oauth.get(url)\nresponse.raise_for_status()\n\n#response.json()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#list-all-orders","position":15},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Access the data","lvl2":"Check Status"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#access-the-data","position":16},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl3":"Access the data","lvl2":"Check Status"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#access-the-data","position":17},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl4":"Prepare a bbox","lvl3":"Access the data","lvl2":"Check Status"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#prepare-a-bbox","position":18},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl4":"Prepare a bbox","lvl3":"Access the data","lvl2":"Check Status"},"content":"\n\nminx, miny = aoi[\"coordinates\"][0][0]\nmaxx, maxy = aoi[\"coordinates\"][0][2]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#prepare-a-bbox","position":19},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl4":"Prepare evalscript","lvl3":"Access the data","lvl2":"Check Status"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#prepare-evalscript","position":20},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl4":"Prepare evalscript","lvl3":"Access the data","lvl2":"Check Status"},"content":"\n\n# True color\nevalscript_true_color = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\"bands\": [\"B1\", \"B2\", \"B3\"]}],\n    output: { bands: 3}\n  };\n}\n\nvar f = 3000;\nfunction evaluatePixel(sample) {\n  return [sample.B3, sample.B2, sample.B1].map(s => s / f);\n}\n\"\"\"\n\n# NDVI\nevalscript_ndvi = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\"bands\": [\"B3\", \"B4\"]}],\n    output: { bands: 3}\n  };\n}\n\nfunction evaluatePixel(sample) {\n  var ndvi = (sample.B4 - sample.B3) / (sample.B4 + sample.B3)\n  return colorBlend(ndvi, [0.0, 0.2, 0.6], [[1,0,0], [1,1,0], [0.1,0.30,0]])\n}\n\"\"\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#prepare-evalscript","position":21},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl4":"Access data with SH process API","lvl3":"Access the data","lvl2":"Check Status"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#access-data-with-sh-process-api","position":22},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl4":"Access data with SH process API","lvl3":"Access the data","lvl2":"Check Status"},"content":"\n\n# Prepare process API request\nbody = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [minx, miny, maxx, maxy],\n            \"properties\":{\n                \"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"\n            }\n        },\n        \"data\": [\n            {\n                \"type\": \"CUSTOM\",\n                \"dataFilter\": {\n                    \"collectionId\": collection_id,\n                    \"timeRange\": {\n                        \"from\": date_from,\n                        \"to\": date_to\n                    },\n                }\n            }\n        ]\n    },\n    \"evalscript\": \"\",\n    \"output\": {\n        \"height\": 512,\n        \"width\": 512,\n        \"responses\": [\n          {\n            \"identifier\": \"default\",\n            \"format\": {\n                  \"type\": \"image/jpeg\",\n                   \"quality\": 100\n                }\n          }\n        ]\n    }\n}\n\ndef override_evalscript_in_body (body, evalscript):\n    body [\"evalscript\"] = evalscript\n    return body\n\nresponse_true_color = oauth.post(\n    'https://services.sentinel-hub.com/api/v1/process', \n    json=override_evalscript_in_body(body, evalscript_true_color)\n)\nresponse_ndvi = oauth.post(\n    'https://services.sentinel-hub.com/api/v1/process', \n    json=override_evalscript_in_body(body, evalscript_ndvi)\n)\nif response_true_color.status_code == response_ndvi.status_code == 200:\n    print(\"Success\")\n\nresponse_true_color.json()\n\nimport io\nfrom PIL import Image\n\n# Display true color and  NDVI\nim1 = Image.open(io.BytesIO(response_true_color.content))\nim2 = Image.open(io.BytesIO(response_ndvi.content))\n\ndef get_concat_h(im1, im2):\n    dst = Image.new('RGB', (im1.width + im2.width+10, im1.height))\n    dst.paste(im1, (0, 0))\n    dst.paste(im2, (im1.width+10, 0))\n    return dst\n\nget_concat_h(im1, im2)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#access-data-with-sh-process-api","position":23},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl4":"Request S2 data for comparison","lvl3":"Access the data","lvl2":"Check Status"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#request-s2-data-for-comparison","position":24},{"hierarchy":{"lvl1":"Third Party Data Import - PlanetScope","lvl4":"Request S2 data for comparison","lvl3":"Access the data","lvl2":"Check Status"},"content":"\n\ndate_from = \"2020-04-10T00:00:00.000Z\" # We extend the time range, as there \n                                       # was no S2 image available for given\n                                       # aoi and time range\n\nevalscript_s2_true_color = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [{\"bands\": [\"B02\", \"B03\", \"B04\"]}],\n    output: { bands: 3}\n  };\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.B04*2.5, sample.B03*2.5, sample.B02*2.5];\n}\n\"\"\"\n\n\n# Prepare process API request\nbody = {\n    \"input\": {\n        \"bounds\": {\n            \"bbox\": [minx, miny, maxx, maxy],\n            \"properties\":{\n                \"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"\n            }\n        },\n        \"data\": [\n            {\n                \"type\": \"S2L1C\",\n                \"dataFilter\": {\n                    \"timeRange\": {\n                        \"from\": date_from,\n                        \"to\": date_to\n                    },\n                }\n            }\n        ]\n    },\n    \"evalscript\": \"\",\n    \"output\": {\n        \"height\": 512,\n        \"width\": 512,\n        \"responses\": [\n          {\n            \"identifier\": \"default\",\n            \"format\": {\n                  \"type\": \"image/jpeg\",\n                   \"quality\": 100\n                }\n          }\n        ]\n    }\n}\n\nresponse_s2_true_color = oauth.post( \\\n            'https://services.sentinel-hub.com/api/v1/process',\n            json=override_evalscript_in_body(body, \n                                             evalscript_s2_true_color))\n\nstream = io.BytesIO(response_s2_true_color.content)\nimg_s2_true_color = Image.open(stream)\n\n# Display PlanetScope true color on the left and S2 L1C on the right\nget_concat_h(im1, img_s2_true_color)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/third-party-planetscope#request-s2-data-for-comparison","position":25},{"hierarchy":{"lvl1":"Important notes"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh","position":0},{"hierarchy":{"lvl1":"Important notes"},"content":"from edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh","position":1},{"hierarchy":{"lvl1":"Important notes","lvl2":"Important notes"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#important-notes","position":2},{"hierarchy":{"lvl1":"Important notes","lvl2":"Important notes"},"content":"This notebook requires:\n\nAWS credentials -> for boto3 setup options see \n\nhttps://​boto3​.amazonaws​.com​/v1​/documentation​/api​/latest​/guide​/configuration​.html\n\nS3 bucket (exposed as environment variable AWS_BUCKET) -> for bucket configuration see \n\nhttps://​docs​.sentinel​-hub​.com​/api​/latest​/​#​/BATCH​_API​/batch​_processor\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#important-notes","position":3},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#client-side-processing-using-data-prepared-via-edc-mass-sentinel-hub","position":4},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#client-side-processing-using-data-prepared-via-edc-mass-sentinel-hub","position":5},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Imports"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#imports","position":6},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Imports"},"content":"\n\n# util\nimport numpy as np\nimport xarray as xr\nimport boto3\nimport json\nimport csv\nimport io\nfrom IPython.display import clear_output\n\n# date & time\nimport time\nfrom datetime import timezone, date, datetime\nfrom dateutil.relativedelta import relativedelta as rdelta\nfrom dateutil.rrule import rrule, MONTHLY\n\n# Oauth\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#imports","position":7},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Get authorization token"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#get-authorization-token","position":8},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Get authorization token"},"content":"\n\n# Your client credentials\nclient_id = %env SH_CLIENT_ID\nclient_secret = %env SH_CLIENT_SECRET\n\n# Create a session\nclient = BackendApplicationClient(client_id=client_id)\noauth = OAuth2Session(client=client)\n\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_id=client_id, client_secret=client_secret)\n\nresp = oauth.get(\"https://services.sentinel-hub.com/oauth/tokeninfo\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#get-authorization-token","position":9},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Configure Request"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#configure-request","position":10},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Configure Request"},"content":"Enter start and end date, input bands, indices. The resulting data cube will have two time intervals per month, being split at day_of_new_interval.\n\nstartdate = date(2018,7,1) # Y,M,D\nenddate = date(2018,9,15)  # Y,M,D\n\ninput_bands = [\"B03\",\n               \"B04\",\n               \"B05\",\n               \"B08\"]\nindices = ['NDVI',\n           \"NDWI\",\n           \"CVI\"]\n\nbucket_name = %env AWS_BUCKET\n\nday_of_new_interval = 16 # leave this unchanged in most of the cases\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#configure-request","position":11},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl3":"Calculate Data Cube Parameters","lvl2":"Configure Request"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#calculate-data-cube-parameters","position":12},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl3":"Calculate Data Cube Parameters","lvl2":"Configure Request"},"content":"\n\nstarttime = datetime(*startdate.timetuple()[:6])\nendtime = datetime(*enddate.timetuple()[:6])\n\nd=day_of_new_interval\ndates = list(rrule(MONTHLY, dtstart=startdate, until=enddate, bymonthday=[1,d-1,d,31]))\ndates = [starttime] + dates if dates[0] != starttime else dates\ndates = dates + [endtime] if dates[-1] != endtime else dates\n\nstarts = dates[0::2]\nstarts = [int(d.timestamp()) for d in starts] # timestamps for arithmetic\nends   = [d+rdelta(hour=23, minute=59, second=59) for d in dates[1::2]]\nends   = [int(d.timestamp()) for d in ends]   # timestamps for arithmetic\navg_times = list(np.mean(list(zip(starts,ends)), axis=1))\navg_times = [datetime.utcfromtimestamp(a) for a in avg_times]\navg_times = [dt.isoformat() for dt in avg_times]\n\nmasks = [\"SCL\", \"dataMask\"] # SCL ... Scene Classification Layer\n\noutput_bands = input_bands + indices\noutput_array =  [ { 'id': \"\\\"\" + ob + \"\\\"\", 'bands': len(avg_times), \"sampleType\": \"SampleType.UINT16\"} for ob in output_bands ]\nfor oa in output_array:\n    if oa[\"id\"] == '\"CVI\"':\n        oa[\"sampleType\"] = \"SampleType.FLOAT32\"\noutput_array = str(output_array).replace(\"'\", '')\n\nint_bands = '{' + ','.join([f'{ib}: []' for ib in input_bands]) + '}'\nresults_object = '{' + ','.join([f'{ob}: []' for ob in output_bands]) + '}'\ndebug_results = '{' + ','.join([f\"{output_bands[i]}: [{i+1}]\" for i in range(len(output_bands))]) + '}'\nresponses = [{\"identifier\": ob,\"format\": {\"type\": \"image/tiff\"}} for ob in output_bands]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#calculate-data-cube-parameters","position":13},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl3":"Define Evalscript & the Request Payload","lvl2":"Configure Request"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#define-evalscript-the-request-payload","position":14},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl3":"Define Evalscript & the Request Payload","lvl2":"Configure Request"},"content":"\n\n#double curly brackets render as single curly brackets in f-strings\nevalscript = f\"\"\"\n//VERSION=3\n\nvar debug = []\n\nvar ic = {{  // index components\n  'NDVI':  [\"B08\", \"B04\"],\n  \"GNDVI\": [\"B08\", \"B03\"],\n  \"BNDVI\": [\"B08\", \"B02\"],\n  \"NDSI\":  [\"B11\", \"B12\"],\n  \"NDWI\":  [\"B03\", \"B08\"]\n}}\n\nfunction setup(ds) {{\n  return {{\n    input: [{{\n      bands: {str(input_bands + masks)}, \n      units: \"DN\"\n    }}],\n    output: {output_array},\n    mosaicking: Mosaicking.ORBIT       \n  }}\n}}\n\nfunction validate (sample) {{\n  if (sample.dataMask!=1) return false;\n  \n  var scl = Math.round(sample.SCL);\n  \n  if (scl === 3) {{ // SC_CLOUD_SHADOW\n    return false;\n  }} else if (scl === 9) {{ // SC_CLOUD_HIGH_PROBA\n    return false; \n  }} else if (scl === 8) {{ // SC_CLOUD_MEDIUM_PROBA\n    return false;\n  }} else if (scl === 7) {{ // SC_CLOUD_LOW_PROBA\n    //return false;\n  }} else if (scl === 10) {{ // SC_THIN_CIRRUS\n    return false;\n  }} else if (scl === 11) {{ // SC_SNOW_ICE\n    return false;\n  }} else if (scl === 1) {{ // SC_SATURATED_DEFECTIVE\n    return false;\n  }} else if (scl === 2) {{ // SC_DARK_FEATURE_SHADOW\n    //return false;\n  }}\n  return true;\n}}\n\nfunction calculateIndex(a,b)\n{{\n  if ((a+b)==0) return 0;\n  // stretch [-1,+1] to [0,1]\n  return ((a-b)/(a+b)+1)/2;\n}}\n\nfunction interpolatedValue(arr)\n{{\n  //here we define the function on how to define the proper value - e.g. linear interpolation; we will use average \n  if (arr.length==0) return 0;\n  if (arr.length==1) return arr[0];\n  var sum = 0;\n  for (j=0;j<arr.length;j++)\n  {{sum+=arr[j];}}\n  return Math.round(sum/arr.length);\n}}\n\nvar results = {results_object}\n\n// We split each month into two halves. This will make it easier to append months to data cube later\nvar day_of_new_interval = {day_of_new_interval}\nvar endtime = new Date({datetime(*enddate.timetuple()[:3],23,59,59).timestamp()*1000}) // UNIX epoch in ms\n\nfunction evaluatePixel(samples, scenes, inputMetadata, customData, outputMetadata) {{\n  \n  //Debug part returning \"something\" if there are no  valid samples (no observations)\n  if (!samples.length)\n  return {debug_results}\n  \n  var is_in_last_half_of_month = endtime.getUTCDate() >= day_of_new_interval\n  var i = 0; // interval number\n  var int_bands = {int_bands}\n  \n  for (var j = 0; j < samples.length; j++) {{\n    \n    //TODO order should be reversed when we go leastRecent\n    \n    // if scene is outside of current half of month, fill result array and change half of month\n    // algorithm starts with most recent observation\n    if (( !is_in_last_half_of_month && scenes[j].date.getUTCDate() >= day_of_new_interval) ||\n    (  is_in_last_half_of_month && scenes[j].date.getUTCDate() <  day_of_new_interval))\n    {{\n      fillResultArray(i, int_bands)\n      \n      //reset values\n      for (var int_b in int_bands) {{\n        int_bands[int_b] = []\n      }}\n      \n      is_in_last_half_of_month = !is_in_last_half_of_month;\n      i++;\n    }}\n    \n    if (validate(samples[j]))\n    {{\n      // push input samples into their respective arrays\n      for (var int_b in int_bands) {{\n        int_bands[int_b].push(samples[j][int_b])\n      }}\n    }}\n    \n  }}\n  \n  //execute this for the last interval \n  fillResultArray(i, int_bands);\n  \n  return results\n}}\n\nfunction fillResultArray(i, int_bands)\n{{\n  for (var b in int_bands) {{\n    if(int_bands[b].length==0) results[b][i] = 0\n    else results[b][i] = interpolatedValue(int_bands[b])\n  }}\n  \n  for (var ix of {indices}) {{\n    if(ic.hasOwnProperty(ix)) {{\n      results[ix][i] = 65535*calculateIndex(\n        results[ic[ix][0]][i],\n        results[ic[ix][1]][i]\n      )\n    }}\n    if(ix===\"CVI\"){{\n      // output sample type for CVI is FLOAT32\n      results[ix][i] = results[\"B08\"][i]*results[\"B05\"][i] / (results[\"B03\"][i]*results[\"B03\"][i])\n    }}\n  }}\n}}\n\nfunction updateOutputMetadata(scenes, inputMetadata, outputMetadata) {{\n  outputMetadata.userData = {{\n    \"date_created\": Date(),\n    \"metadata\": scenes.map(s => {{\n      s.date = s.date.toString()\n      return s\n    }}),\n    \"time\" : {avg_times},\n    \"debug\": debug\n  }}\n}}\n\"\"\"\n\npayload = {\n  \"processRequest\": {\n    \"input\": {\n      \"bounds\": {\n        \"properties\": {\n          \"crs\": \"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"\n        },\n        \"bbox\": [16.446445736463346, 47.680841561177864, 16.49776618971013, 47.72587417451863]\n      },\n      \"data\": [\n        {\n          \"location\": \"AWS:eu-central-1\",\n          \"type\": \"S2L2A\",\n          \"dataFilter\": {\n            \"timeRange\": {\n              \"from\": starttime.isoformat() + 'Z',\n              \"to\": endtime.isoformat() + 'Z'\n            },\n            \"mosaickingOrder\": \"mostRecent\",\n            \"maxCloudCoverage\": 100,\n            \"previewMode\": \"DETAIL\"\n          }\n        }\n      ]\n    },\n    \"output\": {\n      \"responses\": [*responses]\n    },\n    \"evalscript\": evalscript\n  },\n  \"tilingGridId\": 0,\n  \"bucketName\": bucket_name,\n  \"resolution\": 60.0,\n  \"description\": \"Test Loipersbach\"\n}\n\nheaders = {\n  #'Accept': 'application/tar'\n}\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#define-evalscript-the-request-payload","position":15},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Send Request and Create Data Cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#send-request-and-create-data-cube","position":16},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Send Request and Create Data Cube"},"content":"\n\ndef generate_url(request_id=\"\", action=\"\"):\n    url = 'https://services.sentinel-hub.com/batch/v1/process/'\n    if request_id:\n        url += f'{request_id}/'\n        if action:\n            url += f'{action}'\n    return url\n\n%%time\n# Creating request\nresponse = oauth.request(\"POST\", generate_url(), headers=headers, json = payload).json()\nrequest_id = response[\"id\"]\n\n# Starting processing\noauth.request(\"POST\", generate_url(request_id, 'start'))\n\n# Polling for completion\nresponse_status = \"\"\nwhile response_status not in ['DONE', 'FAILED']:\n    clear_output(True); print('Waiting upon completion...');\n    response_status = oauth.request(\"GET\", generate_url(request_id)).json()['status']\n    print(f\"Request {request_id} {response_status}\")\n    time.sleep(1)\n\ntiles = oauth.request('GET', generate_url(request_id, 'tiles')).json()['member']\ncosts = sum([t['cost'] for t in tiles])\nprint(f'Processing Costs: {costs:.2f} Processing Units')\n\ns3 = boto3.resource('s3')\nbk = s3.Bucket(bucket_name)\nprint(\"Data Cube Size: {:.2f} MiB\"\n      .format(sum([obj.size for obj in bk.objects.all().filter(Prefix=request_id)])/2**20)) # total size in bytes\n\n%%capture\n# Save metadata to bucket\nbk.put_object(Key=request_id + '/userdata.json', Body=json.dumps({\n    'bands': output_bands,\n    'request_id': request_id,\n    'tiles': [tile['id'] for tile in tiles],\n    'time': avg_times    \n}))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#send-request-and-create-data-cube","position":17},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Access Data Cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#access-data-cube","position":18},{"hierarchy":{"lvl1":"Client Side Processing using data prepared via EDC Mass Sentinel Hub","lvl2":"Access Data Cube"},"content":"\n\n# Load metadata\nuserdata_obj = bk.Object(f'{request_id}/userdata.json')\nfile_stream = io.BytesIO()\nuserdata_obj.download_fileobj(file_stream) # load userdata.json into file_stream\nuserdata = json.loads(file_stream.getvalue())\nuserdata\n\n# Load data cube into xarray Dataset\ndss = []\nfor t in userdata['tiles']:\n    arrs = {b: xr.open_rasterio(f's3://{bucket_name}/{request_id}/{t}/{b}.tif') for b in userdata['bands']}\n    dss.append(xr.Dataset(arrs))\nds = xr.combine_by_coords(dss)\n\n# Describe xarray Dataset with metadata\nds = ds.rename({'band': 'time', 'y': 'lat', 'x': 'lon'})\nds.coords['time'] = [np.datetime64(t) for t in userdata['time']]\nds\n\ndef scale_index(val, src=(0,2**16-1), dst=(-1,+1)): \n    \"\"\"\n    Scale the given value from the scale of src to the scale of dst.\n    \"\"\"\n    return ((val - src[0]) / (src[1]-src[0])) * (dst[1]-dst[0]) + dst[0]\n\nscale_index(ds.isel(lat=2, lon=2).NDVI).plot.line('b-o')","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/client-side-processing-using-mass-sh#access-data-cube","position":19},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/cmems-data-download","position":0},{"hierarchy":{"lvl1":""},"content":"As the first step of the process we need install mptuclient on EDC environment. Currently the master version is not working, so we use the 1.8.8 branch.\n\n!pip install motuclient==1.8.8\n\nRun the request for a specific product. It will be downloaded into the root folder. Change “out_dir” and “out_name” to specify a different download path. Use the edc credentials to set the CMEMS_USERNAME and CMEMS_PASSWORD.\n\nimport os\nfrom datetime import datetime\n\ncmems_usr = %env CMEMS_USERNAME\ncmems_passwd = %env CMEMS_PASSWORD\n\n# change these paramaters for different products. Details are available here https://resources.marine.copernicus.eu/product-detail/GLOBAL_ANALYSIS_FORECAST_PHY_001_024/DATA-ACCESS\ndataset_id=\"GLOBAL_ANALYSIS_FORECAST_PHY_001_024-TDS\"\nproduct_id=\"cmems_mod_glo_phy_anfc_merged-uv_PT1H-i\"\nvariable1 = \"uo\"\n\nlon_min=\"28.5\"\nlon_max=\"32.5\"\nlat_min=\"42.5\"\nlat_max=\"46.0\"\ndate_min=datetime(2021, 1, 6, 0, 0, 0, 0)\ndate_max=datetime(2021, 4, 9, 0, 0, 0, 0)\ndepth_min=0.494024\ndepth_max=0.494026\n\n#destination folder and file names\nout_dir = \".\"\nnc_name = 'out.nc'\n\n\n#do not change!!\nmotu_server =\"http://nrt.cmems-du.eu/motu-web/Motu\"\n\nfullPath = os.path.join(os.path.abspath('.'), out_dir, nc_name) \nprint(fullPath)\nif os.path.exists(fullPath):\n    os.remove(fullPath)\n\ncommand = \"python -m motuclient --user \" + str(cmems_usr) + \" --pwd \" + str(cmems_passwd) +\" --motu \" + str(motu_server) + \" --service-id \" + str(dataset_id) + \" --product-id \" + str(product_id) + \" --longitude-min \" + str(lon_min) + \" --longitude-max \" + str(lon_max) + \" --latitude-min \" + str(lat_min) + \" --latitude-max \" + str(lat_max) + \" --date-min \" + str(date_min) + \" --date-max \" + str(date_max) + \" --variable \" + str(variable1) + \" --out-dir \" + str(out_dir) + \" --out-name \" + str(nc_name) + \" --depth-min \" + str(depth_min) + \" --depth-max \" + str(depth_max)\nprint(\"Executing command:\")\nos.system(command)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/cmems-data-download","position":1},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial","position":0},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package"},"content":"\n\nSource: \n\nBring Your Own COG documentation","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial","position":1},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Getting started with Bring Your Own COG(BYOC)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#getting-started-with-bring-your-own-cog-byoc","position":2},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Getting started with Bring Your Own COG(BYOC)"},"content":"Sentinel Hub allows you to access your own data stored in your S3 bucket with the powerful Sentinel Hub API. Since data remains on your bucket, you keep full control over it. This functionality requires no replication of data and allows you to exercise the full power of the Sentinel Hub service including Custom algorithms. \n\nMore information here!.\n\nThe \n\nSentinel Hub Dashboard has a very user-friendly “Bring your own COG” tab. If you are not going to be creating collections, adding/updating collection tiles, etc. daily, the Dashboard tool is your friend. For the rest, this tutorial is a simple walk-through on creating, updating, listing, and deleting your BYOC collections through Python using sentinelhub-py.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#getting-started-with-bring-your-own-cog-byoc","position":3},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Outline"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#outline","position":4},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Outline"},"content":"In this demonstration Jupyter Notebook, based on the \n\nSentinel Hub Python package BYOC examples, we will learn how to:\n\nSet up for prerequisites\n\nImports\n\nCredentials\n\nManage BYOC collections\n\nCreate new collection\n\nGet a list of your collections\n\nUpdate existing collection\n\nDelete collection\n\nManage BYOC tiles (cogs in the collection)\n\nCreating a new tile (and ingesting it to collection)\n\nAdd multiple tiles to a single collection\n\nGet tiles from your collection\n\nVisualize the tiles in your collection\n\nUpdate and delete a tile\n\nRetrieve data from collection\n\nimport sys\nsys.path.append(“/home/jovyan”)\nfrom credentials import *## Set up for prerequisites\nBefore accessing the data, we will start by importing the necessary Python libraries (already configured in your EDC workspace) and generate credentials automatically to access the services.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#outline","position":5},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Imports","lvl2":"Outline"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#imports","position":6},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Imports","lvl2":"Outline"},"content":"\n\n# EDC libraries\nfrom edc import setup_environment_variables\n\n# Utilities\nimport os\nimport boto3\nimport numpy as np\nimport datetime as dt\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Sentinel Hub\nfrom sentinelhub import (SHConfig, DataCollection, Geometry, BBox, CRS, \n                         SentinelHubRequest, filter_times, bbox_to_dimensions, MimeType, \n                         SentinelHubBYOC, ByocCollection, ByocTile, ByocCollectionAdditionalData,\n                         DownloadFailedException)\n\n# Configure plots for inline use in Jupyter Notebook\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#imports","position":7},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Credentials","lvl2":"Outline"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#credentials","position":8},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Credentials","lvl2":"Outline"},"content":"Credentials for Sentinel Hub services are automatically injected as environement variables. It is therefore easy to populate Sentinel Hub’s credential manager with the values.\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\nThis example notebook will demonstrate how to ingest tiles from AWS S3 bucket taking \n\nSentinel-2 L2A 120m Mosaic data as an example. You will need aws credentials to access data on AWS S3 bucket. Please create a text file named custom.env in your home directory with the following input:AWS_ACCESS_KEY_ID = \"<aws_access_key_id>\"\nAWS_SECRET_ACCESS_KEY = \"<aws_secret_access_key>\"\n\nconfig.aws_access_key_id = os.environ[\"AWS_ACCESS_KEY_ID\"]\nconfig.aws_secret_access_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#credentials","position":9},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Manage BYOC collections"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#manage-byoc-collections","position":10},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Manage BYOC collections"},"content":"SentinelHubBYOC class holds the methods for interacting with Sentinel-Hub services. Let’s initialize it with our config:\n\n# Initialize SentinelHubBYOC class\nbyoc = SentinelHubBYOC(config=config)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#manage-byoc-collections","position":11},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Create new collection","lvl2":"Manage BYOC collections"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#create-new-collection","position":12},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Create new collection","lvl2":"Manage BYOC collections"},"content":"The easiest way to create a collection is to use its dataclass:\n\nnew_collection = ByocCollection(name='new collection', s3_bucket='byoc-tutorial-bucket')\n\nThe new collection is accessible on byoc-tutorial-bucket s3 bucket (please see how to configure your bucket for Sentinel-Hub service \n\nhere).\n\ncreated_collection = byoc.create_collection(new_collection)\n\ncreated_collection_name = created_collection['name']\ncreated_collection_id = created_collection['id']\nprint('name:', created_collection_name)\nprint('id:', created_collection_id)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#create-new-collection","position":13},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Get a list of your collections","lvl2":"Manage BYOC collections"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#get-a-list-of-your-collections","position":14},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Get a list of your collections","lvl2":"Manage BYOC collections"},"content":"Now we have created a data collection named new collection, we can retrieve it with the following code.\n\nmy_collection = byoc.get_collection(created_collection_id)\n\nLet’s have a look at the collection we just created.\n\nprint(f\"name: {my_collection['name']}\")\nprint(f\"collection id: {my_collection['id']}\")\n\nIn cases where you have a large amount of collections and you would only like to load collection info for a few collections, the following code would be a good option for you:\n\ncollections_iterator = byoc.iter_collections()\n\nmy_collection_using_next = next(collections_iterator)\nmy_collection_using_next\nprint('name:', my_collection_using_next['name'])\nprint('id:', my_collection_using_next['id'])\n\nNote: next() will only show the first collection on its first execution, the second collection for its second execution, and so on. if you already have collections the code below won’t necessarily show the one we just created.\n\nIf you prefer to work with dataclasses, you can also run the following code:my_collection = ByocCollection.from_dict(next(collections_iterator))\n\nOne can of course retrieve all of them in one go like so:\n\nmy_collections = list(collections_iterator)\n\nfor collection in my_collections:\n    print((collection['name'], collection['id']))\n\nA useful way for managing your collections is pandas.DataFrame you can create like so:\n\nmy_collections_df = pd.DataFrame(data=list(byoc.iter_collections()))\nmy_collections_df[['id','name','created']].head()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#get-a-list-of-your-collections","position":15},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Update existing collection","lvl2":"Manage BYOC collections"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#update-existing-collection","position":16},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Update existing collection","lvl2":"Manage BYOC collections"},"content":"Anything you can do on Dashboard, Bring your own COG tab, you can do programmatically as well. Below we’re going to rename the ‘byoc-tutorial’ collection to ‘byoc-tutorial-renamed’:\n\nmy_collection['name'] = 'renamed new collection'\n\nWhen using next(), run the following code:my_collection['name'] = 'renamed new collection'\n\nWhen using dataclass, run the following code:my_collection.name = 'renamed new collection'\n\nWhen using list, run the following code:collection_to_be_updated = [x for x in my_collections if x['name']=='new collection'][0]\ncollection_to_be_updated['name'] = 'renamed new collection'\n\nNote: While you can change other fields as well, s3_bucket cannot be changed, and the bitDepth of bands in the collection is something that is pertinent to the COGs themselves and populated during the ingestion.\n\nTo update the collection, call:\n\nbyoc.update_collection(my_collection)\n\nNow we can see that the new collection collection has been renamed as renamed new collection.\n\nget_renamed_collection = byoc.get_collection(created_collection_id)\nprint(\"name:\", get_renamed_collection['name'])\nprint(\"id:\", get_renamed_collection['id'])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#update-existing-collection","position":17},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Delete collection","lvl2":"Manage BYOC collections"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#delete-collection","position":18},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Delete collection","lvl2":"Manage BYOC collections"},"content":"If you are the owner of the collection, you can also delete it. Let’s delete the renamed new collection collection we just created.\n\nWarning:\n\nBeware! Deleting the collection will also delete all its tiles!\n\nbyoc.delete_collection(my_collection)\n\nThe collection can also be deleted via passing its id to byoc.delete_collection() as shown below:byoc.delete_collection(my_collection['id'])\n\nTrying to access this collection now will fali.\n\ntry:\n    deleted_collection = byoc.get_collection([x for x in my_collections if x['id']==created_collection_id][0])\nexcept DownloadFailedException as e:\n    print(e)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#delete-collection","position":19},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Manage BYOC tiles (cogs in the collection)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#manage-byoc-tiles-cogs-in-the-collection","position":20},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Manage BYOC tiles (cogs in the collection)"},"content":"Your data needs to be organized into collections of tiles. Each tile needs to contain a set of bands and (optionally) an acquisition date and time. Tiles with the same bands can be grouped into collections. Think of the Sentinel-2 data source as a collection of Sentinel-2 tiles.\n\nTiles have to be on an s3 bucket and need to be in COG format. We will not go into details about the COGification process; users can have a look at the documentation or use the BYOC tool that will take care of creating a collection and ingesting the tiles for you.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#manage-byoc-tiles-cogs-in-the-collection","position":21},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Creating a new tile (and ingesting it to collection)","lvl2":"Manage BYOC tiles (cogs in the collection)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#creating-a-new-tile-and-ingesting-it-to-collection","position":22},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Creating a new tile (and ingesting it to collection)","lvl2":"Manage BYOC tiles (cogs in the collection)"},"content":"When we create a new tile and add it to the collection, the ingestion process on the Sentinel-Hub side will happen, checking if the tile corresponds to the COG specifications as well as if it conforms to the collection. For more information refer to the \n\nBring Your Own COG API documentation.\n\nThe simplest way to create a new tile is by using the ByocTile dataclass, which will complain if the required fields are missing. In the following cell we will show how to ingest \n\nSentinel-2 L2A 120m Mosaic data listed on open registry data on AWS.\n\nnew_tile = ByocTile(path='2019/11/27/28V/(BAND).tif',\n                    sensing_time=dt.datetime(2019, 11, 27, 0, 0, 0)\n                   )\n\nNote:\n\nThe most important field of the tile is its path on an s3 bucket. For example, if your band files are stored in s3://bucket-name/folder/, then set folder as the tile path. In this case, the band names will equal the file names. For example, the band B1 corresponds to the file s3://bucket-name/folder/B1.tiff. If your file names have something other than just the band name, such as a prefix, this is fine as long as the prefix is the same for all files. In this case, the path needs to include this prefix and also the band placeholder: (BAND). Adding the extension is optional. For example, this is what would happen if you would use the following path folder/tile_1_(BAND)_2019.tiff for the following files:\n\ns3://bucket-name/folder/tile_1_B1_2019.tiff - the file would be used, the band name would be B1\n\ns3://bucket-name/folder/tile_1_B2_2019.tiff - the file would be used, the band name would be B2\n\ns3://bucket-name/folder/tile_2_B1_2019.tiff - the file would not be used\n\ns3://bucket-name/folder/tile_2_B2_2019.tiff - the file would not be used\n\nByocTile takes sensing_time as optional parameters, but setting the sensing_time is highly recommended since it makes the collection “temporal” and help you search for the data with Sentinel Hub services.\n\ntile_geometry is optional as it is the bounding box of the tile and will be read from COG file.\n\ncover_geometry is the geometry of where the data (within the bounding box) is and can be useful for optimized search as an optional parameter. For a good explanation of the coverGeometry please see \n\ndocs.\n\nLet’s \n\ncreate a new collection for these tiles.\n\nnew_collection = ByocCollection(name='byoc-s2l2a-120m-mosaic', s3_bucket='sentinel-s2-l2a-mosaic-120')\ncreated_collection = byoc.create_collection(new_collection)\n\ncreated_tile = byoc.create_tile(created_collection, new_tile)\n\nThe response from byoc.create_tile has a valid id, and its status is set to WAITING. Checking the tile status after a while (by \n\nrequesting this tile) will tell you if it has been INGESTED or if the ingestion procedure FAILED. In case of failure, additional information (with the cause of failure) will be available in the tile additional_data.\n\ncreated_tile\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#creating-a-new-tile-and-ingesting-it-to-collection","position":23},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Add multiple tiles to a single collection","lvl2":"Manage BYOC tiles (cogs in the collection)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#add-multiple-tiles-to-a-single-collection","position":24},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Add multiple tiles to a single collection","lvl2":"Manage BYOC tiles (cogs in the collection)"},"content":"A data collection can for sure contain multiple tiles. It is important to know that adding multiple tiles will work only if these tiles have the same bands. Let’s add more tiles from the \n\nSentinel-2 L2A 120m Mosaic listed on the open data registry on AWS to the collection.\n\nWe first define a function to get a list of paths for each tile:\n\ndef list_objects_path(bucket, aws_access_key_id, aws_secret_access_key, y=None, m=None, d=None):\n    tiles_path = []\n    client = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n    result = client.list_objects(Bucket=bucket, Delimiter='/')\n    for year in result.get('CommonPrefixes')[:y]:\n        year_result = client.list_objects(Bucket=bucket, Delimiter='/', Prefix=year.get('Prefix'))\n        for month in year_result.get('CommonPrefixes')[:m]:\n            month_result = client.list_objects(Bucket=bucket, Delimiter='/', Prefix=month.get('Prefix'))\n            for day in month_result.get('CommonPrefixes')[:d]:\n                day_result = client.list_objects(Bucket=bucket, Delimiter='/', Prefix=day.get('Prefix'))\n                for tile in day_result.get('CommonPrefixes'):\n                    tiles_path.append(tile.get('Prefix'))\n    return tiles_path\n\nNext we obtain a list of paths for tiles available on s3://sentinel-s2-l2a-mosaic-120/2019/1/1/.\n\ntiles_path = list_objects_path('sentinel-s2-l2a-mosaic-120', config.aws_access_key_id, config.aws_secret_access_key, y=1, m=1, d=1)\n\nThen we can add tiles to the collection with a for loop.\n\nfor tile in tiles_path:\n    byoc_tile = ByocTile(path=f'{tile}(BAND).tif', \n                         sensing_time=dt.datetime(int(tile.split('/')[0]), \n                                                  int(tile.split('/')[1]), \n                                                  int(tile.split('/')[2]), \n                                                  0, \n                                                  0, \n                                                  0)\n                        )\n    byoc.create_tile(created_collection, byoc_tile)\n\nNote: The tile ingesting process could take some time, please wait a few more minutes after the cell has done running before heading to the next step.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#add-multiple-tiles-to-a-single-collection","position":25},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Get tiles from your collection","lvl2":"Manage BYOC tiles (cogs in the collection)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#get-tiles-from-your-collection","position":26},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Get tiles from your collection","lvl2":"Manage BYOC tiles (cogs in the collection)"},"content":"After byoc.create_tile being executed, we can request the tile from the collection where it is ingested. To request one specific tile in the collection, you can do it by passing the collection id and the tile id to the get_tile method.\n\ntile = byoc.get_tile(collection=created_collection['id'], tile=created_tile['id'])\n\ntile\n\nYou can of course retrieve all tiles into a list.\n\ntiles = list(byoc.iter_tiles(created_collection))\n\nIn cases where you have a large collection with a lot of tiles and you would only like to load tile info for a few tiles, the following code using next() would be a good option for you:tile = next(byoc.iter_tiles(created_collection))\n\nTo convert it to ByocTile dataclass using the code below:tile = ByocTile.from_dict(next(byoc.iter_tiles(created_collection)))\n\nLet’s take a look at the keys of the first dictionary, which contains the info of the first tile, in the returned list.\n\nlist(tiles[0].keys())\n\nTo check if there’s any tile failed to be ingested, run the code below:\n\ntiles_failed_to_be_ingested = [x['path'] for x in tiles if x['status']=='FAILED']\ntiles_failed_to_be_ingested\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#get-tiles-from-your-collection","position":27},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Visualize the tiles in your collection","lvl2":"Manage BYOC tiles (cogs in the collection)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#visualize-the-tiles-in-your-collection","position":28},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Visualize the tiles in your collection","lvl2":"Manage BYOC tiles (cogs in the collection)"},"content":"Using ByocTile dataclass, which will properly parse tile geometries, date-time strings, etc., one can create a geopandas.GeoDataFrame.\n\nNote: the geometries can be in different coordinate reference systems, so a transform to a common CRS might be needed.\n\ntile_iterator = byoc.iter_tiles(created_collection)\n\ntiles_for_visualized = []\nfor i in range(100):\n    tiles_for_visualized.append(ByocTile.from_dict(next(tile_iterator)))\n\ntiles_gdf = gpd.GeoDataFrame(tiles_for_visualized, geometry=[t.cover_geometry.transform(CRS.WGS84).geometry for t in tiles_for_visualized], crs='epsg:4326')\ntiles_gdf.head()\n\nfig, ax = plt.subplots(figsize=(17,8))\ntiles_gdf.plot(ax=ax);\n\nIn the above example, the ingested tiles are 100 tiles from the pull out from the \n\nSentinel-2 L2A 120m Mosaic which contains 19869 tiles around the globe, hence the tiles are so sparse in the image above.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#visualize-the-tiles-in-your-collection","position":29},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Updating and deleting a tile","lvl2":"Manage BYOC tiles (cogs in the collection)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#updating-and-deleting-a-tile","position":30},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl3":"Updating and deleting a tile","lvl2":"Manage BYOC tiles (cogs in the collection)"},"content":"\n\nUpdating and deleting a tile follow the same logic as updating/deleting a collection:\n\nTo updatea tile:\n\ntile_to_be_updated = byoc.get_tile(collection=created_collection['id'], tile=created_tile['id'])\ntile_to_be_updated['sensingTime'] = '2021-06-29T18:02:34'\nbyoc.update_tile(created_collection, tile_to_be_updated)\n\nAfter updating we can see that the sensingTime has been changed.\n\nbyoc.get_tile(collection=created_collection['id'], tile=created_tile['id'])['sensingTime']\n\nTo delete a tile:\n\ntile_to_be_deleted = byoc.get_tile(collection=created_collection['id'], tile=created_tile['id'])\nbyoc.delete_tile(created_collection, tile_to_be_deleted)\n\nNow the tile is gone forever.\n\ntiles = list(byoc.iter_tiles(created_collection))\n[x for x in tiles if x['id']==created_tile['id']]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#updating-and-deleting-a-tile","position":31},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Retrieve data from collection"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#retrieve-data-from-collection","position":32},{"hierarchy":{"lvl1":"How to bring your own data to EDC: Using Sentinel Hub Python package","lvl2":"Retrieve data from collection"},"content":"Once we have a collection created and its tiles ingested, we can retrieve the data from said collection.\nWe will be using ProcessAPI for this.\n\ndata_collection = DataCollection.define_byoc(created_collection['id'])\n\nAlternatively using dataclasee:data_collection = my_collection_dataclass.to_data_collection()\n\ntile_time = dt.datetime.fromisoformat(tiles[0]['sensingTime'].split(\"T\")[0])\n\nIf using dataclass run:tile_time = tile_dataclass.sensing_time\n\ntiles[0]['sensingTime']\n\nBelow we’re going to request a false color image of Caspian Sea.\n\ncaspian_sea_bbox = BBox([49.9604, 44.7176, 51.0481, 45.2324], crs=CRS.WGS84)\n\nfalse_color_evalscript = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B08\",\"B04\",\"B03\", \"dataMask\"],\n    output: { bands: 4 },\n  };\n}\n\nvar f = 2.5/10000;\nfunction evaluatePixel(sample) {\n  return [f*sample.B08, f*sample.B04, f*sample.B03, sample.dataMask];\n}\n\"\"\"\n\nrequest = SentinelHubRequest(\n        evalscript=false_color_evalscript,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=data_collection,\n                time_interval=tile_time\n            )\n        ],\n        responses=[\n            SentinelHubRequest.output_response('default', MimeType.PNG)\n        ],\n        bbox=caspian_sea_bbox,\n        size=bbox_to_dimensions(caspian_sea_bbox, 100),\n        config=config\n    )\n\ndata = request.get_data()[0]\n\nfig, ax = plt.subplots(figsize=(15, 10))\n\nax.imshow(data)\nax.set_title(tile_time.date().isoformat(), fontsize=10)\n\nplt.tight_layout()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-byoc-tutorial#retrieve-data-from-collection","position":33},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm","position":0},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)"},"content":"This notebook shows the steps towards preparing data for training a supervised machine learning model on EDC. We will train the model based on the optical bands with 10 m resolution of Sentinel-2 imagery, i.e., the B2, B3, B4, and B8.\n\nWe will use the Long Short-Term Memory model (LSTM), a variation of a recurrent neural network (RNN), which learns the temporal context of a particular yearly time series of a crop.\n\nAs for the ground truth, we will use the \n\nSouth Africa Crop Type Competition collection, which is part of the EDC public collection and contains the field identification label representing the area of crop fields and the corresponding crop type collected via aerial and vehicle surveys.\n\nIn this example notebook, the expected outcome is a muticlass classifier that identifies different crop types planted in the fields in South Africa.\n\nWe will prepare the training data in the following steps:\n\nSearch for available ground truth labels\n\nDownload features and labels\n\nReshape data for model training\n\nNormalize and undersample data\n\nTrain model\n\nRun model on validation data\n\nEvaluate results\n\n%load_ext autoreload\n%autoreload 2\n\nimport sys\n\nprint(sys.version)\n\n# NOTE: all necessary packages are preinstalled in the EuroDataCube curated 'edcg-2023.10-01' conda kernel!\n\nimport datetime\nimport os\nimport pickle\nfrom collections import defaultdict\n\nimport contextily as cx\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport torch\nimport torch.nn.functional as F\nfrom eolearn.core import (\n    EOExecutor,\n    EOPatch,\n    EOTask,\n    EOWorkflow,\n    FeatureType,\n    OverwritePermission,\n    SaveTask,\n    linearly_connect_tasks,\n)\nfrom eolearn.features.extra.interpolation import LinearInterpolationTask\nfrom eolearn.io import SentinelHubEvalscriptTask, SentinelHubInputTask\nfrom matplotlib.colors import BoundaryNorm, ListedColormap\nfrom sentinelhub import (\n    CRS,\n    Band,\n    BBox,\n    DataCollection,\n    SentinelHubStatistical,\n    SentinelHubStatisticalDownloadClient,\n    SHConfig,\n    Unit,\n    UtmZoneSplitter,\n    bbox_to_dimensions,\n)\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.auto import tqdm\n\nrng = np.random.default_rng(42)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm","position":1},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"1. Search for available ground truth’s labels"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-1-search-for-available-ground-truths-labels","position":2},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"1. Search for available ground truth’s labels"},"content":"To start preparing a training dataset, we need to find the areas which contain ground truth available in the \n\nSouth Africa Crop Type Competition data collection on EDC. We will use the geographical coverage and the temporal availability provided on the linked webpage above to make a Catalog API request.\n\n# load the SH config\nconfig = SHConfig()\n\n# split the AOI into 2560m x 2560m tiles\nextent = BBox((17.85, -33.089240, 18.193359, -32.7), crs=CRS.WGS84)\nbbox_list = UtmZoneSplitter([extent.geometry], crs=extent.crs, bbox_size=[2560, 2560]).bbox_list\n\nplt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(12, 5))\nfig.patch.set_alpha(1)\n\n# construct grid for plotting\ngrid = defaultdict(list)\nfor idx, bbox in enumerate(bbox_list):\n    grid[bbox.crs.epsg].append({\"geometry\": bbox.geometry, \"bbox_id\": idx})\n\ngdf_list = [\n    gpd.GeoDataFrame(subset, geometry=\"geometry\", crs=crs).to_crs(CRS.WGS84.epsg) for crs, subset in grid.items()\n]\ngdf = pd.concat(gdf_list).sort_values(\"bbox_id\").reset_index(drop=True)\n\n# plot grid and basemap\ngdf.plot(edgecolor=\"k\", alpha=0.2, ax=ax)\ncx.add_basemap(ax, crs=gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)\n\ndef get_coverage_request(\n    bbox: BBox,\n    time_interval: tuple[str, str],\n    evalscript: str,\n    collection: DataCollection = DataCollection.SENTINEL2_L2A,\n):\n    \"\"\"Construct request for SentinelHubStatistical data to get coverage of labels in the tile\"\"\"\n    patch_size = bbox_to_dimensions(bbox, resolution=60)\n\n    return SentinelHubStatistical(\n        aggregation=SentinelHubStatistical.aggregation(\n            evalscript=evalscript,\n            time_interval=time_interval,\n            aggregation_interval=\"P1D\",\n            size=patch_size,\n        ),\n        input_data=[SentinelHubStatistical.input_data(collection)],\n        bbox=bbox,\n    )\n\n\n# prepare evalscript for downloading crop labels\nlabels_evalscript = \"\"\"\n//VERSION=3\n\nfunction setup() {\n    return {\n        input: [\n            {\"bands\": [\"crop\", \"dataMask\"]}\n        ],\n        output: [\n            {\n                id: \"LABELS\",\n                bands: 1,\n                sampleType: \"UINT8\"\n            },\n            {\n                id: \"dataMask\",\n                bands: 1,\n                sampleType: \"UINT8\"\n            }\n        ]\n    };\n}\n\nfunction evaluatePixel(sample) {\n    return {LABELS: [sample.crop], dataMask: [sample.dataMask]};\n}\n\"\"\"\n\n# define collection which points to crop labels\ncollection_id = \"bd457670-af1b-45cd-bef2-6a7c93bf5e6e\"\nsouth_africa_crop = DataCollection.define_byoc(\n    collection_id, bands=[Band(name=\"crop\", units=(Unit.DN,), output_types=(np.uint8,))], metabands=[], is_timeless=True\n)\n\n# specify labels definition time (from webpage) and run the requests\nlabels_time_interval = (\"2017-08-01\", \"2017-08-02\")\nkwargs = dict(time_interval=labels_time_interval, evalscript=labels_evalscript, collection=south_africa_crop)\nrequests = [get_coverage_request(bbox, **kwargs).download_list[0] for bbox in bbox_list]\nclient = SentinelHubStatisticalDownloadClient()\n\n# download or load data from disk\nif not os.path.exists(\"stats.pkl\"):\n    stats = client.download(requests)\n    pickle.dump(stats, open(\"stats.pkl\", \"wb\"))\nelse:\n    stats = pickle.load(open(\"stats.pkl\", \"rb\"))\n\ndef extract_coverage(stats: list[dict]):\n    \"\"\"Extract labels coverage from the statistical data\"\"\"\n    data = stats[\"data\"][0][\"outputs\"][\"LABELS\"][\"bands\"][\"B0\"][\"stats\"]\n    return 1 - data[\"noDataCount\"] / data[\"sampleCount\"]\n\n\n# extract coverage from the stats\ncoverages = np.array([extract_coverage(s) if s[\"data\"] else 0 for s in stats])\n\nplt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(15, 5))\nfig.patch.set_alpha(1)\n\n# plot labels coverage over tiles, ignore tiles with no data\nax.hist(coverages[coverages > 0], bins=30)\nax.set_xlabel(\"Reference data coverage\");\n\n\n\n# let's keep only the tiles with coverage above 40%\ncoverage_filter = np.array(coverages) > 0.40\nprint(f\"{np.count_nonzero(coverage_filter)} eligible patches\")\n\nfiltered = np.array(bbox_list)[coverage_filter]\n\nplt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(12, 5))\nfig.patch.set_alpha(1)\n\n# set new column\ngdf[\"eligible\"] = coverage_filter\n\n# plot grid and basemap\ngdf.plot(color=\"none\", edgecolor=\"k\", alpha=0.2, ax=ax)\ngdf[gdf[\"eligible\"]].plot(color=\"C0\", edgecolor=\"k\", alpha=0.5, ax=ax)\ncx.add_basemap(ax, crs=gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-1-search-for-available-ground-truths-labels","position":3},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"2. Download features and labels"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-2-download-features-and-labels","position":4},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"2. Download features and labels"},"content":"Now we know where the groud truth is available, we use eo-learn to download the data and the labels. This is what the eo-learn workflow does:\n\nDownload bands data (B, G, R, NIR)\n\nDownload labels data\n\nConstruct valid mask from data availability mask and cloud mask\n\nPerform temporal interpolation and resample to uniform timestamps across whole AOI\n\nFor the purpose of this notebook, we will download only 2 EOPatches, but to properly train the model, set the tutorial_mode to False to properly train the model\n\ntutorial_mode = True\nif tutorial_mode:  # select first two eligible EOPatches\n    subset = [18, 20]\n    selected = filtered[subset]\n    gdf[\"selected\"] = False\n    gdf.loc[gdf.loc[gdf.eligible].index[subset], \"selected\"] = True\nelse:  # select all eligible EOPatches\n    selected = filtered\n    gdf[\"selected\"] = coverage_filter\n\n# prepare task for joining valid data mask and cloud masks from SH\nclass SentinelHubValidDataTask(EOTask):\n    \"\"\"\n    Combine the downloaded cloud mask with `IS_DATA` to define a valid data mask\n    The SentinelHub's cloud mask is expected in eopatch.mask['CLM']\n    \"\"\"\n\n    def __init__(self, output_feature):\n        self.output_feature = output_feature\n\n    def execute(self, eopatch):\n        eopatch[self.output_feature] = eopatch.mask[\"IS_DATA\"].astype(bool) & (~eopatch.mask[\"CLM\"].astype(bool))\n        return eopatch\n\n\n# BAND DATA\n# Add a request for S2 bands.\n# Here we also do a simple filter of cloudy scenes (on tile level).\n# The s2cloudless masks are requested via additional data.\nband_names = [\"B02\", \"B03\", \"B04\", \"B08\"]\nadd_data = SentinelHubInputTask(\n    bands_feature=(FeatureType.DATA, \"BANDS\"),\n    bands=band_names,\n    resolution=10,\n    maxcc=0.8,\n    time_difference=datetime.timedelta(minutes=120),\n    data_collection=DataCollection.SENTINEL2_L2A,\n    additional_data=[(FeatureType.MASK, \"dataMask\", \"IS_DATA\"), (FeatureType.MASK, \"CLM\")],\n    max_threads=5,\n)\n\n# LABELS DATA\n# Add a request for crop labels.\nadd_labels = SentinelHubEvalscriptTask(\n    features=(FeatureType.MASK_TIMELESS, \"LABELS\"),\n    evalscript=labels_evalscript,\n    data_collection=south_africa_crop,\n    resolution=10,\n    max_threads=5,\n)\n\n# VALIDITY MASK\n# Validate pixels using SentinelHub's cloud detection mask and region of acquisition\nadd_sh_validmask = SentinelHubValidDataTask((FeatureType.MASK, \"IS_VALID\"))\n\n# LINEAR TEMPORAL INTERPOLATION\n# linear interpolation of full time-series and date resampling\n# needed to evaluate time series at specific dates for all data\ntime_interval = (\"2017-01-01\", \"2017-12-31\")\nresampled_range = (time_interval[0], time_interval[1], 15)  # define target timestamps (every 15 days)\nlinear_interp = LinearInterpolationTask(\n    (FeatureType.DATA, \"BANDS\"),  # name of field to interpolate\n    mask_feature=(FeatureType.MASK, \"IS_VALID\"),  # mask to be used in interpolation\n    copy_features=[(FeatureType.MASK_TIMELESS, \"LABELS\")],  # features to keep\n    resample_range=resampled_range,\n)\n\n# SAVING TO OUTPUT\nsave = SaveTask(\"./eopatches\", overwrite_permission=OverwritePermission.OVERWRITE_FEATURES)\n\n# Define the workflow\nworkflow_nodes = linearly_connect_tasks(\n    add_data,\n    add_labels,\n    add_sh_validmask,\n    linear_interp,\n    save,\n)\nworkflow = EOWorkflow(workflow_nodes)\n\n# Define additional parameters of the workflow\ninput_bands = workflow_nodes[0]\nsave_node = workflow_nodes[-1]\nexecution_args = []\nfor idx, bbox in enumerate(selected):\n    execution_args.append(\n        {\n            input_bands: {\"bbox\": bbox, \"time_interval\": time_interval},\n            save_node: {\"eopatch_folder\": f\"eopatch_{idx}\"},\n        }\n    )\n\n# Execute the workflow\nif not os.path.exists(\"eopatches\"):\n    executor = EOExecutor(workflow, execution_args, save_logs=True)\n    executor.run(workers=2)\n\n# collect the data and labels over all eopatches\ndata_list = []\nlabels_list = []\nfor eop_idx in tqdm(range(len(selected))):\n    eop = EOPatch.load(f\"./eopatches/eopatch_{eop_idx}\")\n    data_list.append(eop.data[\"BANDS\"])\n    labels_list.append(eop.mask_timeless[\"LABELS\"])\n\n# plot selected scenes in true color\nncols = 2\nnrows = 1\ntime_idx = 12\n\nplt.style.use([\"default\", \"bmh\"])\nfig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 2, nrows * 2))\nfig.patch.set_alpha(1)\n\nfor ax, image in zip(axs.flatten(), data_list):\n    ax.imshow(np.clip(image[time_idx][..., [2, 1, 0]] * 3.5, 0, 1))\n    ax.axis(\"off\")\n\nplt.tight_layout()\n\n# plot also labels\nncols = 2\nnrows = 1\n\nlabel_codes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nlabel_colors = [\n    \"#ffffff\",\n    \"#a6cee3\",\n    \"#1f78b4\",\n    \"#b2df8a\",\n    \"#33a02c\",\n    \"#fb9a99\",\n    \"#e31a1c\",\n    \"#fdbf6f\",\n    \"#ff7f00\",\n    \"#cab2d6\",\n]\nlabel_text = [\n    \"No data\",\n    \"Lucerne/Medics\",\n    \"Planted pastures (perennial)\",\n    \"Fallow\",\n    \"Wine grapes\",\n    \"Weeds\",\n    \"Small grain grazing\",\n    \"Wheat\",\n    \"Canola\",\n    \"Rooibos\",\n]\n\nplt.style.use([\"default\", \"bmh\"])\nfig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 2, nrows * 2))\nfig.patch.set_alpha(1)\n\ncmap = ListedColormap(label_colors)\nnorm = BoundaryNorm(label_codes, 10)\n\nfor ax, image in zip(axs.flatten(), labels_list):\n    ax.imshow(image.squeeze(-1), cmap=cmap, norm=norm, interpolation=\"none\")\n    ax.axis(\"off\")\n\nplt.tight_layout()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-2-download-features-and-labels","position":5},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"3. Reshape data for model training"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-3-reshape-data-for-model-training","position":6},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"3. Reshape data for model training"},"content":"The data for the LSTM model needs to be in the form of N x T x C, where N represents the number of pixels, T represents the number of timestamps, and C the number of channels.\n\nWe have 25 timestamps and 4 channels (B, G, R, NIR).\n\n# split tiles into train and validation patches\ntrain_slice = slice(None, None, 2)  # evens\nval_slice = slice(1, None, 2)  # odds\n\ntrain_data, train_labels = data_list[train_slice], labels_list[train_slice]\nvalidate_data, validate_labels = data_list[val_slice], labels_list[val_slice]\n\nsel_gdf = gdf[gdf.selected].copy()\nsel_gdf[\"train_split\"] = False\nsel_gdf.loc[train_slice, \"train_split\"] = True\n\nplt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(12, 5))\nfig.patch.set_alpha(1)\n\n# plot grid and basemap\ngdf.plot(color=\"none\", edgecolor=\"k\", alpha=0.2, ax=ax)\nsel_gdf[sel_gdf.train_split].plot(color=\"xkcd:green\", edgecolor=\"k\", alpha=0.2, ax=ax)\nsel_gdf[~sel_gdf.train_split].plot(color=\"xkcd:brick\", edgecolor=\"k\", alpha=0.2, ax=ax)\ncx.add_basemap(ax, crs=gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)\n\n# function for extracting and reshaping the data and labels\ndef get_model_input(data: np.ndarray, labels: np.ndarray) -> tuple:\n    t, h, w, d = data.shape\n    x = np.reshape(np.moveaxis(data, 0, -2), (h * w, t, d))  # N x T x C\n    y = np.reshape(labels, (h * w))\n    return x[y != 0], y[y != 0]\n\n# reshape for train data\nx_train, y_train = [], []\nfor data, labels in zip(train_data, train_labels):\n    model_input = get_model_input(data, labels)\n    x_train.append(model_input[0])\n    y_train.append(model_input[1])\n\nx_train = np.concatenate(x_train, axis=0).astype(np.float32)\ny_train = np.concatenate(y_train, axis=0).astype(np.uint8)\ndel train_data, train_labels\n\nprint(x_train.shape)\nprint(y_train.shape)\n\n# reshape for validation data\nx_validate, y_validate = [], []\nfor data, labels in zip(validate_data, validate_labels):\n    model_input = get_model_input(data, labels)\n    x_validate.append(model_input[0])\n    y_validate.append(model_input[1])\n\nx_validate = np.concatenate(x_validate, axis=0).astype(np.float32)\ny_validate = np.concatenate(y_validate, axis=0).astype(np.uint8)\ndel validate_data, validate_labels\n\nprint(x_validate.shape)\nprint(y_validate.shape)\n\nplt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(15, 5), ncols=2, sharex=True)\nfig.patch.set_alpha(1)\n\nlabels_dict = dict(zip(label_codes, label_text))\n\nlabels, counts = np.unique(y_train, return_counts=True)\nax[0].barh(range(len(labels)), counts)\nax[0].set_title(\"Train data labels distribution\")\nax[0].set_yticks(range(len(labels)), [labels_dict[lbl] for lbl in labels])\n\nlabels, counts = np.unique(y_validate, return_counts=True)\nax[1].barh(range(len(labels)), counts)\nax[1].set_title(\"Validation data labels distribution\")\nax[1].set_yticks(range(len(labels)), [labels_dict[lbl] for lbl in labels])\n\nplt.tight_layout()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-3-reshape-data-for-model-training","position":7},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"4. Normalize and undersample data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-4-normalize-and-undersample-data","position":8},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"4. Normalize and undersample data"},"content":"For the columns that contain numerical data, we should ensure the data range is normalized in case the data has different scales. This process may improve the models performance, and also preserve outliers.\n\nHere we will use a simple method of undersampling just to minimize the amount of huge data we are handling, but the balance of the classes will remain the same.\n\n# set random seet\nnp.random.seed(42)\n\n# define percentage of data to use\npercentage = 0.3\n\n# sample train data\nsample_mask = np.random.choice(x_train.shape[0], int(percentage * x_train.shape[0]))\nclass_counts_before = np.unique(y_train, return_counts=True)\nx_train = x_train[np.sort(sample_mask)]\ny_train = y_train[np.sort(sample_mask)]\nclass_counts_after = np.unique(y_train, return_counts=True)\n\n# sample validation data\nsample_mask_val = np.random.choice(x_validate.shape[0], int(percentage * x_validate.shape[0]))\nx_validate = x_validate[sample_mask_val]\ny_validate = y_validate[sample_mask_val]\n\n# normalize train data\nn, t, c = x_train.shape\nx_train = StandardScaler().fit_transform(x_train.reshape(n * t, c)).reshape(n, t, c)\n\n# normalize validation data\nn, t, c = x_validate.shape\nval_scaler = StandardScaler().fit(x_validate.reshape(n * t, c))\nx_validate = val_scaler.transform(x_validate.reshape(n * t, c)).reshape(n, t, c)\n\n# check shapes\nx_train.shape, x_validate.shape\n\n# fill nan values with -1\nx_train = np.nan_to_num(x_train, nan=-1)\nx_validate = np.nan_to_num(x_validate, nan=-1)\n\n# check labels distribution before and after undersampling\nplt.style.use([\"default\", \"bmh\"])\nfig, axs = plt.subplots(figsize=(12, 7), ncols=2)\nfig.patch.set_alpha(1)\n\nlabels_dict = dict(zip(label_codes, label_text))\ncolors_dict = dict(zip(label_codes, label_colors))\n\naxs[0].pie(\n    class_counts_before[1],\n    labels=[labels_dict[lbl] for lbl in class_counts_before[0]],\n    autopct=\"%1.1f%%\",\n    colors=[colors_dict[lbl] for lbl in class_counts_before[0]],\n    wedgeprops={\"linewidth\": 2, \"edgecolor\": \"white\", \"alpha\": 0.7},\n)\naxs[0].set_title(\"Class Distribution Before Undersampling\")\n\naxs[1].pie(\n    class_counts_after[1],\n    labels=[labels_dict[lbl] for lbl in class_counts_after[0]],\n    autopct=\"%1.1f%%\",\n    colors=[colors_dict[lbl] for lbl in class_counts_after[0]],\n    wedgeprops={\"linewidth\": 2, \"edgecolor\": \"white\", \"alpha\": 0.7},\n)\naxs[1].set_title(\"Class Distribution After Undersampling\")\n\nplt.tight_layout()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-4-normalize-and-undersample-data","position":9},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"5. Train the model"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-5-train-the-model","position":10},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"5. Train the model"},"content":"Now it’s time to construct and train the LSTM model. First we need a bunch of classes that the model will use, from the dataloaders to the model itself.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-5-train-the-model","position":11},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl4":"Define the data loaders","lvl2":"5. Train the model"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#define-the-data-loaders","position":12},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl4":"Define the data loaders","lvl2":"5. Train the model"},"content":"\n\n# class for the dataloader\nclass CustomImageDataset(Dataset):\n    def __init__(self, x_data: np.ndarray, y_data: np.ndarray, encoder: LabelEncoder):\n        self.x_data = x_data\n        self.y_data = encoder.transform(y_data)\n\n    def __len__(self):\n        return len(self.y_data)\n\n    def __getitem__(self, idx):\n        return self.x_data[idx], self.y_data[idx]\n\n\n# encode labels to 0 - num_labels\nencoder = LabelEncoder().fit(list(set(y_train) | set(y_validate)))\nfor lbl in encoder.classes_:\n    print(f\"{lbl} -> {encoder.transform([lbl])[0]}\")\n\n# define the batch size and the dataloaders for train/validation data\nBATCH_SIZE = 1024 if tutorial_mode else 4096\ntrain_dataloader = DataLoader(CustomImageDataset(x_train, y_train, encoder), batch_size=BATCH_SIZE, shuffle=True)\nvalidation_dataloader = DataLoader(\n    CustomImageDataset(x_validate, y_validate, encoder), batch_size=BATCH_SIZE, shuffle=True\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#define-the-data-loaders","position":13},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl3":"Define the model architecture","lvl2":"5. Train the model"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#define-the-model-architecture","position":14},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl3":"Define the model architecture","lvl2":"5. Train the model"},"content":"\n\nclass AverageMetric:\n    \"\"\"\n    Simple class for averaging metrics.\n    \"\"\"\n\n    def __init__(self):\n        self.values = list()\n\n    def add(self, new):\n        self.values.append(new)\n\n    def get(self):\n        return np.array(self.values).mean()\n\n\n# This code is taken from https://github.com/TUM-LMF/BreizhCrops\nclass LSTM(nn.Module):\n    \"\"\"\n    Implementation of the LSTM model for classification of a input sequence into n classes.\n\n    :param input_dim: number of input features entering LSTM cell (i.e. 13 if all S2 bands are used)\n    :type input_dim: int\n    :param n_classes: number of classes\n    :type n_classes: int (class labels have to be between 0 and n_classes-1)\n    :param hidden_dims: The number of features in the hidden state `h`\n    :type hidden_dims: int\n    :param num_rnn_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n                           would mean stacking two LSTMs together to form a `stacked LSTM`,\n                           with the second LSTM taking in outputs of the first LSTM and\n                           computing the final results.\n    :type num_rnn_layers: int\n    :param dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n                    LSTM layer except the last layer, with dropout probability equal to\n                    :attr:`dropout`.\n    :type dropout: float (between 0.0 and 1.0)\n    :param bidirectional: If ``True``, becomes a bidirectional LSTM.\n    :type bidirectional: bool\n    :param use_batchnorm: If ``True``, use batch normalization.\n    :type use_batchnorm: bool\n    :param use_layernorm: If ``True``, applies Layer Normalization over a mini-batch of inputs.\n    :type use_layernorm: bool\n    \"\"\"\n\n    def __init__(\n        self,\n        input_dim,\n        n_classes,\n        hidden_dims,\n        num_rnn_layers=1,\n        dropout=0,\n        bidirectional=False,\n        use_batchnorm=False,\n        use_layernorm=True,\n    ):\n        super().__init__()\n\n        self.nclasses = n_classes\n        self.use_batchnorm = use_batchnorm\n        self.use_layernorm = use_layernorm\n\n        self.d_model = num_rnn_layers * hidden_dims\n        if use_layernorm:\n            self.inlayernorm = nn.LayerNorm(input_dim)\n            self.clayernorm = nn.LayerNorm((hidden_dims + hidden_dims * bidirectional) * num_rnn_layers)\n\n        self.lstm = nn.LSTM(\n            input_size=input_dim,\n            hidden_size=hidden_dims,\n            num_layers=num_rnn_layers,\n            bias=False,\n            batch_first=True,\n            dropout=dropout,\n            bidirectional=bidirectional,\n        )\n\n        if bidirectional:\n            hidden_dims = hidden_dims * 2\n\n        self.linear_class = nn.Linear(hidden_dims * num_rnn_layers, n_classes, bias=True)\n\n        if use_batchnorm:\n            self.bn = nn.BatchNorm1d(hidden_dims)\n\n    def _logits(self, x):\n        x = x.transpose(1, 2)\n\n        if self.use_layernorm:\n            x = self.inlayernorm(x)\n\n        outputs, last_state_list = self.lstm.forward(x)\n\n        # TODO: check what is goinig on here\n        if self.use_batchnorm:\n            b, t, d = outputs.shape\n            o_ = outputs.view(b, -1, d).permute(0, 2, 1)\n            outputs = self.bn(o_).permute(0, 2, 1).view(b, t, d)\n\n        h, c = last_state_list\n\n        nlayers, batchsize, n_hidden = c.shape\n        # TODO: shouldn't this be executed only uf layernorm is True\n        h = self.clayernorm(c.transpose(0, 1).contiguous().view(batchsize, nlayers * n_hidden))\n        logits = self.linear_class.forward(h)\n\n        return logits\n\n    def forward(self, x):\n        logits = self._logits(x)\n        logprobabilities = F.log_softmax(logits, dim=-1)\n        return logprobabilities\n\n    def save(self, path=\"model.pth\", **kwargs):\n        model_state = self.state_dict()\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n        torch.save(dict(model_state=model_state, **kwargs), path)\n\n    def load(self, path):\n        snapshot = torch.load(path, map_location=\"cpu\")\n        model_state = snapshot.pop(\"model_state\", snapshot)\n        self.load_state_dict(model_state)\n        return snapshot\n\n    def update_and_freeze_body(self, pretrained, freeze_layers=(0, -1)):\n        self.inlayernorm = pretrained.inlayernorm\n        self.clayernorm = pretrained.clayernorm\n        self.lstm = pretrained.lstm\n\n        for child in list(self.children())[freeze_layers[0] : freeze_layers[1]]:\n            for param in child.parameters():\n                param.requires_grad = False\n\n    def unfreeze(self):\n        for child in self.children():\n            for param in child.parameters():\n                param.requires_grad = True\n\n\ndef train(model, optimizer, train_loader, validation_loader, epochs):\n    \"\"\"\n    Vanilla function to run the inference on all train samples given in training dataloader.\n    At each epoch end the loss and accuracy of samples from the validation loader are printed.\n    \"\"\"\n    model.train()\n\n    if torch.cuda.is_available():\n        model = model.cuda()\n\n    for epoch in range(epochs):\n        # train phase\n        train_loss_log = AverageMetric()\n        model.train()\n        for data in train_loader:\n            optimizer.zero_grad()\n\n            inputs, targets = data\n\n            if torch.cuda.is_available():\n                inputs = inputs.cuda()\n                targets = targets.cuda()\n\n            logprobabilities = model.forward(inputs.transpose(1, 2))\n\n            loss = torch.nn.functional.nll_loss(logprobabilities, targets)\n            train_loss_log.add(loss.cpu().detach().numpy())\n\n            loss.backward()\n            optimizer.step()\n\n        # val phase\n        val_loss_log = AverageMetric()\n        model.eval()\n        predictions_list = list()\n        targets_list = list()\n        for _, data in enumerate(validation_loader):\n            inputs, targets = data\n\n            if torch.cuda.is_available():\n                inputs = inputs.cuda()\n                targets = targets.cuda()\n\n            logprobabilities = model.forward(inputs.transpose(1, 2))\n            loss = torch.nn.functional.nll_loss(logprobabilities, targets)\n            val_loss_log.add(loss.cpu().detach().numpy())\n\n            targets_list.append(targets.cpu().detach().numpy())\n            predictions_list.append((logprobabilities.cpu().detach().numpy()).argmax(1))\n\n        val_acc = accuracy_score(np.concatenate(targets_list), np.concatenate(predictions_list))\n        print(\n            f\"Epoch {epoch}: train loss {train_loss_log.get():.3f} | \"\n            f\"val loss {val_loss_log.get():.3f} | \"\n            f\"val acc = {val_acc:.3f}\"\n        )\n\n    return model\n\n# set up the model\nmodel = LSTM(\n    input_dim=x_train.shape[-1],\n    n_classes=len(encoder.classes_),\n    hidden_dims=128,\n    num_rnn_layers=3,\n    dropout=0.1,\n    bidirectional=True,\n    use_batchnorm=False,\n    use_layernorm=True,\n)\n\n# set up the optimizer\noptimizer = Adam(model.parameters(), lr=5e-5)\n\nmodel_path = \"./model.pth\"\nif not os.path.exists(model_path):\n    n_epochs = 2 if tutorial_mode else 50\n    # train the model for a few epochs and save when training is done\n    model = train(model, optimizer, train_dataloader, validation_dataloader, epochs=n_epochs)\n    model.save(model_path)\nelse:\n    # or load the saved model from path\n    model = LSTM(\n        input_dim=x_train.shape[-1],\n        n_classes=len(encoder.classes_),\n        hidden_dims=128,\n        num_rnn_layers=3,\n        dropout=0.1,\n        bidirectional=True,\n        use_batchnorm=False,\n        use_layernorm=True,\n    )\n    model.load(model_path)\n    model.eval()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#define-the-model-architecture","position":15},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"6. Run the model on validation data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-6-run-the-model-on-validation-data","position":16},{"hierarchy":{"lvl1":"South Africa Crop Type Classification on Euro Data Cube (EDC)","lvl2":"6. Run the model on validation data"},"content":"Now that the model is trained, let’s run it on the validation data and see how well it performs.\n\n# convert validation data to the proper format for inference\nn_samples = 2000 if tutorial_mode else 10000\nval_sample_mask = np.random.choice(range(len(x_validate)), n_samples)\nval_tensor = torch.from_numpy(x_validate[val_sample_mask]).transpose(1, 2)\nlogprobas = model.forward(val_tensor).cpu().detach().numpy()\n\n# calculate the confidence and predictions\nprobas = np.exp(logprobas)\npredictions = encoder.classes_[probas.argmax(axis=1)]\n\n# Calculate Accuracy, Precision and Recall, F1-Score\ny_true = y_validate[val_sample_mask]\nlabels = sorted(set(y_true) | set(predictions))\n\naccuracy = accuracy_score(y_true, predictions)\nprecision = precision_score(y_true, predictions, average=None, labels=labels)\nrecall = recall_score(y_true, predictions, average=None, labels=labels)\nf1 = f1_score(y_true, predictions, average=None, labels=labels)\n\nPlot F1-score per label\n\nfig, ax = plt.subplots(figsize=(12, 5))\n\n# calculate F1 score dataframe\ndf_f1 = pd.DataFrame({\"Code\": lbl, \"Label\": [labels_dict[lbl] for lbl in labels], \"F1 score\": f1})\n\n# plot scores\nax.barh(df_f1[\"Label\"], df_f1[\"F1 score\"])\n\nax.set_title(\"Labels F1-Score\")\nax.set_xlabel(\"F1-Score\")\n\nPlot confusion matrix\n\ntrue_labels_counts_dict = dict(zip(*np.unique(y_validate[val_sample_mask].tolist(), return_counts=True)))\ncounts = [true_labels_counts_dict.get(lbl, 0) for lbl in labels]\n\nlabels = np.array(labels)[np.argsort(counts)[::-1]]\ncounts = sorted(counts)[::-1]\n\ncm = confusion_matrix(y_true, predictions, normalize=\"true\", labels=labels)\nax = sns.heatmap(\n    cm,\n    annot=True,\n    cmap=\"Greens\",\n    fmt=\".2f\",\n    xticklabels=[labels_dict[lbl] for lbl in labels],\n    yticklabels=[f\"{labels_dict[lbl]}\\n({c})\" for lbl, c in zip(labels, counts)],\n    cbar=False,\n    annot_kws={\"color\": \"black\"},\n)\nax.set_xlabel(\"Predicted labes\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion matrix\")\nplt.show()\n\nPlot time series according to the true label\n\nncols = 3\nnrows = len(encoder.classes_) // ncols + 1\n\nfig, axs = plt.subplots(figsize=(15, 7), nrows=nrows, ncols=ncols)\n\nn, t, c = x_validate.shape\nplot_data = val_scaler.inverse_transform(x_validate.reshape(n * t, c)).reshape(n, t, c)[val_sample_mask]\nndvi = (plot_data[..., 3] - plot_data[..., 2]) / (plot_data[..., 3] + plot_data[..., 2])\n\nfor idx, (ax, cc) in enumerate(zip(axs.ravel(), encoder.classes_)):\n    ax.plot(ndvi[y_true == cc][:200].T, color=f\"C{idx}\", alpha=0.1)\n    ax.set_title(f\"Crop Type {cc} ({labels_dict[cc]})\")\n\nplt.tight_layout()\n\nPlot time series according to the predicted label\n\nncols = 3\nnrows = len(encoder.classes_) // ncols + 1\n\nfig, axs = plt.subplots(figsize=(15, 7), nrows=nrows, ncols=ncols)\n\nfor idx, (ax, cc) in enumerate(zip(axs.ravel(), encoder.classes_)):\n    ax.plot(ndvi[predictions == cc][:200].T, color=f\"C{idx}\", alpha=0.1)\n    ax.set_title(f\"Crop Type {cc} ({labels_dict[cc]})\")\n\nplt.tight_layout()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-notebook-lstm#id-6-run-the-model-on-validation-data","position":17},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example","position":0},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series"},"content":"from eoxhub import check_compatibility\ncheck_compatibility(\"user-2022.10-14\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example","position":1},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#crop-classification-using-sentinel-2-time-series","position":2},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series"},"content":"This notebook implements a crop classification algorithm for Sentinel-2 time-series based on deep learning. The input time-series are derived from the signals computed by the Eurocrops BYOA. The method here implemented is described in more detail in the \n\ncrop-classification marker blog-post.\n\nFor more examples on how to create markers for monitoring agricultural activity using Sentinel-2 signals, consult \n\nthis blog series.\n\nThis notebook will use a sample of pre-downloaded signals, and can be run on a CPU-based instance or laptop.\n\nTable of Contents:\n\nConstants\n\nRetrieve signals and labels\n\nAI-ready dataset\n\nModel training\n\nModel evaluation\n\nimport os\nimport sys\n\n!{sys.executable} -m pip install torch torchvision\nos.environ['EDC_PATH'] + \"/notebooks/contributions/eurocrops-model\"\nsys.path.append(os.path.join(os.environ['EDC_PATH'] + \"/notebooks/contributions/eurocrops-model\"))\n\nimport json\nimport logging\nimport sys\nimport zipfile\n\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\nimport subprocess\nfrom lstm import LSTM\nfrom polygon import PolyDataset\nfrom transforms import get_sample_n_timestamps\nfrom utils import test, train\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\n\nfrom sentinelhub import parse_time\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#crop-classification-using-sentinel-2-time-series","position":3},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"0. Constants "},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-0-constants","position":4},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"0. Constants "},"content":"This section initialises paths, constants and utility functions used in the notebook.\n\n# path to local folders, change as desired\nINPUT_FOLDER = \"./input\"\nRESULTS_FOLDER = \"./output\"\n\n# name of files and folders of downloaded signals, do not change\nDATAFILE = \"ml-example-data.zip\"\nDOWNLOAD_URL = f\"https://sinergise0-my.sharepoint.com/:u:/g/personal/nejc_vesel_sinergise_com/ETMx7NG-JHpBntNMJfnsCOMBVuEegDjYq8WtTmJYl8tZ-A?e=Ck5opE&download=1\"\nEUROCROPS_GPKG = \"input_geometries.gpkg\"\nSIGNALS_FOLDER = \"ml-example-signals\"\n\n\n# utility function to read json payload into a dataframe\ndef stats_to_df(stats_data):\n    \"\"\"Transform Statistical API response into a pandas.DataFrame\"\"\"\n    df_data = []\n\n    for single_data in stats_data[\"data\"]:\n        df_entry = {}\n        is_valid_entry = True\n\n        df_entry[\"interval_from\"] = parse_time(single_data[\"interval\"][\"from\"]).date()\n        df_entry[\"interval_to\"] = parse_time(single_data[\"interval\"][\"to\"]).date()\n\n        for output_name, output_data in single_data[\"outputs\"].items():\n            for band_name, band_values in output_data[\"bands\"].items():\n                band_stats = band_values[\"stats\"]\n                if band_stats[\"sampleCount\"] == band_stats[\"noDataCount\"]:\n                    is_valid_entry = False\n                    break\n\n                for stat_name, value in band_stats.items():\n                    col_name = f\"{output_name}_{band_name}_{stat_name}\"\n                    if stat_name == \"percentiles\":\n                        for perc, perc_val in value.items():\n                            perc_col_name = f\"{col_name}_{perc}\"\n                            df_entry[perc_col_name] = perc_val\n                    else:\n                        df_entry[col_name] = value\n\n        if is_valid_entry:\n            df_data.append(df_entry)\n\n    return pd.DataFrame(df_data)\n\n\n# utility function to log training progress\ndef define_logger(logger_name) -> logging.Logger:\n    logger = logging.getLogger(logger_name)\n    logger.setLevel(logging.INFO)\n    formatter = logging.Formatter(\"[%(asctime)s] {%(filename)s:%(lineno)d} %(levelname)s - %(message)s\")\n\n    stdout_handler = logging.StreamHandler(sys.stdout)\n    stdout_handler.setFormatter(formatter)\n    logger.addHandler(stdout_handler)\n    return logger\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-0-constants","position":5},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"1. Retrieve signals and labels "},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-1-retrieve-signals-and-labels","position":6},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"1. Retrieve signals and labels "},"content":"In this Section, signals are read from JSON files, while the labels used during model training are extracted from the Eurocrops dataset. For this notebook, sample files are provided and downloaded locally in the following cells.\n\nif not os.path.exists(INPUT_FOLDER):\n    os.mkdir(INPUT_FOLDER)\n\nwget_str = f\"wget {DOWNLOAD_URL} -O {os.path.join(INPUT_FOLDER, DATAFILE)}\"\nsubprocess.call(wget_str.split(\" \"))\n\n# unzip files\nwith zipfile.ZipFile(os.path.join(INPUT_FOLDER, DATAFILE), \"r\") as zip_ref:\n    zip_ref.extractall(INPUT_FOLDER)\n\n!ls {INPUT_FOLDER}\n\nRead signals from JSON files as returned by Statistical API and create a dataframe.\n\ndfs = []\nfor result_json in os.listdir(os.path.join(INPUT_FOLDER, \"ml-example-signals\")):\n    with open(os.path.join(INPUT_FOLDER, \"ml-example-signals\", result_json)) as f:\n        result = json.load(f)\n\n    result_df = stats_to_df(result[\"response\"])\n    result_df[\"identifier\"] = int(result[\"identifier\"])\n    dfs.append(result_df)\n\nsignals = pd.concat(dfs)\n\nCheck size of dataset and one time observation.\n\nlen(signals)\n\nsignals.iloc[0]\n\nRead labels from provided geopackage file. These labels can be directly retrieved from GeoDB.\n\neurocrops_gdf = gpd.read_file(os.path.join(INPUT_FOLDER, EUROCROPS_GPKG))\n\nMerge signals and crop labels into a single dataframe, by looking at the identifier of the field of interest (FOI).\n\neurocrops_signals = pd.merge(eurocrops_gdf, signals, on=\"identifier\")\n\neurocrops_signals.iloc[0]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-1-retrieve-signals-and-labels","position":7},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"2. AI-ready dataset "},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-2-ai-ready-dataset","position":8},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"2. AI-ready dataset "},"content":"This Section adds some features to be added to the raw bands which will be used by the model.\n\n# add column for cloud probability\neurocrops_signals[\"CLP\"] = eurocrops_signals[\"clp_B0_mean\"] / 255\n# compute NDVI\neurocrops_signals[\"NDVI\"] = (eurocrops_signals[\"bands_B7_mean\"] - eurocrops_signals[\"bands_B3_mean\"]) / (\n    eurocrops_signals[\"bands_B7_mean\"] + eurocrops_signals[\"bands_B3_mean\"]\n)\n# compute day-of-year from timestamp\neurocrops_signals[\"DOY\"] = eurocrops_signals.interval_from.apply(lambda x: x.timetuple().tm_yday)\n\n# get name of columns to be used as features, i.e. mean values of raw bands\nfeature_cols = [x for x in eurocrops_signals.columns if x.startswith(\"bands_\") and x.endswith(\"_mean\")]\n# name of utility features\ndoy_feature = \"DOY\"\ncrop_type_feature = \"ec_hcat_c\"\ncrop_name_feature = \"ec_hcat_n\"\nlabel_feature = \"label\"\nidentifier_feature = \"identifier\"\n\nMap all the possible crop-types to specific groups assigned in Eurocrops.\n\ncrop_id_to_label_mapping = {val: idx for idx, val in enumerate(eurocrops_signals[crop_type_feature].unique())}\n\ncrop_id_to_name_mapping = {\n    crop_id: crop_name\n    for crop_id, crop_name in eurocrops_signals[[crop_type_feature, crop_name_feature]].drop_duplicates().values\n}\n\neurocrops_signals[label_feature] = eurocrops_signals[crop_type_feature].map(crop_id_to_label_mapping)\n\nSplit the signals into a training and validation set. This datasets are demonstrative only, as in reality, a larger dataset would be required, and more robust validation strategies required to robustly estimate the performance of the model.\n\ntrain_ids, val_ids = train_test_split(\n    eurocrops_signals[identifier_feature].unique(), train_size=0.6, test_size=0.4, random_state=42\n)\n\ntrain_df = eurocrops_signals[eurocrops_signals[identifier_feature].isin(train_ids)]\nval_df = eurocrops_signals[eurocrops_signals[identifier_feature].isin(val_ids)]\n\nCreate the training and validation datasets to be used for model training and validation.\n\ntrain_poly_dataset = PolyDataset(\n    train_df,\n    feature_cols=feature_cols,\n    label_col=label_feature,\n    poly_id_col=identifier_feature,\n    doys_col=doy_feature,\n    online_transform=get_sample_n_timestamps(40),\n)\n\nval_poly_dataset = PolyDataset(\n    val_df,\n    feature_cols=feature_cols,\n    label_col=label_feature,\n    poly_id_col=identifier_feature,\n    doys_col=doy_feature,\n    online_transform=get_sample_n_timestamps(40),\n)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-2-ai-ready-dataset","position":9},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"3. Model training "},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-3-model-training","position":10},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"3. Model training "},"content":"In this Section, a LSTM model is trained on the signals for estimation of crop-type. The parameters of the LSTM might need tuning to different use-cases.\n\nBATCH_SIZE = 16\nN_WORKERS = 4\nSHUFFLE = True\n\nThe number of epochs is set to 5 to for this demonstration. For more accurate results, it is recommended that this is increased (i.e. to 20 or 30).\n\nN_EPOCHS = 5 \n\ntrain_loader = DataLoader(dataset=train_poly_dataset, batch_size=BATCH_SIZE, num_workers=N_WORKERS, shuffle=SHUFFLE)\n\nval_loader = DataLoader(dataset=val_poly_dataset, batch_size=BATCH_SIZE, num_workers=N_WORKERS, shuffle=False)\n\nInitialise the model.\n\nlstm = LSTM(\n    input_dim=len(feature_cols),\n    n_classes=eurocrops_signals[label_feature].nunique(),\n    hidden_dims=128,\n    num_rnn_layers=3,\n    dropout=0.2,\n    bidirectional=True,\n    use_batchnorm=False,\n    use_layernorm=True,\n)\n\nInitialise the optimiser.\n\noptimizer = Adam(\n    filter(lambda x: x.requires_grad, lstm.parameters()),\n    betas=(0.9, 0.98),\n    eps=1e-09,\n    lr=0.001,\n)\n\nInitialise the logger.\n\nlogger = define_logger(\"Training\")\n\nTrain the model !!\n\nlstm = train(lstm, optimizer, train_loader, val_loader, N_EPOCHS, verbose=False, logger=logger)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-3-model-training","position":11},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"4. Model evaluation "},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-4-model-evaluation","position":12},{"hierarchy":{"lvl1":"Crop-classification using Sentinel-2 time-series","lvl2":"4. Model evaluation "},"content":"This Section evaluates the performance of the trained model on the validation dataset. Perfomance is displayed as a confusion matrix, where estimated and reference crop-types are compared.\n\nimport numpy as np\n\ndef plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http://matplotlib.org/examples/color/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(20, 20))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=90)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = np.nanmax(cm) / 1.5 if normalize else np.nanmax(cm) / 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy, misclass))\n    plt.show()\n\n\npredictions, targets, polygon_ids, logprobabilities = test(lstm, val_loader)\n\ncm = confusion_matrix(targets, predictions, labels=list(crop_id_to_label_mapping.values()))\n\nplot_confusion_matrix(cm, target_names=[crop_id_to_name_mapping[x] for x in crop_id_to_label_mapping.keys()])","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/eurocrops-crop-classification-example#id-4-model-evaluation","position":13},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-so2-trend-veda-api-igarss-2023","position":0},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI"},"content":"This notebook is divided into two parts, each demonstrating the functionalities of the VEDA Earth Observation API (EOAPI).\n\nReading and visualizing one of the datasets from the VEDA data catalog\n\nUsing the EOAPI to generate a time-series of OMI (ozone monitoring instrument) NO₂ and SO₂ datasets\n\nAuthor: Slesa Adhikari\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-so2-trend-veda-api-igarss-2023","position":1},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"1. Reading and visualizing one of the datasets from the VEDA data catalog"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-so2-trend-veda-api-igarss-2023#id-1-reading-and-visualizing-one-of-the-datasets-from-the-veda-data-catalog","position":2},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"1. Reading and visualizing one of the datasets from the VEDA data catalog"},"content":"\n\nImport all the necesssary libraries\n\nMake sure you install these first using:pip install pystac_client folium seaborn pandas\n\n# imports\nimport requests\nfrom pystac_client import Client\nimport folium\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nDefine the API endpoints\n\nThe EOAPI is a combination of two components.\n\nData catalog - the \n\nSpatioTemporal Asset Catalog (STAC) specification is used to catalog the available datasets\n\nDynamic tile server - \n\nTiTiler is used to dynamically serve cloud optimized geotiff (raster) data files\n\nSTAC_API_URL = \"https://staging-stac.delta-backend.com/\"\nRASTER_API_URL = \"https://staging-raster.delta-backend.com\"\n\nUse the pystac_client library to interact with the STAC data catalog\n\ncatalog = Client.open(STAC_API_URL)\n\nList all the datasets (collections) in the catalog\n\nfor collection in list(catalog.get_collections()):\n    print(f\"{collection.id} - {collection.title}\")\n\nChoose a collection to work with. We’ll choose the no2-monthly dataset for this example.\nThis is the global nitrogen dioxide data organized into monthly metrics.\n\ncollection_id = \"no2-monthly\"\n\nSearch all the items in the collection.\n\nsearch = catalog.search(collections=[collection_id])\nitems = list(search.items())\nitems\n\nLoad and inspect one of the item’s assets. In the catalog, the cloud optimized geotiffs (COG) are indexed under cog_default asset.\n\ns3_uri = items[0].assets[\"cog_default\"].href\n\nGet statistics for the COG file using the TiTiler api endpoint /cog/statistics\n\nstats = requests.get(\n    f\"{RASTER_API_URL}/cog/statistics\",\n    params={\"url\": s3_uri}\n).json()\nstats\n\nDisplay the COG in a map\n\nNow, we’ll make a request for imagery tiles to the raster API.\n\nDefine the query parameters for the request:\n\ncollection\n\nitem\n\nrescale\n\ncolormap\n\nassets\n\ncollection = collection_id\nitem = items[0].id\ncolormap = \"rainbow\"\nassets = \"cog_default\"\nrescale = f\"{stats['1']['min']},{stats['1']['max']}\"\n\nGet the tileset json for the relevant item.\n\ntiles = requests.get(\n    f\"{RASTER_API_URL}/stac/tilejson.json?collection={collection}&item={item}&assets={assets}&colormap_name={colormap}&rescale={rescale}\"\n).json()\n\ntiles\n\nUse the /tiles endpoint to visualize the file in a map\n\nm = folium.Map(\n    zoom_start=10,\n    scroll_wheel_zoom=True, \n    tiles=tiles[\"tiles\"][0],\n    attr=\"VEDA\", \n    minzoom=0, \n    maxzoom=18,\n)\n\nm\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-so2-trend-veda-api-igarss-2023#id-1-reading-and-visualizing-one-of-the-datasets-from-the-veda-data-catalog","position":3},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"2. Using the EOAPI to generate a time-series of OMI NO₂ and SO₂ datasets"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-so2-trend-veda-api-igarss-2023#id-2-using-the-eoapi-to-generate-a-time-series-of-omi-no-and-so-datasets","position":4},{"hierarchy":{"lvl1":"Using the NASA VEDA EOAPI","lvl2":"2. Using the EOAPI to generate a time-series of OMI NO₂ and SO₂ datasets"},"content":"\n\nThere’s a story published in the EODashboard with the following title:\n\nAir pollution in India, China and the U.S. have changed significantly over the past two decades\n\nLink: \n\nhttps://​eodashboard​.org​/story​?id​=​air​-pollution​-us​-india​-china\n\nThe story talks about the trend of air pollution in India, China and the U.S. using the NO2 and SO2 readings taken from the OMI instrument\n\nHere, we’ll recreate the analysis using the EOAPI.\n\n# Here, we find the relevant collection ID for the dataset\ncollections = {\n    \"no2\": \"OMI_trno2-COG\",\n    \"so2\": \"OMSO2PCA-COG\",\n}\n\nDefine the roughly similar Area of Interest (AOI) for each of the countries as seen in the story.\n\nDisclaimer: Since the AOI is roughly similar, but not exactly the same, the results may differe slightly, but should maintain similar trends.\n\naois = {\n    \"india\": {\n      \"type\": \"Feature\",\n      \"properties\": {},\n      \"geometry\": {\n        \"coordinates\": [\n          [\n            [\n              84.44227371801799,\n              25.276852788244952\n            ],\n            [\n              81.73331688510166,\n              25.379576397063317\n            ],\n            [\n              81.40290450746915,\n              20.640781701865322\n            ],\n            [\n              84.09079123546121,\n              20.59296261766137\n            ],\n            [\n              84.44227371801799,\n              25.276852788244952\n            ]\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n    },\n    \"china\": {\n      \"type\": \"Feature\",\n      \"properties\": {},\n      \"geometry\": {\n        \"coordinates\": [\n          [\n            [\n              118.14487188674968,\n              40.38237805885373\n            ],\n            [\n              112.59679754686567,\n              40.39197699341523\n            ],\n            [\n              112.78712023622006,\n              32.015052150835814\n            ],\n            [\n              117.937454307721,\n              32.102440507249895\n            ],\n            [\n              118.14487188674968,\n              40.38237805885373\n            ]\n          ]\n        ],\n        \"type\": \"Polygon\"\n      }\n    },\n    \"usa\": {\n        \"type\": \"Feature\",\n        \"properties\": {},\n        \"geometry\": {\n            \"coordinates\": [\n            [\n                [\n                -80.16702521343733,\n                41.73420113945659\n                ],\n                [\n                -83.56446680395005,\n                38.599369254919566\n                ],\n                [\n                -82.00280661075571,\n                37.54658260550103\n                ],\n                [\n                -78.28140359718638,\n                40.450899619800595\n                ],\n                [\n                -80.16702521343733,\n                41.73420113945659\n                ]\n            ]\n            ],\n            \"type\": \"Polygon\"\n        }\n    },\n}\n\nDefine a function that takes the following params:\n\nitem: a STAC item\n\ngeojson: the geojson of the AOI\n\nUsing the /cog/statistics/ endpoint of the raster API, we get back the statistics of the item (which corresponds to one COG file) within the given geojson AOI.\n\nThe statistics includes min, max, mean, std, etc.\n\n# the bounding box should be passed to the geojson param as a geojson Feature or FeatureCollection\ndef generate_stats(item, geojson):\n    result = requests.post(\n        f\"{RASTER_API_URL}/cog/statistics\", \n        params={\n            \"url\": item.assets[\"cog_default\"].href\n        },\n        json=geojson\n    ).json()\n    return {\n        **result[\"properties\"],\n        \"start_datetime\": str(item.properties.get(\"datetime\", item.properties.get(\"start_datetime\")))[:4],\n        \"collection\": item.collection_id\n    }\n\nLet’s start out with the US 🇺🇸 !\n\nWe’ll get all the items in the NO2 and SO2 collections and generate the statistics from them for the Ohio River Valley region of the United States.\n\nusa_aoi = aois[\"usa\"]\nitems = list(catalog.search(collections=[collections[\"no2\"], collections[\"so2\"]]).items())\nusa_stats = [\n    generate_stats(item, usa_aoi)\n    for item in items\n]\n\nCreate a function that takes the statistics (which is a json) and converts it to a pandas dataframe in a format that’ll make it easy to read and visualize.\n\nWe are only concerned with the mean statistics for this example. Specifically the change from the year 2005 as a percentage. We’ll use pandas to calculate this change percentage and assign it to the change column.\n\ndef clean_stats(stats_json) -> pd.DataFrame:\n    # convert the stats_json as is to pandas dataframe\n    df = pd.json_normalize(stats_json)\n    # simple renaming for readability\n    df.columns = [col.replace(\"statistics.1.\", \"\") for col in df.columns]\n    # create a date column from the start_datetime column\n    df[\"date\"] = pd.to_datetime(df[\"start_datetime\"], format=\"mixed\")\n    # rename the collection to a more friendly name\n    df[\"collection\"] = df[\"collection\"].map(lambda x: next(key for key, value in collections.items() if value == x))\n    # sort the dataframe by the date column\n    df = df.sort_values(by=[\"date\"])\n    # create a change column that calculates the change of the mean values from the value in 2005\n    df[\"change\"] = df.groupby(\"collection\", group_keys=False)[\"mean\"].apply(lambda x: x.div(x.iloc[0]).subtract(1).mul(100))\n    return df\n\ncleaned_stats_df = clean_stats(usa_stats)\n\nWe’ll now create a time-series of the change in mean values for NO2 and SO2 for the area in the US.\n\nplt.xticks([i for i in range(0, 21, 2)])\nsns.set_style(\"darkgrid\")\nax = sns.lineplot(\n    x=\"start_datetime\",\n    y=\"change\",\n    hue=\"collection\",\n    data=cleaned_stats_df,\n    palette=[\"#2196f3\", \"#ff5722\"],\n    style=\"collection\",\n    markers=[\"*\", \"d\"],\n)\nax.set_title(\"US - Ohio River Valley\")\nax.set_xlabel(\"Years\")\nax.set_ylabel(\"Change from 2005 (%)\")\nplt.legend(frameon=False, ncol=3)\nplt.show()\n\nNow, let’s create a function that creates this trend graph, given the country.\n\ndef create_chart(country):\n    stats = [generate_stats(item, aois[country]) for item in list(catalog.search(collections=[collections[\"no2\"], collections[\"so2\"]]).items())]\n    df = clean_stats(stats)\n\n    # Create a chart using Seaborn\n    plt.xticks([i for i in range(0, 21, 2)])\n    sns.set_style(\"darkgrid\")\n    ax = sns.lineplot(\n        x=\"start_datetime\",\n        y=\"change\",\n        hue=\"collection\",\n        data=df,\n        palette=[\"#2196f3\", \"#ff5722\"],\n        style=\"collection\",\n        markers=[\"*\", \"d\"],\n        legend=\"full\",\n        # label=[\"no2\", \"so2\"]\n    )\n    ax.set_title(country.title())\n    ax.set_xlabel(\"Years\")\n    ax.set_ylabel(\"Change from 2005 (%)\")\n    ax.legend([\"no2\", \"so2\"])\n    plt.legend(frameon=False, ncol=3)\n    plt.show()\n\nWe can use this function to create charts for the rest of the AOIs.\n\nIndia 🇮🇳\n\ncreate_chart(\"india\")\n\nChina 🇨🇳\n\ncreate_chart(\"china\")","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/no2-so2-trend-veda-api-igarss-2023#id-2-using-the-eoapi-to-generate-a-time-series-of-omi-no-and-so-datasets","position":5},{"hierarchy":{"lvl1":"Important notes"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ogc-edc","position":0},{"hierarchy":{"lvl1":"Important notes"},"content":"from edc import setup_environment_variables\nsetup_environment_variables()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ogc-edc","position":1},{"hierarchy":{"lvl1":"Important notes","lvl2":"Important notes"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ogc-edc#important-notes","position":2},{"hierarchy":{"lvl1":"Important notes","lvl2":"Important notes"},"content":"This notebook requires:\n\nOGC layer installed in EDC marketplace (with access url exposed as environment variable MY_OGC_EDC_URL)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ogc-edc#important-notes","position":3},{"hierarchy":{"lvl1":"OGC-EDC example calls"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ogc-edc#ogc-edc-example-calls","position":4},{"hierarchy":{"lvl1":"OGC-EDC example calls"},"content":"\n\nThis Notebook containes some WMs calls for the generated and configured EGC_OGC URL, all the presented samples where taken from\npre-configured collecions and layers.\n\nThe wms layers were simply requested using the python requests library, and the desired parameters were set to exploit EDC-OGC backend potentials\n\nBelow is a comparison between a True Color image (Top) and a NDVI image (Bottom) of Sentinel 2 L1C\n\nimport requests\nfrom IPython.display import Image, display\n\n# api-endpoint \nURL = %env MY_OGC_EDC_URL\n  \nPARAMS_1 = {\n    'service': 'WMS',\n    'version': '1.3.0',\n    'request': 'GetMap',\n    'layers': 'S2L1C__TRUECOLOR',\n    'bbox': '-15.759545,46.269951,-15.698739,46.426163',\n    'crs': 'EPSG:4326',\n    'styles': '',\n    'width': 1000,\n    'height': 500,\n    'format': 'image/png',\n    'time' : '',\n}\n  \nPARAMS_2 = {\n    'service': 'WMS',\n    'version': '1.3.0',\n    'request': 'GetMap',\n    'layers': 'L8L1C__NDVI',\n    'bbox': '-15.759545,46.269951,-15.698739,46.426163',\n    'crs': 'EPSG:4326',\n    'styles': 'EOX NDVI Colorscale',\n    'width': 1000,\n    'height': 500,\n    'format': 'image/png',\n    'time' : '',\n}\n\nr_1 = requests.get(url = URL, params = PARAMS_1, stream=all) \nr_2= requests.get(url = URL, params = PARAMS_2, stream=all)\n\n\n\ndisplay(Image(r_1.content))\n\ndisplay(Image(r_2.content))\n\n\nusers can set the required cloud coverage to filter out cloud, jsut by setting the cloud coverage parameter ‘maxcc’.\nbelow is a comparison between a 100% cloud coverage image  and a 50% cloud coverage\n\nPARAMS_3 = {\n    'service': 'WMS',\n    'version': '1.3.0',\n    'request': 'GetMap',\n    'layers': 'S2L1C__TRUECOLOR',\n    'bbox': '1466647.93,6036752.61,1517415.19,6052309.71',\n    'crs': 'EPSG:3857',\n    'styles': '',\n    'width': 1000,\n    'height': 300,\n    'format': 'image/png',\n    'time' : '',\n    'maxcc': '100'\n} \n\nPARAMS_4 = {\n    'service': 'WMS',\n    'version': '1.3.0',\n    'request': 'GetMap',\n    'layers': 'S2L1C__TRUECOLOR',\n    'bbox': '1466647.93,6036752.61,1517415.19,6052309.71',\n    'crs': 'EPSG:3857',\n    'styles': '',\n    'width': 1000,\n    'height': 300,\n    'format': 'image/png',\n    'time' : '',\n    'maxcc': '50'\n}  \n\na_1 = requests.get(url = URL, params = PARAMS_3, stream=all) \na_2= requests.get(url = URL, params = PARAMS_4, stream=all) \n\ndisplay(Image(a_1.content))\n\ndisplay(Image(a_2.content))\n\n\nbelow is S5 dataset\n\nPARAMS_3 = {\n    'service': 'WMS',\n    'version': '1.3.0',\n    'request': 'GetMap',\n    'layers': 'S5PL2__NO2',\n    'bbox': '45,-11.25,56.25,0',\n    'crs': 'EPSG:4326',\n    'styles': '',\n    'width': 512,\n    'height': 512,\n    'format': 'image/png',\n    'time' : '2020-04-21/2020-04-26',\n    'maxcc': '100'\n}\n\na = requests.get(url = URL, params = PARAMS_3, stream=all)\n\ndisplay(Image(a.content))","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/ogc-edc#ogc-edc-example-calls","position":5},{"hierarchy":{"lvl1":"openEO Client Demo"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/openeo-client-demo","position":0},{"hierarchy":{"lvl1":"openEO Client Demo"},"content":"This notebook demonstrates how an openEO job execution can be managed from Python.\n\nTo run this notebook, an openEO early adopters account is necessary. Please obtain one via this link:\n\n\nhttps://​openeo​.cloud​/early​-adopters/\n\nimport openeo\n\nconnection = openeo.connect('https://openeo.cloud').authenticate_oidc()\n\nprocess_graph = {\n    \"1\": {\n      \"arguments\": {\n        \"bands\": [\n          \"B04\",\n          \"B02\",\n          \"B03\"\n        ],\n        \"id\": \"SENTINEL2_L2A_SENTINELHUB\",\n        \"spatial_extent\": {\n          \"east\": 84.30320684519523,\n          \"north\": 28.28834175540571,\n          \"south\": 28.268476701871247,\n          \"west\": 84.25171700124623\n        },\n        \"temporal_extent\": [\n          \"2019-05-01T00:01:00Z\",\n          \"2019-05-15T00:01:00Z\"\n        ]\n      },\n      \"position\": [\n        0,\n        0\n      ],\n      \"process_id\": \"load_collection\"\n    },\n    \"2\": {\n      \"arguments\": {\n        \"data\": {\n          \"from_node\": \"1\"\n        },\n        \"format\": \"GTIFF\"\n      },\n      \"position\": [\n        240,\n        0\n      ],\n      \"process_id\": \"save_result\",\n      \"result\": True\n    }\n}\n\n\njob = connection.create_job(process_graph)\n\njob.start_and_wait()\n\njob.describe_job()\n\njob_results = job.get_results()\n\njob_results.get_assets()\n\ndownloaded_files = job_results.download_files(\"/home/jovyan/results\")\ndownloaded_files\n\nimport rasterio\nfrom rasterio.plot import show\n\nfor path in downloaded_files:\n    img = rasterio.open(path)\n    show(img)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/openeo-client-demo","position":1},{"hierarchy":{"lvl1":"Visualizing data with xcube viewer in EuroDataCube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-viewer-as-a-service-in-edc1","position":0},{"hierarchy":{"lvl1":"Visualizing data with xcube viewer in EuroDataCube"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-viewer-as-a-service-in-edc1","position":1},{"hierarchy":{"lvl1":"Visualizing data with xcube viewer in EuroDataCube","lvl2":"Brought to you by Brockmann Consult GmbH"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-viewer-as-a-service-in-edc1#brought-to-you-by-brockmann-consult-gmbh","position":2},{"hierarchy":{"lvl1":"Visualizing data with xcube viewer in EuroDataCube","lvl2":"Brought to you by Brockmann Consult GmbH"},"content":"This Notebook demonstrates how to use the features of the xcube JupyterLab integration.\nThe Notebook demonstrates three scenarios how xcube Viewer is utilized in JupyterLab.\nIn particular, we open xcube Viewer for any xarray.Dataset instances\n\nopened or otherwise created in this Notebook (in-memory datasets);\n\npersisted in this Notebooks’s workspace or from other sources (saved datasets).\n\nopen a dataset served by an external xcube server and published in a xcube viewer.\n\nFor this to work in EuroDataCube, the following requirements must be satisfied:\n\nyou must have an active EuroDataCube EOxHub Workspace\n\nyou must have an active xcube Viewer subscription\n\nimport numpy as np\nimport xarray as xr\n\nfrom xcube.webapi.viewer import Viewer\nfrom xcube.core.store import new_data_store\nfrom xcube.core.select import select_subset\n\nWe create some datasets so we have something to show. We use the xcube datastore framework here to open the dataset, but it could also be opened by other means, e.g., xr.open_dataset(), provided it has variables with dimensions [“time”, “y”, “x”] or [“y”, “x”].\n\nIf you have your own bucket, which you wish to access and the access credentials are not saved as environment variables, you can add them to the parameters of new_data_store:store = new_data_store(\"s3\",\n                       root=\"PATH_TO_YOUR_S3_BUCKET, \n                       storage_options=dict(anon=False, \n                                            key=\"YOUR_ACCESS_KEY_ID\", \n                                            secret=\"YOUR_ACCESS_KEY_SECRET\")\n                           ) \n\nstore = new_data_store(\"s3\", \n                       root=\"xcube-dcfs/edc-xc-viewer-data\",\n                       storage_options={\"anon\": True})\nstore.list_data_ids()\n\ndataset = store.open_data('HH_CityCube_RGB.zarr')\n\ndataset\n\ndataset_subset = select_subset(\n    dataset,\n    time_range=[\"2021-08-01 00:00:00\", \n                \"2021-08-31 23:59:59\"],\n    var_names=[\"B04\", \"B03\", \"B02\", \"NDVI\"]\n)\ndataset_subset.attrs[\"title\"] = \"Hamburg NDVI and RGB Subset\"\ndataset_subset\n\n\n\nScenario 1: Open xcube Viewer for a dataset instances opened or otherwise created in this Notebook (in-memory datasets).Documentation about the functionalities of xcube viewer is available here: \n\nhttps://​xcube​.readthedocs​.io​/en​/latest​/viewer​.html​#functionality\n\nviewer = Viewer()\n\nviewer.add_dataset(dataset)\nviewer.add_dataset(dataset_subset)\n\nYou can click on the viewer link to open xcube Viewer in a new browser tab:\n\nviewer.info()\n\nYou can also open xcube Viewer inlined here:\n\nviewer.show()\n\nTo stop the server and viewer:\n\nviewer.stop_server()\n\n\n\nScenario 2: Open xcube Viewer for a dataset instances persisted in this Notebooks’s workspace or from other sources (saved datasets).\n\ndataset_subset.to_zarr(\"hamburg-NDVI-RGB-subset.zarr\", mode=\"w\")\n\nlocal_store = new_data_store(\"file\", root=\"./.\") # adjust the path if you store the subset somewhere else\nlocal_store.list_data_ids()\n\ndataset = local_store.open_data('hamburg-NDVI-RGB-subset.zarr')\n\nviewer = Viewer()\n\nviewer.add_dataset(dataset)\n\nYou can click on the viewer link to open xcube Viewer in a new browser tab:\n\nviewer.info()\n\nYou can also open xcube Viewer inlined here:\n\nviewer.show()\n\nviewer.stop_server()\n\n\n\nScenario 3: Use custom server configuration to start server and pass it to the viewer constructor. In this case, we have created a local file with the configuration and load it as a dictionary and pass it to the viewer.\n\nThe custom configuration allows you to predefine your value ranges, the colormaps that should be used as well as which bands can be used to create an RGB image, then the RGB switch in the viewer will allow to show the RGB imgage.\n\nIf you do not have a server-config.yaml file in your directory, please create one with the following content:DataStores:\n  - Identifier: edc\n    StoreId: file\n    StoreParams:\n      root: \"./.\" # adjust if you have stored the subset elsewhere\n    Datasets:\n      - Path: hamburg-NDVI-RGB-subset-1.zarr # adjust if you have named it differently.\n        Style: default\n\n\nStyles:\n  - Identifier: default\n    ColorMappings:\n      NDVI:\n        ColorBar: RdYlGn\n        ValueRange: [-1., 1.]\n      rgb:\n        Red:\n          Variable: B04\n          ValueRange: [0., 0.25]\n        Green:\n          Variable: B03\n          ValueRange: [0., 0.25]\n        Blue:\n          Variable: B02\n          ValueRange: [0., 0.25]\n\n\nTo get details about the server configuration file, please checkout the documentation: \n\nhttps://​xcube​.readthedocs​.io​/en​/latest​/cli​/xcube​_serve​.html\n\nfrom xcube.util.config import load_configs\n\nviewer = Viewer(server_config=load_configs(\"server-config.yaml\"))\n\nYou can also open xcube Viewer inlined here:\n\nviewer.show()\n\nviewer.stop_server()\n\nLet’s clean up and remove the test subset:\n\nlocal_store.delete_data('hamburg-NDVI-RGB-subset.zarr')\n\n\n\nScenario 4: Open a dataset served from an external xcube server and published via xcube viewer.\n\nPlease head over to the eurodatacube xcube viewer: \n\nhttps://​edc​-viewer​.brockmann​-consult​.de/\nThere please select the dataset called CMEMS Black Sea Chl. This dataset only has one variable, so you don’t need to change the variable.\n\nOnce you have selected the dataset, open the info panel on the right hand side of the xcube viewer. Then you will see a python icon in the panel next to the datasets title, please select it.\n\nCopy the displayed code snippet, and paste it into your jupyter notebook like done below:\n\nfrom xcube.core.store import new_data_store\n\nstore = new_data_store(\n    \"s3\",\n    root=\"datasets\",  # can also use \"pyramids\" here\n    storage_options={\n        \"anon\": True,\n        \"client_kwargs\": {\n            \"endpoint_url\": \"https://edc-api.brockmann-consult.de/api/s3\"\n        }\n    }\n)\n# store.list_data_ids()\ndataset = store.open_data(data_id=\"esdl~esdc-8d-0.25deg-1x720x1440-2.1.1.zarr\")\n\ndataset\n\nFor the variable and the selected time stamp you will find a code snippet as well:\n\nvar = dataset.air_temperature_2m.sel(time=\"2015-01-05 01:00:00\", method=\"nearest\")\nvar.plot.imshow(vmin=190, vmax=320, cmap=\"plasma\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-viewer-as-a-service-in-edc1#brought-to-you-by-brockmann-consult-gmbh","position":3},{"hierarchy":{"lvl1":"Using xcube to access non-commercial and commercial data sets"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets","position":0},{"hierarchy":{"lvl1":"Using xcube to access non-commercial and commercial data sets"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets","position":1},{"hierarchy":{"lvl1":"Using xcube to access non-commercial and commercial data sets","lvl2":"Using xcube to access non-commercial and commercial data sets"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#using-xcube-to-access-non-commercial-and-commercial-data-sets","position":2},{"hierarchy":{"lvl1":"Using xcube to access non-commercial and commercial data sets","lvl2":"Using xcube to access non-commercial and commercial data sets"},"content":"This notebook shows how to access different data sets through the EDC Sentinel Hub API via xcube:\n\nAccess Sentiel-1 through xcube Sentinel hub Store\n\nAccess Sentiel-2 through xcube Sentinel hub Store\n\nAccess Sentiel-5P through xcube Sentinel hub Store\n\nAccess Pleiades through xcube Sentinel hub Store\n\nAccess PlanetScope through xcube Sentinel hub Store\n\nTo access all dataset you need to have account at Sentinel Hub and provide your credentials client_id and client_secret and for some datasets instance_id and collection_id. All available via Sentinel-Hub\nBrief tutorial video about Sentinel Hub is available \n\nhere\n\n# Set Sentinel Hub credentials\nsh_credentials = dict(client_id='<sentinel hub clinet id>',\n                      client_secret='<sentinel hub clinet secret>')\n\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.sentinelhub import SentinelHub\nimport xarray as xr\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom sentinelhub import BBox, WmsRequest, DataSource, SHConfig\nfrom functools import partial\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#using-xcube-to-access-non-commercial-and-commercial-data-sets","position":3},{"hierarchy":{"lvl1":"1. Sentinel-1 GRD"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#id-1-sentinel-1-grd","position":4},{"hierarchy":{"lvl1":"1. Sentinel-1 GRD"},"content":"\n\nSetting of AOI bounding box\n\nx1 = 10.00  # degree\ny1 = 54.27  # degree\nx2 = 11.00  # degree\ny2 = 54.60  # degree\n\nbbox = x1, y1, x2, y2\n\nspatial_res = 0.00018   # = 20.038 meters in degree\n\nSentinel Hub currently supported Sentinel-1 GRD (Ground Range Detected) products: \n\nhere\n\ncube_config = CubeConfig(dataset_name='S1GRD',\n                         band_names=['VH'],\n                         tile_size=[512, 512],\n                         crs = \"http://www.opengis.net/def/crs/EPSG/0/4326\",\n                         spatial_res = spatial_res,\n                         geometry=bbox,\n                         time_range=['2019-05-14', '2019-07-31'],\n                         time_period='2D')  \n\ncube = open_cube(cube_config, **sh_credentials)\ncube\n\ncube.VH.isel(time=1).plot.imshow(cmap='Greys',vmax =0.08, figsize = [16,12])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#id-1-sentinel-1-grd","position":5},{"hierarchy":{"lvl1":"Sentinel-2 L2A (SLC)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#sentinel-2-l2a-slc","position":6},{"hierarchy":{"lvl1":"Sentinel-2 L2A (SLC)"},"content":"\n\nSentinel Hub currently supported Sentinel-2 products: \n\nhere\n\ncube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['SCL'],\n                         tile_size=[512, 512],\n                         geometry=bbox,\n                         spatial_res=spatial_res,\n                         time_range=['2018-05-14', '2018-07-31'],\n                         time_tolerance='30M')  \n\nsh_credentials.update(instance_id='<your sentinel hub instance id>') # To access Sentinel 2, instance id has to be provided. Can be obtained at Sentinel-hub dashboard\n\ncube = open_cube(cube_config, **sh_credentials)\ncube\n\ncube.SCL.isel(time=5, lat=slice(0,2000),lon=slice(0,2000)).plot.imshow(cmap='tab20c')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#sentinel-2-l2a-slc","position":7},{"hierarchy":{"lvl1":"3. Sentinel-5P L2"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#id-3-sentinel-5p-l2","position":8},{"hierarchy":{"lvl1":"3. Sentinel-5P L2"},"content":"\n\nSentinel Hub currently supported Sentinel-5P products: \n\nhere\n\ncube_config = CubeConfig(dataset_name='S5PL2',\n                         band_names=['NO2'],\n                         tile_size=[512, 512],\n                         geometry=bbox,\n                         spatial_res=(bbox[2]-bbox[0])/512,\n                         time_range=['2018-05-14', '2018-07-31'],\n                         time_period='3D')  \n\nsh_credentials.update(api_url='https://creodias.sentinel-hub.com/api/v1') # Sentinel-3 OLCI, Sentinel-3 SLSTR and Sentinel-5 layers are processed on different infrastructure, which requires to used different end-point\n\ncube = open_cube(cube_config, **sh_credentials)\ncube\n\ncube.NO2.isel(time=5).plot.imshow()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#id-3-sentinel-5p-l2","position":9},{"hierarchy":{"lvl1":"4. Pleiades"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#id-4-pleiades","position":10},{"hierarchy":{"lvl1":"4. Pleiades"},"content":"\n\nDataset as Pleiades or PlanetScope are available as similar as \n\nBYOC data i.e. dataset name is ‘CUSTOM’ and specific instance-id together with collection id have to be provided\n\nsh_credentials.update(instance_id='<sentinel hub pleiades instance id>') # pleiades instance id, can be found at Sentinel Hub dashboard at configuration\nsh_credentials.update(api_url='https://services.sentinel-hub.com/api/v1') # changing of the base url back to services.sentinel-hub\n\n\nNew bbox for scenes available for Pleiades (Esselunga supermarket Rome). Others \n\nhere\n\nx1 = 1398664 # meters\ny1 = 5145138  # meters\n\nspatial_res = 2 # 2m resolution of Pleiades\n\ndef coor(axis,res,point):\n    return res*axis + point\npoint = partial(coor,500,3)\n\nbbox = x1, y1, point(x1), point(y1)\n\ncube_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=['B0', 'B1', 'B2'],                        \n                         tile_size=[500, 500],\n                         crs='http://www.opengis.net/def/crs/EPSG/0/3857',\n                         geometry=bbox,\n                         time_range=['2019-03-31', '2019-05-01'],\n                         time_period='10d',\n                         spatial_res=spatial_res,\n                         band_sample_types='FLOAT32',\n                         collection_id='<collection_id>')\n\ncube = open_cube(cube_config, **sh_credentials)\ncube\n\ncube.time\n\ncube_time = cube.sel(time='2019-04-05')\n\ny, x = cube_time.B0.shape\n\nRED(B2), GREEN(B1), BLUE(B0) \n\nviz\n\nrgb_data = np.zeros((y, x, 3), 'float32')\nrgb_data[:, :, 0] = cube_time.B2.values/10000\nrgb_data[:, :, 1] = cube_time.B1.values/10000\nrgb_data[:, :, 2] = cube_time.B0.values/10000\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#id-4-pleiades","position":11},{"hierarchy":{"lvl1":"Pleiades (directly from Sentinel Hub)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#pleiades-directly-from-sentinel-hub","position":12},{"hierarchy":{"lvl1":"Pleiades (directly from Sentinel Hub)"},"content":"\n\nCLIENT_ID = '<your client id>'\nCLIENT_SECRET = '<your client secret>'\n\nINSTANCE_ID = '<your instance id>' # instance_id  corresponding to PlanetScope instance (can be found at Sentinel-hub dashboard)\nCOLECTION_ID = '<your colection id>' # colleciton_id (can be found at Sentinel-hub dashboard at instance configuration)\nLAYER_ID = 'TRUECOLOR'  # layer_id can be found at Sentinel-hub dashboard at instance configuration\n\nconfig = SHConfig()\nconfig.sh_client_id = CLIENT_ID\nconfig.sh_client_secret = CLIENT_SECRET\nconfig.instance_id = INSTANCE_ID\n\nx1 = 1398664 # meters\ny1 = 5145138  # meters\nspatial_res = 3 # 3m resolution of PlanetScope\n\ndef coor(axis,res,p):\n    return res*axis + p\npoint = partial(coor,500,3)\n\nbbox = BBox(bbox=[x1, y1, point(x1), point(y1)], crs=3857)\n\nbyoc_request = WmsRequest(\n    data_source=DataSource(COLECTION_ID),\n    layer=LAYER_ID,\n    bbox=bbox,\n    width=500,\n    time=('2019-03-31', '2019-05-01'),\n    config=config\n)\n\nbyoc_data = byoc_request.get_data()\nplt.imshow(byoc_data[0])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#pleiades-directly-from-sentinel-hub","position":13},{"hierarchy":{"lvl1":"5. PlanetScope"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#id-5-planetscope","position":14},{"hierarchy":{"lvl1":"5. PlanetScope"},"content":"\n\nDataset as Pleiades or PlanetScope are available as similar as \n\nBYOC data i.e. dataset name is ‘CUSTOM’ and specific instance-id together with collection id have to be provided\n\nsh_credentials.update(instance_id='<planetscope instance id>')\n\nNew bbox for scenes available for PlaneteScope (Esselunga supermarket Rome). Others \n\nhere\n\nx1 = 1398664 # meters\ny1 = 5145138  # meters\n\nspatial_res = 3 # 3m resolution of PlanetScope\n\nwidth = 500\nheight = 500\nx2 = spatial_res*width + x1\ny2 = spatial_res*height + y1\n\nbbox = x1, y1, x2, y2\n\ncube_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=['B1', 'B2', 'B3'],                        \n                         tile_size=[width, height],\n                         crs='http://www.opengis.net/def/crs/EPSG/0/3857',\n                         geometry=bbox,\n                         time_range=['2019-03-31', '2019-05-01'],\n                         time_period='1d',\n                         spatial_res=spatial_res,\n                         band_sample_types='FLOAT32',\n                         collection_id='<collection id>')\n\ncube = open_cube(cube_config, **sh_credentials)\ncube\n\ncube_time = cube.isel(time=0, x=slice(0,width),y=slice(0,height))\ny, x = cube_time.B1.shape\n\nRED(B3), GREEN(B2), BLUE(B1) \n\nviz\n\nrgb_data = np.zeros((y, x, 3), 'float32')\nrgb_data[:, :, 0] = cube_time.B3.values/3000\nrgb_data[:, :, 1] = cube_time.B2.values/3000\nrgb_data[:, :, 2] = cube_time.B1.values/3000\n\nrgb_array = xr.DataArray(rgb_data, dims=('y', 'x', 'rgb'),  coords=dict(x=cube.B1.x, y=cube.B1.y))\nrgb_array.plot.imshow()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#id-5-planetscope","position":15},{"hierarchy":{"lvl1":"PlanetScope (directly from Sentinel Hub)"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#planetscope-directly-from-sentinel-hub","position":16},{"hierarchy":{"lvl1":"PlanetScope (directly from Sentinel Hub)"},"content":"\n\nCLIENT_ID = '<your client id>'\nCLIENT_SECRET = '<your client secret>'\n\nINSTANCE_ID = '<your instance id>' # instance_id  corresponding to PlanetScope instance (can be found at Sentinel-hub dashboard)\nCOLECTION_ID = '<your colection id>' # colleciton_id (can be found at Sentinel-hub dashboard at instance configuration)\nLAYER_ID = '1_TRUE-COLOR' # layer_id can be found at Sentinel-hub dashboard at instance configuration\n\nconfig = SHConfig()\nconfig.sh_client_id = CLIENT_ID\nconfig.sh_client_secret = CLIENT_SECRET\nconfig.instance_id = INSTANCE_ID\n\nx1 = 1398864 # meters\ny1 = 5145138  # meters\nspatial_res = 3 # 3m resolution of PlanetScope\n\ndef coor(axis,res,point):\n    return res*axis + point\nres = partial(coor,500,3)\n\nbbox = BBox(bbox=[x1, y1, res(x1), res(y1)], crs=3857)\n\nbyoc_request = WmsRequest(\n    data_source=DataSource(COLECTION_ID),\n    layer=LAYER_ID,\n    bbox=bbox,\n    width=500,\n    time=('2019-03-31', '2019-05-01'),\n    config=config\n)\n\nbyoc_data = byoc_request.get_data()\nplt.imshow(byoc_data[0])","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/xcube-access-datasets#planetscope-directly-from-sentinel-hub","position":17},{"hierarchy":{"lvl1":"How to access IACS Spatial Data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data","position":0},{"hierarchy":{"lvl1":"How to access IACS Spatial Data"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"GEODB\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data","position":1},{"hierarchy":{"lvl1":"How to access IACS Spatial Data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#how-to-access-iacs-spatial-data","position":2},{"hierarchy":{"lvl1":"How to access IACS Spatial Data"},"content":"Easily access publicly available georeferenced LPIS/GSAA data in a homogenised format through the \n\nmarketplace.\n\nIn this notebook, you will be guided through the steps to access LPIS/GSAA data purchased through the \n\nIACS Spatial Data tile in the Marketplace.\n\n# Import libraries\nfrom edc import setup_environment_variables\nfrom xcube_geodb.core.geodb import GeoDBClient\nimport pandas as pd\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#how-to-access-iacs-spatial-data","position":3},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl2":"1. List available collections"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#id-1-list-available-collections","position":4},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl2":"1. List available collections"},"content":"In the following steps we will list the geodb collections that are available to you. By default, a certain number of collections are available freely for demonstration purposes. Once you have purchased the data for a or multiple EU member states, the collections will appear in the list.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#id-1-list-available-collections","position":5},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"Fetch the GeoDB client","lvl2":"1. List available collections"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#fetch-the-geodb-client","position":6},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"Fetch the GeoDB client","lvl2":"1. List available collections"},"content":"\n\ngeodb = GeoDBClient()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#fetch-the-geodb-client","position":7},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"Check your username","lvl2":"1. List available collections"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#check-your-username","position":8},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"Check your username","lvl2":"1. List available collections"},"content":"In the next cell we will print our geodb username.\n\ngeodb.whoami\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#check-your-username","position":9},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"List the collections currently accessible in the lpis_iacs database","lvl2":"1. List available collections"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#list-the-collections-currently-accessible-in-the-lpis-iacs-database","position":10},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"List the collections currently accessible in the lpis_iacs database","lvl2":"1. List available collections"},"content":"Even if you haven’t yet purchased the access to a collection, you should be able to see the free datasets available for demonstration purposes.\n\nmy_collection = geodb.get_my_collections(database=\"lpis_iacs\")\n\n# Print list of collections accessible\nmy_collection\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#list-the-collections-currently-accessible-in-the-lpis-iacs-database","position":11},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl2":"2. Access a specific collection"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#id-2-access-a-specific-collection","position":12},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl2":"2. Access a specific collection"},"content":"Now that we have listed the available collections, we will see how to access a specific collection. For further information on how to manipulate the collection, you can refer to the following tutorial notebooks:\n\nGeoDB: Manage Datasets\n\nGeoDB: Explore Datasets\n\nGeoDB: Sharing Data\n\nFor this example, we will access a free demonstration dataset called land_use_slo in the lpis_iacs database. This dataset represents Land Use / Land Cover for Slovenia in 2018. Since it is a large collection, we will limit the request to the first 20 entries.\n\ngdf = geodb.get_collection_pg('land_use_slo', database='lpis_iacs', limit=20)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#id-2-access-a-specific-collection","position":13},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"Print the requested dataset","lvl2":"2. Access a specific collection"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#print-the-requested-dataset","position":14},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"Print the requested dataset","lvl2":"2. Access a specific collection"},"content":"\n\ngdf\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#print-the-requested-dataset","position":15},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"Plot the collection based on a specific column","lvl2":"2. Access a specific collection"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#plot-the-collection-based-on-a-specific-column","position":16},{"hierarchy":{"lvl1":"How to access IACS Spatial Data","lvl3":"Plot the collection based on a specific column","lvl2":"2. Access a specific collection"},"content":"First, we will query the dataset for a given area, using the get_collection_by_bbox method.\n\n# Get bounding box coordinates for Ljubljiana in EPSG: 3794\nlju_coords = (456543, 99294, 460617, 103213)\n\n\n# Fetch collection in the given bounding box\ngdf_lju = geodb.get_collection_by_bbox('land_use_slo', database='lpis_iacs', bbox = lju_coords, comparison_mode=\"contains\", bbox_crs=3794)\n\nThen we can easily plot the sampled data by one of it’s attributes.\n\ngdf_lju.plot(column=\"raba_id\", figsize=(15,15), cmap = 'viridis')","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data#plot-the-collection-based-on-a-specific-column","position":17},{"hierarchy":{"lvl1":"Access CCI data with xcube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-access-cci-data","position":0},{"hierarchy":{"lvl1":"Access CCI data with xcube"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.07-01\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-access-cci-data","position":1},{"hierarchy":{"lvl1":"Access CCI data with xcube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-access-cci-data#access-cci-data-with-xcube","position":2},{"hierarchy":{"lvl1":"Access CCI data with xcube"},"content":"This notebook provides a walk-through demonstrating how to use xcube and the xcube store for the \n\nOpen Data Portal of the \n\nESA Climate Change Initiative (CCI) to read and explore CCI data.\n\n# mandatory imports\nfrom xcube.core.store import find_data_store_extensions\nfrom xcube.core.store import get_data_store_params_schema\nfrom xcube.core.store import new_data_store\n\n# Utilities for notebook visualization\nimport shapely.geometry\nfrom IPython.display import JSON\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = 16,8\n\nxcube store are self-descritptive and may be queried for detailed information, e.g., which data store parameters are available for cciodp? (We’ll take a look at the ccizarr data store later.)\n\nget_data_store_params_schema('cciodp')\n\nInstantiate a new cci store:\n\nstore = new_data_store('cciodp')\nstore\n\nWhich datasets are provided? (the list may contain both gridded and vector datasets):\n\nThe store can be queried for a specific dataset:\n\nstore.has_data('esacci.OC.5-days.L3S.CHLOR_A.multi-sensor.multi-platform.MERGED.3-1.geographic')\n\nIn many cases, however, a search for specific crieteria will precede a query. How can this be done?\n\nstore.get_search_params_schema()\n\nIn this example, a multi-sensor sea surface temperature data (SST) with a daily frequency is searched for. The search results in three items.\n\niterator = store.search_data(cci_attrs=dict(ecv='SST', sensor='multi-sensor', frequency='day'))\nJSON([item.to_dict() for item in iterator])\n\nWhich parameters must be passsed or are available to open a specific dataset?\n\nstore.get_open_data_params_schema('esacci.SST.day.L4.SSTdepth.multi-sensor.multi-platform.OSTIA.1-1.r1')\n\nThis query selects one variable form a specific dataset and subsets it in time. Note that the data is loaded lazily, which ensures a fast view into the dataset, even if large. In turn, however, the data transfer may slow down large-scale processing. Depending on the application, separating data transfer and processing may be advisable.\n\ndataset = store.open_data('esacci.SST.day.L4.SSTdepth.multi-sensor.multi-platform.OSTIA.1-1.r1', \n                          variable_names=['analysed_sst'],\n                          time_range=['2000-01-01','2010-12-31'])\n\ndataset\n\nPlot one time stamp of the dataset for a analysed_sst in order to take a brief look at the dataset:\n\ndataset.analysed_sst.sel(time='2005-12-12', method='nearest').plot.imshow(cmap='plasma')\n\ndataset_ts = store.open_data('esacci.SST.day.L4.SSTdepth.multi-sensor.multi-platform.OSTIA.1-1.r1', \n                          variable_names=['analysed_sst'], bbox=[-50, 20.,-49.95,20.05],\n                          time_range=['2000-01-01','2000-12-31'])\n\ndataset_ts\n\ndataset_ts.analysed_sst.plot()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-access-cci-data#access-cci-data-with-xcube","position":3},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11","position":0},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"GEODB\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11","position":1},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#manage-collections-in-your-geodb","position":2},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#manage-collections-in-your-geodb","position":3},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Connecting to the GeoDB"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#connecting-to-the-geodb","position":4},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Connecting to the GeoDB"},"content":"\n\nfrom xcube_geodb.core.geodb import GeoDBClient\nfrom xcube_geodb.version import version\n\ngeodb = GeoDBClient()\n\n# If you are logged in, this will tell you what account the system currently uses\ngeodb.whoami\n\nCheckout the deployed SQL version:\n\ngeodb.get_geodb_sql_version()\n\nCheckout the version of xcube geoDB software in your workspace:\n\nversion\n\n# Lets get already existing collections\nds = geodb.get_my_collections()\nds\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#connecting-to-the-geodb","position":5},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Creating collections"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#creating-collections","position":6},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Creating collections"},"content":"Once the connection has been established you will be able to create a collection. The collection will contain standard properties (fields) plus custom properties\nwhich you can add at your disgretion. Please use \n\nPostGreSQL type definitions. We recommend stying simple with\nyour data types as we have not tested every single type.\n\nds = geodb.get_my_collections()\n\nif ds[(ds.database == geodb.whoami) & (ds.collection == 'land_use')].collection.count() == 0:\n    # Have a look at fiona feature schema\n    collections = {\n            \"land_use\": \n            {\n                \"crs\": 3794,\n                \"properties\": \n                {\n                    \"RABA_PID\": \"float\", \n                    \"RABA_ID\": \"float\", \n                    \"D_OD\": \"date\"\n                }\n            }\n        }\n\n\n    geodb.create_collections(collections)\n    import geopandas\n    import os\n    gdf = geopandas.read_file(\"/shared/eurodatacube/curated/data/sample/land_use.shp\")\n    geodb.insert_into_collection('land_use', gdf)\n\nds = geodb.get_my_collections(database=geodb.whoami)\nds\n\nSee the chanhes made to the collection:\n\ngeodb.get_event_log('land_use')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#creating-collections","position":7},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Loading data into a dataset"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#loading-data-into-a-dataset","position":8},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Loading data into a dataset"},"content":"Once the table has been created, you can load data into the dataset. The example below loads a shapefile. The attributes of the shapefile correspond to the dataset’s properties.\n\nimport geopandas\nimport os\ngdf = geopandas.read_file(\"/shared/eurodatacube/curated/data/sample/land_use.shp\")\ngdf\n\ngeodb.insert_into_collection('land_use', gdf)\n\nSee the chanhes made to the collection:\n\ngeodb.get_event_log('land_use')\n\ngeodb.get_collection('land_use', query=\"raba_id=eq.7000\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#loading-data-into-a-dataset","position":9},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Delete from a Collection"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#delete-from-a-collection","position":10},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Delete from a Collection"},"content":"\n\ngeodb.delete_from_collection('land_use', query=\"raba_id=eq.7000\")\n\nSee the chanhes made to the collection:\n\ngeodb.get_event_log('land_use')\n\ngeodb.get_collection('land_use', query=\"raba_id=eq.7000\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#delete-from-a-collection","position":11},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Updating a Collection"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#updating-a-collection","position":12},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Updating a Collection"},"content":"\n\ngeodb.get_collection('land_use', query=\"raba_id=eq.1300\")\n\ngeodb.update_collection('land_use', query=\"raba_id=eq.1300\", values={'d_od': '2000-01-01'})\n\ngeodb.get_collection('land_use', query=\"raba_id=eq.1300\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#updating-a-collection","position":13},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Managing Properties of a Collection"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#managing-properties-of-a-collection","position":14},{"hierarchy":{"lvl1":"Manage Collections in your GeoDB","lvl2":"Managing Properties of a Collection"},"content":"\n\ngeodb.get_my_collections()\n\ngeodb.get_properties('land_use')\n\ngeodb.add_property('land_use', \"test_prop\", 'integer')\n\ngeodb.get_properties('land_use')\n\ngeodb.drop_property('land_use', 'test_prop')\n\ngeodb.get_properties('land_use')\n\ngeodb.add_properties('land_use', properties={'test1': 'integer', 'test2': 'date'})\n\ngeodb.get_properties('land_use')\n\ngeodb.drop_properties('land_use', properties=['test1', 'test2'])\n\ngeodb.get_properties('land_use')\n\ngeodb.drop_collection('land_use')\n\nSee the chanhes made to the collection:\n\ngeodb.get_event_log('land_use')","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-1-manage-datasets-v11#managing-properties-of-a-collection","position":15},{"hierarchy":{"lvl1":"Exploring Data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-2-explore-datasets-2","position":0},{"hierarchy":{"lvl1":"Exploring Data"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"GEODB\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-2-explore-datasets-2","position":1},{"hierarchy":{"lvl1":"Exploring Data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-2-explore-datasets-2#exploring-data","position":2},{"hierarchy":{"lvl1":"Exploring Data"},"content":"\n\nfrom xcube_geodb.core.geodb import GeoDBClient\n\n# utility needed for plotting\nimport matplotlib.pyplot as plt\n\ngeodb = GeoDBClient()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-2-explore-datasets-2#exploring-data","position":3},{"hierarchy":{"lvl1":"Exploring Data","lvl2":"Get your user name"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-2-explore-datasets-2#get-your-user-name","position":4},{"hierarchy":{"lvl1":"Exploring Data","lvl2":"Get your user name"},"content":"\n\ngeodb.whoami\n\nds = geodb.get_my_collections()\n\nif ds[(ds.database == geodb.whoami) & (ds.collection == 'land_use')].collection.count() == 0:\n    # Have a look at fiona feature schema\n    collections = {\n            \"land_use\": \n            {\n                \"crs\": 3794,\n                \"properties\": \n                {\n                    \"RABA_PID\": \"float\", \n                    \"RABA_ID\": \"float\", \n                    \"D_OD\": \"date\"\n                }\n            }\n        }\n\n\n    geodb.create_collections(collections)\n    import geopandas\n    import os\n    gdf = geopandas.read_file(\"/shared/eurodatacube/curated/data/sample/land_use.shp\")\n    geodb.insert_into_collection('land_use', gdf)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-2-explore-datasets-2#get-your-user-name","position":5},{"hierarchy":{"lvl1":"Exploring Data","lvl2":"List Datasets"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-2-explore-datasets-2#list-datasets","position":6},{"hierarchy":{"lvl1":"Exploring Data","lvl2":"List Datasets"},"content":"Step 1: List all datasets a user has access to.\n\ngeodb.get_my_collections()\n\nStep 2: Let’s get the whole content of a particular data set.\n\ngdf = geodb.get_collection('land_use')\ngdf\n\nStep 3: Plot the GeoDataframe, select a reasonable column to diplay\n\ngdf.plot(column=\"raba_id\", figsize=(15,15), cmap = 'jet')\nplt.show()\n\nStep 5: Subselect the data. Here: Select a specific use by defining an ID value to choose\n\ngdfsub = geodb.get_collection('land_use', query='raba_id=eq.1410')\ngdfsub.head()\n\ngdfsub.plot(column=\"raba_id\", figsize=(15,15), cmap = 'jet')\nplt.show()\n\nStep 6: Filter by bbox, limit it to 200 entries\n\ngdf = geodb.get_collection_by_bbox(collection=\"land_use\", bbox = (452750.0, 88909.549, 464000.0, 102486.299), comparison_mode=\"contains\", bbox_crs=3794, limit=200, offset=10)\ngdf\n\ngdf.plot(column=\"raba_pid\", figsize=(15,15), cmap = 'jet')\nplt.show()\n\nStep 6: Fltering using PostGres Syntax; see \n\nhttps://​www​.postgresql​.org​/docs​/9​.1​/index​.html for details\n\ngdf = geodb.get_collection_pg(collection='land_use', where='raba_id=1410')\ngdf.head()\n\ngdf.plot(column=\"raba_pid\", figsize=(15,15), cmap = 'jet')\nplt.show()\n\nStep 7: Fltering using PostGres Syntax Allowing Aggregation\nHere according to data, note that the data set has been reduced to 200 entries above\n\ndf = geodb.get_collection_pg('land_use', where='raba_id=1410', group='d_od', select='COUNT(d_od) as ct, d_od')\ndf.head()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-2-explore-datasets-2#list-datasets","position":7},{"hierarchy":{"lvl1":"Sharing Data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1","position":0},{"hierarchy":{"lvl1":"Sharing Data"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"GEODB\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1","position":1},{"hierarchy":{"lvl1":"Sharing Data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1#sharing-data","position":2},{"hierarchy":{"lvl1":"Sharing Data"},"content":"\n\nfrom xcube_geodb.core.geodb import GeoDBClient\n\ngeodb = GeoDBClient()\ngeodb.whoami\n\nds = geodb.get_my_collections()\n\nif ds[(ds.database == geodb.whoami) & (ds.collection == 'land_use')].collection.count() == 0:\n    # Have a look at fiona feature schema\n    collections = {\n            \"land_use\": \n            {\n                \"crs\": 3794,\n                \"properties\": \n                {\n                    \"RABA_PID\": \"float\", \n                    \"RABA_ID\": \"float\", \n                    \"D_OD\": \"date\"\n                }\n            }\n        }\n\n\n    geodb.create_collections(collections)\n    import geopandas\n    import os\n    gdf = geopandas.read_file(\"/shared/eurodatacube/curated/data/sample/land_use.shp\")\n    geodb.insert_into_collection('land_use', gdf)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1#sharing-data","position":3},{"hierarchy":{"lvl1":"Sharing Data","lvl2":"Publish a Collection to the World"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1#publish-a-collection-to-the-world","position":4},{"hierarchy":{"lvl1":"Sharing Data","lvl2":"Publish a Collection to the World"},"content":"\n\ngeodb.list_my_grants()\n\ngeodb.publish_collection(\"land_use\")\n\nSee the chanhes made to the collection:\n\ngeodb.get_event_log('land_use')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1#publish-a-collection-to-the-world","position":5},{"hierarchy":{"lvl1":"Sharing Data","lvl2":"Accessing Collection as a different User"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1#accessing-collection-as-a-different-user","position":6},{"hierarchy":{"lvl1":"Sharing Data","lvl2":"Accessing Collection as a different User"},"content":"Please be aware that you cannot change the user easily within a Notebook. Here, we changed the credentials in the background. The following cells will not run and are for demonstration only.\n\ngeodb = GeoDBClient()\ngeodb.whoami\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1#accessing-collection-as-a-different-user","position":7},{"hierarchy":{"lvl1":"Sharing Data","lvl2":"Revoke access"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1#revoke-access","position":8},{"hierarchy":{"lvl1":"Sharing Data","lvl2":"Revoke access"},"content":"\n\ngeodb.list_my_grants()\n\ngeodb.unpublish_collection(\"land_use\")\n\nSee the chanhes made to the collection:\n\ngeodb.get_event_log('land_use')\n\ngeodb.list_my_grants()\n\ngdf = geodb.get_collection_by_bbox(collection=\"land_use\", bbox=(452750.0, 88909.549, 464000.0, 102486.299),\n                comparison_mode=\"contains\", bbox_crs=3794, limit=2, offset=10)\ngdf","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-3-share-datasets1#revoke-access","position":9},{"hierarchy":{"lvl1":"[xcube-geodb] How to accesss EEA Urban Atlas Data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-access-urban-atlas-data-v1","position":0},{"hierarchy":{"lvl1":"[xcube-geodb] How to accesss EEA Urban Atlas Data"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"GEODB\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-access-urban-atlas-data-v1","position":1},{"hierarchy":{"lvl1":"[xcube-geodb] How to accesss EEA Urban Atlas Data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-access-urban-atlas-data-v1#id-xcube-geodb-how-to-accesss-eea-urban-atlas-data","position":2},{"hierarchy":{"lvl1":"[xcube-geodb] How to accesss EEA Urban Atlas Data"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-access-urban-atlas-data-v1#id-xcube-geodb-how-to-accesss-eea-urban-atlas-data","position":3},{"hierarchy":{"lvl1":"[xcube-geodb] How to accesss EEA Urban Atlas Data","lvl2":"Brought to you by Brockmann Consult"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-access-urban-atlas-data-v1#brought-to-you-by-brockmann-consult","position":4},{"hierarchy":{"lvl1":"[xcube-geodb] How to accesss EEA Urban Atlas Data","lvl2":"Brought to you by Brockmann Consult"},"content":"\n\nThe full statistical validation of Urban Atlas 2018 hasn't been performed yet. The European Environment Agency accepts no responsibility or liability whatsoever with regard to use of the non-validated Urban Atlas 2018 data.\n\nIn this Notebook we present how to:\n\nUse xcube-geodb\n\nThe xcube-geodb consists of a Restful service and a Python client. Let’s import the Python dependencies to access the geodb service.\n\nStep 1: Import the geodb client\n\nfrom xcube_geodb.core.geodb import GeoDBClient\n\nStep 2: Instantiate the client\n\ngeodb = GeoDBClient()\n\nStep 3: As a subscriber a user name is associated with you. Check your user name.\n\ngeodb.whoami\n\nStep 4: Let’s see if you have access to the collections within ‘eea-urban-atlas’ database\n\nds = geodb.get_my_collections(database='eea-urban-atlas')\nds\n\nStep 5: In the table ‘METADATA’ you can find a list of all table_names with a link to the corresponding metadata xml.\n\nmetadata = geodb.get_collection('METADATA', database='eea-urban-atlas')\nmetadata\n\nStep 6: Let’s checkout the metadata for Hamburg:\n\nmetadata.loc[metadata['table_name'] == 'DE002L1_HAMBURG_UA2018']\n\nStep 7: Let’s check the data for Hamburg, it is a lot - so it might take a moment:\n\ndata_hh = geodb.get_collection('DE002L1_HAMBURG_UA2018', database='eea-urban-atlas')\ndata_hh\n\nStep 8: Are you eager to vizualise the data? Here we go, import matplotlib first and then you can go ahead and plot the data. Again - it takes a few moments, after all there are 75883 polygons in the data :)\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1, figsize=(20,18))\ndata_hh.plot(column=\"code_2018\", cmap=\"tab20\", ax=ax, legend=True)\n\nHere some fun stuff :) Let’s make an interactive plot where you can choose from all the tables available in database ‘eea-urban-atlas’\n\nFrist, let’s create a sorted list of all table_names:\n\ncities = sorted(metadata['table_name'].tolist())\n\ndef plot_city(city=cities[0]):\n    #A bit hidden in this function lies the query against the RACE collection of interest.\n    gdf = geodb.get_collection(city, database='eea-urban-atlas')\n    separator = ' '\n    title =  separator.join(city.split('_')[1:-1])\n\n    fig, ax = plt.subplots(1, 1, figsize=(20,18))\n    plt.title(title)\n    gdf.plot(column=\"code_2018\", cmap=\"tab20\", ax=ax, legend=True)\n    plt.show()\n    plt.close()\n    \n\n\nBy default, the firtst item of the city list is plotted. If you want a certain place, you can simply use the plot function with the table_name.\n\nplot_city()\n\nAs an addition we can now use the above function to get an interactive widget to query the eea-urban-atlas database.\n\nfrom __future__ import print_function\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\n\n\n# interact(plot_city, city=cities);\n\nAlright, now you are ready to explore the data on your own! Enjoy!\n\nThe full statistical validation of Urban Atlas 2018 hasn't been performed yet. The European Environment Agency accepts no responsibility or liability whatsoever with regard to use of the non-validated Urban Atlas 2018 data.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-geodb-access-urban-atlas-data-v1#brought-to-you-by-brockmann-consult","position":5},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic","position":0},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic","position":1},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#edc-sentinel-hub-data-fusion","position":2},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#edc-sentinel-hub-data-fusion","position":3},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Example 1: Filling clouds in a Sentinel-2 image with Sentinel-1 SAR data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#example-1-filling-clouds-in-a-sentinel-2-image-with-sentinel-1-sar-data","position":4},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Example 1: Filling clouds in a Sentinel-2 image with Sentinel-1 SAR data"},"content":"This notebook shows how to request \n\nS1 GRD and \n\nS2 L1A from the \n\nSentinel Hub API, and how to merge the data in an \n\nevalscript.\n\nThe S2 True Color composition is returned (R: B04, G: B03, B: B02), whereas cloud covered areas are replaced by the S1 VV polarization band.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#example-1-filling-clouds-in-a-sentinel-2-image-with-sentinel-1-sar-data","position":5},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl3":"Prerequisites","lvl2":"Example 1: Filling clouds in a Sentinel-2 image with Sentinel-1 SAR data"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#prerequisites","position":6},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl3":"Prerequisites","lvl2":"Example 1: Filling clouds in a Sentinel-2 image with Sentinel-1 SAR data"},"content":"This notebook requires an active subscription to:\n\nEDC Sentinel Hub\n\n# Request tools imports\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# Utilities\nimport os\nimport shapely.geometry\nimport IPython.display\n\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#prerequisites","position":7},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl3":"Setup","lvl2":"Example 1: Filling clouds in a Sentinel-2 image with Sentinel-1 SAR data"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#setup","position":8},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl3":"Setup","lvl2":"Example 1: Filling clouds in a Sentinel-2 image with Sentinel-1 SAR data"},"content":"\n\n# Pass the Sentinel Hub Client ID and Secret to variables to be used in the request.\nmy_client_id = %env SH_CLIENT_ID\nmy_client_secret = %env SH_CLIENT_SECRET\n\n# Create an OAuth2 session based on the client ID\nclient = BackendApplicationClient(client_id=my_client_id)\noauth = OAuth2Session(client=client)\n\nThe Sentinel Hub API uses OAuth2 Authentication and requires that you have an \n\naccess token. These tokens are limited in time, but a new one can be requested with the following command.\n\n# Get a token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_id=my_client_id, client_secret=my_client_secret)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#setup","position":9},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Setting an area of interest"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#setting-an-area-of-interest","position":10},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Setting an area of interest"},"content":"We will download Sentinel-1 and Sentinel-2  imagery of the hills located to the North of # Ljubljana, Slovenia.\nThe bounding box is in the WGS84 coordinate system, and consists of the longitude and latitude coordinates of lower left and upper right corners.\n\n# Set bounding box coordinates for the area of interest\nbbox = (14.37595, 46.09347, 14.56924, 46.19266)\n\n# Display the coordinates on a map\nIPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#setting-an-area-of-interest","position":11},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"API request"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#api-request","position":12},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"API request"},"content":"We need to specify arguments to send a POST request, more information about all the availaible options \n\nhere:\n\nThe access point URL:  set it to https://services.sentinel-hub.com/api/v1/process\n\njson - the contents of the request containing:\n\ninput: (required) specifies the data to request:\n\nbounds: defines the request bounds by specifying the bounding box and/or geometry for the request.\n\ndata: describes the data being requested along with certain processing and filtering parameters.\n\noutput: (optional) allows to set parameters for the returned data\n\nwidth: The request image width. Must be an integer between 1 and 2500.\n\nheight: The request image height. Must be an integer between 1 and 2500.\n\nevalscript: calculates the output values for each pixel\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#api-request","position":13},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 1","lvl2":"API request"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#step-1","position":14},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 1","lvl2":"API request"},"content":"First, set the input options. The options are set in the form of a dictionary with key/values pairs.\n\nSpecify the bounds of your request using the bounding box previously described and specifying the \n\nprojection (one of the CRS supported by Sentinel Hub API).\n\nSpecify the data to fetch. As in this example there are 2 data sources (Sentinel-1 and Sentinel-2), the options for each sensor are specified in a list of dictionaries.\n\n# 1. Bounds \nbounds = {\"properties\":{\"crs\":\"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"}, \"bbox\": bbox}\n\n# 2. Data\ndata = [{\"id\": \"s1\", \n         \"type\": \"S1GRD\",\n          \"dataFilter\": {\"timeRange\": {\"from\": \"2020-02-01T00:00:00Z\",\n                                       \"to\": \"2020-02-06T00:00:00Z\"},\n                         \"mosaickingOrder\": \"mostRecent\"}},\n         {\"id\": \"l2a\",\n          \"type\": \"S2L2A\",\n          \"dataFilter\": {\"timeRange\": {\"from\": \"2020-02-01T00:00:00Z\",\n                                       \"to\": \"2020-02-06T00:00:00Z\"},\n                         \"mosaickingOrder\": \"mostRecent\"}}]\n# Set the options to the input\ninput_options = {\"bounds\": bounds, \"data\": data,}\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#step-1","position":15},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 2","lvl2":"API request"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#step-2","position":16},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 2","lvl2":"API request"},"content":"Then set the output options. The default output size of the requested image is 256x256 pixels, so here we will modify the output to be larger. The result will be displayed only, therefore we also set the output format to jpeg.\n\noutput_options = {\"width\": 640, \"height\": 640, \"responses\": [{\"format\": {\"type\": \"image/jpeg\",\n                                                                         \"quality\": 90}}]}\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#step-2","position":17},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 3","lvl2":"API request"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#step-3","position":18},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 3","lvl2":"API request"},"content":"The \n\nevalscript is a piece of javascript code that allows to process the pixels of the images that are returned.\n\nIn the current example, the S1 and S2 bands needed are called in the setup function of the script.\n\nThe evaluatePixel function returns the S1 VV polarization band for the pixels in the S2-L2A SCL band (see \n\nhere) classified as:\n\n7 - Clouds low probability / Unclassified\n\n8 - Clouds medium probability\n\n9 - Clouds high probability\n\n10 - Cirrus\n\nFor all the other pixels the S2 \n\nTrue Color visualisation is returned (scaled by 2.5 for better viewing).\n\nevascript = \"\"\"\n//VERSION=3\nfunction setup (){\n  return {\n    input: [\n      {datasource: \"s1\", bands:[\"VV\"]},\n      {datasource: \"l2a\", bands:[\"B02\", \"B03\", \"B04\", \"SCL\"], units:[\"REFLECTANCE\", \"REFLECTANCE\", \"REFLECTANCE\", \"DN\"]}],\n    output: [\n      {id: \"default\", bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\nfunction evaluatePixel(samples, inputData, inputMetadata, customData, outputMetadata) {\n  var sample = samples.s1[0]\n  var sample2 = samples.l2a[0]\n  \n  if ([7, 8, 9, 10].includes(sample2.SCL)) {\n    return {\n      default: [sample.VV, sample.VV, sample.VV]\n    }\n  } else {\n    return {\n      default: [sample2.B04*2.5, sample2.B03*2.5, sample2.B02*2.5]\n    }\n  }\n}\n\"\"\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#step-3","position":19},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 4 (final)","lvl2":"API request"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#step-4-final","position":20},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 4 (final)","lvl2":"API request"},"content":"The different parts of the request built above are merged together in the oauth.post command and the request is posted. If all the elements are correct, the command should return a 200 status.\n\nresponse = oauth.post('https://services.sentinel-hub.com/api/v1/process',\n  json={\"input\": input_options,\n        \"evalscript\": evascript,\n        \"output\": output_options,\n})\n\nprint(\"Request status: %s, %s\" % (response.status_code, response.reason))\n\nIf the request was successful, you can now observe the image:\n\nIPython.display.Image(response.content)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-basic#step-4-final","position":21},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi","position":0},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi","position":1},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#edc-sentinel-hub-data-fusion","position":2},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#edc-sentinel-hub-data-fusion","position":3},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Example 2: Mapping crop NDVI with Sentinel-1 and Sentinel-2"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#example-2-mapping-crop-ndvi-with-sentinel-1-and-sentinel-2","position":4},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Example 2: Mapping crop NDVI with Sentinel-1 and Sentinel-2"},"content":"NDVI is a widely used vegetation index that uses Near Infra-Red (NIR) and Red wavelengths to measure the photosynthetic capacity of plant canopies. This index is a widely-used tool to assess agricultural crop conditions throughout the phenological cycle of the crops, linking chlorophyll activity to yield or canopy health [e.g. 1, 2].\n\nSentinel-2 is an ideal tool to monitor NDVI based on its NIR (B08, 842 nm) and Red bands (B04, 665 nm), owing to its large coverage, high spatial resolution (10/20 m), regular overpasses (~ 5 days) in comparison to other sensors. However, depending on the region and time of year, cloud cover can lead to sparse observations with the consequence of missing key stages of vegetation growth or activity. Furthermore, a 5-day revisit-time may not be sufficient to capture rapid changes in vegetation cover.\n\nStudies have linked Synthetic Aperture Radar (SAR) backscattering data to vegetation development [e.g. 3, 4], and in particular to NDVI [5]. C-band SAR satellites such as \n\nSentinel-1 offer frequent (~ 6 days) high-resolution observations of the Earth’s surface that have the advantage of being unaffected by cloud cover.\n\nIn this Notebook, based on the relationship between radar backscatter and NDVI [5], we combine a Sentinel-2 L2A NDVI product partly occulted by clouds with Sentinel-1 GRD observation to produce a seamless NDVI product.\n\n[1] Quarmby et al., 1993, The use of multi-temporal NDVI measurements from AVHRR data for crop yield estimation and prediction, DOI: 10.1080/01431169308904332.\n\n[2] Mazzetto et al., 2010, Integration of optical and analogue sensors for monitoring canopy health and vigour in precision viticulture, DOI: 10.1007/s11119-010-9186-1.\n\n[3] Capodici et al., 2013, Investigating the Relationship between X-Band SAR Data from COSMO-SkyMed Satellite and NDVI for LAI Detection. DOI: 10.3390/rs5031389.\n\n[4] Inoue et al., 2014, Capability of C-band backscattering coefficients from high-resolution satellite SAR sensors to assess biophysical variables in paddy rice, DOI: 10.1016/j.rse.2013.09.001.\n\n[5] Filgueiras et al., 2019, Crop NDVI Monitoring Based on Sentinel 1, DOI: 10.3390/rs11121441.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#example-2-mapping-crop-ndvi-with-sentinel-1-and-sentinel-2","position":5},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl3":"Prerequisites","lvl2":"Example 2: Mapping crop NDVI with Sentinel-1 and Sentinel-2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#prerequisites","position":6},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl3":"Prerequisites","lvl2":"Example 2: Mapping crop NDVI with Sentinel-1 and Sentinel-2"},"content":"This notebook requires an active subscription to:\n\nEDC Sentinel Hub\n\n# Request tools imports\nfrom oauthlib.oauth2 import BackendApplicationClient\nfrom requests_oauthlib import OAuth2Session\n\n# Utilities\nimport shapely.geometry\nimport IPython.display\n\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#prerequisites","position":7},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl3":"Setup","lvl2":"Example 2: Mapping crop NDVI with Sentinel-1 and Sentinel-2"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#setup","position":8},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl3":"Setup","lvl2":"Example 2: Mapping crop NDVI with Sentinel-1 and Sentinel-2"},"content":"\n\n# Pass the Sentinel Hub Client ID and Secret to variables to be used in the request.\nmy_client_id = %env SH_CLIENT_ID\nmy_client_secret = %env SH_CLIENT_SECRET\n\n# Create an OAuth2 session based on the client ID\nclient = BackendApplicationClient(client_id=my_client_id)\noauth = OAuth2Session(client=client)\n\nThe Sentinel Hub API uses OAuth2 Authentication and requires that you have an \n\naccess token. These tokens are limited in time, but a new one can be requested with the following command.\n\n# Get a token for the session\ntoken = oauth.fetch_token(token_url='https://services.sentinel-hub.com/oauth/token',\n                          client_id=my_client_id, client_secret=my_client_secret)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#setup","position":9},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Setting an area of interest"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#setting-an-area-of-interest","position":10},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Setting an area of interest"},"content":"We will download Sentinel-1 and Sentinel-2 imagery over cropland located to the west of Dodge City, Kansas. The region is characterised by intensive agriculture, mainly wheat and sorghum cultivated in circular crop fields.\n\nThe bounding box is in the WGS84 coordinate system, and consists of the longitude and latitude coordinates of lower left and upper right corners.\n\n# Set bounding box coordinates for the area of interest\nbbox = (-100.9204, 37.5718, -100.4865, 37.8640)\n\n# Display the coordinates on a map\nIPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#setting-an-area-of-interest","position":11},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"API request"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#api-request","position":12},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"API request"},"content":"We need to specify arguments to send a POST request, more information about all the availaible options \n\nhere:\n\nThe access point URL:  set it to https://services.sentinel-hub.com/api/v1/process\n\njson - the contents of the request containing:\n\ninput: (required) specifies the data to request:\n\nbounds: defines the request bounds by specifying the bounding box and/or geometry for the request.\n\ndata: describes the data being requested along with certain processing and filtering parameters.\n\noutput: (optional) allows to set parameters for the returned data\n\nwidth: The request image width. Must be an integer between 1 and 2500.\n\nheight: The request image height. Must be an integer between 1 and 2500.\n\nevalscript: calculates the output values for each pixel\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#api-request","position":13},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 1","lvl2":"API request"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#step-1","position":14},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 1","lvl2":"API request"},"content":"First, set the input options. The options are set in the form of a dictionary with key/values pairs.\n\nSpecify the bounds of your request using the bounding box previously described and specifying the \n\nprojection (one of the CRS supported by Sentinel Hub API).\n\nSpecify the data to fetch. As in this example there are 2 data sources (Sentinel-1 and Sentinel-2), the options for each sensor are specified in a list of dictionaries.\n\n# 1. Bounds \nbounds = {\"properties\":{\"crs\":\"http://www.opengis.net/def/crs/OGC/1.3/CRS84\"}, \"bbox\": bbox}\n\n# 2. Data\n# Following Filgueiras et al. (2019), the Sentinel-1 orthorectified sigma_0 bands are returned.\n# We also use Atmospherically corrected Sentinel-2 (L2A) data\n\ndata = [{\"id\": \"s1\", \n         \"type\": \"S1GRD\",\n          \"dataFilter\": {\"timeRange\": {\"from\": \"2019-04-26T00:00:00Z\",\n                                       \"to\": \"2019-04-26T23:59:00Z\"},\n                         \"mosaickingOrder\": \"mostRecent\"},\n         \"processing\": {\n                    \"orthorectify\": \"true\",\n                    \"backCoeff\": \"SIGMA0_ELLIPSOID\"\n                }},\n         {\"id\": \"l2a\",\n          \"type\": \"S2L2A\",\n          \"dataFilter\": {\"timeRange\": {\"from\": \"2019-04-26T00:00:00Z\",\n                                       \"to\": \"2019-04-26T23:59:00Z\"},\n                         \"mosaickingOrder\": \"mostRecent\"}}]\n# Set the options to the input\ninput_options = {\"bounds\": bounds, \"data\": data,}\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#step-1","position":15},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 2","lvl2":"API request"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#step-2","position":16},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 2","lvl2":"API request"},"content":"Then set the output options. The default output size of the requested image is 256x256 pixels, so here we will modify the output to be larger. The result will be displayed only, therefore we also set the output format to jpeg.\n\noutput_options = {\"width\": 640, \"height\": 640, \"responses\": [{\"format\": {\"type\": \"image/jpeg\",\n                                                                         \"quality\": 90}}]}\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#step-2","position":17},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 3","lvl2":"API request"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#step-3","position":18},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 3","lvl2":"API request"},"content":"The \n\nevalscript is a piece of javascript code that allows to process the pixels of the images that are returned.\n\nIn the current example, the S1 and S2 bands needed are called in the setup function of the script.\n\nTo compare the results of the fused NDVI product, several requests will be run with slightly different evalscripts. We will return:\n\n1 - The S2 \n\nTrue Color visualisation (scaled by 2.5 for better viewing).\n\n2 - The S2 NDVI visualisation.\n\n3 - The merged S1-S2 NDVI visualisation.\n\n# 1. Evalscript returning the True Color Visualisation of S2 data\ntc_evalscript = \"\"\"\n//VERSION=3\nfunction setup (){\n  return {\n    input: [\n      {datasource: \"s1\", bands:[\"VV\", \"VH\"]},\n      {datasource: \"l2a\", bands:[\"B02\", \"B03\", \"B08\", \"B04\", \"SCL\"], units:[\"REFLECTANCE\", \"REFLECTANCE\", \"REFLECTANCE\", \"REFLECTANCE\", \"DN\"]}],\n    output: [\n      {id: \"default\", bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\n\nfunction evaluatePixel(samples) {\n  var s2 = samples.l2a[0]\n  \n  return {default: [s2.B04 * 2.5, s2.B03 * 2.5, s2.B02 * 2.5]}\n  }\n\"\"\"\n\n# 2. Evalscript returning the S2 NDVI\ns2_ndvi_evalscript = \"\"\"\n//VERSION=3\nfunction setup (){\n  return {\n    input: [\n      {datasource: \"s1\", bands:[\"VV\", \"VH\"]},\n      {datasource: \"l2a\", bands:[\"B02\", \"B03\", \"B08\", \"B04\", \"SCL\"], units:[\"REFLECTANCE\", \"REFLECTANCE\", \"REFLECTANCE\", \"REFLECTANCE\", \"DN\"]}],\n    output: [\n      {id: \"default\", bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\n\nfunction evaluatePixel(samples) {\n    \n  var s2 = samples.l2a[0]\n\n  // Create an NDVI visualiser\n  var viz=new ColorMapVisualizer([[0.0,0xa50026],\n                                  [0.0,0xd73027], [0.2,0xf46d43],\n                                  [0.3,0xfdae61], [0.4,0xfee08b],\n                                  [0.5,0xffffbf], [0.6,0xd9ef8b],\n                                  [0.7,0xa6d96a], [0.8,0x66bd63],\n                                  [0.9,0x1a9850], [1.0,0x006837]]);\n  // Calculate S2 NDVI\n  let ndvi = index(s2.B08, s2.B04)\n\n  return {default: viz.process(ndvi)}\n}\n\"\"\"\n\ns12_ndvi_evalscript = \"\"\"\n//VERSION=3\nfunction setup (){\n  return {\n    input: [\n      {datasource: \"s1\", bands:[\"VV\", \"VH\"]},\n      {datasource: \"l2a\", bands:[\"B02\", \"B03\", \"B08\", \"B04\", \"SCL\"], units:[\"REFLECTANCE\", \"REFLECTANCE\", \"REFLECTANCE\", \"REFLECTANCE\", \"DN\"]}],\n    output: [\n      {id: \"default\", bands: 3, sampleType: SampleType.AUTO}\n    ]\n  }\n}\n\nfunction toDb(linear) {\n  // Convert the linear backscatter to DB (Filgueiras et al. (2019), eq. 3)\n  return 10 * Math.LN10 * linear\n}\n\nfunction calc_s1_ndvi(sigmaVV, sigmaVH){\n    // Convert sigma0 to Decibels\n    let vh_Db = toDb(sigmaVH)\n    let vv_Db = toDb(sigmaVV)\n\n    // Calculate NRPB (Filgueiras et al. (2019), eq. 4)\n    let NRPB = (vh_Db - vv_Db) / (vh_Db + vv_Db)\n\n    // Calculate NDVI_nc with approach A3 (Filgueiras et al. (2019), eq. 14)\n    let NDVInc = 2.572 - 0.05047 * vh_Db + 0.176 * vv_Db + 3.422 * NRPB\n\n    return NDVInc\n}\n\nfunction evaluatePixel(samples) {\n  var s1 = samples.s1[0]\n  var s2 = samples.l2a[0]\n\n  // Create an NDVI visualiser\n  var viz=new ColorMapVisualizer([[0.0,0xa50026],\n                                  [0.0,0xd73027], [0.2,0xf46d43],\n                                  [0.3,0xfdae61], [0.4,0xfee08b],\n                                  [0.5,0xffffbf], [0.6,0xd9ef8b],\n                                  [0.7,0xa6d96a], [0.8,0x66bd63],\n                                  [0.9,0x1a9850], [1.0,0x006837]]);\n  // Calculate S2 NDVI\n  let ndvi = index(s2.B08, s2.B04)\n  // Calculate S1 NDVI\n  let s1_ndvi = calc_s1_ndvi(s1.VV, s1.VH)\n  \n  // Use the S2-L2A classification to identify clouds\n  if ([7, 8, 9, 10].includes(s2.SCL)) {\n    // If clouds are present use S1 NDVI\n    return {\n      default: viz.process(s1_ndvi)\n    }\n  } else {\n    // Otherwise use s2 NDVI\n    return {\n      default: viz.process(ndvi)\n    }\n  }\n}\n\"\"\"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#step-3","position":19},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 4 (final)","lvl2":"API request"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#step-4-final","position":20},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl4":"Step 4 (final)","lvl2":"API request"},"content":"The different parts of the request built above are merged together in the oauth.post command and the request is posted. If all the elements are correct, the command should return a 200 status.\n\n# Here we call the first evalscript for a True Color visualisation of Sentinel-2. \nresponse_tc = oauth.post('https://services.sentinel-hub.com/api/v1/process',\n  json={\"input\": input_options,\n        \"evalscript\": tc_evalscript,\n        \"output\": output_options,\n})\n\nprint(\"Request status: %s, %s\" % (response_tc.status_code, response_tc.reason))\n\n# Here we call the first evalscript for the Sentinel-2 NDVI visualisation. \nresponse_s2_ndvi = oauth.post('https://services.sentinel-hub.com/api/v1/process',\n  json={\"input\": input_options,\n        \"evalscript\": s2_ndvi_evalscript,\n        \"output\": output_options,\n})\n\nprint(\"Request status: %s, %s\" % (response_s2_ndvi.status_code, response_s2_ndvi.reason))\n\n# Here we call the first evalscript for the Sentinel-2 NDVI visualisation. \nresponse_s12_ndvi = oauth.post('https://services.sentinel-hub.com/api/v1/process',\n  json={\"input\": input_options,\n        \"evalscript\": s12_ndvi_evalscript,\n        \"output\": output_options,\n})\n\nprint(\"Request status: %s, %s\" % (response_s12_ndvi.status_code, response_s12_ndvi.reason))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#step-4-final","position":21},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Results"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#results","position":22},{"hierarchy":{"lvl1":"EDC Sentinel Hub: Data Fusion","lvl2":"Results"},"content":"Below, the True Color visualisation of the Sentinel-2 image shows the circular crop fields forming the agricultural landscape near Dodge City. The brown colored fields are most likely bare soil (i.e. the crops haven’t yet emerged) given the date of the acquisition (26-04-2019). A certain number of fields appear to have crops growing (they appear green in the image). Part of the image is occulted by dense cloud cover.\n\nIPython.display.Image(response_tc.content)\n\nBelow, the Sentinel-2 NDVI product clearly highlights the fields in which crop are present (green) with varying NDVI values (represented in different shades of green, the darker the green, the higher the NDVI value). The agricultural plots where no crops are growing are shown in red in the image (NDVI < 0). However, the right part of the image is mostly cloud covered, which is clearly visible in the NDVI product.\n\nIPython.display.Image(response_s2_ndvi.content)\n\nIn the image below, the Sentinel-2 NDVI values located in cloud-covered areas were replaced with NDVI calculated from the Sentinel-1 data. The fusion of the two data sources now allows showing the NDVI for the areas that were not resolved simply using Sentinel-2 data. A number of large fields, where crops are growing are now visible in the right part of the image.\n\nA few caveats remain nevertheless:\n\nThe image is quite noisy: the noise could be removed by speckle filtering. However, Sentinel Hub only allows a pixel-per-pixel approach at the moment, and therefore filtering windows cannot be applied.\n\nThe method developed by Filgueiras et al. (2019) is tied to the type of crop that it was calibrated for (soybean and maize). In the example shown here, the fields are mostly sorghum and wheat, thus leading to a bias in the absolute values of NDVI. This can be observed in the product, as the crops appear to have higher NDVI values in the parts of the image calculated with Sentinel-1. Applying this method to accurately analyse the NDVI in this image would require additional steps (regression over a cloud-free zone), but is out of the scope of this Notebook, whose purpose is to show the potential of data-fusion with Sentinel Hub.\n\nIPython.display.Image(response_s12_ndvi.content)","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinelhub-datafusion-ndvi#results","position":23},{"hierarchy":{"lvl1":"EDC Sentinel Hub - data access using xcube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-data-access","position":0},{"hierarchy":{"lvl1":"EDC Sentinel Hub - data access using xcube"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-data-access","position":1},{"hierarchy":{"lvl1":"EDC Sentinel Hub - data access using xcube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-data-access#edc-sentinel-hub-data-access-using-xcube","position":2},{"hierarchy":{"lvl1":"EDC Sentinel Hub - data access using xcube"},"content":"This notebook shows the various ways to open data cubes from Sentinel Hub (SH) for a given time range, region, and spatial resolution:\n\nA temporarily regular Sentinel-2 cube with aggregated observations that fall into equal-size time periods;\n\nA temporarily irregular Sentinel-2 cube which only includes time stamps where there were valid observations;\n\nA cube using projected coordinates.\n\n# xcube_sh imports\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.observers import Observers\nfrom xcube_sh.viewer import ViewerServer\n\n# xcube imports\nfrom xcube.core.maskset import MaskSet\nfrom xcube.core.geom import mask_dataset_by_geometry\nfrom xcube.core.geom import clip_dataset_by_geometry\n\n# Various utilities\nimport json\nimport xarray as xr\nimport shapely.geometry\nimport IPython.display\nimport zarr\n\n%matplotlib inline\n\nimport xcube\nimport xcube_sh\n\nxcube_sh.__version__\n\nxcube.__version__\n\n\n\n\nFor this demo, we are focussing on small coastal area near Kiel in Northern Germany (Baltic Sea)\n\nx1 = 10.00  # degree\ny1 = 54.27  # degree\nx2 = 11.00  # degree\ny2 = 54.60  # degree\n\nbbox = x1, y1, x2, y2\n\nVisualize the bounding box. If you don’t see anything, please refer to EDC Setup example \n\nhere.\n\nIPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)\n\nLater in this NB we are going to compute some indexes from bands atmospherically corrected bands B04, B05, B06, B11 of Sentinel-2 (S2L2A)\nOur time range covers two and a half month of last year’s summer: 2018-05-14 to 2018-07-31\n\nThe desired resolution is roughly 20 meters per pixel:\n\nspatial_res = 0.00018   # = 20.038 meters in degree>\n\n\n\nExample (!): Sentinel-2 L2A with aggregated observations that fall into equal-size time_period of 2 days:\n\ncube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B04', 'B05', 'B06', 'B11', 'SCL', 'CLD'],\n                         tile_size=[512, 512],\n                         bbox=bbox,\n                         spatial_res=spatial_res,\n                         time_range=['2018-05-14', '2018-07-31'],\n                         time_period='2D')\n\nWe define a request_collector as an observer for SH requests made, so we can show SH usage stats. This is a developer tool, useful for demonstration purposes too. Otherwise, this is not needed.\n\nrequest_collector = Observers.request_collector()\n\nOpen a data cube:\n\ncube = open_cube(cube_config, observer=request_collector)\n\ncube\n\nNo requests have been made yet. Requests are made only if data is actually required.\n\nrequest_collector.stats\n\nNote, the cube’s time coordinates are monotonically increasing and the distance between two time steps is varying:\n\ncube.time.diff(dim='time').plot.line()\n\ncube.B04\n\ncube.B04.sel(time='2018-05-21 10:00:00', method='nearest').plot.imshow(vmin=0, vmax=0.2, cmap='Greys_r', figsize=(16, 10))\n\nNow SentinelHub data requests have been made\n\nrequest_collector.stats\n\nxcube mask sets also follow data cube structure\n\n\n\nExample (2): Sentinel-2 L2A which only includes time stamps where there were valid observations for a given region. We use a time_tolerance of 30 minutes to decide whether scenes shall be combined:\n\ncube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B04', 'B05', 'B06', 'B11', 'SCL', 'CLD'],\n                         tile_size=[512, 512],\n                         bbox=bbox,\n                         spatial_res=spatial_res,\n                         time_range=['2018-05-14', '2018-07-31'],                         \n                         time_tolerance='30M')\n\ncube = open_cube(cube_config)\ncube\n\ncube.time.diff(dim='time').plot.line()\n\n\n\nExample (3): Using projected coordinates, setting the crs parameter to 'http://www.opengis.net/def/crs/EPSG/0/3857' (EPSG:3857), that is Pseude-Mercato using a WGS-84 Ellisoid. Note that the spatial coordinates now switched from lon, lat to x, y. For other CRSes, refer to \n\nhttps://​docs​.sentinel​-hub​.com​/api​/latest​/​#​/API​/crs.\n\nWe need to provide the bbox and spatial_res parameters in EPSG:3857 units (meters) now, Ljubljana area:\n\nx1 = 1545577  # meters\ny1 = 5761986  # meters\nx2 = 1705367  # meters\ny2 = 5857046  # meters\n\nbbox = x1, y1, x2, y2\n\nspatial_res = (x2 - x1) / 512  # meters\n\nVerify we are right:\n\ngeom = shapely.geometry.box(*bbox)\n\nimport functools\nimport pyproj\nimport shapely.ops\n\nproject = functools.partial(\n    pyproj.transform,\n    pyproj.Proj(init='epsg:3857'),  # source coordinate system (Web Mercator)\n    pyproj.Proj(init='epsg:4326'))  # destination coordinate system (WGS-84)\n\ngeom_wgs84 = shapely.ops.transform(project, geom)  # apply projection\nIPython.display.GeoJSON(geom_wgs84.__geo_interface__)\n\ncube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B04', 'B05', 'B06', 'B11', 'SCL', 'CLD'],\n                         tile_size=[512, 512],\n                         crs='http://www.opengis.net/def/crs/EPSG/0/3857',\n                         bbox=bbox,\n                         spatial_res=spatial_res,\n                         time_range=['2018-05-01', '2018-05-10'],                         \n                         time_period='1D')\n\ncube = open_cube(cube_config)\ncube\n\ncube.B04.isel(time=5).plot.imshow(vmin=0, vmax=0.18, cmap='Greys_r', figsize=(16, 10))","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-data-access#edc-sentinel-hub-data-access-using-xcube","position":3},{"hierarchy":{"lvl1":"EDC Sentinel Hub - using xcube to access different data sets in Sentinel Hub"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets","position":0},{"hierarchy":{"lvl1":"EDC Sentinel Hub - using xcube to access different data sets in Sentinel Hub"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets","position":1},{"hierarchy":{"lvl1":"EDC Sentinel Hub - using xcube to access different data sets in Sentinel Hub"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#edc-sentinel-hub-using-xcube-to-access-different-data-sets-in-sentinel-hub","position":2},{"hierarchy":{"lvl1":"EDC Sentinel Hub - using xcube to access different data sets in Sentinel Hub"},"content":"This notebook shows how to access different data sets through the Sentinel Hub API:\n\nAccess Sentiel-2 L2A through xcube Sentinel hub Store\n\nAccess Sentiel-2 L1C through xcube Sentinel hub Store\n\nAccess Sentiel-1 GRD through xcube Sentinel hub Store\n\nAccess DEM through xcube Sentinel hub Store\n\nAccess to a custom data set ingested into Sentinel Hub via \n\nBYOD mechanism\n\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.sentinelhub import SentinelHub\nimport xarray as xr\nimport numpy as np\n\nx1 = 10.00  # degree\ny1 = 54.27  # degree\nx2 = 11.00  # degree\ny2 = 54.60  # degree\n\nbbox = x1, y1, x2, y2\n\nspatial_res = 0.00018   # = 20.038 meters in degree\n\nSH = SentinelHub()\nSH.dataset_names\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#edc-sentinel-hub-using-xcube-to-access-different-data-sets-in-sentinel-hub","position":3},{"hierarchy":{"lvl1":"Sentinel-2 L2A"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#sentinel-2-l2a","position":4},{"hierarchy":{"lvl1":"Sentinel-2 L2A"},"content":"\n\nSH.band_names('S2L2A')\n\ncube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['SCL'],\n                         tile_size=[512, 512],\n                         bbox=bbox,\n                         spatial_res=spatial_res,\n                         time_range=['2018-05-14', '2018-07-31'],\n                         time_tolerance='30M')  \n\ncube = open_cube(cube_config)\ncube\n\ncube.SCL.isel(time=5, lat=slice(0,2000),lon=slice(0,2000)).plot.imshow(cmap='tab20c')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#sentinel-2-l2a","position":5},{"hierarchy":{"lvl1":"Sentinel-2 L1C"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#sentinel-2-l1c","position":6},{"hierarchy":{"lvl1":"Sentinel-2 L1C"},"content":"\n\nSH.band_names('S2L1C')\n\ncube_config = CubeConfig(dataset_name='S2L1C',\n                         band_names=['B04'],\n                         tile_size=[512, 512],\n                         bbox=bbox,\n                         spatial_res=spatial_res,\n                         time_range=['2018-05-14', '2018-07-31'],\n                         time_tolerance='30M')  \n\ncube = open_cube(cube_config)\ncube\n\ncube.B04.isel(time=5, lat=slice(0,2000),lon=slice(0,2000)).plot.imshow(cmap='Greys', vmax = .17)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#sentinel-2-l1c","position":7},{"hierarchy":{"lvl1":"Sentinel-1 GRD"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#sentinel-1-grd","position":8},{"hierarchy":{"lvl1":"Sentinel-1 GRD"},"content":"\n\nSH.band_names('S1GRD')\n\nx1 = 10.00  # degree\ny1 = 54.27  # degree\nx2 = 10.50  # degree\ny2 = 54.60  # degree\n\nbbox = x1, y1, x2, y2\n\nspatial_res = 0.00018 \n\ncube_config = CubeConfig(dataset_name='S1GRD',\n                         band_names=['VH'],\n                         tile_size=[512, 512],\n                         crs = \"http://www.opengis.net/def/crs/EPSG/0/4326\",\n                         spatial_res = spatial_res,\n                         bbox=bbox,\n                         time_range=['2019-05-14', '2019-07-31'],\n                         time_period='2D')  \n\ncube = open_cube(cube_config)\ncube\n\ncube.VH.isel(time=1).plot.imshow(cmap='Greys',vmax =0.08, figsize = [16,12])\n\nSH.dataset_names\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#sentinel-1-grd","position":9},{"hierarchy":{"lvl1":"Digital Elevation Model"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#digital-elevation-model","position":10},{"hierarchy":{"lvl1":"Digital Elevation Model"},"content":"\n\nSH.band_names('DEM')\n\nx1 = 10.00  # degree\ny1 = 54.27  # degree\nx2 = 10.50  # degree\ny2 = 54.40  # degree\n\nbbox = x1, y1, x2, y2\n\nspatial_res = 0.0002\n\ncube_config = CubeConfig(dataset_name='DEM',\n                         band_names=['DEM'],\n                         tile_size=[512, 512],\n                         crs = \"http://www.opengis.net/def/crs/EPSG/0/4326\",\n                         spatial_res = spatial_res,\n                         bbox=bbox,\n                         time_range=['2019-05-14', '2019-07-31'],\n                         time_period='100D')  \n\ncube = open_cube(cube_config)\ncube\n\ncube.DEM.isel(time=0).plot.imshow(vmin = -50, figsize = [14,10])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#digital-elevation-model","position":11},{"hierarchy":{"lvl1":"Bring your own data"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#bring-your-own-data","position":12},{"hierarchy":{"lvl1":"Bring your own data"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#bring-your-own-data","position":13},{"hierarchy":{"lvl1":"Bring your own data","lvl2":"Define bounding box in Mercator coordinates"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#define-bounding-box-in-mercator-coordinates","position":14},{"hierarchy":{"lvl1":"Bring your own data","lvl2":"Define bounding box in Mercator coordinates"},"content":"\n\nx1 = 1545577  # meters\ny1 = 5761986  # meters\nx2 = 1705367  # meters\ny2 = 5857046  # meters\n\nbbox = x1, y1, x2, y2\n\nwidth = 512\nspatial_res = (x2 - x1) / width\nheight = max(1, round((y2 - y1) / spatial_res))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#define-bounding-box-in-mercator-coordinates","position":15},{"hierarchy":{"lvl1":"Bring your own data","lvl2":"Custom data set contains bands B04 (red band), B03 (green band), and B02 (blue band)."},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#custom-data-set-contains-bands-b04-red-band-b03-green-band-and-b02-blue-band","position":16},{"hierarchy":{"lvl1":"Bring your own data","lvl2":"Custom data set contains bands B04 (red band), B03 (green band), and B02 (blue band)."},"content":"\n\ncube_config = CubeConfig(dataset_name='CUSTOM',\n                         band_names=['B04', 'B03', 'B02'],                        \n                         tile_size=[width, height],\n                         crs='http://www.opengis.net/def/crs/EPSG/0/3857',\n                         bbox=bbox,\n                         time_range=['2020-01-01', '2021-01-01'],\n                         time_period='7d',\n                         spatial_res=spatial_res,\n                         band_sample_types='UINT16',\n                         collection_id='484d8dbb-9e3e-41f2-b96b-35189d3ae37f')\n\ncube = open_cube(cube_config)\ncube \n\ncubew = cube.isel(time=26)\n\nrgb_data = np.zeros((305, 512, 3), 'uint16')\nrgb_data[:, :, 0] = cubew.B04.values/10000*255\nrgb_data[:, :, 1] = cubew.B03.values/10000*255\nrgb_data[:, :, 2] = cubew.B02.values/10000*255\n\nrgb_array = xr.DataArray(rgb_data, dims=('y', 'x', 'b'), coords=dict(x=cube.B04.x, y=cube.B04.y))\nrgb_array.plot.imshow(rgb='b', figsize=(16, 10))\n\nrgb_array","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-datasets#custom-data-set-contains-bands-b04-red-band-b03-green-band-and-b02-blue-band","position":17},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup","position":0},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup","position":1},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#setup-for-edc-core-api-access-using-xcube-client-library","position":2},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#setup-for-edc-core-api-access-using-xcube-client-library","position":3},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library","lvl2":"Installation"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#installation","position":4},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library","lvl2":"Installation"},"content":"For creating an xcube Python environment and installing xcube follow the instructions given in the \n\nxcube’s README.\nFor installing the xcube_sh plugin follow the instructions given in the \n\nxcube-sh’s README.\n\nBefore using Jupyter Lab for the first time install the jupyterlab package and make sure the\n\n\nJupyter GeoJSON extension is installed too:(xcube) conda install -c conda-forge jupyterlab\n(xcube) jupyter labextension install @jupyterlab/geojson-extension","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#installation","position":5},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library","lvl2":"API access (OAuth2)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#api-access-oauth2","position":6},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library","lvl2":"API access (OAuth2)"},"content":"For API access the following environment variables must be provided via a .env fileSH_CLIENT_ID=\nSH_CLIENT_SECRET=\nSH_INSTANCE_ID=\n\nYou can find these values in your Euro Data Cube Dashboard in the API Access (OAuth2) section of the Euro Data Cube service.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#api-access-oauth2","position":7},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library","lvl2":"Test Setup"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#test-setup","position":8},{"hierarchy":{"lvl1":"Setup for EDC core API access using xcube client library","lvl2":"Test Setup"},"content":"Test whether setup was successfull by importing some important xcube_sh exports:\n\n# Configure data cubes using CubeConfig\nfrom xcube_sh.config import CubeConfig\n# Open data cubes from SH with given CubeConfig\nfrom xcube_sh.cube import open_cube\n# Observe SH requests made open_cube()\nfrom xcube_sh.observers import Observers\n# View stored cubes\nfrom xcube_sh.viewer import ViewerServer\n\nfrom xcube_sh.version import version\nversion\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#test-setup","position":9},{"hierarchy":{"lvl1":"Setup for Euro Data Cube geoDB"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#setup-for-euro-data-cube-geodb","position":10},{"hierarchy":{"lvl1":"Setup for Euro Data Cube geoDB"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#setup-for-euro-data-cube-geodb","position":11},{"hierarchy":{"lvl1":"Setup for Euro Data Cube geoDB","lvl2":"Installation"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#installation-1","position":12},{"hierarchy":{"lvl1":"Setup for Euro Data Cube geoDB","lvl2":"Installation"},"content":"For installing the xcube_geodb plugin follow the instructions given in the \n\nxcube-geodb’s README.\n\nBefore using Jupyter Lab for the first time install the jupyterlab package and make sure the\n\n\nJupyter GeoJSON extension is installed too:conda install -c conda-forge jupyterlab\njupyter labextension install @jupyterlab/geojson-extension","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#installation-1","position":13},{"hierarchy":{"lvl1":"Setup for Euro Data Cube geoDB","lvl2":"API access (OAuth2)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#api-access-oauth2-1","position":14},{"hierarchy":{"lvl1":"Setup for Euro Data Cube geoDB","lvl2":"API access (OAuth2)"},"content":"For API access the following environment variables must be provided via a .env fileGEODB_API_SERVER_URL=\nGEODB_AUTH_CLIENT_ID=\nGEODB_AUTH_CLIENT_SECRET=\nGEODB_AUTH_AUD=\nGEODB_API_SERVER_PORT=\nGEODB_AUTH_DOMAIN=\n\nYou can find these values in your Euro Data Cube Dashboard in the API Access (OAuth2) section of the Euro Data Cube - geoDB service.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-setup#api-access-oauth2-1","position":15},{"hierarchy":{"lvl1":"EDC Sentinel Hub - XCUBE integration"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-xcube-integration","position":0},{"hierarchy":{"lvl1":"EDC Sentinel Hub - XCUBE integration"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-xcube-integration","position":1},{"hierarchy":{"lvl1":"EDC Sentinel Hub - XCUBE integration"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-xcube-integration#edc-sentinel-hub-xcube-integration","position":2},{"hierarchy":{"lvl1":"EDC Sentinel Hub - XCUBE integration"},"content":"This notebook demonstrates the deep integration between Sentinel Hub and the xcube\n\nOn-the-fly access to any SentinelHub datasets\n\nUtilising band / flag mask information\n\nUtilising external vector / feature data\n\nPersisting data cube’s in user’s workspace\n\nUsing Xcube Viewer to visualize generated cubes\n\n# xcube_sh imports\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.observers import Observers\nfrom xcube_sh.viewer import ViewerServer\n\n# xcube imports\nfrom xcube.core.maskset import MaskSet\nfrom xcube.core.geom import mask_dataset_by_geometry\nfrom xcube.core.geom import clip_dataset_by_geometry\n\n# Various utilities\nimport json\nimport numpy as np\nimport xarray as xr\nimport shapely.geometry\nimport IPython.display\nimport zarr\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\nFor this demo, we are focussing on small coastal area near Kiel in Northern Germany (Baltic Sea)\n\nx1 = 10.00  # degree\ny1 = 54.27  # degree\nx2 = 11.00  # degree\ny2 = 54.60  # degree\n\nbbox = x1, y1, x2, y2\n\n#IPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)\n\nLater in this NB we are going to compute some indexes from bands atmospherically corrected bands B04, B05, B06, B11 of Sentinel-2 (S2L2A)\nOur time range covers two and a half month of last year’s summer: 2018-05-14 to 2018-07-31\n\nThe desired resolution is roughly 20 meters per pixel:\n\nspatial_res = 0.00018   # = 20.038 meters in degree>\n\n\n\nExample (!): Sentinel-2 L2A with aggregated observations that fall into equal-size time_period of 2 days:\n\ncube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B04', 'B05', 'B06', 'B11', 'SCL', 'CLD'],\n                         tile_size=[512, 512],\n                         bbox=bbox,\n                         spatial_res=spatial_res,\n                         time_range=['2018-05-14', '2018-07-31'],\n                         time_period='2D')\n\nWe define a request_collector as an observer for SH requests made, so we can show SH usage stats. This is a developer tool, useful for demonstration purposes too. Otherwise, this is not needed.\n\nrequest_collector = Observers.request_collector()\n\nOpen a data cube:\n\ncube = open_cube(cube_config, observer=request_collector)\n\ncube\n\nNote: a data cube equivalent to cube can be generated persistently using the following CLI command:$ xcsh cubify S2L1C -o cube.zarr -b B08 -g 10.237174,53.506205,10.271174,53.540205 -r 6.640625e-05 -t 2017-08-01,2017-08-31 -p 1D\n$ python \n>>> import xarray as xr\n>>> cube = xr.open_zarr('cube.zarr')\n>>> cube\n\ncube.time\n\nNo requests have been made yet. Requests are made only if data is actually required.\n\nrequest_collector.stats\n\nBand metadata also comprises wavelength info:\n\ncube.B04\n\n# SH requests\ncube.B04.sel(time='2018-05-21 10:00:00', method='nearest').plot.imshow(vmin=0, vmax=0.2, cmap='Greys_r', figsize=(16, 10))\n\nNow SentinelHub data requests have been made\n\nrequest_collector.stats\n\nScene classification flags have CF-conformant flag encoding information, which xcube can decode\n\ncube.SCL\n\nimport xcube.core.maskset as maskset\n\nscene_classif = maskset.MaskSet(cube.SCL)\nprint(scene_classif)\n\nxcube mask sets also follow data cube structure:\n\nscene_classif.water\n\n# SH requests\nscene_classif.water.sel(time='2018-05-21').plot.imshow(figsize=(16, 10))\n\nrequest_collector.stats\n\nWe can use any of the mask or combinations of it to mask entire cubes. Here we create a “water cube”:\n\nwater_cube = cube.where(scene_classif.water)\nwater_cube\n\n# SH requests\nwater_cube.B04.sel(time='2018-05-21').plot.imshow(vmin=0, vmax=0.05, cmap='Greys_r', figsize=(16, 10))\n\nrequest_collector.stats\n\n\n\nWe now compute a Chlorophyll indicator called Maximum Chlorophyll Index from bands B04, B05, B06:\n\nb_from = water_cube.B04\nb_peek = water_cube.B05\nb_to = water_cube.B06\n\nwlen_from = b_from.attrs['wavelength']\nwlen_peek = b_peek.attrs['wavelength']\nwlen_to = b_to.attrs['wavelength']\n\nf = (wlen_peek - wlen_from) / (wlen_to - wlen_from)\nmci = (b_peek - b_from) - f * (b_to - b_from)\n\nmci.attrs['long_name'] = 'Maximum Chlorophyll Index'\nmci.attrs['units'] = 'unitless'\nmci\n\n\n\nAnd the well-known Normalised Difference Vegetation Index:\n\nveg_cube = cube.where(scene_classif.vegetation)\nveg_cube\n\nb_red = veg_cube.B04\nb_nir = veg_cube.B11\nndvi = (b_nir - b_red) / (b_nir + b_red)\nndvi.attrs['long_name'] = 'Normalized Difference Vegetation Index'\nndvi.attrs['units'] = 'unitless'\nndvi\n\nmy_cube = xr.Dataset({'mci': mci, 'ndvi': ndvi})\nmy_cube\n\n# Plot mci index\nmy_cube.mci.isel(time=8).plot.imshow(vmin=0, vmax=0.005, cmap='viridis', figsize=(16, 10))\n\nrequest_collector.stats","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-sentinel-hub-xcube-integration#edc-sentinel-hub-xcube-integration","position":3},{"hierarchy":{"lvl1":"NDVI timeline"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline","position":0},{"hierarchy":{"lvl1":"NDVI timeline"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline","position":1},{"hierarchy":{"lvl1":"NDVI timeline"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#ndvi-timeline","position":2},{"hierarchy":{"lvl1":"NDVI timeline"},"content":"This notebook presents an example on how a user can exploit the xcube client library to access and analyse data served via Euro Data Cube service API.\n\nThematically, this notebook illustrates how to generate a timeline of NDVI values calculated from Sentinel-2 bands. The normalized difference vegetation index (NDVI) is a simple graphical indicator that can be used to analyze remote sensing measurements acquired by a space platform, assessing whether or not the target being observed contains live green vegetation.\n\nIt demonstrates how xcube tools and Euro Data Cube complement each other. While Euro Data Cube services are used to access the data, xcube tools are utilized for analysis and visualization.\n\nSpecifically, following actions are demonstrated by this notebook:\n\nDefining a new data cube for a given time range, region, and spatial resolution.\n\nAdding a new data layer to cube - calculated value of NDVI\n\nFilling the cube with the data: requesting satellite imagery and calcualting NDVI layer\n\nDisplaying imageries, time series and linear plots for selected bands, area-of-interest and time\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#ndvi-timeline","position":3},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Importing dependancies"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#importing-dependancies","position":4},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Importing dependancies"},"content":"The user needs to first import the dependancies.\n\n# xcube_sh imports\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.observers import Observers\nfrom xcube_sh.viewer import ViewerServer\n\n# xcube imports\nfrom xcube.core.maskset import MaskSet\nfrom xcube.core.geom import mask_dataset_by_geometry\nfrom xcube.core.geom import clip_dataset_by_geometry\n\n# Various utilities\nimport json\nfrom datetime import date, timedelta\nimport xarray as xr\nimport shapely.geometry\nimport IPython.display\nimport zarr\nimport numpy as np\n\nTo present the timeline of NDVI values, you will need to create a linear chart.\n\nTo create the chart, it´s neccessary to import the Matplot library (matplotlib) first. The matplotlib is a plotting library which renders the plots.\n\nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#importing-dependancies","position":5},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Specification of a geographical area of interest"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#specification-of-a-geographical-area-of-interest","position":6},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Specification of a geographical area of interest"},"content":"The next step is to specify the area of interest - i.e. a geographical area, which the cube should cover and for which the NDVI will be calculated.\n\nThe area of interest is specified via bounding box. You have to specify geographical coordinates of each corner of this bounding box.\n\nFor this demo, we are focussing on small coastal area near Kiel in Northern Germany (Baltic Sea).\n\nx1 = 10.00 # degree\ny1 = 54.27  # degree\nx2 = 10.40  # degree\ny2 = 54.50  # degree\n\ndays = 30\n\nbbox = x1, y1, x2, y2\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#specification-of-a-geographical-area-of-interest","position":7},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Visualisation of area of interest"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#visualisation-of-area-of-interest","position":8},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Visualisation of area of interest"},"content":"To check whether the area of interest has been specified correctly, you can integrate a simple map allowing visualisation of this area.\n\nVisualize the bounding box.\n\nIPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#visualisation-of-area-of-interest","position":9},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Setting the spatial resolution of the cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#setting-the-spatial-resolution-of-the-cube","position":10},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Setting the spatial resolution of the cube"},"content":"The next step is to specify the spatial resolution (pixel size) on which the raster data (in this case Sentinel-2 imageries) should be resampled and stored in.\n\nIn this case, the desired resolution is roughly 10 meters per pixel:\n\nspatial_res = 0.00018   # = 10.038 meters in degree>\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#setting-the-spatial-resolution-of-the-cube","position":11},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Configuring the data content of the cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#configuring-the-data-content-of-the-cube","position":12},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Configuring the data content of the cube"},"content":"Now we specify the properties of our cube.\nFirst, the satellite and processing level of data to be integrated is specified. In this case, the Sentinel-2 Level 2A data will be used.\n\nIn the second row, the spectral bands are selected, which should be integarated. As we need to calculate NDVI index, we will need red and NIR bands (B04 and B08 of Sentinel-2).\n\nAlso, the time range and time period of the cube is specified in this step. In this case, we will be interested in data acquired between 14.5. and 31.7. 2018. A custom days time period will be used.\n\nend_date = date(2018, 6, 28)\ntime_range = [(end_date - timedelta(days=days)).strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")]\ncube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B04', 'B08'],\n                         tile_size=[512, 512],\n                         bbox=bbox,\n                         spatial_res=spatial_res,\n                         time_range=time_range,\n                         time_period='5D')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#configuring-the-data-content-of-the-cube","position":13},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Defining a “request collector”"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#defining-a-request-collector","position":14},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Defining a “request collector”"},"content":"We define a request_collector as an observer for SentinelHub (SH) requests made, so we can show SH usage statistics.\n\nrequest_collector = Observers.request_collector()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#defining-a-request-collector","position":15},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Loading data into the cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#loading-data-into-the-cube","position":16},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Loading data into the cube"},"content":"Now, when the cube is correctly specified, we can open it. A lazy loading technique is used - it means that the data is loaded to the cube only when we actually use it (for some calcualtion, vizualization etc.).\n\ncube = open_cube(cube_config, observer=request_collector)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#loading-data-into-the-cube","position":17},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Verifying the content of the cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#verifying-the-content-of-the-cube","position":18},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Verifying the content of the cube"},"content":"Once the cube is opened, we can check whether it has been created in accordance with our expectations.\n\nThe Cube Dataset information can be displayed, enabling to verify that the cube is specified correctly.\n\ncube\n\nNo requests have been made yet. Requests are made only if data is actually required.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#verifying-the-content-of-the-cube","position":19},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying information on specific band in the cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-information-on-specific-band-in-the-cube","position":20},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying information on specific band in the cube"},"content":"It is possible to check each band loaded into the cube separately. In this case, we will check the band 04 (RED) and then band 08 (NIR)\n\ncube.B04\n\ncube.B08\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-information-on-specific-band-in-the-cube","position":21},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying values for each time step in the time serie (band 04)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-values-for-each-time-step-in-the-time-serie-band-04","position":22},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying values for each time step in the time serie (band 04)"},"content":"Once the cube is built and time serie generated, we can display the spectral values for each time step of the serie.\n\nFor this example we’ll select a point at latitude=54.40, longitude=10.1 inside our area of interest (or geographical extent of the cube).\n\nIn this case, the nearest-neighbor interpolation methods is used by xcube. Nearest neighbour interpolation is the simplest approach to interpolation. This method simply determines the “nearest” neighbouring pixel, and assumes the intensity value of it.\n\ntimeseriesB04 = cube.B04.sel(lat=54.40, lon=10.1, method='nearest').to_series()\ntimeseriesB04\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-values-for-each-time-step-in-the-time-serie-band-04","position":23},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying values for each time step in the time serie in a linear plot (band 04)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-values-for-each-time-step-in-the-time-serie-in-a-linear-plot-band-04","position":24},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying values for each time step in the time serie in a linear plot (band 04)"},"content":"Once the maplot library is imported, the same spectral values for each step of the time serie can be displayed also in a linear chart.\n\nplt.plot(timeseriesB04)\nplt.xticks(rotation='vertical')\nplt.figsize=(15, 6)\nplt.show()\n\nThe time serie can be plotted in a similar manner also for the band 08:\n\ntimeseriesB08 = cube.B08.sel(lat=54.40, lon=10.1, method='nearest').to_series()\ntimeseriesB08\n\nplt.plot(timeseriesB08)\nplt.xticks(rotation='vertical')\nplt.figsize=(15, 6)\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-values-for-each-time-step-in-the-time-serie-in-a-linear-plot-band-04","position":25},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaing cube data for selected band and time step as imageries"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaing-cube-data-for-selected-band-and-time-step-as-imageries","position":26},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaing cube data for selected band and time step as imageries"},"content":"We can also display the data for any combination of selected spectral band and time step of the times serie contained in the cube as an imagery. We may need this to check the data visually, over entire area of interest (geographical extent of the cube).\nFor example we’ll select the time step 21.5.2018 and display the data as image for both spectral bands contianed in the cube (B04 RED and B08 NIR).\n\ncube.B04.sel(time='2018-05-21 10:00:00', method='nearest').plot.imshow(vmin=0.0, vmax=0.2, cmap='gray', figsize=(16, 10))\n\ncube.B08.sel(time='2018-05-21 10:00:00', method='nearest').plot.imshow(vmin=0.2, vmax=0.6, cmap='gray', figsize=(16, 10))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaing-cube-data-for-selected-band-and-time-step-as-imageries","position":27},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaing statistics for SentinelHub request"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaing-statistics-for-sentinelhub-request","position":28},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaing statistics for SentinelHub request"},"content":"Now SentinelHub data requests have been made. We can easilly display statistics on this request.\n\nrequest_collector.stats\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaing-statistics-for-sentinelhub-request","position":29},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Preparing values for new NDVI layer"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#preparing-values-for-new-ndvi-layer","position":30},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Preparing values for new NDVI layer"},"content":"Now we will prepare values for the new NDVI layer, based on combination of the bands already contained in our cube.\n\nWe are going to compute NDVI indexes from bands B04 and B08 of Sentinel-2 (S2L2A), using following well-know prescription:\n\nNormalized Difference Vegetation Index (NDVI) = (NIR-RED)/(NIR+RED). In our case, Sentinel-2 bandwise speaking, NDVI = (B08-B04)/(B08+B04).\n\nndvi=(cube.B08-cube.B04)/(cube.B04+cube.B08)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#preparing-values-for-new-ndvi-layer","position":31},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Specifying properties of new NDVI layer"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#specifying-properties-of-new-ndvi-layer","position":32},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Specifying properties of new NDVI layer"},"content":"We can also specify some properties of the new NDVI layer, which should be added into our cube - in this case, we set the “long name” and units of the layer.\n\nndvi.attrs['long_name']='Normalized Difference Vegetation Index'\nndvi.attrs['units']='unitless'\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#specifying-properties-of-new-ndvi-layer","position":33},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Adding a new NDVI layer to cube"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#adding-a-new-ndvi-layer-to-cube","position":34},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Adding a new NDVI layer to cube"},"content":"Now the values are calculated and the properties specified, we can easilly add the new NDVI layer into our cube.\n\ncube['NDVI']=ndvi\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#adding-a-new-ndvi-layer-to-cube","position":35},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying information for NDVI layer"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-information-for-ndvi-layer","position":36},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying information for NDVI layer"},"content":"Again, as in case of original bands 04 and 08, we can ceck the properties of the NDVI layer.\n\ncube.NDVI\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-information-for-ndvi-layer","position":37},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displayng time serie of NDVI"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displayng-time-serie-of-ndvi","position":38},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displayng time serie of NDVI"},"content":"Also, we can display time serie of values of NDVI band at selected location for all time steps.\n\nFor example we’ll select the point at latitude=54.40, longitude=10.1\nNearest-neighbor interpolation is used by xcube to find closest satellite pixel at each time step.\n\ntimeseriesNDVI = cube.NDVI.sel(lat=54.40, lon=10.1, method='nearest').to_series()\ntimeseriesNDVI\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displayng-time-serie-of-ndvi","position":39},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displayng time serie of NDVI in linear plot"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displayng-time-serie-of-ndvi-in-linear-plot","position":40},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displayng time serie of NDVI in linear plot"},"content":"Now, when we computed the NDVI values for each step in the time serie, we can easily display them in linear plot, as in case of original Sentinel-2 bands.\n\nplt.plot(timeseriesNDVI)\nplt.xticks(rotation='vertical')\nplt.figsize=(15, 6)\nplt.show()\n\nPlotting time-series NDVI data produces a temporal curve that summarizes the various stages that green vegetation undergoes during a complete growing season.\nSuch curves can be analyzed to extract key phenological variables, or metrics, about a particular season, such as the start, peak and end of the growing season. These characteristics may correspond directly to conventional, ground-based phenological events like growing (the NDVI values grows), mowing, harvesting or ploughing (NDVI values drops rapidly) and provide indications of ecosystem dynamics.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displayng-time-serie-of-ndvi-in-linear-plot","position":41},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying NDVI at selected time step as image"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-ndvi-at-selected-time-step-as-image","position":42},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying NDVI at selected time step as image"},"content":"To check the NDVI values over whole area of interest, we can display the NDVI values for any selected time step of the time serie as image in selected color scale.\nFor example we’ll select the time step 21.5.2018.\n\ncube.NDVI.sel(time='2018-05-21 10:00:00', method='nearest').plot.imshow(vmin=-1, vmax=1, cmap='RdYlGn', figsize=(16, 10))\n#cube.NDVI.sel(time='2018-06-25 10:00:00', method='nearest').plot.imshow(vmin=-1, vmax=1, cmap='RdYlGn', figsize=(16, 10))\n#cube.NDVI.sel(time='2018-07-25 10:00:00', method='nearest').plot.imshow(vmin=-1, vmax=1, cmap='RdYlGn', figsize=(16, 10))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-ndvi-at-selected-time-step-as-image","position":43},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying NDVI for all time steps in the serie as image"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-ndvi-for-all-time-steps-in-the-serie-as-image","position":44},{"hierarchy":{"lvl1":"NDVI timeline","lvl2":"Displaying NDVI for all time steps in the serie as image"},"content":"To check the NDVI values over whole area of interest for all time step in the time serie,\nwe can display the NDVI values for all selected time steps of the serie as image in the same color scale beside each other.\nThis allows us to visually compare the development of NDVI values over whole time serie and to compare various time steps with each other.\n\nimg=cube.NDVI.plot.imshow(col='time', col_wrap=4, vmin=-1, vmax=1,cmap='RdYlGn')","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-usecase-ndvi-timeline#displaying-ndvi-for-all-time-steps-in-the-serie-as-image","position":45},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps","position":0},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps","position":1},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#first-steps-on-the-euro-data-cube-platform","position":2},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform"},"content":"Euro Data Cube provides a JupyterLab environment, which automatically provides credentials for services with active subscriptions as environment variables.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#first-steps-on-the-euro-data-cube-platform","position":3},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Setup"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#setup","position":4},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Setup"},"content":"As you can see here, the credentials for your subscriptions are automatically part of your environment variables.You can also print them, but make sure to keep them confidential!\n\nimport os\n'SH_CLIENT_SECRET' in os.environ\n\nUsually, it is not even necessary to access the credentials.Many libraries such as xcube_sh or xcube_geodb load them directly from the environment by default.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#setup","position":5},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Retrieving data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#retrieving-data","position":6},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Retrieving data"},"content":"Let’s say you want to retrieve some Sentinel Data as defined by the following cube (don’t worry if you don’t understand all the details here, it will be explained \n\nhere):\n\nfrom xcube_sh.config import CubeConfig\ncube_config = CubeConfig(\n    dataset_name=\"S2L2A\",\n    band_names=[\"B04\", \"B08\"],\n    tile_size=[512, 512],\n    bbox=(10.00, 54.27, 10.30, 54.50),\n    spatial_res=0.00018,\n    time_range=[\"2018-05-02\", \"2018-05-26\"],\n    time_period=\"3D\",\n)\n\nThe following xcube call will fetch the data using your active SentinelHub subscription automatically using the credentials from the environment variables:\n\nfrom xcube_sh.cube import open_cube\ncube = open_cube(cube_config)\ncube.B04.lat\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#retrieving-data","position":7},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Explicit credential handling for advanced libraries"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#explicit-credential-handling-for-advanced-libraries","position":8},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Explicit credential handling for advanced libraries"},"content":"Some libraries such as the EO-Learn ML library do require you to set up credentials manually. Since the credentials are available using environment variables, there are different means of using them.\n\nOne way of accessing the environment variables is to use the Jupyter feature %env:\n\nclient_id = %env SH_CLIENT_ID\n\nYou can however also access the credentials using idiomatic python:\n\nclient_id = os.environ['SH_CLIENT_ID']\n\nUsing this, we can extract the credentials in an SHConfig object and pass this object to an external library:\n\nfrom sentinelhub import SHConfig\n\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\nSee for example \n\nthis notebook for a concrete use case of how to pass this SHConfig object to a library.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#explicit-credential-handling-for-advanced-libraries","position":9},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Adding custom credentials e.g. for S3 buckets"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#adding-custom-credentials-e-g-for-s3-buckets","position":10},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Adding custom credentials e.g. for S3 buckets"},"content":"If you want to use external services, such as Amazon S3 buckets, you can also manage the relevant credentials via the app \n\nedc-my-credentials on \n\neurodatacube.com. Those credentials will be automatically injected just like for purchased services.\n\nSee this guide for step by step instructions on how to add your custom credentials.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#adding-custom-credentials-e-g-for-s3-buckets","position":11},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Conclusion"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#conclusion","position":12},{"hierarchy":{"lvl1":"First steps on the Euro Data Cube platform","lvl2":"Conclusion"},"content":"The Euro Data Cube platform allows you to focus on your data without needing to think about authentication and login credentials.\n\nYou can even share notebooks in the Euro Data Cube marketplace without any changes required. If anyone else runs this notebook on this platform, their respective API service credentials will be used automatically.\n\nTo learn more about using SentinelHub or GeoDB on the Euro Data Cube platform, check out these notebooks in the marketplace.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/edc-first-steps#conclusion","position":13},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2","position":0},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2","position":1},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#earth-system-data-lab-tutorial-euro-data-cube","position":2},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#earth-system-data-lab-tutorial-euro-data-cube","position":3},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube","lvl2":"Brought to you by Brockmann Consult"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#brought-to-you-by-brockmann-consult","position":4},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube","lvl2":"Brought to you by Brockmann Consult"},"content":"The Earth System Data Cube is a collection of pre-generated data cubes with geophysical, biogeochemical, and ecological variables relevant for Earth System Sciences. These data sets are open and free and thus also available also through EDC. This notebook demonstrates access to the ESDC data sets.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#brought-to-you-by-brockmann-consult","position":5},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube","lvl2":"Import packages"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#import-packages","position":6},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube","lvl2":"Import packages"},"content":"\n\nDue to memory problems with dask versions greater than 2021.03.1 as described in issue \n\ndask/dask#7583 it is necessary to use dask distributed client. We also import ‘progress’ to visualize the computing time.\n\nfrom dask.distributed import Client, progress\n\nclient = Client()\n\nclient.current()\n\n#client.close()\n\nfrom xcube.core.store import new_data_store\nimport xarray as xr\n\n# utilities\nfrom ipywidgets import interact\nimport matplotlib.pyplot as plt\nimport matplotlib\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.simplefilter('ignore')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#import-packages","position":7},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube","lvl2":"Data Access"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#data-access","position":8},{"hierarchy":{"lvl1":"Earth System Data Lab Tutorial @ Euro Data Cube","lvl2":"Data Access"},"content":"\n\nroot = \"esdl-esdc-v2.1.1\"\n\ndata_store = new_data_store(\"s3\", \n                            root=root, \n                            storage_options=dict(anon=True)\n                           ) \n\nlist(data_store.get_data_ids())\n\n\nESDC_hi = data_store.open_data(\"esdc-8d-0.083deg-1x2160x4320-2.1.1.zarr\")\n\nESDC_hi.land_surface_temperature\n\nESDC_hi.land_surface_temperature.attrs\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#data-access","position":9},{"hierarchy":{"lvl1":"Basic plotting"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#basic-plotting","position":10},{"hierarchy":{"lvl1":"Basic plotting"},"content":"\n\nESDC_hi.analysed_sst.sel(time='2000-07-15', method='nearest').plot.pcolormesh(figsize=(16,10))\n\nvar_names = []\nfor var_name in ESDC_hi.data_vars:\n    var_names.append(var_name)\n    \ndef plot_image(time_index=1400, variable_name=var_names[5]):\n    ESDC_hi[variable_name][time_index].plot(figsize=(18,9), aspect='auto')\n\n# interact(plot_image, time_index=(0,ESDC_hi.time.size - 1,1), variable_name=var_names)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#basic-plotting","position":11},{"hierarchy":{"lvl1":"Computation"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#computation","position":12},{"hierarchy":{"lvl1":"Computation"},"content":"","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#computation","position":13},{"hierarchy":{"lvl1":"Computation","lvl2":"xarray API"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#xarray-api","position":14},{"hierarchy":{"lvl1":"Computation","lvl2":"xarray API"},"content":"\n\nESDC_low_time_opt = data_store.open_data(\"esdc-8d-0.25deg-184x90x90-2.1.1.zarr\")\n\nCFC_globalmean = ESDC_low_time_opt.cfc.mean(dim='time').persist() # start computation in the background\n\nprogress(CFC_globalmean)      # watch progress\n\nCFC_globalmean\n\nCFC_globalmean.plot.imshow(figsize=(18,9), cmap = \"coolwarm\")\n\nCFC_globalmean.close()\nESDC_low_time_opt.close()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#xarray-api","position":15},{"hierarchy":{"lvl1":"Resampling"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#resampling","position":16},{"hierarchy":{"lvl1":"Resampling"},"content":"\n\nESDC_low = data_store.open_data(\"esdc-8d-0.25deg-1x720x1440-2.1.1.zarr\")\n\nprecip_monthly = ESDC_low.precipitation.resample(time = '1M',keep_attrs = True).sum('time')\nprecip_monthly = precip_monthly.sel(time=slice('2000-07-01', '2010-12-31'))\n\nprecip_monthly_rechunked = precip_monthly.chunk({'lat': 120, 'lon': 120,'time': 240}).persist()\n\nprogress(precip_monthly_rechunked)\n\nprecip_monthly_rechunked.sel(lat=53,lon=7., method='nearest').plot()\n\nprecip_3month = precip_monthly_rechunked.rolling(time=3,min_periods=1, center=True).mean(skipna=True).persist()\n\nprogress(precip_3month)\n\nfig, ax = plt.subplots(figsize = [14,5], ncols=1)\nprecip_3month.sel(lat=53,lon=7., method='nearest').plot(ax=ax, color = 'red')\nprecip_monthly_rechunked.sel(lat=53,lon=7., method='nearest').plot(ax=ax, color = 'blue')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#resampling","position":17},{"hierarchy":{"lvl1":"Own functions"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#own-functions","position":18},{"hierarchy":{"lvl1":"Own functions"},"content":"\n\nFor the following functions it is good to use the time optimized data cube again, that’s why ESDC_low_time_opt is used.\n\nEurope = ESDC_low_time_opt.sel(lat = slice(70.,30.), lon = slice(-20.,30.))\n\nEurope_zscore = ((Europe-Europe.mean(dim='time'))/Europe.std(dim='time'))\n\n\nESRIN_zscore = Europe_zscore.sel(lon = 12.67,lat = 41.83, method = 'nearest')\n\n\nESRIN_zscore.air_temperature_2m.plot(figsize=(18,9))\n\nimport numpy as np\n\ndef above_Nsigma(x,Nsigma):\n    return np.fabs(x)>Nsigma\n\nres = Europe_zscore.apply(above_Nsigma,Nsigma = 2)\n\nair_temp_sum = res.air_temperature_2m.sum(dim=\"time\").persist()\n\nprogress(air_temp_sum)\n\nevap = res.evaporation.sum(dim=\"time\").persist()\n\nprogress(evap)\n\nfig2, ax2 = plt.subplots(figsize = [12,5], ncols=2)\n\nair_temp_sum.plot(ax = ax2[0])\nax2[0].set_title(\"No of obs above or below 2 sigma\")\n\nevap.plot(ax = ax2[1])\nax2[1].set_title(\"No of obs above or below 2 sigma\")\n\nplt.tight_layout()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/esdl-edc-v0-2#own-functions","position":19},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc","position":0},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc","position":1},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#exploring-time-and-space-a-guide-to-accessing-analysing-and-visualising-data-in-the-euro-data-cube","position":2},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube"},"content":"\n\nWritten by: William Ray","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#exploring-time-and-space-a-guide-to-accessing-analysing-and-visualising-data-in-the-euro-data-cube","position":3},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl2":"Getting started with EDC"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#getting-started-with-edc","position":4},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl2":"Getting started with EDC"},"content":"In this demonstration Jupyter Notebook, we will be visualising and analysing river flooding using Sentinel data to demonstrate how you can use EDC for your own applications. Much of what we we will focus on can be used for many other applications and use cases.\n\nWe are going to use the EDC and its associated libaries and APIs to do this. In this notebook we will learn how to:\n\nBuild a cube\n\nVisualise a variable in your data cube\n\nCreate a new variable\n\nCreate a new variable using a threshold\n\nVisualise a spatial subset of a variable over time\n\nCreate a new variable based upon space and time.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#getting-started-with-edc","position":5},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl2":"Configuration"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#configuration","position":6},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl2":"Configuration"},"content":"Before acccessing the data, we will start by importing the necessary Python libraries (already configured in your EDC workspace), and generate credentials automatically to access the services.\n\n# EDC libraries\nfrom edc import setup_environment_variables\nfrom xcube_sh.config import CubeConfig\nfrom xcube_sh.cube import open_cube\nfrom xcube_sh.sentinelhub import SentinelHub\nfrom xcube.core.gen2.local.combiner import CubesCombiner\nfrom xcube.core.geom import mask_dataset_by_geometry\n\n# Sentinel Hub\nfrom sentinelhub import BBox, SentinelHubRequest, bbox_to_dimensions, DataCollection, MimeType, SHConfig, geometry\n\n# Utilities\nimport IPython.display\nfrom os import environ\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport geopandas\nimport rioxarray\n\n# Numerical computation\nimport xarray as xr\nimport numpy as np\n\n# Fetch credentials as environement variables\nsetup_environment_variables()\n\n# Pass Sentinel Hub credentials to dictionnary\nsh_credentials = dict(client_id=environ[\"SH_CLIENT_ID\"],\n                      client_secret=environ[\"SH_CLIENT_SECRET\"])\n\nDefine an AOI\n\nNext, we will define our area of interest using a bounding box. This must be provided in WGS84 coordinates to build the cube. But later, we will clip this further using a GeoJSON to a far better defined AOI. We have chosen an AOI on the River Severn in the UK. This area regularly floods in the winter months with a wide floodplain. Last winter (2020/2021), there was significant flooding in the second half of December and at the end of January / start of February.\n\n# Bbox\ntewkesbury_uk_bbox = [-2.24, 51.93, -2.09, 52.10]\nsmaller_box = [-2.24, 51.99, -2.15, 52.05]\n\n# Bbox EPSG\nbbox_epsg = 4326\n\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(smaller_box,crs=bbox_epsg).get_geojson())\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#configuration","position":7},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"How to build a data cube","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#how-to-build-a-data-cube","position":8},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"How to build a data cube","lvl2":"Configuration"},"content":"Firstly, we will go through how to build a data cube.\n\nWe are going to visualise the floods using Sentinel-2 imagery. Sentinel-2 is part of the Copernicus programme and collects multispectral data globally with a revisit time of 5 days. The satellite’s multispectral imager provides collects data in 13 spectral bands spanning from the visible and near infrared to the shortwave infrared. The visible and near infrared data we will use in this example is collected at 10m resolution.\n\nCheck Sentinel-2 L2A available bands\n\nUsing EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset to help us build the cube!\n\n# Create a Sentinel Hub class, using our Sentinel Hub credentials\nSH = SentinelHub(**sh_credentials)\n\n# List bands for S2-L2A\nSH.band_names('S2L2A')\n\nBuild an xcube\n\nIn the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S2L2A for Sentinel-2 L2A. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call the B02, B03, B04, B08, CLM (Blue, Green, Red & NIR, Cloud Mask) bands.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-2 L2A data is available from October 2016 onwards. In this example, we will fetch data for December 2020 - February 2021.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30M corresponds to 30 minutes, thus avoiding duplicate datasets.\n\nNote: the return _coerce_scalar_to_timedelta_type(arg, unit=unit, errors=errors) warning can be safely ignored.\n\n# Setup xcube\ns2_cube_config = CubeConfig(dataset_name='S2L2A',\n                         band_names=['B02', 'B03', 'B04', 'B08', 'CLM'],\n                         bbox=smaller_box,\n                         spatial_res=0.000089,\n                         time_range=['2020-12-01', '2021-02-28'],\n                         time_tolerance='30M')\n\nOpen the xcube\n\nIn the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube. It’s important to note that at this stage, we’re not processing anything, just generating a cube on the fly with data ready to be called when needed for analysis.\n\nOnce you open the cube, you can visualise the contents. You can view the number of timestamps and a list of them all too in the Coordinates tab. You can also visualise the seperate variables, with information on the size of the variables and their data type too.\n\n# Open cube (on the fly)\ns2_cube = open_cube(s2_cube_config, **sh_credentials)\n\n# Display contents\ns2_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#how-to-build-a-data-cube","position":9},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"How to visualise your datacube","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#how-to-visualise-your-datacube","position":10},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"How to visualise your datacube","lvl2":"Configuration"},"content":"Now we have built our cube, let’s visualise the data! We are going to visualise a True Color image and an NDWI image in the same plot. In the below cell you can see we are selecting each band for 10:00:00 28th December 2020, and selecting the nearest acquisition to this date and time. We then stack the three bands and plot this using Matplotlib. We will call the three bands in the visible spectrum. In addition we will multiply the reflectance values by 3 to brighten the image due to the acquisition we’re visualising being acquired in the winter months.\n\nAnother way to visualise the extent of surface water is to use the Normalised Difference Water Index (NDWI). This is an index that can be used to extract surface water using multispectral imagery such as Sentinel-2. We can calculate the index with the Green and NIR bands as stated below, and add it into the data cube as a new variable.\n\nNDWI = Green - NIR / Green + NIR\n\nFor this we are going to create a new variable in the next cell. To create the new variable we are using two existing variables defined as s2.cube.B03 and s2_cube.B08. We then insert these variables into an index formula to create NDWI. Once ndwi has been calculated it’s attributed a long_name and units before being defined as ndwi so that we can call it as a definition later in the notebook.\n\n# Define NDWI in visualisation\nndwi = ((s2_cube.B03-s2_cube.B08)/(s2_cube.B03+s2_cube.B08))\n\nndwi.attrs['long_name']='NDWI'\nndwi.attrs['units']='unitless'\n\ns2_cube['NDWI']= ndwi  \n\nNext we want to plot both the True Color image and the NDWI in the same plot. We will use Matplotlib to achieve this.\n\n# Select the bands and stack them.\nRed = s2_cube.B04.sel(time='2020-12-28 10:00:00', method='nearest')\nGreen = s2_cube.B03.sel(time='2020-12-28 10:00:00', method='nearest')\nBlue = s2_cube.B02.sel(time='2020-12-28 10:00:00', method='nearest')\n\nrgb = np.dstack((Red,Green,Blue)) #Stack the three arrays\n\nndwi = s2_cube.NDWI.sel(time='2020-12-28 10:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[10, 15])\nf.add_subplot(1, 2, 1)\nplt.title(f\"True Color: {str(s2_cube.time.sel(time='2020-12-28 10:00:00', method='nearest').data).split('T')[0]}\")\nplt.imshow(5 * rgb)  # We multiply the rgb by 5 to make the image brighter\nf.add_subplot(1, 2, 2)\nplt.title(f\"NDWI: {str(s2_cube.time.sel(time='2020-12-28 10:00:00', method='nearest').data).split('T')[0]}\")\nplt.imshow(ndwi, vmin=-1, vmax=1, cmap='GnBu')\nplt.show()\n\nThis looks good, and the extent of the flood waters is visualised really nicely here. The 10m resolution also enables us to see individual fields that are flooded with the linear boundaries of the fields highlighted nicely in the high resolution image provided by the 10m Sentinel 2 bands. This looks really useful so let’s try and visualise some more dates in the time period that we are examining;\n\n# Select timestamps\nndwi1 = s2_cube.NDWI.sel(time='2020-12-05 10:00:00', method='nearest')\nndwi2 = s2_cube.NDWI.sel(time='2020-12-24 10:00:00', method='nearest')\nndwi3 = s2_cube.NDWI.sel(time='2020-12-31 10:00:00', method='nearest')\nndwi4 = s2_cube.NDWI.sel(time='2021-01-05 10:00:00', method='nearest')\nndwi5 = s2_cube.NDWI.sel(time='2021-01-24 10:00:00', method='nearest')\nndwi6 = s2_cube.NDWI.sel(time='2021-02-05 10:00:00', method='nearest')\n\n\n# Plot \nf = plt.figure(figsize=[15,11])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\nax4 = f.add_subplot(2,3, 4)\nax5 = f.add_subplot(2,3, 5)\nax6 = f.add_subplot(2,3, 6)\n\naxlist=[ax1,ax2,ax3,ax4,ax5,ax6]\n\nt = ndwi1.plot.imshow(ax=ax1, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi2.plot.imshow(ax=ax2, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi3.plot.imshow(ax=ax3, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi4.plot.imshow(ax=ax4, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi5.plot.imshow(ax=ax5, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\nndwi6.plot.imshow(ax=ax6, vmin=-1, vmax=1, cmap='GnBu', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"NDWI\")\n\nplt.show()\n\nThis is not so useful! Unsurprisingly, in a maritime climate most of the images are cloudy and of no use to flood monitoring. Of the six dates we have requested, only one is fully cloud free and four of the dates are unusable. From the limited data we have, we know the river was in its normal state on 5th December and in flood on 5th February but due to cloud cover we don’t know what is happening in between those dates. This problem is very common in the UK where cloud cover is extremely common during the winter months, meaning you are almost certain to have incomplete time series of data. Fortunately, there is a solution we can use, thanks to the Sentinel-1 platform.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#how-to-visualise-your-datacube","position":11},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Sentinel-1 description","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#sentinel-1-description","position":12},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Sentinel-1 description","lvl2":"Configuration"},"content":"Like Sentinel-2, Sentinel-1 is also part of the Copernicus programme and collects data globally with a revisit time of 5 days. In contrast to Sentinel-2, Sentinel-1 SAR is an active sensor using SAR signals recording the backscatter. Due to the wavelengths used, SAR is not hindered by clouds and can be operated day and night.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#sentinel-1-description","position":13},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#check-sentinel-1-grd-available-bands","position":14},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Check Sentinel-1 GRD available bands","lvl2":"Configuration"},"content":"Using EDC inbuilt functions that query Sentinel Hub services, we can easily list the available bands for a given dataset.\n\n# List bands for S1-GRD\nSH.band_names('S1GRD')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#check-sentinel-1-grd-available-bands","position":15},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Build an xcube","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#build-an-xcube","position":16},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Build an xcube","lvl2":"Configuration"},"content":"In the following cell we will specify the input parameters needed to build an xcube array. The following parameters are specified:\n\ndataset_name: the Sentinel Hub identification of the dataset. Here we will call S1GRD for Sentinel-1 GRD. All available datasets can be listed with SH.dataset_names\n\nband_names: the band names to be used in the xcube array (see previous code cell). Here, we will call just the VV polarisation band.\n\nbbox: the bounding box that sets the extent of the AOI. Because we are using the default WGS84 coordinate system here, the CRS parameter doesn’t need to be set.\n\nspatial_res: the spatial resolution of the rasters contained in the xcube array. The spatial resolution is expressed in the units of the coordinate system used. Therefore, in this example, the spatial resolution is set in degrees. For an approximate pixel size of 10 meters, we set the resolution to 0.000089 degrees.\n\ntime_range: a list of two dates [start_date, end_date] forming a time period for which all acquisitions will be returned. Sentinel-1 GRD data is available from February 2015 onwards. In this example, we will fetch data for December 2020 - February 2021.\n\ntime_tolerance: The tolerance used to identify whether a dataset should still be included within a time period. Here, 30M corresponds to 30 minutes, thus avoiding duplicate datasets.\n\nNote: the return _coerce_scalar_to_timedelta_type(arg, unit=unit, errors=errors) warning can be safely ignored.\n\n# Setup xcube\ns1_cube_config = CubeConfig(dataset_name='S1GRD',\n                         band_names=['VV'],\n                         bbox=smaller_box,\n                         spatial_res=0.000089,\n                         time_range=['2020-12-01', '2021-02-28'],\n                         time_tolerance='30M')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#build-an-xcube","position":17},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Open the xcube","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#open-the-xcube","position":18},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Open the xcube","lvl2":"Configuration"},"content":"In the following cell we open the cube and display its contents. The automatically generated credentials obtained earlier in this Jupyter Notebook are specified as a parameter when opening the cube.\n\n# Open cube (on the fly)\ns1_cube = open_cube(s1_cube_config, **sh_credentials)\n\n# Display contents\ns1_cube\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#open-the-xcube","position":19},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Visualising the flooded areas using SAR","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#visualising-the-flooded-areas-using-sar","position":20},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Visualising the flooded areas using SAR","lvl2":"Configuration"},"content":"We are going to use the VV band to visualise the flooding. From our earlier visualisation, we know that there was significant surface water flooding just after Christmas 2020 so will select the same date as last time, but as this is a different sensor we will expect an acquisition from a different date.\n\nFirstly, we need to generate a new variable. In GRD data the VV polarisation is provided in Digital Number format and to perform some analysis we need to convert this to decibels. This is done by mutiplying the log10 of each DN pixel by 10. Secondly, as there will be pixels with a value of -inf after this operation, we need to account for this with the second function which will automatically assign 0 to these pixels.\n\n# Convert VV Digital numbers to Decibels\nvv_dn = s1_cube.VV\nvv_db = 10 * (np.log10(vv_dn))\n\nvv_db = vv_db.where(np.isfinite(vv_db), 0)\n\nvv_db.attrs['long_name']='VV_dB'\nvv_db.attrs['units']='decibels'\n\ns1_cube['VV_dB']= vv_db\n\nLike previously, we are going to visualise the VV_dB variable we have just generated for our AOI.\n\n# select and define the timestamp you want to visualise \nVV_dB_timestamp = s1_cube.VV_dB.sel(time='2020-12-28 10:00:00', method='nearest')\n\n# plot the timestamp\nVV_dB_timestamp.plot.imshow(vmin=-40, vmax=0, cmap='winter', figsize=(10, 10))\n\n# save and display the plot\nplt.show()\n\nThis looks very similar to the NDWI we derived earlier showing the flood extent fairly clearly (the blue areas). It looks fairly well defined so let’s visualise the same but over several timestamps to confirm that this is a good variable to use to generate a flood mask.\n\n#### Timestamp selection\nvv1 = s1_cube.VV_dB.sel(time='2020-12-05 10:00:00', method='nearest')\nvv2 = s1_cube.VV_dB.sel(time='2020-12-24 10:00:00', method='nearest')\nvv3 = s1_cube.VV_dB.sel(time='2020-12-31 10:00:00', method='nearest')\nvv4 = s1_cube.VV_dB.sel(time='2021-01-05 10:00:00', method='nearest')\nvv5 = s1_cube.VV_dB.sel(time='2021-01-24 10:00:00', method='nearest')\nvv6 = s1_cube.VV_dB.sel(time='2021-02-05 10:00:00', method='nearest')\n\n# Plot \nf = plt.figure(figsize=[16,11])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\nax4 = f.add_subplot(2,3, 4)\nax5 = f.add_subplot(2,3, 5)\nax6 = f.add_subplot(2,3, 6)\n\naxlist=[ax1,ax2,ax3,ax4,ax5,ax6]\n\nt = vv1.plot.imshow(ax=ax1, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv2.plot.imshow(ax=ax2, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv3.plot.imshow(ax=ax3, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv4.plot.imshow(ax=ax4, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv5.plot.imshow(ax=ax5, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\nvv6.plot.imshow(ax=ax6, vmin=-40, vmax=0, cmap='winter', add_colorbar=False)\n\ncbar_ax = f.add_axes([1, 0.15, 0.05, 0.7])\nf.colorbar(t, cax=cbar_ax, label=\"VV dB\")\n\nplt.show()\n\nThis gives a much clearer picture of flooding during the time period than using NDWI, and we now know much more about the spatial and temporal extent of the flooding in the AOI in the winter of 2020/2021. Next we want to generate a flood mask using a threshold. Generally, as a good rule of thumb; in the VV band, values below -20 dB are usually surface water. We will try this value first, but we will also look to visualise how the flood mask changes if we adjust the threshold value. First, let’s generate the new variable using the .where function in xarray.\n\nAt first glance, the below cell may not make much sense. It may read that the step 1 function as assigning a value of 1 to pixels in VV_dB that are equal or more than -20. However, what is actually happening is that the .where function preserves all the pixel values in the variable that are below -20 and assigns everything else a value of 1. More can be found in the xarray documentation \n\nhttp://​xarray​.pydata​.org​/en​/stable​/generated​/xarray​.DataArray​.where​.html\n\n# Assign all pixels equal or smaller than -20 a value of 1 and preserve the values of pixels \nstep1 = s1_cube.VV_dB.where(s1_cube.VV_dB >= -20, 1)\n\n# Assign all other pixels a value of 0. \nflooded = step1.where(step1 == 1, 0)\n\nflooded.attrs['long_name'] ='flooded'\nflooded.attrs['units'] ='nounits'\n\ns1_cube['flooded'] = flooded\n\nNext let’s see what happens the the flood mask extent, if we change the threshold to -15 dB and -25dB:\n\nflood_threshold1_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB >= -15, 1)\nflood_threshold2_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB >= -20, 1)\nflood_threshold3_step1 = s1_cube.VV_dB.where(s1_cube.VV_dB >= -25, 1)\n\nflood_threshold1_step2 = flood_threshold1_step1.where(flood_threshold1_step1 == 1, 0)\nflood_threshold2_step2 = flood_threshold2_step1.where(flood_threshold2_step1 == 1, 0)\nflood_threshold3_step2 = flood_threshold3_step1.where(flood_threshold3_step1 == 1, 0)\n\nflood_threshold1 = flood_threshold1_step2.sel(time='2020-12-28 10:00:00', method='nearest')\nflood_threshold2 = flood_threshold2_step2.sel(time='2020-12-28 10:00:00', method='nearest')\nflood_threshold3 = flood_threshold3_step2.sel(time='2020-12-28 10:00:00', method='nearest')\n\nNext we will plot the new thresholds we want to test:\n\n# Plot \nf = plt.figure(figsize=[20,12])\nax1 = f.add_subplot(2,3, 1)\nax2 = f.add_subplot(2,3, 2)\nax3 = f.add_subplot(2,3, 3)\n\nflood_threshold1.plot.imshow(ax=ax1, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nflood_threshold2.plot.imshow(ax=ax2, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\nflood_threshold3.plot.imshow(ax=ax3, vmin=0, vmax=1, cmap='Blues', add_colorbar=False)\n\nplt.show()\n\nChanging the threshold by only 5 dB makes a large difference. If we set it as a higher number we pick up a lot more false positives and with a lower threshold we start to create more false negatives and a more fragmented flood extent. For now, let’s use -20 dB as the threshold. Let’s extrapolate our threshold out to a few more dates and see how this looks:\n\nExcellent, this looks like a good threshold across time and space. Let’s move on to visualising the data from the temporal point of view.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#visualising-the-flooded-areas-using-sar","position":21},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Plotting Time Series","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#plotting-time-series","position":22},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Plotting Time Series","lvl2":"Configuration"},"content":"How to generate a time series plot for a point\n\nExcellent, we are getting a really good picture of how the flooding evolved over space and time. Now let’s generate a time series for a Longitude and Latitude within the AOI and observe how NDWI and then VV_dB variables in the cubes compare over time. Firstly, we define the point_lat and point_lon and then using these as inputs we select the variable accross all the timesteps and to recieve the timeseries use the .to_series() function. It’s at this point too that we use the CLM variable to mask out cloudy areas from the Sentinel 2 acquisitions in the time steps.\n\n# Set latitude and longitude of point to query\npoint_lat = 52.000089\npoint_lon = -2.167874\n\n# Get timeseries\nmasked = s2_cube.NDWI.where(s2_cube.CLM == 0)\ntimeseriesNDWI_masked = masked.sel(lat=point_lat, lon=point_lon, method='nearest').to_series()\ntimeseriesNDWI_masked = timeseriesNDWI_masked.where(timeseriesNDWI_masked !=0).dropna()\n\ntimeseriesNDWI = s2_cube.NDWI.sel(lat=point_lat, lon=point_lon, method='nearest').to_series()\ntimeseriesNDWI = timeseriesNDWI.where(timeseriesNDWI !=0).dropna()\n\ntimeseriesVV_dB = s1_cube.VV_dB.sel(lat=point_lat, lon=point_lon, method='nearest').to_series()\ntimeseriesVV_dB = timeseriesVV_dB.where(timeseriesVV_dB !=0).dropna()\n\nUsing matplotlib we can now visualise how NDWI changes over time. In the plot we will plot 2 series, a cloud-masked series in blue, and an unmasked series in grey.\n\n# Plot NDWI timeseries\n_, ax = plt.subplots(1, figsize=(15, 6))\nax.plot(timeseriesNDWI, color=\"Grey\", marker=\"o\", linewidth=0.5, alpha=0.4)\nax.plot(timeseriesNDWI_masked, color=\"blue\", linestyle=\"none\", marker=\"o\", linewidth=0.5)\nax.set_title(f\"NDWI timeseries. Latitude: {point_lat}, Longitude: {point_lon}.\")\nplt.show()\n\nThe NDWI time series for Sentinel-2 doesn’t really show us anything significant. There is no farily consistent NDWI value to go from which makes it difficult to establish a point of reference. There are peaks in NDWI at the end of December and the start of February but as was demonstrated earlier cloud cover is a big issue. There are big gaps between non-cloudy acquisitions of over a month in some cases. Let’s plot the same but for the VV polarisation from Sentinel-1.\n\nPlot VV dB timeseries for a given location\n\nWe can now visualise how VV dB changes over time.\n\n# Plot VV_dB timeseries\nfig, ax = plt.subplots(1, figsize=(12, 6))\nax.plot(timeseriesVV_dB, color=\"blue\", marker=\"o\", linewidth=0.5)\nax.set_title(f\"VV dB timeseries. Latitude: {point_lat}, Longitude: {point_lon}.\")\nplt.show()\n\nThis is much clearer than the Sentinel 2 time series as we have more observations due to no interference from cloud cover. We have a clear point of reference for what the VV polarisation response is during flood and non flooded time periods with a VV response of -8 to 0 dB when dry and < -20 dB when flooded. The time series really clearly shows the two flood events at the end of December / start of January and the end of January / start of February.\n\nPlot VV dB timeseries for a given field or AOI\n\nLet’s take this another step further, and generate the time series using a polygon instead of a point. First we have already generated a GeoJSON of a field on the banks of the River Severn near Tewkesbury. This field is part of the floodplain so we should see the flood peak again from the data. First let’s import the GeoJSON and visualise it:\n\n# Plot the bounding box on a map\n\nfield = {\n    \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [\n              -2.164928913116455,\n              52.00127710606571\n            ],\n            [\n              -2.1648645401000977,\n              52.00164699252238\n            ],\n            [\n              -2.166323661804199,\n              52.00146204967612\n            ],\n            [\n              -2.1764731407165527,\n              52.00024669196227\n            ],\n            [\n              -2.175872325897217,\n              51.9993087302974\n            ],\n            [\n              -2.175271511077881,\n              51.9974195365859\n            ],\n            [\n              -2.1735334396362305,\n              51.99625691621346\n            ],\n            [\n              -2.170572280883789,\n              51.995556687103125\n            ],\n            [\n              -2.166731357574463,\n              51.996336186743406\n            ],\n            [\n              -2.165207862854004,\n              51.998027257946404\n            ],\n            [\n              -2.164928913116455,\n              52.00127710606571\n            ]\n          ]\n        ]}\n\nIPython.display.GeoJSON(field)\n\nNext, let’s mask our dataset by the field we have just defined and visualise our ‘masked’ datacube. You can see that the variables we calculated have been generated and carried across into the new datacube.\n\nwater_meadow = mask_dataset_by_geometry(s1_cube, geometry=field)\n\nLet’s visualise our masked data cube using the first timestep and the VV_dB variable:\n\nwater_meadow.VV_dB.isel(time=0).plot.imshow(cmap='Greys', vmin=-20, vmax=0, figsize=(10, 10))\nplt.show()\n\nOK, this looks good, now we are now going to calculate the mean VV dB polarisation across the field for each time step. Firstly, we want to calculate the mean VV_dB on axis 1 (lat) and 2 (lon). The second function removes any observations with values of 0 (observations that don’t cover our field of interest). Visualising this array we have 59 timesteps each assigned the mean value of the field.\n\n# calculate the mean VV dB for each time step\ntimeseriesVV_dB = water_meadow.VV_dB.mean(axis=(1,2), skipna=True)\n\n# remove any observations with no data\ntimeseriesVV_dB = timeseriesVV_dB.where(timeseriesVV_dB !=0).dropna(\"time\")\n\n# return the new data cube chunk\ntimeseriesVV_dB\n\nNext we can plot this new array we have generated. The result is an excellent picture showing the two flood events that occured in the time period. We can see the larger picture as this is the mean value over several pixels rather than just a single point like we previously plotted.\n\n# Plot VV_dB timeseries\nfig, ax = plt.subplots(1, figsize=(10, 6))\nax.plot(timeseriesVV_dB.time, timeseriesVV_dB, color=\"blue\", marker=\"o\", linewidth=0.5)\nax.set_title(\"Mean VV dB returned from AOI over 11-01-20 to 28-02-21\")\nax.set_xlabel('Time')\nax.set_ylabel('VV dB')\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#plotting-time-series","position":23},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Creating advanced variables","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#creating-advanced-variables","position":24},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Creating advanced variables","lvl2":"Configuration"},"content":"Mapping flooding frequency across the whole AOI\n\nLastly, we are going to return to the full data cube and study area, and we are going to calculate the number of observations that each pixel is flooded during the time period we are examining by calculating the sum of the flood mask pixels. This will create an array with the number of observations a pixel was flooded assigned to each pixel.\n\nSecondly, as using the absolute value makes comparisons with other time periods / areas difficult we will also calculate the proportion of observations that a pixel was flooded. To calculate this, we can then divide the sum of the flooded pixels by the number of timesteps in our data cube (the count).\n\nflood_sum = s1_cube.flooded.sum(dim=\"time\")\nflood_count = s1_cube.flooded.count(dim=\"time\")\nflood_average = flood_sum / flood_count\n\n#flood_sum.attrs['long_name']='flood_sum'\n#flood_sum.attrs['units']='nounits'\n\n#s1_cube['flood_sum']= flood_sum\n\nflood_average.attrs['long_name']='flood_average'\nflood_average.attrs['units']='nounits'\n\ns1_cube['flood_average']= flood_average\n\nNow let’s plot the flood_average into a plot:\n\nflood_average.plot.imshow(cmap='GnBu', vmin=0, vmax=0.5, figsize=(10, 10))\nplt.show()\n\nThis looks great, we have identified the flood plain very clearly here and can also identify some areas that are more susceptible to flooding than others.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#creating-advanced-variables","position":25},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Export a variable to GeoTiff","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#export-a-variable-to-geotiff","position":26},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Export a variable to GeoTiff","lvl2":"Configuration"},"content":"Finally we will export some of the variables we have generated in this notebook. This is really easy to do and is shown in the next cell:\n\n# define the timestep you wish to export\ntimestep = flood_threshold2_step2.sel(time='2020-12-28 10:00:00', method='nearest')\n\n# define projection\ntimestep_wgs84 = timestep.rio.write_crs(\"epsg:4326\")\n\n# write to raster\ntimestep_wgs84.rio.to_raster(\"flood_extent_20201228.tif\")\n\nNow let’s export the flood_average variable which is even easier to do as we don’t need to select a single timestamp.\n\n# define projection\nflood_average_wgs84 = flood_average.rio.write_crs(\"epsg:4326\")\n\n# write to raster\nflood_average_wgs84.rio.to_raster(\"flood_average.tif\")\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#export-a-variable-to-geotiff","position":27},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Summary","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#summary","position":28},{"hierarchy":{"lvl1":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","lvl3":"Summary","lvl2":"Configuration"},"content":"So what have we learned through this post and accompanying notebook? We have learnt how to…\n\nCalculate and create a new variable.\n\nGenerate time series plots.\n\nCalculate advanced variables using time and space.\n\nExport our variables from the data cube to GeoTiff.\n\nI hope you have found this notebook interesting and useful in helping you make your first steps into using data cubes in your own work and workflows! Hopefully, I’ve also been able to make them a little less scary and easier to approach. I look forward to seeing you apply the lessons from here to your own applications!\n\nAnd that concludes this notebook in how you can use EDC to display, manipulate and and analyse Sentinel 1 data. We hope this has been useful in showing you what you can achieve using the EDC.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/exploring-time-and-space-with-edc#summary","position":29},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api","position":0},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API"},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api","position":1},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API"},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#how-to-access-dem-data-through-sentinel-hub-api","position":2},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API"},"content":"\n\nDEM (digital elevation model) is a 3D representation of the terrain’s surface created from terrain elevation data. DEM is mainly used for terrain analysis and orthorectification, which helps improve the accuracy of satellite imagery. Sentinel Hub API supports Mapzen DEM and Copernicus DEM as described in the \n\ndocumentation.\n\nMapzen DEM provides bare-earth terrain heights and is based on SRTM30 (Shuttle Radar Topography Mission). The \n\nCopernicus DEM represents the bare-earth surface and all above ground natural and built features and is derived from  \n\nWorldDEM™ DSM which is based on \n\nTanDEM-X mission data. Copernicus DEM data is available through Sentinel Hub API in two instances of 30m and 90m resolution.\n\nThis notebook demostrates how to access Corpenicus DEM and Mapzen DEM data on Euro Data Cube platform through Sentinel Hub API. This notebook runs on EDC EOxHub Workspace\n\nThe examples in this notebook are based on  \n\nsentinelhub python package documentation","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#how-to-access-dem-data-through-sentinel-hub-api","position":3},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Pre-requisites"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#pre-requisites","position":4},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Pre-requisites"},"content":"EOxHub Workspace subscription\n\nSentinel Hub subscription\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#pre-requisites","position":5},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Configuration"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#configuration","position":6},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Configuration"},"content":"To set up the workspace,first import the neccessary python libraries. These libraries are pre-installed in EOxHub Workspace. Additionally import environment variables which automatically includes Sentinel Hub credentials that will be used to configure Sentinel Hub API.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#configuration","position":7},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Imports","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#imports","position":8},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Imports","lvl2":"Configuration"},"content":"\n\n# EDC libraries\nfrom edc import setup_environment_variables\n\n# Utilities\nimport os\nimport matplotlib.pyplot as plt\nimport IPython.display\n\n# Sentinel Hub python package\nfrom sentinelhub import SHConfig, MimeType, CRS, BBox, SentinelHubRequest,DataCollection, bbox_to_dimensions\n\n# Configure plots for inline use in Jupyter Notebook\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#imports","position":9},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Credentials","lvl2":"Configuration"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#credentials","position":10},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Credentials","lvl2":"Configuration"},"content":"Sentinel Hub credentials SH_CLIENT_ID and SH_CLIENT_SECRET are already imported as envornment variables. In the next step pass the credentials to SHConfig() object\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#credentials","position":11},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Define area of interest (AOI)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#define-area-of-interest-aoi","position":12},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Define area of interest (AOI)"},"content":"AOI is defined by providing bounding box (longitude and latitude coordinates of lower left and upper right corners) and the corresponding coordinate reference system. AOI can also be defined as a polygon object as described in the \n\nAPI reference.In this example we define Betsiboka Estuary as the AOI.\n\n# define the bounding box\nbetsiboka_coords_wgs84 = [46.16, -16.15, 46.51, -15.58]\n# Plot the bounding box on a map\nIPython.display.GeoJSON(BBox(betsiboka_coords_wgs84,crs=CRS.WGS84).get_geojson())\n\n# Initialize the  BBox, an instance of sentinelhub BBox is required\nbetsiboka_bbox = BBox([46.16, -16.15, 46.51, -15.58], crs=CRS.WGS84)\n## bbox size\nbetsiboka_size = bbox_to_dimensions(betsiboka_bbox, resolution=30)      \nprint(betsiboka_size)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#define-area-of-interest-aoi","position":13},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Define time interval","lvl2":"Define area of interest (AOI)"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#define-time-interval","position":14},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Define time interval","lvl2":"Define area of interest (AOI)"},"content":"\n\ntime_interval=('2021-09-12', '2021-09-13')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#define-time-interval","position":15},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Request DEM"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#request-dem","position":16},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Request DEM"},"content":"To request DEM data through Sentinel Hub, we need to create a Process API request by setting data input parameters and an evalscript that determines what the process API returns. Lets start with Copernicus 30m  DEM.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#request-dem","position":17},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"1. Copernicus 30m  DEM","lvl2":"Request DEM"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#id-1-copernicus-30m-dem","position":18},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"1. Copernicus 30m  DEM","lvl2":"Request DEM"},"content":"\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#id-1-copernicus-30m-dem","position":19},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Evalscript","lvl2":"Request DEM"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#evalscript","position":20},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Evalscript","lvl2":"Request DEM"},"content":"We define an evalscript that returns the raw values of DEM band in FlOAT32 format as DEM values are in meters and can be negative for areas which lie below sea level.For more examples of evalscripts that return DEM in various formats, check \n\nExamples for DEM Sentinel Hub documentation  and \n\nDEM custom scripts examples.\n\nevalscript_orthometric_heights = \"\"\"\n  //VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output:{ \n      id: \"default\",\n      bands: 1, \n      sampleType: SampleType.FLOAT32\n    }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM]\n}\n\"\"\"\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#evalscript","position":21},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Request Payload","lvl2":"Request DEM"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#request-payload","position":22},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Request Payload","lvl2":"Request DEM"},"content":"In the payload, we specify the basic input parameters; the data collection, time interval, bbox . For the data collection, we specify DEM_COPERNICUS_30 to get 30 m resolution DEM. In the same way we can also specify DEM_COPERNICUS_90 for 90 m resolution DEM and  DEM_MAPZEN  for Mapzen DEM. The returned data is in form of numpy arrays\n\nrequest_orthometric_height = SentinelHubRequest(\n    data_folder='dem_dir',\n    evalscript=evalscript_orthometric_heights,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.DEM_COPERNICUS_30,\n            time_interval=time_interval # DEM is static data, does not depend on date\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.TIFF)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n\n## get dem data\ncopernicus_dem = request_orthometric_height.get_data()[0]\n\n## save dem data to disk (to the data_folder specified in the request payload)\nrequest_orthometric_height.save_data()\n\n## plot the dem\nplt.figure(figsize=(12,15))\nplt.imshow(copernicus_dem, cmap = 'Greys_r')\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#request-payload","position":23},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"2. Mapzen DEM","lvl2":"Request DEM"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#id-2-mapzen-dem","position":24},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"2. Mapzen DEM","lvl2":"Request DEM"},"content":"To access Mapzen DEM, specify data_collection=DataCollection.DEM_MAPZEN\n\nevalscript_orthometric_heights = \"\"\"\n//VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output:{ \n      id: \"default\",\n      bands: 1, \n      sampleType: SampleType.FLOAT32\n    }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM]\n}\n\"\"\"\nrequest_orthometric_height = SentinelHubRequest(\n    evalscript=evalscript_orthometric_heights,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.DEM_MAPZEN,\n            time_interval=time_interval # DEM is static data, does not depend on date\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.TIFF)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n## get dem data\nmapzen_dem = request_orthometric_height.get_data()[0]\n\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#id-2-mapzen-dem","position":25},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Plot Copernicus and Mapzen DEM","lvl2":"Request DEM"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#plot-copernicus-and-mapzen-dem","position":26},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"Plot Copernicus and Mapzen DEM","lvl2":"Request DEM"},"content":"\n\nfig, (ax, ax1) = plt.subplots(1,2, figsize=(12, 15))\nax.imshow(copernicus_dem, cmap=\"Greys_r\")\nax1.imshow(mapzen_dem, cmap=\"Greys_r\")\nax.set_title(\"Copernicus DEM\")\nax1.set_title(\"Mapzen DEM\")\nplt.show()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#plot-copernicus-and-mapzen-dem","position":27},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Color Visualisation"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#color-visualisation","position":28},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl2":"Color Visualisation"},"content":"In the next example, we define an evalscript that returns color visualisation of DEM band in the default UINT8 format.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#color-visualisation","position":29},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"3. Copernicus 90m  DEM","lvl2":"Color Visualisation"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#id-3-copernicus-90m-dem","position":30},{"hierarchy":{"lvl1":"How to access DEM data through Sentinel Hub API","lvl3":"3. Copernicus 90m  DEM","lvl2":"Color Visualisation"},"content":"The same color visualisation can be requested for DEM_COPERNICUS_30  and  DEM_MAPZEN  by adjusting the data_collection accordingly\n\nevalscript_colour_visualisation = \"\"\"\n  //VERSION=3\n\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output:{ \n      id: \"default\",\n      bands:3\n    }\n  }\n}\n\nfunction evaluatePixel(sample) {\nreturn colorBlend(sample.DEM, [-12000,-9000,-6000,-1000,-500,-200,-50,-20,-10,0,10,30,50,200,300,400,500,1000,3000,5000,7000,9000],\n[[0.000, 0.000, 0.157],\n[0.118, 0.000, 0.353],\n[0.118, 0.118, 0.471],\n[0.157, 0.196, 0.706],\n[0.235, 0.235, 0.902],\n[0.235, 0.314, 0.961],\n[0.353, 0.333, 0.980],\n[0.471, 0.471, 0.922],\n[0.627, 0.627, 1.000],\n[0.784, 0.784, 0.784],\n[0.392, 0.220, 0.235],\n[0.471, 0.180, 0.157],\n[0.549, 0.298, 0.157],\n[0.667, 0.376, 0.000],\n[0.471, 0.220, 0.353],\n[0.824, 0.573, 0.706],\n[0.549, 0.431, 0.000],\n[0.471, 0.549, 0.706],\n[0.627, 0.667, 0.941],\n[0.745, 0.784, 0.980],\n[0.863, 0.941, 1.000],\n[1.000, 1.000, 1.000]])\n}\n\"\"\"\n\nrequest_colour_visualisation = SentinelHubRequest(\n    evalscript=evalscript_colour_visualisation,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.DEM_COPERNICUS_90,\n            time_interval=time_interval # DEM is static data, does not depend on date\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n\n# get the dem\nvis_dem = request_colour_visualisation.get_data()[0]\n\n## plot the dem\nplt.figure(figsize=(10,15))\nplt.imshow(vis_dem)\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/how-to-access-dem-data-through-sentinel-hub-api#id-3-copernicus-90m-dem","position":31},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide."},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn","position":0},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide."},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn","position":1},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide."},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#using-eo-learn-in-edc-a-starters-guide","position":2},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide."},"content":"\n\nSource: \n\neo-learn Python package documentation","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#using-eo-learn-in-edc-a-starters-guide","position":3},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Getting started with eo-learn"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#getting-started-with-eo-learn","position":4},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Getting started with eo-learn"},"content":"eo-learn is a collection of open source Python packages that have been developed to seamlessly access and process spatio-temporal image sequences acquired by any satellite fleet in a timely and automatic manner. eo-learn is easy to use, it’s design modular, and encourages collaboration – sharing and reusing of specific tasks in a typical EO-value-extraction workflows, such as cloud masking, image co-registration, feature extraction, classification, etc.\n\neo-learn makes extraction of valuable information from satellite imagery as easy as defining a sequence of operations to be performed on satellite imagery. Image below illustrates a processing chain that maps water in satellite imagery by thresholding the Normalised Difference Water Index in user specified region of interest.\n\neo-learn acts as a bridge between Earth observation/Remote sensing field and Python ecosystem for data science and machine learning. The library is written in Python and uses NumPy arrays to store and handle remote sensing data. Its aim is to make entry easier for non-experts to the field of remote sensing on one hand and bring the state-of-the-art tools for computer vision, machine learning, and deep learning existing in Python ecosystem to remote sensing experts.\n\neo-learn is divided into several subpackages according to different functionalities and external package dependencies. Therefore it is not necessary for user to install entire package but only the parts that he needs.\n\nAt the moment there are the following subpackages:\n\neo-learn-core - The main subpackage which implements basic building blocks (EOPatch, EOTask and EOWorkflow) and commonly used functionalities.\n\neo-learn-coregistration - The subpackage that deals with image co-registraion.\n\neo-learn-features - A collection of utilities for extracting data properties and feature manipulation.\n\neo-learn-geometry - Geometry subpackage used for geometric transformation and conversion between vector and raster data.\n\neo-learn-io - Input/output subpackage that deals with obtaining data from Sentinel Hub services or saving and loading data locally.\n\neo-learn-mask - The subpackage used for masking of data and calculation of cloud masks.\n\neo-learn-ml-tools - Various tools that can be used before or after the machine learning process.\n\neo-learn-visualization - Visualization tools for core elements of eo-learn.","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#getting-started-with-eo-learn","position":5},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Outline"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#outline","position":6},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Outline"},"content":"In this demonstration Jupyter Notebook, based on the \n\nSpatio-Temporal Feature notebook, we will learn how to:\n\nCreate an EOWorkflow\n\nVisualize the EOPatch output from the EOWorkflow\n\nVALID_DATA mask\n\nCloud cover\n\nSpatiotemporal features of a specific field\n\nDistribution of temporal indices\n\nFalse color images of NDVI features\n\nLoad an existing EOPatch from a filesystem to build another EOWorkflow\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#outline","position":7},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Prerequisites"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#prerequisites","position":8},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Prerequisites"},"content":"Before starting to build our own processing chain for Earth Observation (EO) data, we need to import necessary Python libraries (already configured in your EDC workplace) and generate credentials automatically to access the services.\n\n# EDC libraries\n# from edc import setup_environment_variables\n\n# Utilities\nimport os\nimport warnings\nimport itertools as it\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import timedelta\nfrom matplotlib.colors import ListedColormap, BoundaryNorm\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\n# eo-learn\nfrom eolearn.core import (LoadTask, SaveTask, EONode, EOWorkflow, FeatureType, EOPatch, \n                          EOTask, ZipFeatureTask, OutputTask)\nfrom eolearn.io import SentinelHubInputTask\nfrom eolearn.features.ndi import NormalizedDifferenceIndexTask\nfrom eolearn.features.extra.interpolation import LinearInterpolationTask\n\n# Sentinel Hub\nfrom sentinelhub import BBox, CRS, DataCollection, SHConfig\n\n# Supress warnings for a neater notebook\nwarnings.filterwarnings(\"ignore\")\n\n# Add plot to the Jupyter Notebook\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#prerequisites","position":9},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Define required EOTask"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#define-required-eotask","position":10},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Define required EOTask"},"content":"In the following cell, we will create self-defined EOTasks which will be used in this example.\n\n# Define a task using ZipFeatureTask\nclass AddValidDataMaskTask(ZipFeatureTask):\n    def zip_method(self, *mask):\n        return np.logical_and(\n            mask[0].astype(bool), # 0 to False and 1 to True\n            np.logical_not((mask[1] != 0).astype(bool)) # CLM==1 or CLM==255 (clouds and no data) to False CLM==0 (clear) to True\n        )\n\nclass AddSpatioTemporalFeaturesTask(EOTask):\n    \"\"\"Task that implements and adds to eopatch the spatio-temporal features proposed in [1].\n\n    This task assumes that the argmax/argmin of NDVI, NDVI slope and B4 are present in eopatch. The computed\n    spatio-temporal features correspond to the concatenation of reflectance (green, red, near-infrared and short-wave\n    infrared in [1]) values taken at dates where:\n\n    1) NDVI is maximum\n    2) NDVI is minimum\n    3) red reflectances are maximum\n    4) NDVI slope is maximum\n    5) NDVI slope is minimum\n\n    The features are added to the `data_timeless` attribute dictionary of eopatch.\n\n    [1] Waldner et al. \"Automated annual cropland mapping using knowledge-based temporal features\", ISPRS Journal of\n    Photogrammetry and Remote Sensing, 2015\n\n    \"\"\"\n\n    def __init__(\n        self,\n        argmax_ndvi=\"ARGMAX_NDVI\",\n        argmin_ndvi=\"ARGMIN_NDVI\",\n        argmax_red=\"ARGMAX_B4\",\n        argmax_ndvi_slope=\"ARGMAX_NDVI_SLOPE\",\n        argmin_ndvi_slope=\"ARGMIN_NDVI_SLOPE\",\n        feats_feature=\"STF\",\n        data_feature=\"BANDS-S2-L1C\",\n        indices=None,\n    ):\n        \"\"\"Class constructor\n\n        Initialisation of task variables. The name of the dictionary keys that will be used for the computation of the\n        features needs to be specified. These features are assumed to be existing in the eopatch. The indices of the\n        reflectances to be used as features is an input parameter. If `None` is used, the data attribute is supposed to\n        have 13 bands and indices for green/red/infrared/short-wave-infrared are used.\n\n        :param argmax_ndvi: Name of `argmax_ndvi` feature in eopatch. Default is `'ARGMAX_NDVI'`\n        :param argmin_ndvi: Name of `argmin_ndvi` feature in eopatch. Default is `'ARGMIN_NDVI'`\n        :param argmax_red: Name of `argmax_red` feature in eopatch. Default is `'ARGMAX_B4'`\n        :param argmax_ndvi_slope: Name of `argmax_ndvi_slope` feature in eopatch. Default is `'ARGMAX_NDVI_SLOPE'`\n        :param argmin_ndvi_slope: Name of `argmin_ndvi_slope` feature in eopatch. Default is `'ARGMIN_NDVI_SLOPE'`\n        :param feats_feature: Name of feature containing spatio-temporal features. Default is `'STF'`\n        :param data_feature: Name of feature containing the reflectances to be used as features. Default is\n            `'BANDS-S2-L1C'`\n        :param indices: List of indices from `data_feature` to be used as features. Default is `None`, corresponding to\n            [2, 3, 7, 11] indices\n        \"\"\"\n        self.argmax_ndvi = argmax_ndvi\n        self.argmin_ndvi = argmin_ndvi\n        self.argmax_red = argmax_red\n        self.argmax_ndvi_slope = argmax_ndvi_slope\n        self.argmin_ndvi_slope = argmin_ndvi_slope\n        self.feats_feature = feats_feature\n        self.data_feature = data_feature\n        if indices is None:\n            indices = [2, 3, 7, 11]\n        self.indices = indices\n\n    def execute(self, eopatch: EOPatch) -> EOPatch:\n        \"\"\"Compute spatio-temporal features for input eopatch\n\n        :param eopatch: Input eopatch\n        :return: eopatch with computed spatio-temporal features\n        \"\"\"\n        # pylint: disable=invalid-name\n        amax_ndvi, amin_ndvi = eopatch.data_timeless[self.argmax_ndvi], eopatch.data_timeless[self.argmin_ndvi]\n        amax_ndvi_slope = eopatch.data_timeless[self.argmax_ndvi_slope]\n        amin_ndvi_slope = eopatch.data_timeless[self.argmin_ndvi_slope]\n        amax_red = eopatch.data_timeless[self.argmax_red]\n\n        stf_idx = [amax_ndvi, amin_ndvi, amax_ndvi_slope, amin_ndvi_slope, amax_red]\n\n        bands = eopatch.data[self.data_feature][..., self.indices]\n\n        _, h, w, _ = bands.shape\n        hh, ww = np.ogrid[:h, :w]\n        stf = np.concatenate([bands[ii.squeeze(), hh, ww] for ii in stf_idx if ii is not None], axis=-1)\n\n        eopatch.data_timeless[self.feats_feature] = stf\n\n        return eopatch\n\n\nclass AddMaxMinTemporalIndicesTask(EOTask):\n    \"\"\"Task to compute temporal indices of the maximum and minimum of a data feature\n\n    This class computes the `argmax` and `argmin` of a data feature in the input eopatch (e.g. NDVI, B4). The data\n    can be masked out by setting the `mask_data` flag to `True`. In that case, the `'VALID_DATA'` mask feature is\n    used for masking. If `mask_data` is `False`, the data is masked using the `'IS_DATA'` feature.\n\n    Two new features are added to the `data_timeless` attribute.\n    \"\"\"\n\n    def __init__(\n        self,\n        data_feature=\"NDVI\",\n        data_index=None,\n        amax_data_feature=\"ARGMAX_NDVI\",\n        amin_data_feature=\"ARGMIN_NDVI\",\n        mask_data=True,\n    ):\n        \"\"\"Task constructor\n\n        :param data_feature: Name of the feature in data used for computation of max/min. Default is `'NDVI'`\n        :param data_index: Index of to be extracted from last dimension in `data_feature`. If None, last dimension of\n            data array is assumed ot be of size 1 (e.g. as in NDVI). Default is `None`\n        :param amax_data_feature: Name of feature to be associated to computed feature of argmax values\n        :param amin_data_feature: Name of feature to be associated to computed feature of argmin values\n        :param mask_data: Flag specifying whether to mask data with `'VALID_DATA'` mask. If `False`, the `'IS_DATA'`\n            mask is used\n        \"\"\"\n        self.data_feature = data_feature\n        self.data_index = data_index\n        self.mask_data = mask_data\n        self.amax_feature = amax_data_feature\n        self.amin_feature = amin_data_feature\n\n    def execute(self, eopatch: EOPatch) -> EOPatch:\n        \"\"\"Compute argmax/argmin of specified `data_feature` and `data_index`\n\n        :param eopatch: Input eopatch\n        :return: eopatch with added argmax/argmin features\n        \"\"\"\n        valid_data_mask = eopatch.mask[\"VALID_DATA\"] if self.mask_data else eopatch.mask[\"IS_DATA\"]\n\n        data = (\n            eopatch.data[self.data_feature]\n            if self.data_index is None\n            else eopatch.data[self.data_feature][..., self.data_index][..., np.newaxis]\n        )\n\n        madata = np.ma.array(data, dtype=np.float32, mask=np.logical_or(~valid_data_mask.astype(bool), np.isnan(data)))\n\n        argmax_data = np.ma.MaskedArray.argmax(madata, axis=0)\n        argmin_data = np.ma.MaskedArray.argmin(madata, axis=0)\n\n        if argmax_data.ndim == 2:\n            argmax_data = argmax_data.reshape(argmax_data.shape + (1,))\n\n        if argmin_data.ndim == 2:\n            argmin_data = argmin_data.reshape(argmin_data.shape + (1,))\n\n        eopatch.data_timeless[self.amax_feature] = argmax_data\n        eopatch.data_timeless[self.amin_feature] = argmin_data\n\n        return eopatch\n\n\nclass AddMaxMinNDVISlopeIndicesTask(EOTask):\n    \"\"\"Task to compute the argmax and argmin of the NDVI slope\n\n    This task computes the slope of the NDVI feature using central differences. The NDVI feature can be masked using the\n    `'VALID_DATA'` mask. Current implementation loops through every location of eopatch, and is therefore slow.\n\n    The NDVI slope at date t is computed as $(NDVI_{t+1}-NDVI_{t-1})/(date_{t+1}-date_{t-1})$.\n    \"\"\"\n\n    def __init__(\n        self,\n        data_feature=\"NDVI\",\n        argmax_feature=\"ARGMAX_NDVI_SLOPE\",\n        argmin_feature=\"ARGMIN_NDVI_SLOPE\",\n        mask_data=True,\n    ):\n        \"\"\"Task constructor\n\n        :param data_feature: Name of data feature with NDVI values. Default is `'NDVI'`\n        :param argmax_feature: Name of feature with computed argmax values of the NDVI slope\n        :param argmin_feature: Name of feature with computed argmin values of the NDVI slope\n        :param mask_data: Flag for masking NDVI data. Default is `True`\n        \"\"\"\n        self.data_feature = data_feature\n        self.argmax_feature = argmax_feature\n        self.argmin_feature = argmin_feature\n        self.mask_data = mask_data\n\n    def execute(self, eopatch: EOPatch) -> EOPatch:\n        \"\"\"Computation of NDVI slope using finite central differences\n\n        This implementation loops through every spatial location, considers the valid NDVI values and approximates their\n        first order derivative using central differences. The argument of min and max is added to the eopatch.\n\n        The NDVI slope at date t is computed as $(NDVI_{t+1}-NDVI_{t-1})/(date_{t+1}-date_{t-1})$.\n\n        :param eopatch: Input eopatch\n        :return: eopatch with NDVI slope argmin/argmax features\n        \"\"\"\n        # pylint: disable=invalid-name\n        if self.mask_data:\n            valid_data_mask = eopatch.mask[\"VALID_DATA\"]\n        else:\n            valid_data_mask = eopatch.mask[\"IS_DATA\"]\n\n        ndvi = np.ma.array(eopatch.data[self.data_feature], dtype=np.float32, mask=~valid_data_mask.astype(bool))\n\n        all_dates = np.asarray([x.toordinal() for x in eopatch.timestamps])\n\n        if ndvi.ndim == 4:\n            h, w = ndvi.shape[1:3]\n        else:\n            raise ValueError(f\"{self.data_feature} feature has incorrect number of dimensions\")\n\n        argmax_ndvi_slope, argmin_ndvi_slope = np.zeros((h, w, 1), dtype=np.uint8), np.zeros((h, w, 1), dtype=np.uint8)\n\n        for ih, iw in it.product(range(h), range(w)):\n            ndvi_curve = ndvi[:, ih, iw, :]\n            valid_idx = np.where(~ndvi.mask[:, ih, iw])[0]\n\n            ndvi_curve = ndvi_curve[valid_idx]\n            valid_dates = all_dates[valid_idx]\n\n            ndvi_slope = np.convolve(ndvi_curve.squeeze(), [1, 0, -1], \"valid\") / np.convolve(\n                valid_dates, [1, 0, -1], \"valid\"\n            )\n\n            # +1 to compensate for the 'valid' convolution which eliminates first and last\n            argmax_ndvi_slope[ih, iw] = valid_idx[np.argmax(ndvi_slope) + 1]\n            argmin_ndvi_slope[ih, iw] = valid_idx[np.argmin(ndvi_slope) + 1]\n\n            del ndvi_curve, valid_idx, valid_dates, ndvi_slope\n\n        eopatch.data_timeless[self.argmax_feature] = argmax_ndvi_slope\n        eopatch.data_timeless[self.argmin_feature] = argmin_ndvi_slope\n\n        return eopatch\n\nQuick tip:\n\nSentinelHubInputTask(), NormalizedDifferenceIndexTask(), AddMaxMinTemporalIndicesTask(), AddMaxMinTemporalIndicesTask(), AddMaxMinNDVISlopeIndicesTask(), AddSpatioTemporalFeaturesTask(), SaveTask(), OutputTask are self-defined EOTasks performing the tasks listed above. You can also defined your own EOTask as shown below:class FooTask(EOTask):\n    def __init__(self, foo_param):\n        self.foo_param = foo_param\n        \n    def execute(self, eopatch, *, patch_specific_param):\n        # do what foo does on input eopatch and return it\n        return eopatch\n\nFor more detail and other pre-defined functions please refer to our eo-learn \n\ndocumentation.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#define-required-eotask","position":11},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl4":"Credentials","lvl2":"Define required EOTask"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#credentials","position":12},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl4":"Credentials","lvl2":"Define required EOTask"},"content":"Credentials for Sentinel Hub services are automatically injected as environement variables. It is therefore easy to populate Sentinel Hub’s credential manager with the values.\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#credentials","position":13},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Create an EOWorkflow"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#create-an-eoworkflow","position":14},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Create an EOWorkflow"},"content":"In the following cell, we will create an EOWorkflow implementing the spatiotemporal features proposed by Waldner et al., 2015 [1].\n\nThe workflow consists of:\n\na task to download Sentinel-2 data\n\na task to calculate NDVI\n\na task to generate valid data mask\n\na task to compute the argmax and argmin of NDVI\n\na task to compute the argmax and argmin of the red band\n\na task to compute the argmax and argmin of NDVI slope\n\na task to compute spatiotemporal features correspond to the concatenation of reflectance (green, red, NIR and SWIR) values taken at dates where:\n\nNDVI is maximum\n\nNDVI is minimum\n\nred reflectance are maximum\n\nNDVI slope is maximum\n\nNDVI slope is minimum\n\na task to save the given EOPatch to a filesystem\n\na task to keep the eo-patch in memory after the completion of the workflow\n\nAfter each task is defined as an EOTask, we can wrap EOTasks into EONodes and assemble all EONodes to form an EOWorkflow ready to be executed.\n\n[1] Waldner et al. “Automated Annual Cropland Mapping Using Knowledge-based Temporal Features”, 2015 ISPRS Journal of Photogrammetrz and Remote Sensing.\n\n# Define `EOTasks`\nadd_data_task = SentinelHubInputTask(\n    data_collection = DataCollection.SENTINEL2_L1C, \n    bands_feature=(FeatureType.DATA, 'BANDS-S2-L1C'),\n    time_difference = timedelta(hours=2),\n    resolution=20,\n    additional_data = [\n        (FeatureType.MASK, 'CLM'),\n        (FeatureType.MASK, 'dataMask', 'IS_DATA'), # assigning 'dataMask' band to 'IS_DATA'\n    ],\n    config=config\n)\n\nndvi_task = NormalizedDifferenceIndexTask(\n    input_feature=(FeatureType.DATA, 'BANDS-S2-L1C'),\n    output_feature=(FeatureType.DATA, 'NDVI'),\n    bands = [7,2]    \n)\n\nadd_valmask = AddValidDataMaskTask({FeatureType.MASK: ['IS_DATA', 'CLM']}, (FeatureType.MASK, 'VALID_DATA'))\n\nadd_maxmin_ndvi = AddMaxMinTemporalIndicesTask(mask_data=True)\n\nadd_maxmin_red = AddMaxMinTemporalIndicesTask(data_feature='BANDS-S2-L1C', \n                                              data_index=3, \n                                              amax_data_feature='ARGMAX_B4',\n                                              amin_data_feature='ARGMIN_B4',\n                                              mask_data=True)\n\nadd_maxmin_ndvi_sl = AddMaxMinNDVISlopeIndicesTask()\n\nadd_stf = AddSpatioTemporalFeaturesTask()\n\nsave_task = SaveTask('./stf', overwrite_permission=1, compress_level=0)\n\noutput_task = OutputTask(\"eopatch\")\n\nNext, we can wrap EOTasks into EONode, join all the EONodes together into an acyclic executable EOWorkflow, and visualize it with dependency_graph() function. Below demonstrates the most comprehensive way to build a EOWorkflow. Other simplified methods can be found in the \n\ndocumentation.\n\n# Wrap `EOTasks` into `EONode`\nadd_data_node = EONode(add_data_task, inputs=[], name=\"Sentinel Hub Input Task\")\nndvi_node = EONode(ndvi_task, inputs=[add_data_node], name=\"Compute NDVI Task\")\nadd_valmask_node = EONode(add_valmask, inputs=[ndvi_node], name=\"Add Valid Mask Task\")\nadd_maxmin_ndvi_node = EONode(add_maxmin_ndvi, inputs=[add_valmask_node], name=\"Add MaxMin NDVI Task\")\nadd_maxmin_red_node = EONode(add_maxmin_red, inputs=[add_maxmin_ndvi_node], name=\"Add ArgMaxMin Red Task\")\nadd_maxmin_ndvi_sl_node = EONode(add_maxmin_ndvi_sl, inputs=[add_maxmin_red_node], name=\"Add MaxMin NDVI Slope Task\")\nadd_stf_node = EONode(add_stf, inputs=[add_maxmin_ndvi_sl_node], name=\"Add Spatiotemporal Features Task\")\nsave_task_node = EONode(save_task, inputs=[add_stf_node], name=\"Save Task\")\noutput_node = EONode(output_task, inputs=[save_task_node], name=\"Output EOPatch\")\n\n# Assemble `EOTasks` to an `EOWorkflow`\nworkflow = EOWorkflow(\n    [\n        add_data_node,\n        ndvi_node,\n        add_valmask_node,\n        add_maxmin_ndvi_node,\n        add_maxmin_red_node,\n        add_maxmin_ndvi_sl_node,\n        add_stf_node,\n        save_task_node,\n        output_node\n    ]\n)\n\n\n# Visualize the `EOWorkflow`\nworkflow.dependency_graph()\n\nNow we need to define an area of interest and a time interval for the implementation of our EOWorkflow.\n\n# Define the area of interest and time interval\naoi_bbox = BBox(bbox=[5.60, 52.68, 5.75, 52.63], crs=CRS.WGS84)\ntime_interval = ('2017-04-01', '2017-10-31')\n\nFinally, we execute the workflow in the following cell.\n\nresult = workflow.execute({\n    add_data_node: {'bbox': aoi_bbox, 'time_interval': time_interval},\n    save_task_node: {'eopatch_folder': 'eopatch'}\n})\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#create-an-eoworkflow","position":15},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#visualize-the-eopatch-output-from-the-eoworkflow","position":16},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"content":"Once the EOWorkflow is run and done processing, we can open the result as an EOPatch. The following cell shows the way to open the results of an EOWorkflow as an EOPatch and the structure of EO data stored inside it.\n\n# Open data output from `EOWorkflow`\n# The key of outputs is defined by OutputTask()\neop = result.outputs[\"eopatch\"]\neop\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#visualize-the-eopatch-output-from-the-eoworkflow","position":17},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"VALID_DATA mask","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#valid-data-mask","position":18},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"VALID_DATA mask","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"content":"Below we visualize how a valid data mask is generated. \n\nZipFeatureTask allows us to feed in a self-defined formula that takes multiple inputs and returns a single output. In this Jupyter Notebook we define AddValidDataMaskTask() on the top of ZipFeatureTask to combine IS_DATA (taken from \n\ndataMask) and CLM (see \n\ndescription) to form the VALID_DATA mask. Pixel values are valid only if IS_DATA is True (there is data) and CLM is False (no clouds).\n\nts_idx = 5\n\nsubplot_kw = {'xticks': [], 'yticks': [], 'frame_on': True}\nfig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,5), subplot_kw=subplot_kw)\n\nax = axs[0]\nax.imshow(eop.mask['IS_DATA'][ts_idx].squeeze(), vmin=0, vmax=1, cmap='gray')\nax.set_title('IS_DATA')\n\nax = axs[1]\nax.imshow(eop.mask['CLM'][ts_idx].squeeze(),  vmin=0, vmax=1, cmap='gray')\nax.set_title('CLM')\n\nax = axs[2]\nim = ax.imshow(eop.mask['VALID_DATA'][ts_idx].squeeze(),\n               cmap=ListedColormap(['#000000', '#ffffff']), \n               norm=BoundaryNorm([-0.5, 0.5, 1.5], 2))\nax.set_title('VALID_DATA')\n\ncb = fig.colorbar(im, ax=axs.ravel().tolist(), orientation='horizontal', pad=0.05, aspect=100)\ncb.set_ticks([0,1])\ncb.ax.set_xticklabels([False, True], fontsize=12);\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#valid-data-mask","position":19},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"Cloud cover","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#cloud-cover","position":20},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"Cloud cover","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"content":"We can also calculate the cloud cover percentage and visualize its changes along the timestamps of data.\n\n# cloud coverage\ncc = [np.sum(x)/(np.prod(x.shape)) for x in eop.mask['CLM']]\n\nfix, ax = plt.subplots(1,1,figsize=(15,5))\nplt.plot(eop.timestamp, cc, '*--')\nplt.ylabel('Cloud coverage')\nplt.xlabel('Time')\nplt.title('Cloud coverage over an area in the Netherlands - 2017');\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#cloud-cover","position":21},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"Spatiotemporal features of a specific field","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#spatiotemporal-features-of-a-specific-field","position":22},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"Spatiotemporal features of a specific field","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"content":"If we’re looking into a specific field, it is easy to slice the field out of the EOPatch and visualize its NDVI variation thourghout the timestamps.\n\nfield_mask = (slice(None), slice(227, 241), slice(314,330))\nndvi_patch = eop.data['NDVI'][field_mask].squeeze(-1)\n\nfix, axs = plt.subplots(1,2,figsize=(20,8))\n\nax = axs[0]\nax.imshow(ndvi_patch[20])\nax.set_aspect('auto')\n\nax = axs[1]\nmean = np.mean(ndvi_patch, axis=(1,2))\nstd = np.std(ndvi_patch, axis=(1,2))\nax.plot(eop.timestamp, mean, color='g', label='NDVI')\nax.fill_between(eop.timestamp, mean-std, mean+std, alpha=0.2, color='g');\nax.set_aspect('auto')\n\nplt.legend(fontsize=15);\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#spatiotemporal-features-of-a-specific-field","position":23},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"Distribution of temporal indices","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#distribution-of-temporal-indices","position":24},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"Distribution of temporal indices","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"content":"In the following cell we visualize the distribution of temporal indices having the maximum or minimum values of NDVI features, which gives an overview on when most of the fields have maximum or minimum values of NDVI features.\n\nsubplot_kw = {'xticks': [], 'yticks': [], 'frame_on': True}\nfig, axs = plt.subplots(nrows = 2, ncols = 3, figsize=(20,8), subplot_kw = subplot_kw)\n\nax = axs[0,0]\nim = ax.imshow(eop.data_timeless['ARGMAX_NDVI'].squeeze())\nax.set_title(\"Temporal indices for argmax NDVI - no interpolation\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[0,1]\nim = ax.imshow(eop.data_timeless['ARGMIN_NDVI'].squeeze())\nax.set_title(\"Temporal indices for argmin NDVI - no interpolation\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[0,2]\nim = ax.imshow(eop.data_timeless['ARGMAX_NDVI_SLOPE'].squeeze())\nax.set_title(\"Temporal indices for argmax NDVI slope\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[1,1]\nim = ax.imshow(eop.data_timeless['ARGMIN_NDVI_SLOPE'].squeeze())\nax.set_title(\"Temporal indices for argmin NDVI slope\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[1,0]\nim = ax.imshow(eop.data_timeless['ARGMAX_B4'].squeeze())\nax.set_title(\"Temporal indices for argmax red\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[1,2]\nax.axis(False);\n\nplt.tight_layout()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#distribution-of-temporal-indices","position":25},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"False color images of NDVI features","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#false-color-images-of-ndvi-features","position":26},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl3":"False color images of NDVI features","lvl2":"Visualize the EOPatch output from the EOWorkflow"},"content":"Traditionally a combination of infrared-red-green false color image is useful for vegetation monitoring. Below we visualize the false color images of NDVI features to have an overview on vegetation changes during a crop cycle.\n\nsubplot_kw = {'xticks': [], 'yticks': [], 'frame_on': True}\nfig, axs = plt.subplots(nrows = 2, ncols = 3, figsize=(20,10), subplot_kw = subplot_kw)\n\nax = axs[0,0]\nax.imshow(np.clip(eop.data_timeless['STF'][:,:,[2,1,0]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmax NDVI\", fontsize=15)\n\nax = axs[0,1]\nax.imshow(np.clip(eop.data_timeless['STF'][:,:,[6,5,4]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmin NDVI\", fontsize=15)\n\nax = axs[0,2]\nax.imshow(np.clip(eop.data_timeless['STF'][:,:,[10,9,8]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmax NDVI slope\", fontsize=15)\n\nax = axs[1,1]\nax.imshow(np.clip(eop.data_timeless['STF'][:,:,[14,13,12]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmin NDVI slope\", fontsize=15)\n\nax = axs[1,0]\nax.imshow(np.clip(eop.data_timeless['STF'][:,:,[18,17,16]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmax red\", fontsize=15);\n\nax = axs[1,2]\nax.axis(False);\n\nplt.tight_layout()\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#false-color-images-of-ndvi-features","position":27},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Load an existing EOPatch from a filesystem to build another EOWorkflow"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#load-an-existing-eopatch-from-a-filesystem-to-build-another-eoworkflow","position":28},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Load an existing EOPatch from a filesystem to build another EOWorkflow"},"content":"In the previous processing chain, we calculated spatiotemporal indices via masking out invalid data which could lead to data gaps within the time interval. From a machine learning perspective, we train models to recognize features of indices’ temporal changes, meaning that data gaps should be avoided. One way to solve this problem is to create a homogenous temporal data-stack using interpolation. Since the changes of vegetation is usually a slow process over time, it is reasonable to implement a linear interpolation to fill up the missing data to make our data better for ML training. Here we will show how to build another EOWorkflow to implement interpolation before calculating spatiotemporal indices in a few steps:\n\nLoad the previously saved EOPatch\n\nDefine EOTasks implementing interpolation\n\nWrap EOTasks into EONodes\n\nBuild a new EOWorkflow from EONodes\n\n# Load existing `EOPatch`\nload_task = LoadTask('./stf/')\n\n# Define new `EOTasks`\ninterp_ndvi = LinearInterpolationTask((FeatureType.DATA, 'NDVI'), mask_feature=(FeatureType.MASK, 'VALID_DATA'))\n\ninterp_bands = LinearInterpolationTask((FeatureType.DATA, 'BANDS-S2-L1C'), mask_feature=(FeatureType.MASK, 'VALID_DATA'))\n\nadd_maxmin_ndvi = AddMaxMinTemporalIndicesTask(mask_data=False)\n\nadd_maxmin_red = AddMaxMinTemporalIndicesTask(data_feature='BANDS-S2-L1C', \n                                              data_index=3, \n                                              amax_data_feature='ARGMAX_B4',\n                                              amin_data_feature='ARGMIN_B4',\n                                              mask_data=False)\n\nadd_maxmin_ndvi_sl = AddMaxMinNDVISlopeIndicesTask()\n\nadd_stf = AddSpatioTemporalFeaturesTask()\n\noutput = OutputTask(\"interp_eopatch\")\n\n# Wrap `EOTasks` into `EONodes`\nload_node = EONode(load_task, inputs=[], name=\"Load EOPatch\")\ninterp_ndvi_node = EONode(interp_ndvi, inputs=[load_node], name=\"Interpolate NDVI Task\")\ninterp_bands_node = EONode(interp_bands, inputs=[interp_ndvi_node], name=\"Interpolate Bands Task\")\nadd_maxmin_ndvi_node = EONode(add_maxmin_ndvi, inputs=[interp_bands_node], name=\"Add MaxMin NDVI Task\")\nadd_maxmin_red_node = EONode(add_maxmin_red, inputs=[add_maxmin_ndvi_node], name=\"Add ArgMaxMin Red Task\")\nadd_maxmin_ndvi_sl_node = EONode(add_maxmin_ndvi_sl, inputs=[add_maxmin_red_node], name=\"Add MaxMin NDVI Slope Task\")\nadd_stf_node = EONode(add_stf, inputs=[add_maxmin_ndvi_sl_node], name=\"Add Spatiotemporal Features Task\")\noutput_node = EONode(output, inputs=[add_stf_node], name=\"Output Interpolated EOPatch\")\n\n# Assemble `EONodes` to an `EOWorkflow`\nworkflow_with_interp = EOWorkflow(\n    [\n        load_node,\n        interp_ndvi_node,\n        interp_bands_node,\n        add_maxmin_ndvi_node,\n        add_maxmin_red_node,\n        add_maxmin_ndvi_sl_node,\n        add_stf_node,\n        output_node\n    ]\n)\n\n# Visualize new `EOWorkflow`\nworkflow_with_interp.dependency_graph()\n\n# Execute new `EOWorkflow`\nresult_with_interp = workflow_with_interp.execute({\n    load_node: {'eopatch_folder':'eopatch'}\n})\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#load-an-existing-eopatch-from-a-filesystem-to-build-another-eoworkflow","position":29},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Visualize interpolated data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#visualize-interpolated-data","position":30},{"hierarchy":{"lvl1":"Using eo-learn in EDC: a starter’s guide.","lvl2":"Visualize interpolated data"},"content":"Again we can vasualize the interpolated data in the same way as demonstrated above and see how data gaps over time could affect on the features of indices’ temporal variation.\n\n# Open data output from `EOWorkflow`\neop_interp = result_with_interp.outputs[\"interp_eopatch\"]\neop_interp\n\n# Visualize spatiotemporal features of a specific field\nfield_mask = (slice(None), slice(227, 241), slice(314,330))\nndvi_patch = eop_interp.data['NDVI'][field_mask].squeeze(-1)\n\nfix, axs = plt.subplots(1,2,figsize=(20,8))\n\nax = axs[0]\nax.imshow(ndvi_patch[20])\nax.set_aspect('auto')\n\nax = axs[1]\nmean = np.mean(ndvi_patch, axis=(1,2))\nstd = np.std(ndvi_patch, axis=(1,2))\nax.plot(eop_interp.timestamp, mean, color='g', label='NDVI')\nax.fill_between(eop_interp.timestamp, mean-std, mean+std, alpha=0.2, color='g');\nax.set_aspect('auto')\n\nplt.legend(fontsize=15);\n\n# Distribution of temporal indices\nsubplot_kw = {'xticks': [], 'yticks': [], 'frame_on': True}\nfig, axs = plt.subplots(nrows = 2, ncols = 3, figsize=(20,8), subplot_kw = subplot_kw)\n\nax = axs[0,0]\nim = ax.imshow(eop_interp.data_timeless['ARGMAX_NDVI'].squeeze())\nax.set_title(\"Temporal indices for argmax NDVI\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[0,1]\nim = ax.imshow(eop_interp.data_timeless['ARGMIN_NDVI'].squeeze())\nax.set_title(\"Temporal indices for argmin NDVI\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[0,2]\nim = ax.imshow(eop_interp.data_timeless['ARGMAX_NDVI_SLOPE'].squeeze())\nax.set_title(\"Temporal indices for argmax NDVI slope\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[1,1]\nim = ax.imshow(eop_interp.data_timeless['ARGMIN_NDVI_SLOPE'].squeeze())\nax.set_title(\"Temporal indices for argmin NDVI slope\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[1,0]\nim = ax.imshow(eop_interp.data_timeless['ARGMAX_B4'].squeeze())\nax.set_title(\"Temporal indices for argmax red\", fontsize=15)\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"2%\", pad=0.05)\nfig.colorbar(im, cax=cax)\n\nax = axs[1,2]\nax.axis(False);\n\nplt.tight_layout()\n\n# False color images of NDVI features\nsubplot_kw = {'xticks': [], 'yticks': [], 'frame_on': True}\nfig, axs = plt.subplots(nrows = 2, ncols = 3, figsize=(20,10), subplot_kw = subplot_kw)\n\nax = axs[0,0]\nax.imshow(np.clip(eop_interp.data_timeless['STF'][:,:,[2,1,0]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmax NDVI\", fontsize=15)\n\nax = axs[0,1]\nax.imshow(np.clip(eop_interp.data_timeless['STF'][:,:,[6,5,4]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmin NDVI\", fontsize=15)\n\nax = axs[0,2]\nax.imshow(np.clip(eop_interp.data_timeless['STF'][:,:,[10,9,8]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmax NDVI slope\", fontsize=15)\n\nax = axs[1,1]\nax.imshow(np.clip(eop_interp.data_timeless['STF'][:,:,[14,13,12]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmin NDVI slope\", fontsize=15)\n\nax = axs[1,0]\nax.imshow(np.clip(eop_interp.data_timeless['STF'][:,:,[18,17,16]], 0, 1))\nax.set_title(\"IR-R-G reflectances for argmax red\", fontsize=15);\n\nax = axs[1,2]\nax.axis(False);\n\nplt.tight_layout()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/eo-learn#visualize-interpolated-data","position":31},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide."},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py","position":0},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide."},"content":"from edc import check_compatibility\ncheck_compatibility(\"user-2023.10-01\", dependencies=[\"SH\"])\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py","position":1},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide."},"type":"lvl1","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#using-sentinel-hub-process-api-in-edc-a-starters-guide","position":2},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide."},"content":"\n\nSource: \n\nSentinel Hub Python package documentation","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#using-sentinel-hub-process-api-in-edc-a-starters-guide","position":3},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Getting started with sentinelhub-py"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#getting-started-with-sentinelhub-py","position":4},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Getting started with sentinelhub-py"},"content":"In this demonstration Jupyter Notebook, we will be requesting and exporting analysis-ready Earth Observation data with the Sentinel Hub \n\nProcess API using the dedicated \n\nsentinelhub-py package in the EDC EOxHub Workplace. In this notebook we will learn how to:\n\nRequest a true color (PNG) image on a specific date\n\nAdd cloud mask data to the request\n\nRequest a true color mosaic of least cloudy acquisitions\n\nRequest all Sentinel-2’s raw band values\n\nSave downloaded data to disk and read it from disk\n\nSave downloaded data directly to disk\n\nRequest other data collections supported by sentinelhub-py\n\nPerform a multi-response request\n\nRequest with a raw dictionary\n\nRequest multiple timestamps data\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#getting-started-with-sentinelhub-py","position":5},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Prerequisites"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#prerequisites","position":6},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Prerequisites"},"content":"Before acccessing the data, we will start by importing the necessary Python libraries (already configured in your EDC workspace), generate credentials automatically to access the services and define the plot_image function that can be found in the utils.py \n\nfile located in Sentinel Hub’s \n\nGitHub repository.\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#prerequisites","position":7},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl4":"Imports","lvl2":"Prerequisites"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#imports","position":8},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl4":"Imports","lvl2":"Prerequisites"},"content":"\n\n# EDC libraries\nfrom edc import setup_environment_variables\n\n# Utilities\nimport os\nimport datetime\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Image\n\n# Sentinel Hub\nfrom sentinelhub import (MimeType, CRS, BBox, SentinelHubRequest, SentinelHubDownloadClient, \n                         DataCollection, bbox_to_dimensions, DownloadRequest, SHConfig)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#imports","position":9},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl4":"Credentials","lvl2":"Prerequisites"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#credentials","position":10},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl4":"Credentials","lvl2":"Prerequisites"},"content":"Credentials for Sentinel Hub services are automatically injected as environement variables. It is therefore easy to populate Sentinel Hub’s credential manager with the values.\n\n# Pass Sentinel Hub credentials to SHConfig\nconfig = SHConfig()\nconfig.sh_client_id = os.environ[\"SH_CLIENT_ID\"]\nconfig.sh_client_secret = os.environ[\"SH_CLIENT_SECRET\"]\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#credentials","position":11},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl4":"Utility function for plotting images","lvl2":"Prerequisites"},"type":"lvl4","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#utility-function-for-plotting-images","position":12},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl4":"Utility function for plotting images","lvl2":"Prerequisites"},"content":"In the following cell, we define the plot_image function which will be used to display the requested images for all examples demonstrated in this notebook.\n\n# Define the plot_image function\ndef plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    \"\"\"\n    Utility function for plotting RGB images.\n    \"\"\"\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n# Configure plots for inline use in Jupyter Notebook\n%matplotlib inline\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#utility-function-for-plotting-images","position":13},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Setting area of interest (AOI)"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#setting-area-of-interest-aoi","position":14},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Setting area of interest (AOI)"},"content":"We will download Sentinel-2 imagery of \n\nBetsiboka Estuary such as the one shown below (taken by Sentinel-2 on 2017-12-15):\n\n\n\nThe bounding box in WGS84 coordinate system is [46.16, -16.15, 46.51, -15.58] (longitude and latitude coordinates of lower left and upper right corners). You can get the bbox for a different area at the \n\nbboxfinder website.\n\nAll requests require bounding box to be given as an instance of sentinelhub.geometry.BBox with corresponding Coordinate Reference System (sentinelhub.constants.CRS). In our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from sentinelhub.constants.CRS.\n\nbetsiboka_coords_wgs84 = [46.16, -16.15, 46.51, -15.58]\n\nWhen the bounding box bounds have been defined, you can initialize the BBox of the area of interest. Using the bbox_to_dimensions utility function, you can provide the desired resolution parameter of the image in meters and obtain the output image shape.\n\nresolution = 60\nbetsiboka_bbox = BBox(bbox=betsiboka_coords_wgs84, crs=CRS.WGS84)\nbetsiboka_size = bbox_to_dimensions(betsiboka_bbox, resolution=resolution)\n\nprint(f'Image shape at {resolution} m resolution: {betsiboka_size} pixels')\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#setting-area-of-interest-aoi","position":15},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 1: Request a true color (PNG) image on a specific date"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-1-request-a-true-color-png-image-on-a-specific-date","position":16},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 1: Request a true color (PNG) image on a specific date"},"content":"We build the request according to the \n\nAPI Reference, using the SentinelHubRequest class. Each Process API request also needs an \n\nevalscript.\n\nThe information that we specify in the SentinelHubRequest object is:\n\nan evalscript,\n\na list of input data collections with time interval,\n\na format of the response,\n\na bounding box and it’s size (size or resolution).\n\nThe evalscript in the example is used to select the appropriate bands. We return the RGB (B04, B03, B02) Sentinel-2 L1C bands.\n\nThe image from Jun 12th 2020 is downloaded. Without any additional parameters in the evalscript, the downloaded data will correspond to reflectance values in UINT8 format (values in 0-255 range).\n\nevalscript_true_color = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"]\n            }],\n            output: {\n                bands: 3\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=('2020-06-12', '2020-06-13'),\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n\ntrue_color_imgs = request_true_color.get_data()\n\nThe method get_data() will always return a list of length 1 with the available image from the requested time interval in the form of numpy arrays.\n\nprint(f'Returned data is of type = {type(true_color_imgs)} and length {len(true_color_imgs)}.')\nprint(f'Single element in the list is of type {type(true_color_imgs[-1])} and has shape {true_color_imgs[-1].shape}')\n\nimage = true_color_imgs[0]\nprint(f'Image type: {image.dtype}')\n\n# plot function\n# factor 1/255 to scale between 0-1\n# factor 3.5 to increase brightness\nplot_image(image, factor=3.5/255, clip_range=(0,1))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-1-request-a-true-color-png-image-on-a-specific-date","position":17},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl3":"Example 1.1 Adding cloud mask data","lvl2":"Example 1: Request a true color (PNG) image on a specific date"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-1-1-adding-cloud-mask-data","position":18},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl3":"Example 1.1 Adding cloud mask data","lvl2":"Example 1: Request a true color (PNG) image on a specific date"},"content":"It is also possible to obtain cloud masks when requesting Sentinel-2 data by using the cloud mask band (CLM) or the cloud probabilities band (CLP). More info \n\nhere.\n\nThe factor for increasing the image brightness can already be provided in the evalscript.\n\nevalscript_clm = \"\"\"\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"B02\", \"B03\", \"B04\", \"CLM\"],\n    output: { bands: 3 }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  if (sample.CLM == 1) {\n    return [0.75 + sample.B04, sample.B03, sample.B02]\n  }\n  return [3.5*sample.B04, 3.5*sample.B03, 3.5*sample.B02];\n}\n\"\"\"\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_clm,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=('2020-06-12', '2020-06-13'),\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n\ndata_with_cloud_mask = request_true_color.get_data()\n\nplot_image(data_with_cloud_mask[0], factor=1/255)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-1-1-adding-cloud-mask-data","position":19},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 2: Request a true color mosaic of least cloudy acquisitions"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-2-request-a-true-color-mosaic-of-least-cloudy-acquisitions","position":20},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 2: Request a true color mosaic of least cloudy acquisitions"},"content":"The SentinelHubRequest automatically creates a mosaic from all available images in the given time interval. By default, the mostRecent mosaicking order is used. More information available \n\nhere.\n\nIn this example we will provide a month long interval, order the images w.r.t. the cloud coverage on the tile level (leastCC parameter), and mosaic them in the specified order.\n\nrequest_true_color = SentinelHubRequest(\n    evalscript=evalscript_true_color,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=('2020-06-01', '2020-06-30'),\n            mosaicking_order='leastCC'\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.PNG)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n\nplot_image(request_true_color.get_data()[0], factor=3.5/255, clip_range=(0,1))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-2-request-a-true-color-mosaic-of-least-cloudy-acquisitions","position":21},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 3: Request all Sentinel-2’s raw band values"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-3-request-all-sentinel-2s-raw-band-values","position":22},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 3: Request all Sentinel-2’s raw band values"},"content":"Now let’s define an evalscript which will return all Sentinel-2 spectral bands with raw values.\n\nIn this example we are downloading already quite a big chunk of data, so optimization of the request is not out of the question. Downloading raw digital numbers in the INT16 format instead of reflectances in the FLOAT32 format means that much less data is downloaded, which results in a faster download and a smaller usage of SH processing units.\n\nIn order to achieve this, we have to set the input units in the evalscript to DN (digital numbers) and the output sampleType argument to INT16. Additionally, we can’t pack all Sentinel-2’s 13 bands into a PNG image, so we have to set the output image type to the TIFF format via MimeType.TIFF in the request.\n\nThe digital numbers are in the range from 0-10000, so we have to scale the downloaded data appropriately.\n\nevalscript_all_bands = \"\"\"\n    //VERSION=3\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\"B07\",\"B08\",\"B8A\",\"B09\",\"B10\",\"B11\",\"B12\"],\n                units: \"DN\"\n            }],\n            output: {\n                bands: 13,\n                sampleType: \"INT16\"\n            }\n        };\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B01,\n                sample.B02,\n                sample.B03,\n                sample.B04,\n                sample.B05,\n                sample.B06,\n                sample.B07,\n                sample.B08,\n                sample.B8A,\n                sample.B09,\n                sample.B10,\n                sample.B11,\n                sample.B12];\n    }\n\"\"\"\n\nrequest_all_bands = SentinelHubRequest(\n    evalscript=evalscript_all_bands,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=('2020-06-01', '2020-06-30'),\n            mosaicking_order='leastCC'\n    )],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.TIFF)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n\nall_bands_response = request_all_bands.get_data()\n\n# Image showing the SWIR band B12\n# Factor 1/1e4 due to the DN band values in the range 0-10000\n# Factor 3.5 to increase the brightness\nplot_image(all_bands_response[0][:, :, 12], factor=3.5/1e4, vmax=1)\n\n# From raw bands we can also construct a False-Color image\n# False color image is (B03, B04, B08)\nplot_image(all_bands_response[0][:, :, [2,3,7]], factor=3.5/1e4, clip_range=(0,1))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-3-request-all-sentinel-2s-raw-band-values","position":23},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 4: Save downloaded data to disk and read it from disk"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-4-save-downloaded-data-to-disk-and-read-it-from-disk","position":24},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 4: Save downloaded data to disk and read it from disk"},"content":"All downloaded data can be saved to disk and later read from it. Simply specify the location on disk where data should be saved (or loaded from) via the data_folder argument of the request’s constructor. When executing the request’s get_data method, set the argument save_data to True.\n\nThis also means that in all the future requests for data, the request will first check the provided location if the data is already there, unless you explicitly demand to redownload the data.\n\nrequest_all_bands = SentinelHubRequest(\n    data_folder='test_dir',\n    evalscript=evalscript_all_bands,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=('2020-06-01', '2020-06-30'),\n            mosaicking_order='leastCC'\n    )],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.TIFF)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n\n%%time\nall_bands_img = request_all_bands.get_data(save_data=True)\n\nprint(f'The output directory has been created and a tiff file with all 13 bands was saved into ' \\\n      'the following structure:\\n')\n\nfor folder, _, filenames in os.walk(request_all_bands.data_folder):\n    for filename in filenames:\n        print(os.path.join(folder, filename))\n\n%%time\n# try to re-download the data\nall_bands_img_from_disk = request_all_bands.get_data()\n\n%%time\n# force the redownload\nall_bands_img_redownload = request_all_bands.get_data(redownload=True)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-4-save-downloaded-data-to-disk-and-read-it-from-disk","position":25},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl3":"Example 4.1: Save downloaded data directly to disk","lvl2":"Example 4: Save downloaded data to disk and read it from disk"},"type":"lvl3","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-4-1-save-downloaded-data-directly-to-disk","position":26},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl3":"Example 4.1: Save downloaded data directly to disk","lvl2":"Example 4: Save downloaded data to disk and read it from disk"},"content":"The get_data method returns a list of numpy arrays and can save the downloaded data to disk, as we have seen in the previous example. Sometimes it is convenient to just save the data directly to disk. You can do that by using save_data method instead.\n\n%%time\nrequest_all_bands.save_data()\n\nprint(f'The output directory has been created and a tiff file with all 13 bands was saved into ' \\\n      'the following structure:\\n')\n\nfor folder, _, filenames in os.walk(request_all_bands.data_folder):\n    for filename in filenames:\n        print(os.path.join(folder, filename))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-4-1-save-downloaded-data-directly-to-disk","position":27},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 5: Request other data collections supported by sh-py"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-5-request-other-data-collections-supported-by-sh-py","position":28},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 5: Request other data collections supported by sh-py"},"content":"The sentinelhub-py package supports various data collections. The example below is shown for one of them, but the process is the same for all of them.\n\nNote: For more examples and information check the \n\ntutorial about data collections and \n\nSentinel Hub documentation about data collections.\n\nprint('Supported DataCollections:\\n')\nfor collection in DataCollection.get_available_collections():\n    print(collection)\n\nFor this example let’s download the digital elevation model data (DEM). The process is similar as before, we just provide the evalscript and create the request. More data on the DEM data collection is available \n\nhere. DEM values are in meters and can be negative for areas which lie below sea level, so it is recommended to set the output format in your evalscript to FLOAT32.\n\nevalscript_dem = '''\n//VERSION=3\nfunction setup() {\n  return {\n    input: [\"DEM\"],\n    output:{\n      id: \"default\",\n      bands: 1,\n      sampleType: SampleType.FLOAT32\n    }\n  }\n}\n\nfunction evaluatePixel(sample) {\n  return [sample.DEM]\n}\n'''\n\ndem_request = SentinelHubRequest(\n    evalscript=evalscript_dem,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.DEM,\n            time_interval=('2020-06-12', '2020-06-13'),\n    )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.TIFF)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n\ndem_data = dem_request.get_data()\n\n# Plot DEM map\n# vmin = 0; cutoff at sea level (0 m)\n# vmax = 120; cutoff at high values (120 m)\nplot_image(dem_data[0], factor=1.0, cmap=plt.cm.Greys_r, vmin=0, vmax=120)\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-5-request-other-data-collections-supported-by-sh-py","position":29},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 6: Multi-response request"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-6-multi-response-request","position":30},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 6: Multi-response request"},"content":"Process API enables downloading multiple files in one response, packed together in a TAR archive.\n\nWe will get the same image as before, download in the form of digital numbers (DN) as a UINT16 TIFF file. Along with the image we will download the inputMetadata which contains the normalization factor value in a JSON format.\n\nAfter the download we will be able to convert the INT16 digital numbers to get the FLOAT32 reflectances.\n\nevalscript = \"\"\"\n    //VERSION=3\n\n    function setup() {\n        return {\n            input: [{\n                bands: [\"B02\", \"B03\", \"B04\"],\n                units: \"DN\"\n            }],\n            output: {\n                bands: 3,\n                sampleType: \"INT16\"\n            }\n        };\n    }\n\n    function updateOutputMetadata(scenes, inputMetadata, outputMetadata) {\n        outputMetadata.userData = { \"norm_factor\":  inputMetadata.normalizationFactor }\n    }\n\n    function evaluatePixel(sample) {\n        return [sample.B04, sample.B03, sample.B02];\n    }\n\"\"\"\n\nrequest_multitype = SentinelHubRequest(\n    evalscript=evalscript,\n    input_data=[\n        SentinelHubRequest.input_data(\n            data_collection=DataCollection.SENTINEL2_L1C,\n            time_interval=('2020-06-01', '2020-06-30'),\n            mosaicking_order='leastCC'\n        )\n    ],\n    responses=[\n        SentinelHubRequest.output_response('default', MimeType.TIFF),\n        SentinelHubRequest.output_response('userdata', MimeType.JSON)\n    ],\n    bbox=betsiboka_bbox,\n    size=betsiboka_size,\n    config=config\n)\n\n# print out information\nmulti_data = request_multitype.get_data()[0]\nmulti_data.keys()\n\n# normalize image\nimg = multi_data['default.tif']\nnorm_factor = multi_data['userdata.json']['norm_factor']\n\nimg_float32 = img * norm_factor\n\nplot_image(img_float32, factor=3.5, clip_range=(0, 1))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-6-multi-response-request","position":31},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 7: Request with a raw dictionary"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-7-request-with-a-raw-dictionary","position":32},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 7: Request with a raw dictionary"},"content":"All requests so far were built with some helper functions. We can also construct a raw dictionary as defined in the \n\nAPI Reference, without these helper functions, so we have full control over building the request body.\n\nrequest_raw_dict = {\n    \"input\": {\n        \"bounds\": {\n            \"properties\": {\n                \"crs\": betsiboka_bbox.crs.opengis_string\n            },\n            \"bbox\": list(betsiboka_bbox)\n        },\n        \"data\": [\n            {\n                \"type\": \"S2L1C\",\n                \"dataFilter\": {\n                    \"timeRange\": {\"from\": '2020-06-01T00:00:00Z', \"to\": '2020-06-30T00:00:00Z'},\n                    \"mosaickingOrder\": \"leastCC\",\n                }\n            }\n        ]\n    },\n    \"output\": {\n        \"width\": betsiboka_size[0],\n        \"height\": betsiboka_size[1],\n        \"responses\": [\n            {\n                \"identifier\": \"default\",\n                \"format\": {\n                    'type': MimeType.TIFF.get_string()\n                }\n            }\n        ]\n    },\n    \"evalscript\": evalscript_true_color\n}\n\n# create request\ndownload_request = DownloadRequest(\n    request_type='POST',\n    url=\"https://services.sentinel-hub.com/api/v1/process\",\n    post_values=request_raw_dict,\n    data_type=MimeType.TIFF,\n    headers={'content-type': 'application/json'},\n    use_session=True\n)\n\n# execute request\nclient = SentinelHubDownloadClient(config=config)\nimg = client.download(download_request)\n\nplot_image(img, factor=3.5/255, clip_range=(0,1))\n\n","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-7-request-with-a-raw-dictionary","position":33},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 8: Request multiple timestamps data"},"type":"lvl2","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-8-request-multiple-timestamps-data","position":34},{"hierarchy":{"lvl1":"Using Sentinel Hub Process API in EDC: a starter’s guide.","lvl2":"Example 8: Request multiple timestamps data"},"content":"It is possible to construct some logic in order to return data for multiple timestamps. By defining the time_interval parameter and some logic of splitting it, it is possible to create an SH reques per each “time slot” and then download the data from all the requests with the SentinelHubDownloadClient in sentinelhub-py. In this example we will create least cloudy monthly images for the year 2019.\n\nHowever, this is already a functionality built on top of this SH API package. We have extended the support for such usage in our package \n\neo-learn. We recommend to use eo-learn for more complex cases where you need multiple timestamps or high-resolution data for larger areas.\n\nstart = datetime.datetime(2019,1,1)\nend = datetime.datetime(2019,12,31)\nn_chunks = 13\ntdelta = (end - start) / n_chunks\nedges = [(start + i*tdelta).date().isoformat() for i in range(n_chunks)]\nslots = [(edges[i], edges[i+1]) for i in range(len(edges)-1)]\n\nprint('Monthly time windows:\\n')\nfor slot in slots:\n    print(slot)\n\ndef get_true_color_request(time_interval):\n    return SentinelHubRequest(\n        evalscript=evalscript_true_color,\n        input_data=[\n            SentinelHubRequest.input_data(\n                data_collection=DataCollection.SENTINEL2_L1C,\n                time_interval=time_interval,\n                mosaicking_order='leastCC'\n            )\n        ],\n        responses=[\n            SentinelHubRequest.output_response('default', MimeType.PNG)\n        ],\n        bbox=betsiboka_bbox,\n        size=betsiboka_size,\n        config=config\n    )\n\n# create a list of requests\nlist_of_requests = [get_true_color_request(slot) for slot in slots]\nlist_of_requests = [request.download_list[0] for request in list_of_requests]\n\n# download data with multiple threads\ndata = SentinelHubDownloadClient(config=config).download(list_of_requests, max_threads=5)\n\n# some stuff for pretty plots\nncols = 4\nnrows = 3\naspect_ratio = betsiboka_size[0] / betsiboka_size[1]\nsubplot_kw = {'xticks': [], 'yticks': [], 'frame_on': False}\n\nfig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(5 * ncols * aspect_ratio, 5 * nrows),\n                        subplot_kw=subplot_kw)\n\nfor idx, image in enumerate(data):\n    ax = axs[idx // ncols][idx % ncols]\n    ax.imshow(np.clip(image * 2.5/255, 0, 1))\n    ax.set_title(f'{slots[idx][0]}  -  {slots[idx][1]}', fontsize=10)\n\nplt.tight_layout()","type":"content","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/sentinelhub-py#example-8-request-multiple-timestamps-data","position":35},{"hierarchy":{"lvl1":"📘 Example Notebook 1"},"type":"lvl1","url":"/notebooks/example1","position":0},{"hierarchy":{"lvl1":"📘 Example Notebook 1"},"content":"This is a test notebook for Jupyter Book.\n\nprint(\"Hello, Jupyter Book!\")","type":"content","url":"/notebooks/example1","position":1},{"hierarchy":{"lvl1":"📘 Example Notebook 2"},"type":"lvl1","url":"/notebooks/example2","position":0},{"hierarchy":{"lvl1":"📘 Example Notebook 2"},"content":"This is a test notebook for Jupyter Book.\n\nprint(\"Hello, Jupyter Book 2!\")","type":"content","url":"/notebooks/example2","position":1}]}